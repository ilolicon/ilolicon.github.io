[{"content":"简要介绍 model-context-protocol\nmcp-intro\nModel Context Protocol\n模型 上下文 协议\n用途 MCP Host 支持MCP协议的软件 比如： Claude Code Cursor Cline Gemini Cli \u0026hellip; MCP Server 和 Tool MCP Server(MCP服务器) 不是传统意义上的服务器 本质就是一个程序，程序执行符合MCP协议，内置了一些功能模块解决对应问题 功能模块 在MCP领域内叫：Tool(函数) 大部分MCP Server都是在本地通过Python或Node启动 weather-mcp-server\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package tools import ( \u0026#34;github.com/mark3labs/mcp-go/mcp\u0026#34; \u0026#34;github.com/mark3labs/mcp-go/server\u0026#34; \u0026#34;github.com/ezh0v/weather-mcp-server/internal/server/handlers\u0026#34; \u0026#34;github.com/ezh0v/weather-mcp-server/internal/server/services\u0026#34; ) func CurrentWeather(svc services.Services) (mcp.Tool, server.ToolHandlerFunc) { tool := mcp.NewTool(\u0026#34;current_weather\u0026#34;, mcp.WithDescription(` The service retrieves the current weather for a specified city and returns only HTML and CSS code designed for displaying weather information directly on a canvas. No additional comments should be included after the response. It processes the city\u0026#39;s name, gathers weather data such as temperature, humidity, wind speed, and general weather conditions, and then generates a structured HTML layout along with appropriate CSS styles. This HTML must be rendered visually on the canvas. After receiving the response, the text inside the HTML should be translated into the language of the request. `), mcp.WithString(\u0026#34;city\u0026#34;, mcp.Required(), mcp.Description(` The name of the city. This field is required and must be provided in English. Only one city is allowed, and it must be the last one provided by the user. `), ), ) handler := handlers.CurrentWeather(svc) return tool, handler } MCP交互流程详解 ","date":"2025-10-10T09:10:16+08:00","permalink":"https://ilolicon.github.io/p/mcp/","title":"MCP"},{"content":"Go 泛型终极指南：定义与最佳实践 本文档旨在为熟悉 Go 语言但尚未使用过泛型的开发者提供一份详尽的泛型学习指南。我们将从基本定义入手，深入探讨语法细节，并总结出社区公认的最佳实践，帮助您在项目中优雅、高效地运用泛型。\n什么是 Go 泛型？ Go 泛型（Generics）是 Go 1.18 版本引入的一个重要特性，它允许我们编写能够处理多种数据类型的函数和数据结构，而无需为每种类型都编写重复的代码。通过泛型，我们可以定义带有类型参数（Type Parameters）的函数或类型，这些类型参数在编译时会被具体的类型替换。\n泛型的核心优势在于：\n代码复用：编写一次，即可用于多种类型。 类型安全：在编译期进行类型检查，避免了使用 interface{} 时可能出现的运行时类型断言失败。 性能：避免了因使用 interface{} 和反射而带来的性能开销。 官方链接: An Introduction to Generics - go.dev\n为什么需要泛型？ 在泛型出现之前，为了编写处理不同类型的通用代码，通常有两种方式：\n为每种类型编写一份代码：这会导致大量的代码重复，难以维护。 使用接口 (interface{}) 和反射：虽然灵活，但牺牲了编译期的类型安全，且通常伴随着性能损耗。 泛型通过在编译期进行类型检查和代码生成，完美地解决了上述问题，让我们能够编写出既通用又安全高效的代码。\n泛型语法核心 Go 泛型的语法主要围绕类型参数和类型约束展开。\n类型参数 (Type Parameters) 类型参数是泛型的核心，它充当一个未指定类型的占位符。类型参数列表定义在函数名或类型名后的方括号 [] 中。\n1 2 3 func PrintSlice[T any](s []T) { // ... } T 就是一个类型参数。 any 是一个类型约束，表示 T 可以是任何类型。 类型约束 (Type Constraints) 类型约束定义了类型参数可以接受的类型范围。它本质上是一个接口类型，规定了类型参数必须满足的条件（例如，必须实现某些方法或支持某些操作）。\n1 2 3 4 5 6 7 8 9 // 一个简单的约束，要求类型支持 + 操作 type Number interface { int | int64 | float64 } // SumNumbers 函数的类型参数 T 必须满足 Number 约束 func SumNumbers[T Number](nums []T) T { // ... } 官方链接: Tutorial: Getting started with generics - go.dev\n泛型函数 泛型函数是指定义了类型参数的函数。\n示例：一个通用的 Sum 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import \u0026#34;fmt\u0026#34; // Number 约束允许整数和浮点数类型 type Number interface { int | int64 | float32 | float64 } // Sum 计算一个切片中所有元素的和 func Sum[T Number](s []T) T { var total T for _, v := range s { total += v } return total } func main() { intSlice := []int{1, 2, 3} fmt.Println(\u0026#34;Sum of ints:\u0026#34;, Sum(intSlice)) // 7 floatSlice := []float64{1.1, 2.2, 3.3} fmt.Println(\u0026#34;Sum of floats:\u0026#34;, Sum(floatSlice)) // 6.6 } 泛型类型 泛型类型是指定义了类型参数的结构体、接口等。这对于创建通用的数据结构（如链表、栈、队列）非常有用。\n示例：一个通用的 Stack 类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import \u0026#34;fmt\u0026#34; // Stack 是一个后进先出的泛型数据结构 type Stack[T any] struct { elements []T } func (s *Stack[T]) Push(value T) { s.elements = append(s.elements, value) } func (s *Stack[T]) Pop() (T, bool) { if len(s.elements) == 0 { var zero T // 声明一个 T 类型的零值 return zero, false } lastIndex := len(s.elements) - 1 value := s.elements[lastIndex] s.elements = s.elements[:lastIndex] return value, true } func main() { intStack := \u0026amp;Stack[int]{} intStack.Push(10) intStack.Push(20) val, _ := intStack.Pop() fmt.Println(val) // 20 stringStack := \u0026amp;Stack[string]{} stringStack.Push(\u0026#34;hello\u0026#34;) stringStack.Push(\u0026#34;world\u0026#34;) strVal, _ := stringStack.Pop() fmt.Println(strVal) // \u0026#34;world\u0026#34; } 类型约束进阶 预声明的约束：any 和 comparable Go 语言内置了两个非常有用的约束：\nany: 它是 interface{} 的别名，表示允许任何类型。这是最宽松的约束。 comparable: 这个约束包含了所有可以使用 == 和 != 进行比较的类型，例如数字、字符串、指针、数组等。注意，切片、map 和函数类型不满足 comparable 约束。 1 2 3 4 5 6 7 8 9 // Find 函数在任何可比较类型的切片中查找元素 func Find[T comparable](slice []T, value T) int { for i, v := range slice { if v == value { return i } } return -1 } 官方链接: The Go Programming Language Specification - Type constraints\n接口作为约束 任何接口类型都可以作为约束。如果一个类型参数使用了某个接口作为约束，那么所有传入的类型实参都必须实现了该接口。\n示例：使用 fmt.Stringer 作为约束\n1 2 3 4 5 6 7 8 9 10 import \u0026#34;fmt\u0026#34; // Stringify 函数将任何实现了 String() 方法的类型转换为字符串切片 func Stringify[T fmt.Stringer](s []T) []string { result := make([]string, len(s)) for i, v := range s { result[i] = v.String() } return result } 自定义约束 我们可以通过定义一个接口来创建自定义的约束。这个接口可以包含：\n方法集：要求类型参数必须实现的方法。 类型联合（Union）：使用 | 来列举一组允许的类型。 底层类型约束（Underlying Type Constraints）：使用 ~ 符号，表示不仅可以是该类型，也可以是所有以该类型为底层类型的自定义类型。 示例：自定义 Numeric 约束\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 自定义类型 type MyInt int // Numeric 约束包含了所有整数和浮点数类型， // 以及它们的底层类型 type Numeric interface { ~int | ~int64 | ~float64 } func Scale[T Numeric](s []T, factor T) []T { result := make([]T, len(s)) for i, v := range s { result[i] = v * factor } return result } 最佳实践 何时应该使用泛型？ 处理通用数据结构：当你需要实现一个适用于多种元素类型的数据结构时（如链表、二叉树、堆），泛型是理想选择。 操作通用集合：当函数需要对切片（slices）、映射（maps）或通道（channels）进行操作，且操作逻辑与元素类型无关时（例如，map、filter、reduce 等函数）。 实现通用算法：例如排序、查找等，这些算法的逻辑通常是类型无关的。 官方链接: When to use generics - go.dev\n何时不应该使用泛型？ 当接口能解决问题时：如果函数的逻辑依赖于类型的特定行为（方法），使用接口通常更清晰、更符合 Go 的习惯。例如，io.Reader 就是一个很好的例子，我们关心的是“能读”这个行为，而不是具体的类型。 代码的可读性降低时：不要为了泛型而泛型。如果泛型使得代码变得过于复杂和难以理解，那么传统的函数或接口可能是更好的选择。 不同类型的实现逻辑不同时：如果一个函数对不同类型的处理逻辑完全不同，那么泛型并不适用。此时应该为每种类型编写独立的函数。 约束应尽可能严格 为类型参数选择最严格、最精确的约束。这能提高类型安全，并在编译时捕获更多的错误，同时也能让函数体内的可用操作更加明确。\n1 2 3 4 5 // 不好：约束过于宽松，v == value 会在编译时报错 // func Find[T any](slice []T, value T) int { ... } // 好：使用 comparable 约束，明确告知编译器 T 支持 == 操作 func Find[T comparable](slice []T, value T) int { ... } 优先使用 any 而非 interface{} 在泛型代码中，any 是 interface{} 的官方别名。使用 any 能够更清晰地表达“可以是任何类型”的意图。\n让编译器推断类型参数 在调用泛型函数时，Go 编译器通常能够根据传入的参数自动推断出类型参数。你应该利用这一点来保持代码的简洁。\n1 2 3 4 5 // 显式指定类型参数（通常不需要） Sum[int]([]int{1, 2, 3}) // 推荐：让编译器自动推断 Sum([]int{1, 2, 3}) 常见误区与限制 类型参数不能作为方法的接收者：你不能在一个类型的方法上定义它自己的类型参数。类型参数必须定义在类型本身上。 谨慎处理泛型类型的零值：泛型函数中 var zero T 的值取决于 T 的具体类型。对于指针、切片等引用类型，零值是 nil；对于数值类型，零值是 0。要意识到这一点，避免潜在的 nil 指针解引用等问题。 不能在 type switch 中直接使用类型参数：你不能直接对一个类型为 T 的变量使用 type switch。需要先将其转换为空接口 any。 官方资源链接 官方入门教程: Tutorial: Getting started with generics 官方博客介绍: An Introduction To Generics 何时使用泛型: When To Use Generics 语言规范: The Go Programming Language Specification - Type parameters 常见问题解答: Go Frequently Asked Questions (FAQ) - Generics ","date":"2025-09-30T18:36:16+08:00","permalink":"https://ilolicon.github.io/p/go-generics/","title":"GO Generics"},{"content":"DNS优化 Kubernetes集群中 我们可以使用CoreDNS来进行集群的域名解析 但是如果在集群规模较大并发较高的情况下 我们仍然需要对DNS进行优化 典型问题：CoreDNS会出现超时5s的情况 超时原因 在iptables模式下(默认情况) 每个服务的kube-proxy在主机网络名称空间的NAT表中创建iptables规则 比如在集群中具有两个DNS服务器实例的kube-dns服务 相关规则大致如下 1 2 3 4 5 6 7 8 9 10 (1) -A PREROUTING -m comment --comment \u0026#34;kubernetes service portals\u0026#34; -j KUBE-SERVICES \u0026lt;...\u0026gt; (2) -A KUBE-SERVICES -d 10.96.0.10/32 -p udp -m comment --comment \u0026#34;kube-system/kube-dns:dns cluster IP\u0026#34; -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU \u0026lt;...\u0026gt; (3) -A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment \u0026#34;kube-system/kube-dns:dns\u0026#34; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-LLLB6FGXBLX6PZF7 (4) -A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment \u0026#34;kube-system/kube-dns:dns\u0026#34; -j KUBE-SEP-LRVEW52VMYCOUSMZ \u0026lt;...\u0026gt; (5) -A KUBE-SEP-LLLB6FGXBLX6PZF7 -p udp -m comment --comment \u0026#34;kube-system/kube-dns:dns\u0026#34; -m udp -j DNAT --to-destination 10.32.0.6:53 \u0026lt;...\u0026gt; (6) -A KUBE-SEP-LRVEW52VMYCOUSMZ -p udp -m comment --comment \u0026#34;kube-system/kube-dns:dns\u0026#34; -m udp -j DNAT --to-destination 10.32.0.7:53 我们知道每个Pod的/etc/resolv.conf文件中都有填充的nameserver 10.96.0.10 所以 来自Pod的DNS查找请求将发送到10.96.0.10 这是kube-dns服务的ClusterIP地址 由于(1)请求进入KUBE-SERVICE链 然后匹配规则(2) 最后根据规则(3)的random随机模式 跳转到(5)或(6)条目 将请求UDP数据包的目的IP地址修改为DNS服务器的实际IP地址 这是通过DNAT完成的 其中10.32.0.6和10.32.0.7是我们集群中CoreDNS的两个Pod副本的IP地址 内核中的DNAT DNAT的主要职责是同时更改传出数据包的目的地 响应数据包的源 并确保对所有后续数据包进行相同的修改 后者严重依赖于连接跟踪机制 也称为conntrack 它被实现为内核模块 conntrack会跟踪系统中正在进行的网络连接 conntrack中的每个连接都由两个元组表示 一个元组用于原始请求(IP_CT_DIR_ORIGINAL) 一个元组用于答复(IP_CT_DIR_REPLY) 对于UDP 每个元组都由源IP地址 源端口以及目标IP地址和目标端口组成 答复元组包含存储在src字段中的目标真实地址 例如：如果IP地址10.40.0.17的Pod向kube-dns的ClusterIP发送一个请求 该请求被转换为10.32.0.6 则将创建以下元组: 1 2 原始：src=10.40.0.17 dst=10.96.0.10 sport=53378 dport=53 回复：src=10.32.0.6 dst=10.40.0.17 sport=53 dport=53378 通过这些条目内核可以相应地修改任何相关数据包的目的地址和源地址 而无需再次遍历DNAT规则 此外 它将知道如何修改回复以及应将回复发送给谁 创建conntrack条目后 将首先对其进行确认 然后如果没有已确认的conntrack条目具有相同的原始元组或回复元组 则内核将尝试确认该条目 conntrack创建和DNAT的简化流程如下所示: 1 2 3 4 5 6 7 8 flowchart TD A[\u0026#34;为给定包创建 conntrack(如果不存在)\u0026#34;] --\u0026gt; B[\u0026#34;ipt_do_table:找到匹配的 DNAT 规则\u0026#34;] B --\u0026gt; C[\u0026#34;get_unique_tuple:1. 根据 DNAT 更新回复元组 src 2. 确保未被已确认连接使用\u0026#34;] C --\u0026gt; D[\u0026#34;nf_nat_packet:根据应答元组打乱数据包目的端口/地址\u0026#34;] D --\u0026gt; E{\u0026#34;_nf_conntrack_confirm:是否存在相同原始/应答元组的已确认连接？\u0026#34;} E --\u0026gt;|否| F[\u0026#34;确认连接\u0026#34;] E --\u0026gt;|是| G[\u0026#34;递增 insert_failed 计数器并删除数据包\u0026#34;] 问题 DNS客户端(glibc 或 musl libc)会并发请求 A 和 AAAA 记录 跟DNS Server通信自然会先connect(建立fd) 后面请求报文使用这个fd来发送 由于 UDP 是无状态协议 connect时并不会创建conntrack表项 而并发请求的 A 和 AAAA 记录默认使用同一个fd发包 这时它们源Port相同 当并发发包时 两个包都还没有被插入conntrack表项 所以netfilter会为它们分别创建conntrack表项 而集群内请求CoreDNS都是访问的CLUSTER-IP 报文最终会被 DNAT成一个具体的Pod IP 当两个包被DNAT成同一个IP 最终它们的五元组相同 在最终插入的时候后面那个包就会被丢掉 如果DNS的Pod副本只有一个实例的情况就很容易发生 现象就是DNS请求超时 客户端默认策略是等待5s自动重试 如果重试成功 我们看到的现象就是DNS请求有5s的延时 只有多个线程或进程 并发从同一个socket发送相同五元组的UDP报文时 才有一定概率发生 glibc、musl(alpine linux的libc库)都使用parallel query 就是并发发出多个查询请求 因此很容易碰到这样的冲突 造成查询请求被丢弃 由于ipvs也使用了conntrack 使用kube-proxy的ipvs模式 并不能避免这个问题 解决方法 内核优化 要彻底解决这个问题最好当然是内核上去FIX掉这个BUG 除了这种方法之外我们还可以使用其他方法来进行规避 我们可以避免相同五元组DNS请求的并发 修改resolv.conf文件 在resolv.conf中就有两个相关的参数可以进行配置\nsingle-request-reopen：发送A类型请求和AAAA类型请求使用不同的源端口 这样两个请求在conntrack表中不占用同一个表项 从而避免冲突 single-request：避免并发 改为串行发送A类型和AAAA类型请求 没有了并发从而也避免了冲突 要给容器的resolv.conf加上options参数 有几个办法\n在容器的ENTRYPOINT或者CMD指令中 执行 /bin/echo 'options single-request-reopen' \u0026gt;\u0026gt; /etc/resolv.conf 在Pod的postStart hook中添加 1 2 3 4 5 6 7 lifecycle: postStart: exec: command: - /bin/sh - -c - \u0026#34;/bin/echo \u0026#39;options single-request-reopen\u0026#39; \u0026gt;\u0026gt; /etc/resolv.conf\u0026#34; 使用template.spec.dnsConfig配置 1 2 3 4 5 template: spec: dnsConfig: options: - name: single-request-reopen 使用ConfigMap覆盖Pod里面的/etc/resolv.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # configmap apiVersion: v1 data: resolv.conf: | nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5 single-request-reopen timeout:1 kind: ConfigMap metadata: name: resolvconf --- # Pod Spec spec: volumeMounts: - name: resolv-conf mountPath: /etc/resolv.conf subPath: resolv.conf # 在某个目录下面挂载一个文件(保证不覆盖当前目录)需要使用subPath -\u0026gt; 不支持热更新 ... volumes: - name: resolv-conf configMap: name: resolvconf items: - key: resolv.conf path: resolv.conf 上面的方法在一定程度上可以解决DNS超时问题 但更好的方式时使用本地DNS缓存\n容器的DNS请求都发往本地的DNS缓存服务 也就不需要走DNAT 当然也不会发生conntrack冲突 而且还可以有效提升CoreDNS的性能瓶颈\nNodeLocal DNSCache 在Kubernetes集群中使用NodeLocalDNSCache\nNodeLocal DNSCache通过在集群节点上运行一个DaemonSet来提高集群DNS性能和可靠性 处于ClusterFirst的DNS模式下的Pod可以连接到kube-dns的serviceIP进行DNS查询 通过kube-proxy组件添加的iptables规则将其转换为CoreDNS端点 通过在每个集群节点上运行DNS缓存 NodeLocal DNSCache可以缩短DNS查找的延迟时间、使 DNS查找时间更加一致 以及减少发送到kube-dns的DNS查询次数 在集群中运行NodeLocal DNSCache有如下几个好处 如果本地没有CoreDNS实例 则具有最高DNS QPS的Pod可能必须到另一个节点进行解析 使用NodeLocal DNSCache后 拥有本地缓存将有助于改善延迟 跳过iptables DNAT和连接跟踪将有助于减少conntrack竞争并避免UDP DNS条目填满conntrack表(上面提到的5s超时问题就是这个原因造成的) 从本地缓存代理到kube-dns服务的连接可以升级到TCP TCP conntrack条目将在连接关闭时被删除 而UDP条目必须超时(默认nfconntrackudp_timeout是30秒) 将DNS查询从UDP升级到TCP将减少归因于丢弃的UDP数据包和DNS超时的尾部等待时间 通常长达30秒(3次重试+ 10秒超时) 安装 1 2 3 4 5 6 7 wget https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml kubedns=`kubectl get svc kube-dns -n kube-system -o jsonpath={.spec.clusterIP}` domain=\u0026lt;cluster-domain\u0026gt; localdns=\u0026lt;node-local-address\u0026gt; kubectl apply -f nodelocaldns.yaml 该资源清单文件中包含几个变量值得注意 其中\n__PILLAR__DNS__SERVER__ 表示kube-dns这个Service的ClusterIP 可以通过命令kubectl get svc kube-dns -n kube-system -o jsonpath={.spec.clusterIP} 获取(我们这里就是 10.96.0.10) __PILLAR__LOCAL__DNS__ 表示DNSCache本地的IP 默认为169.254.20.10 __PILLAR__DNS__DOMAIN__ 表示集群域 默认就是cluster.local 如果kube-proxy运行在IPTABLES模式\n1 2 3 # node-local-dns Pod会设置 __PILLAR__CLUSTER__DNS__ 和 __PILLAR__UPSTREAM__SERVERS__ # 在此模式下 node-local-dns Pod会同时侦听kube-dns服务的IP地址和\u0026lt;node-local-address\u0026gt;的地址 以便Pod可以使用其中任何一个IP地址来查询DNS记录 sed -i \u0026#34;s/__PILLAR__LOCAL__DNS__/$localdns/g; s/__PILLAR__DNS__DOMAIN__/$domain/g; s/__PILLAR__DNS__SERVER__/$kubedns/g\u0026#34; nodelocaldns.yaml 如果kube-proxy运行在IPVS模式 1 2 3 4 # 在此模式下 node-local-dns Pod只会侦听\u0026lt;node-local-address\u0026gt;的地址 # node-local-dns接口不能绑定kube-dns的集群IP地址 因为IPVS负载均衡使用的接口已经占用了该地址 # node-local-dns Pod会设置 __PILLAR__UPSTREAM__SERVERS__ sed -i \u0026#34;s/__PILLAR__LOCAL__DNS__/$localdns/g; s/__PILLAR__DNS__DOMAIN__/$domain/g; s/,__PILLAR__DNS__SERVER__//g; s/__PILLAR__CLUSTER__DNS__/$kubedns/g\u0026#34; nodelocaldns.yaml 查询Pod是否启动成功 1 2 3 4 5 6 $ kubectl get pods -n kube-system -l k8s-app=node-local-dns  ✔  minho-test/monitoring ⎈  21:55:32  ▓▒░ NAME READY STATUS RESTARTS AGE node-local-dns-5rzd9 1/1 Running 0 12m node-local-dns-7fnlk 1/1 Running 0 12m node-local-dns-glc9j 1/1 Running 0 6m45s node-local-dns-m6cnr 1/1 Running 0 34s 需要注意 这里使用DaemoonSet部署node-local-dns 使用了hostNetwork=true 会占用宿主机的8080端口 所以需要保证该端口未被占用 如果kube-proxy使用的ipvs模式 还需要修改kubelet的--cluster-dns参数 将其指向169.254.20.10 DaemonSet会在每个节点创建一个网卡来绑这个IP Pod向本节点这个IP发DNS请求 缓存没有命中的时候才会再代理到上游集群DNS进行查询 iptables模式下Pod还是向原来的集群DNS请求 节点上有这个IP监听 会被本机拦截 再请求集群上游DNS 所以不需要更改--cluster-dns参数 1 2 sed -i \u0026#39;s/10.96.0.10/169.254.20.10/g\u0026#39; /var/lib/kubelet/config.yaml systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart kubelet 部署新Pod验证/etc/resolv.conf 1 2 3 4 root@testdns:~# cat /etc/resolv.conf nameserver 169.254.20.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5 缺点 由于LocalDNS使用的是DaemonSet模式部署 所以如果需要更新镜像则可能会中断服务(不过可以使用一些第三方的增强组件来实现原地升级解决这个问题 比如 openkruise) 性能测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 // main.go package main import ( \u0026#34;context\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) var host string var connections int var duration int64 var limit int64 var timeoutCount int64 func main() { flag.StringVar(\u0026amp;host, \u0026#34;host\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Resolve host\u0026#34;) flag.IntVar(\u0026amp;connections, \u0026#34;c\u0026#34;, 100, \u0026#34;Connections\u0026#34;) flag.Int64Var(\u0026amp;duration, \u0026#34;d\u0026#34;, 0, \u0026#34;Duration(s)\u0026#34;) flag.Int64Var(\u0026amp;limit, \u0026#34;l\u0026#34;, 0, \u0026#34;Limit(ms)\u0026#34;) flag.Parse() var count int64 = 0 var errCount int64 = 0 pool := make(chan interface{}, connections) exit := make(chan bool) var ( min int64 = 0 max int64 = 0 sum int64 = 0 ) go func() { time.Sleep(time.Second * time.Duration(duration)) exit \u0026lt;- true }() endD: for { select { case pool \u0026lt;- nil: go func() { defer func() { \u0026lt;-pool }() resolver := \u0026amp;net.Resolver{} now := time.Now() _, err := resolver.LookupIPAddr(context.Background(), host) use := time.Since(now).Nanoseconds() / int64(time.Millisecond) if min == 0 || use \u0026lt; min { min = use } if use \u0026gt; max { max = use } sum += use if limit \u0026gt; 0 \u0026amp;\u0026amp; use \u0026gt;= limit { timeoutCount++ } atomic.AddInt64(\u0026amp;count, 1) if err != nil { fmt.Println(err.Error()) atomic.AddInt64(\u0026amp;errCount, 1) } }() case \u0026lt;-exit: break endD } } fmt.Printf(\u0026#34;request count：%d\\nerror count：%d\\n\u0026#34;, count, errCount) fmt.Printf(\u0026#34;request time：min(%dms) max(%dms) avg(%dms) timeout(%dn)\\n\u0026#34;, min, max, sum/count, timeoutCount) } 配置好golang环境 然后直接构建上面的测试应用进行测试 1 2 3 4 5 6 7 8 9 10 go build -o testdns . kubectl cp testdns testdns:/root -n default kubectl exec -it testdns -n default -- bash cd /root # 200个并发 持续30s 这需要在集群内部署一个httpbin服务作为请求的目的地址 ./testdns -host httpbin.default -c 200 -d 30 -l 5000 未优化 我们可以看到平均延迟在30ms 性能不是太理想 有部分超时记录 可以使用上面的resolv配置项来解决 也可以使用NodeLocal DNSCache来提升DNS的性能和可靠性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 root@testdsn:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：186586 error count：0 request time：min(1ms) max(5054ms) avg(30ms) timeout(245n) root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：187714 error count：0 request time：min(3ms) max(5085ms) avg(31ms) timeout(304n) root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 lookup httpbin.default.svc.cluster.local. on 10.96.0.10:53: no such host lookup httpbin.default.svc.cluster.local. on 10.96.0.10:53: read udp 10.244.211.25:46083-\u0026gt;10.96.0.10:53: i/o timeout lookup httpbin.default.svc.cluster.local. on 10.96.0.10:53: read udp 10.244.211.25:34202-\u0026gt;10.96.0.10:53: i/o timeout lookup httpbin.default.svc.cluster.local. on 10.96.0.10:53: read udp 10.244.211.25:49917-\u0026gt;10.96.0.10:53: i/o timeout lookup httpbin.default.svc.cluster.local. on 10.96.0.10:53: read udp 10.244.211.25:50036-\u0026gt;10.96.0.10:53: i/o timeout request count：184496 error count：5 request time：min(1ms) max(10023ms) avg(30ms) timeout(244n) single-request-reopen 1 2 3 4 5 6 7 8 9 10 11 12 13 14 root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：177600 error count：0 request time：min(1ms) max(167ms) avg(32ms) timeout(0n) root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：179295 error count：0 request time：min(1ms) max(168ms) avg(32ms) timeout(0n) root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：180339 error count：0 request time：min(1ms) max(193ms) avg(32ms) timeout(0n) NodeLocal DNSCache 性能测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 使用NodeLocal DNSCache之后 我本地环境性能压测并不理想 目前查看是机器CPU负载较高 怀疑可能有影响 后续有条件再进行验证 root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：202710 error count：0 request time：min(1ms) max(5058ms) avg(28ms) timeout(394n) root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：207178 error count：0 request time：min(1ms) max(5058ms) avg(27ms) timeout(364n) root@testdns:~# ./testdns -host httpbin.default.svc.cluster.local. -c 200 -d 30 -l 5000 request count：203354 error count：0 request time：min(1ms) max(5064ms) avg(28ms) timeout(424n) 建议 Service与Pod的DNS\n性能测试发现 集群内解析 推荐写服务的FQDN完全限定域名格式 可以减少无效解析次数 提高性能 比如: httpbin.default.svc.cluster.local. # 最后的. 一定要加上 补充: DNSPolicy pod-s-dns-policy\nDNSPolicy字段值 使用的DNS服务器 Default 只适用于不需要访问集群内部服务的场景 Pod创建时会从运行节点/etc/resolv.conf文件继承DNS服务器列表 ClusterFirst 此为DNSPolicy默认值 Pod会将CoreDNS提供的kube-dns服务IP作为DNS服务器 开启HostNetwork的Pod 如果选择ClusterFirst模式 效果等同于Default ClusterFirstWithHostNet 开启HostNetwork的Pod 如果选择ClusterFirstWithHostNet模式 效果等同于ClusterFirst None 配合DNSConfig字段 可用于自定义DNS服务器和参数 在NodeLocalDNSCache开启注入时 DNSConfig会将DNS服务器指向本地缓存IP及CoreDNS提供的kube-dns服务IP(阿里云ACK) 参考链接 DNS优化\nDNS解析异常问题排查\n在Kubernetes集群中使用NodeLocal DNSCache\n","date":"2025-06-16T22:30:14+08:00","permalink":"https://ilolicon.github.io/p/coredns/","title":"CoreDNS"},{"content":"","date":"2025-06-14T21:36:00+08:00","permalink":"https://ilolicon.github.io/p/tekton/","title":"Tekton"},{"content":"rpm rpm包构建 RPM打包原理、示例、详解及备查\nrpm配置文件处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # .spec文件参考配置 Name: pkg name Version: %{version} Release: %(date +%%y%%m%%d%%0k) Summary: pkg summary License: xxx URL: xxx Source0: %{name}-%{version}.tar.gz %description pkg description. %prep %setup -q %install mkdir -p %{buildroot}%{_bindir} mkdir -p %{buildroot}%{_sysconfdir}/%{name} mkdir -p %{buildroot}%{_sysconfdir}/default mkdir -p %{buildroot}%{_unitdir} install -m 0755 %{_builddir}/%{name}-%{version}/.build/%{_os}-amd64/%{name} %{buildroot}%{_bindir}/%{name} install -m 0644 %{_builddir}/%{name}-%{version}/dist/%{name}.env %{buildroot}%{_sysconfdir}/default/%{name} install -m 0644 %{_builddir}/%{name}-%{version}/config.yml %{buildroot}%{_sysconfdir}/%{name}/config.yml install -m 0644 %{_builddir}/%{name}-%{version}/dist/web-config.yml %{buildroot}%{_sysconfdir}/%{name}/web-config.yml install -m 0644 %{_builddir}/%{name}-%{version}/dist/%{name}.service %{buildroot}%{_unitdir} # 以下为配置文件处理参考 重点:$config(noreplace) %files %defattr(-,root,root,-) %{_bindir}/%{name} %config(noreplace) %{_sysconfdir}/%{name} %config(noreplace) %{_sysconfdir}/default %{_unitdir}/%{name}.service %post systemctl daemon-reload %changelog * Wed May 24 2023 xxx \u0026lt;xxx@xx.com\u0026gt; - initial rpm包私有仓库构建 所有构建好的.rpm包 全部放到准备好的目录$BASE_DIR 进入目录cd $BASE_DIR 执行命令createrepo .即可(或不进目录 跟绝对路径) 搭建http/ftp等服务进行访问 配置.repo文件即可进行安装 问题处理 Q: GO源码包构建遇到RPM build warnings: Missing build-id in /bin/xxx问题 A: 参考该文档解决 也谈GO的可移植性 deb deb包构建 从零开始制作deb文件\nDebian新维护者手册\ndeb配置文件处理 How to mark some file in debian package as config?\nDebian Policy Manual\n针对上面链接说的第三种情况: 本地安装 和 包维护者 都修改过配置文件的情况 升级会提示用户相关问题 需要用户自行解决差异 如果安装的时候 不想进入交互模式(比如批量安装的时候) 则可以使用dpkg的以下参数解决:\n\u0026ndash;force-confold: 保留当前配置文件 将新配置文件安装为.dpkg-dist扩展名 需要手动合并 \u0026ndash;force-confnew: 覆盖当前配置文件，但将旧配置文件备份为.dpkg-old扩展名 \u0026ndash;force-confdef: 当用户未指定具体选项时 采取默认行为保留、覆盖或交互 1 2 sudo dpkg -i --force-confnew package_name.deb # dpkg apt install --force-confnew package_name # apt deb私有仓库制作 借助reprepro设置仓库\nDebianRepoFormat\nSetupWithReprepro\ncreating-your-own-signed-apt-repository-and-debian-packages\n安装软件包 1 sudo apt install -y gnupg reprepro 创建GPG密钥 1 2 3 4 5 # 两个命令都可以 查看man手册获取区别 gpg --gen-key gpg --full-gen-key # 执行之后 按照提示操作即可 gpg -k, list-keys # 查看所有keys 配置包的存储库BASE_DIR 这里以nginx为例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 增加配置 私有仓库自行根据需求添加认证 server { listen 80; access_log /var/log/nginx/repo-error.log; error_log /var/log/nginx/repo-error.log; location / { root /srv/repos/apt; # $BASE_DIR autoindex on; } location ~ /(.*)/conf { deny all; } location ~ /(.*)/db { deny all; } } # nginx -t # systemctl reload nginx 配置reprepro 具体参考 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # create a reprepro configuration directory mkdir -p /srv/repos/apt/debian/conf # create the conf/distributions Origin: Your project name Label: Your project name Codename: \u0026lt;osrelease\u0026gt; Architectures: source i386 amd64 Components: main Description: Apt repository for project x SignWith: \u0026lt;key-id\u0026gt; # \u0026lt;key-id\u0026gt;获取 $ gpg --list-secret-key --with-subkey-fingerprint pub rsa4096 2010-09-23 [SC] E123D55E623D56323D65E123655E623D563D5831 uid [ultimate] Joe User (Some organization) \u0026lt;joe.user@example.com\u0026gt; sub rsa4096 2010-09-23 [E] F24957412415744F1495F149571F2495F2495714 # Here \u0026lt;keyid\u0026gt; (fingerprint) for the OpenPGP key is F24957412415744F1495F149571F2495F2495714 (that\u0026#39;s technically the subkey, which is recommended to be used for this sort of signing purpose). # add an options file to make daily life with reprepro command-line a little easier. This file is in /srv/repos/apt/debian/conf/options: verbose basedir /srv/repos/apt/debian ask-passphrase # 执行命令创建仓库树 reprepro export # 完整命令 reprepro --ask-passphrase -Vb /srv/repos/apt/debian export # 把.deb包加入仓库 # 完整命令也需要加上 --ask-passphrase -Vb /srv/repos/apt/debian # 更多命令行用户参阅man手册: man reprepro reprepro includedeb codename .deb-filename # 把.deb移除仓库 reprepro remove codename package-names # 导出OpenPGP key gpg --armor --output whatever.gpg.key --export-options export-minimal --export \u0026lt;key-id\u0026gt; # Copy this to a webserver so that users can download it and add it to their OpenPGP keychains similarly to this (as root): # 注意: 该方法已弃用 参考下面`client端相关配置` wget -O - http://www.example.com/repos/apt/conf/\u0026lt;whatever\u0026gt;.gpg.key | apt-key add - client端相关配置 http(s) deb仓库搭建完成之后 即可以进行相关包下载\n添加key 1 2 3 4 # wget或curl获取key内容 再通过apt-key add -命令导入会有warning提示 # Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)). # 下面命令废弃 不推荐 wget -O - http://www.example.com/repos/apt/conf/\u0026lt;whatever\u0026gt;.gpg.key | apt-key add - 参考下面回答添加key和source.list warning-apt-key-is-deprecated-manage-keyring-files-in-trusted-gpg-d-instead\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 sudo mkdir -m 0755 -p /etc/apt/keyrings/ curl -fsSL https://example.com/EXAMPLE.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/EXAMPLE.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/EXAMPLE.gpg] https://example.com/apt stable main\u0026#34; | sudo tee /etc/apt/sources.list.d/EXAMPLE.list \u0026gt; /dev/null # Optional (you can find the email address / ID using `apt-key list`) sudo apt-key del support@example.com # Optional (not necessary on most systems) sudo chmod 644 /etc/apt/keyrings/EXAMPLE.gpg sudo chmod 644 /etc/apt/sources.list.d/EXAMPLE.list 如果http服务器添加过认证 需要使用apt-auth管理 否则有warning 参考下面内容 how-to-access-local-apt-repository-that-requires-http-authentication man apt_auth.conf查看具体信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 EXAMPLE Supplying login information for a user named apt with the password debian for the sources.list(5) entry deb https://example.org/debian bookworm main could be done in the entry directly: deb https://apt:debian@example.org/debian bookworm main Alternatively an entry like the following in the auth.conf file could be used: machine example.org login apt password debian Or alternatively within a single line: machine example.org login apt password debian If you need to be more specific all of these lines will also apply to the example entry: machine example.org/deb login apt password debian machine example.org/debian login apt password debian machine example.org/debian/ login apt password debian On the other hand neither of the following lines apply: machine example.org:443 login apt password debian machine example.org/deb/ login apt password debian machine example.org/ubuntu login apt password debian machine example.orga login apt password debian machine example.net login apt password debian deb镜像同步 镜像同步说明\n","date":"2024-03-11T19:53:00+08:00","permalink":"https://ilolicon.github.io/p/build-installation-package-on-linux/","title":"Build installation package on linux"},{"content":" 设计模式是软件设计中常见问题的典型解决方案 每个模式就像一张蓝图 你可以通过对其进行定制来解决代码中的特定设计问题 模式是针对软件设计中常见问题的解决方案工具箱 它们定义了一种让你的团队能更高效沟通的通用语言 不同设计模式在其复杂程度、细节层次以及应用范围等方面各不相同 此外 我们可以根据模式的目的来将它们划分为三个不同的组别 创建型模式 提供对象的创建机制 增加已有代码的灵活性和复用性 结构型模式 介绍如何将对象和类组装成较大的结构 并同时保持结构的灵活和高效 行为型模式 负责对象间的高效沟通和职责委派 创建型模式 在Go语言中 创建型模式(Creational Patterns)是一类用于处理对象创建的设计模式 它们的主要目标是提供一种灵活的方式来创建对象 同时隐藏对象创建的具体细节 从而降低代码的耦合度 并提高代码的可复用性和可维护性 比如标准库: http.NewRequest() bytes.NewReader() md5.New() 等等 \u0026hellip; 创建型模式的核心思想是将对象的创建与使用分离 使得系统不依赖于具体的对象创建方式 而是依赖于抽象 单例模式(Singleton) ✔ 单例模式(singleton) 保证一个类只有一个实例 并提供一个访问它的全局访问点 通常让一个全局变量成为一个对象被访问 但不能防止实例化多个对象 常见做法：让类自身负责保证它的唯一实例 这个类可以保证没有其他实例可以被创建 并且可以提供一个访问该实例的方法 适用场景 当某个对象只能存在一个实例的情况下使用单例模式 比如： 全局Config配置对象 全局Logger日志对象 \u0026hellip; 优点： 提供了对唯一实例的受控访问 由于在系统内存中只存在一个对象 因此可以节约系统资源 对于一些需要频繁创建和销毁的对象 单例模式可以提高系统性能 实现方式及解析 饿汉模式 在程序加载时就创建对象实例 Go语言中我们可以放到init函数中 保证线程安全 会减慢程序启动速度(init启动时会先加载) 如果实例不被调用 则会浪费一段内存空间 特别是该对象比较大的时候 1 2 3 4 5 6 7 8 9 10 11 12 13 package singleton var instance *singleton func init() { instance = \u0026amp;singleton{} } type singleton struct{} func GetInstance() *singleton { return instance } 懒汉模式 在获取对象实例时 如果实例为空则创建 避免饿汉模式的内存空间浪费 在Go中并发非常容易 容易被不正确使用 导致忽略并发安全 1 2 3 4 5 6 7 8 9 10 11 12 package singleton var instance *singleton type singleton struct{} func GetInstance() *singleton { if instance == nil { instance = \u0026amp;singleton{} } return instance } 在上述情况下 多个goroutine都可以执行第一个检查 并且它们都将创建该singleton类型的实例并相互覆盖 无法保证它将在此处返回哪个实例 并且对该实例的其他进一步操作可能与开发人员的期望不一致 如果有代码保留了对该单例实例的引用 则可能存在具有不同状态的该类型的多个实例 从而产生潜在的不同代码行为 这也成为调试过程中的一个噩梦 并且很难发现该错误 因为在调试时 由于运行时暂停而没有出现任何错误 这使非并发安全执行的可能性降到了最低 并且很容易隐藏开发人员的问题 双重检查模式(激进加锁) 解决懒汉模式的非线程安全 避免资源竞争导致数据不一致 潜在问题： 如果实例存在 没有必要加锁 每次请求都加锁(执行过多的锁定) 降低性能/增加瓶颈 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package singleton import \u0026#34;sync\u0026#34; var ( instance *singleton mutex sync.Mutex ) type singleton struct{} func GetInstance() *singleton { mutex.Lock() // 如果实例存在没有必要加锁 defer mutex.Unlock() if instance == nil { instance = \u0026amp;singleton{} } return instance } 优化：检查对应是否为空之后再加锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package singleton import \u0026#34;sync\u0026#34; var ( instance *singleton mutex sync.Mutex ) type singleton struct{} func GetInstance() *singleton { if instance == nil { // // 不太完美 因为这里不是完全原子的 mutex.Lock() defer mutex.Unlock() if instance == nil { instance = \u0026amp;singleton{} } } return instance } 上面的方式仍然不太完美 因为判断实例是否为空的过程仍然不是完全原子的 我们可以使用sync/atomic包 原子化加载并设置一个标志 该标志表明我们是否已初始化实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package singleton import \u0026#34;sync\u0026#34; import \u0026#34;sync/atomic\u0026#34; var ( initialized uint32 instance *singleton mutex sync.Mutex ) type singleton struct{} func GetInstance() *singleton { if atomic.LoadUInt32(\u0026amp;initialized) == 1 { // 原子操作 return instance } mu.Lock() defer mu.Unlock() if initialized == 0 { instance = \u0026amp;singleton{} atomic.StoreUint32(\u0026amp;initialized, 1) } return instance } Sync.Once Go语言单例惯用实现解析 上面实现原子操作的写法稍显繁琐 Go标准库sync中的Once类型 它能保证某个操作仅且只执行一次 sync.Once源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 // Copyright 2009 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. package sync import ( \u0026#34;sync/atomic\u0026#34; ) // Once is an object that will perform exactly one action. // // A Once must not be copied after first use. type Once struct { // done indicates whether the action has been performed. // It is first in the struct because it is used in the hot path. // The hot path is inlined at every call site. // Placing done first allows more compact instructions on some architectures (amd64/386), // and fewer instructions (to calculate offset) on other architectures. done uint32 m Mutex } // Do calls the function f if and only if Do is being called for the // first time for this instance of Once. In other words, given // var once Once // if once.Do(f) is called multiple times, only the first call will invoke f, // even if f has a different value in each invocation. A new instance of // Once is required for each function to execute. // // Do is intended for initialization that must be run exactly once. Since f // is niladic, it may be necessary to use a function literal to capture the // arguments to a function to be invoked by Do: // config.once.Do(func() { config.init(filename) }) // // Because no call to Do returns until the one call to f returns, if f causes // Do to be called, it will deadlock. // // If f panics, Do considers it to have returned; future calls of Do return // without calling f. // func (o *Once) Do(f func()) { // Note: Here is an incorrect implementation of Do: // // if atomic.CompareAndSwapUint32(\u0026amp;o.done, 0, 1) { // f() // } // // Do guarantees that when it returns, f has finished. // This implementation would not implement that guarantee: // given two simultaneous calls, the winner of the cas would // call f, and the second would return immediately, without // waiting for the first\u0026#39;s call to f to complete. // This is why the slow path falls back to a mutex, and why // the atomic.StoreUint32 must be delayed until after f returns. if atomic.LoadUint32(\u0026amp;o.done) == 0 { // Outlined slow-path to allow inlining of the fast-path. o.doSlow(f) } } func (o *Once) doSlow(f func()) { o.m.Lock() defer o.m.Unlock() if o.done == 0 { defer atomic.StoreUint32(\u0026amp;o.done, 1) f() } } 通过上面源码发现 我们可以借助这个实现只执行一次某个函数/方法 once.Do()的用法如下 1 2 3 4 5 6 var once sync.Once once.Do(func() { // 在这里执行安全的初始化 }) 完整示例 使用sync.Once包是安全地实现此目标的首选方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package singleton import ( \u0026#34;sync\u0026#34; ) var ( instance *singleton once sync.Once ) type singleton struct{} func GetInstance() *singleton { once.Do(func() { instance = \u0026amp;singleton{} }) return instance } 简单工厂模式(Simple Factory) ✔ 简单工厂并不是一个正式的设计模式 而是一种编程习惯 它通过一个工厂类来封装对象的创建逻辑 客户端只需要传递参数给工厂类 由工厂类决定创建哪种对象 特点 只有一个工厂类 负责创建所有产品 通道条件判断(如switch或if-else)来决定创建哪种产品 适用场景 产品种类少 且创建逻辑简单的场景 优点 简单易用 适合小型项目 缺点 不符合开闭原则(OCP) 新增产品时需要修改工厂类 开闭原则: 当需求发生变化时 可以通过增加新的代码来扩展系统的功能 而不是修改现有的代码\n示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package main import \u0026#34;fmt\u0026#34; type Product interface { Use() } type ProductA struct{} func (p *ProductA) Use() { fmt.Println(\u0026#34;Using Product A\u0026#34;) } type ProductB struct{} func (p *ProductB) Use() { fmt.Println(\u0026#34;Using Product B\u0026#34;) } func CreateProduct(productType string) Product { switch productType { case \u0026#34;A\u0026#34;: return \u0026amp;ProductA{} case \u0026#34;B\u0026#34;: return \u0026amp;ProductB{} default: return nil } } func main() { productA := CreateProduct(\u0026#34;A\u0026#34;) productA.Use() productB := CreateProduct(\u0026#34;B\u0026#34;) productB.Use() } 工厂方法模式(Factory Method) ✔ 上面的简单工厂模式 一个工厂就负责了多个产品的生产 工厂方法模式则是定义了一个创建对象的接口 但将具体的创建逻辑延迟到子类中 每个子类负责创建一种具体的产品 特点 每个产品对应一个工厂类 符合开闭原则 新增产品时只需增加新的工厂类 无需修改现有代码 将对象的实例化推迟到用于创建实例的专用函数 适用场景 产品种类多 且创建逻辑复杂的场景 优点 符合开闭原则 扩展性强 每个工厂只负责一种产品的创建 职责单一 缺点 类的数量会增加 系统复杂度提高 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package main import \u0026#34;fmt\u0026#34; type Database interface { Connect() string } type MySQL struct{} func (m MySQL) Connect() string { return \u0026#34;Connected to MySQL\u0026#34; } type PostgreSQL struct{} func (p PostgreSQL) Connect() string { return \u0026#34;Connected to PostgreSQL\u0026#34; } // DatabaseFactory工厂接口 type DatabaseFactory interface { CreateDatabase() Database } type MySQLFactory struct{} func (m MySQLFactory) CreateDatabase() Database { return MySQL{} } type PostgreSQLFactory struct{} func (p PostgreSQLFactory) CreateDatabase() Database { return PostgreSQL{} } func UseDatabaseFactory(factory DatabaseFactory) { db := factory.CreateDatabase() fmt.Println(db.Connect()) } func main() { UseDatabaseFactory(\u0026amp;MySQLFactory{}) UseDatabaseFactory(\u0026amp;PostgreSQLFactory{}) } 抽象工厂模式(Abstract Factory) ✘ 抽象工厂模式提供一个创建一系列相关或相互依赖对象的接口 而无需指定它们的具体类 它适用于需要创建一组相关产品的场景 特点 每个工厂类可以创建多个相关产品 强调产品族的概念 例如GUI库中的不同风格组件(Windows风格、Mac风格) 适用场景 需要创建一组相关对象的场景 优点 可以创建一组相关对象 保证对象之间的兼容性 符合开闭原则 扩展性强 缺点 类的数量会增加 系统复杂度提高 新增产品族或产品等级结构时 需要修改抽象工厂接口及其所有实现类 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 package main import \u0026#34;fmt\u0026#34; // 抽象层：数据库连接接口 type DBConnention interface { Connect() string } // 抽象层：数据库命令接口 type DBCommand interface { Execute(query string) string } // 具体产品：MySQL连接 type MySQLConnection struct{} func (m *MySQLConnection) Connect() string { return \u0026#34;Connected to MySQL\u0026#34; } // 具体产品：MySQL命令 type MySQLCommand struct{} func (m *MySQLCommand) Execute(query string) string { return fmt.Sprintf(\u0026#34;Executed MySQL query: %s\u0026#34;, query) } // 具体产品：Postgres连接 type PostgresSQLConnection struct{} func (p *PostgresSQLConnection) Connect() string { return \u0026#34;Connected to Postgres\u0026#34; } // 具体产品：PostgresSQL命令 type PostgresSQLCommand struct{} func (p *PostgresSQLCommand) Execute(query string) string { return fmt.Sprintf(\u0026#34;Executed PostgresSQL query: %s\u0026#34;, query) } // 抽象工厂接口 type DBFactory interface { CreateConnection() DBConnention CreateCommand() DBCommand } // 具体的MySQL工厂 type MySQLFactory struct{} func (m *MySQLFactory) CreateConnection() DBConnention { return \u0026amp;MySQLConnection{} } func (m *MySQLFactory) CreateCommand() DBCommand { return \u0026amp;MySQLCommand{} } // 具体的PostgresSQL工厂 type PostgresSQLFactory struct{} func (p *PostgresSQLFactory) CreateConnection() DBConnention { return \u0026amp;PostgresSQLConnection{} } func (p *PostgresSQLFactory) CreateCommand() DBCommand { return \u0026amp;PostgresSQLCommand{} } func UseDatabase(factory DBFactory) { connection := factory.CreateConnection() command := factory.CreateCommand() fmt.Println(connection.Connect()) fmt.Println(command.Execute(\u0026#34;SELECT * FROM table\u0026#34;)) } // 业务逻辑 func main() { UseDatabase(\u0026amp;MySQLFactory{}) UseDatabase(\u0026amp;PostgresSQLFactory{}) } 建造者模式(Builder) ✔ 用于分步构建复杂对象 建造者模式的核心思想是将一个复杂对象的构建过程与其表示分离 使得同样的构建过程可以创建不同的表示 建造者模式特别适用于以下场景 对象的构建过程非常复杂 包含多个步骤 对象的构建过程需要支持不同的配置或表示 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 package main import \u0026#34;fmt\u0026#34; type House struct { Walls string Roof string Windows string Doors string } func (h *House) Show() { fmt.Printf(\u0026#34;House with %s walls, %s roof, %s windows, and %s doors\\n\u0026#34;, h.Walls, h.Roof, h.Windows, h.Doors) } // 建造者接口 type HouseBuilder interface { BuildWalls() BuildRoof() BuildWindows() BuildDoors() GetHouse() *House } // 具体建造者 type ConcreateHouseBuilder struct { house *House } // 返回一个空House func NewConcreateHouseBuilder() *ConcreateHouseBuilder { return \u0026amp;ConcreateHouseBuilder{house: \u0026amp;House{}} } func (b *ConcreateHouseBuilder) BuildWalls() { b.house.Walls = \u0026#34;concrete\u0026#34; } func (b *ConcreateHouseBuilder) BuildRoof() { b.house.Roof = \u0026#34;tile\u0026#34; } func (b *ConcreateHouseBuilder) BuildWindows() { b.house.Windows = \u0026#34;glass\u0026#34; } func (b *ConcreateHouseBuilder) BuildDoors() { b.house.Doors = \u0026#34;wooden\u0026#34; } func (b *ConcreateHouseBuilder) GetHouse() *House { return b.house } // 指挥者 type Director struct { builder HouseBuilder } func NewDirector(builder HouseBuilder) *Director { return \u0026amp;Director{builder: builder} } func (d *Director) Construct() { d.builder.BuildWalls() d.builder.BuildRoof() d.builder.BuildWindows() d.builder.BuildDoors() } // 客户端代码 func main() { builder := NewConcreateHouseBuilder() // 常见具体构建者 director := NewDirector(builder) // 创建指挥者 director.Construct() // 指挥者构建产品 house := builder.GetHouse() // 获取最终产品 house.Show() } 原型模式(Prototype) ✘ 它通过复制现有对象来创建新对象 而不是通过新建类的方式 原型模式的核心思想是利用对象的克隆能力 避免重复初始化 特别适用于创建成本较高的对象 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package main import \u0026#34;fmt\u0026#34; // 原型接口 type Prototype interface { Clone() Prototype } // 具体原型 type ConcretePrototype struct { Name string Age int } func (p *ConcretePrototype) Clone() Prototype { // 创建一个新对象 并复制当前对象的属性 return \u0026amp;ConcretePrototype{ Name: p.Name, Age: p.Age, } } func (p *ConcretePrototype) String() string { return fmt.Sprintf(\u0026#34;Name: %s, Age: %d\u0026#34;, p.Name, p.Age) } func main() { // 创建原型对象 prototype := \u0026amp;ConcretePrototype{ Name: \u0026#34;Tom\u0026#34;, Age: 18, } // 克隆原型对象 clone := prototype.Clone().(*ConcretePrototype) // 修改克隆对象属性 clone.Name = \u0026#34;Jerry\u0026#34; clone.Age = 20 // 输出原型对象和克隆对象 fmt.Println(\u0026#34;Prototype:\u0026#34;, prototype) fmt.Println(\u0026#34;Clone:\u0026#34;, clone) } 注意事项 使用原型模式 如果有引用类型 则需要考虑深拷贝和浅拷贝的问题 浅拷贝只复制对象本身而不复制其引用的对象 深拷贝则会递归地复制整个对象图 这需要根据需求选择适当的拷贝方式 结构型模式 结构型模式Structural Pattern 它主要关注如何将类或对象组合成更大的结构 以便在不改变原有类或对象的情况下 实现新的功能或优化系统结构 结构型模式的核心思想是通过组合Composition而不是继承Inheritance来实现代码的复用和扩展 它们帮助开发者设计出灵活、可扩展的系统结构 同时降低类与类之间的耦合度 外观模式(Facade) ✔ 根据迪米特法则 如果两个类不必彼此直接通信 那么这两个类就不应当发生直接的相互作用 Facade模式也叫外观模式 是由GoF提出的23种设计模式中的一种 Facade模式为一组具有类似功能的类群 比如类库/子系统等等 提供一个一致的简单的界面 这个一致的简单的界面被称作facade 适用场景 复杂系统需要简单入口使用 客户端程序与多个子系统之间存在很大的依赖性 在层次化结构中 可以使用外观模式定义系统中每一层的入口 层与层之间不直接产生联系 而通过外观类建立联系 降低层之间的耦合度 优点 它对客户端屏蔽了子系统组件 减少了客户端所需处理的对象数目 并使得子系统使用起来更加容易 通过引入外观模式 客户端代码将变得很简单 与之关联的对象也很少 它实现了子系统与客户端之间的松耦合关系 这使得子系统的变化不会影响到调用它的客户端 只需要调整外观类即可 一个子系统的修改对其他子系统没有任何影响 缺点 不能很好地限制客户端直接使用子系统类 如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性 如果设计不当 增加新的子系统可能需要修改外观类的源代码 违背了开闭原则 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 package main import \u0026#34;fmt\u0026#34; type SubSystemA struct {} func (sa *SubSystemA) MethodA() { fmt.Println(\u0026#34;子系统方法A\u0026#34;) } type SubSystemB struct {} func (sb *SubSystemB) MethodB() { fmt.Println(\u0026#34;子系统方法B\u0026#34;) } type SubSystemC struct {} func (sc *SubSystemC) MethodC() { fmt.Println(\u0026#34;子系统方法C\u0026#34;) } type SubSystemD struct {} func (sd *SubSystemD) MethodD() { fmt.Println(\u0026#34;子系统方法D\u0026#34;) } // 外观模式 提供了一个外观类 简化成一个简单的接口供使用 type Facade struct { a *SubSystemA b *SubSystemB c *SubSystemC d *SubSystemD } func (f *Facade) MethodOne() { f.a.MethodA() f.b.MethodB() } func (f *Facade) MethodTwo() { f.c.MethodC() f.d.MethodD() } func main() { // 如果不用外观模式实现MethodA() 和 MethodB() sa := new(SubSystemA) sa.MethodA() sb := new(SubSystemB) sb.MethodB() fmt.Println(\u0026#34;-----------\u0026#34;) // 使用外观模式 f := Facade{ a: new(SubSystemA), b: new(SubSystemB), c: new(SubSystemC), d: new(SubSystemD), } // 调用外观包裹方法 f.MethodOne() } 示例2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 package main import \u0026#34;fmt\u0026#34; // 电视机 type TV struct {} func (t *TV) On() { fmt.Println(\u0026#34;打开 电视机\u0026#34;) } func (t *TV) Off() { fmt.Println(\u0026#34;关闭 电视机\u0026#34;) } // 音箱 type VoiceBox struct {} func (v *VoiceBox) On() { fmt.Println(\u0026#34;打开 音箱\u0026#34;) } func (v *VoiceBox) Off() { fmt.Println(\u0026#34;关闭 音箱\u0026#34;) } // 灯光 type Light struct {} func (l *Light) On() { fmt.Println(\u0026#34;打开 灯光\u0026#34;) } func (l *Light) Off() { fmt.Println(\u0026#34;关闭 灯光\u0026#34;) } // 游戏机 type Xbox struct {} func (x *Xbox) On() { fmt.Println(\u0026#34;打开 游戏机\u0026#34;) } func (x *Xbox) Off() { fmt.Println(\u0026#34;关闭 游戏机\u0026#34;) } // 麦克风 type MicroPhone struct {} func (m *MicroPhone) On() { fmt.Println(\u0026#34;打开 麦克风\u0026#34;) } func (m *MicroPhone) Off() { fmt.Println(\u0026#34;关闭 麦克风\u0026#34;) } // 投影仪 type Projector struct {} func (p *Projector) On() { fmt.Println(\u0026#34;打开 投影仪\u0026#34;) } func (p *Projector) Off() { fmt.Println(\u0026#34;关闭 投影仪\u0026#34;) } // 家庭影院(外观) type HomePlayerFacade struct { tv TV vb VoiceBox light Light xbox Xbox mp MicroPhone pro Projector } // KTV模式 func (hp *HomePlayerFacade) DoKTV() { fmt.Println(\u0026#34;家庭影院进入KTV模式\u0026#34;) hp.tv.On() hp.pro.On() hp.mp.On() hp.light.Off() hp.vb.On() } // 游戏模式 func (hp *HomePlayerFacade) DoGame() { fmt.Println(\u0026#34;家庭影院进入Game模式\u0026#34;) hp.tv.On() hp.light.On() hp.xbox.On() } func main() { homePlayer := new(HomePlayerFacade) homePlayer.DoKTV() fmt.Println(\u0026#34;------------\u0026#34;) homePlayer.DoGame() } 适配器模式(Adapter) ✔ 将一个类的接口转换成客户希望的另外一个接口 使得原本由于接口不兼容而不能一起工作的那些类可以一起工作 优点 将目标类和适配者类解耦 通过引入一个适配器类来重用现有的适配者类 无须修改原有结构 增加了类的透明性和复用性 将具体的业务实现过程封装在适配者类中 对于客户端类而言是透明的 而且提高了适配者的复用性 同一个适配者类可以在多个不同的系统中复用 灵活性和扩展性都非常好 可以很方便地更换适配器 也可以在不修改原有代码的基础上增加新的适配器类 完全符合开闭原则 缺点 适配器中置换适配者类的某些方法比较麻烦 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 package main import \u0026#34;fmt\u0026#34; // 适配的目标 type V5 interface { Use5V() } // 业务类 依赖V5接口 type Phone struct { v V5 } func NewPhone(v V5) *Phone { return \u0026amp;Phone{v} } func (p *Phone) Charge() { fmt.Println(\u0026#34;Phone进行充电...\u0026#34;) p.v.Use5V() } // 被适配的角色 适配者 type V220 struct{} func (v *V220) Use220V() { fmt.Println(\u0026#34;使用220V的电压\u0026#34;) } // 电源适配器 type Adapter struct { v220 *V220 } func (a *Adapter) Use5V() { fmt.Println(\u0026#34;使用适配器进行充电\u0026#34;) // 调用适配者的方法 a.v220.Use220V() } func NewAdapter(v220 *V220) *Adapter { return \u0026amp;Adapter{v220} } // ------- 业务逻辑层 ------- func main() { iphone := NewPhone(NewAdapter(new(V220))) iphone.Charge() } 代理模式(Proxy) ✔ 它通过提供一个代理对象来控制对另一个对象的访问 代理模式的核心思想是在不改变原始对象的情况下 通过代理对象来增强或限制对原始对象的访问 适用场景 延迟初始化 当对象的创建成本较高时 可以通过代理延迟对象的初始化 访问控制 通过代理对象限制对原始对象的访问权限 日志记录 通过代理对象记录对原始对象的访问日志 缓存 通过代理对象缓存原始对象的结果 避免重复计算 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 主题接口 type Subject interface { Request() } // 真实对象 type RealSubject struct{} func (r *RealSubject) Request() { fmt.Println(\u0026#34;RealSubject: Handling Request\u0026#34;) } // 代理对象 type Proxy struct { realSubject *RealSubject } func NewProxy() *Proxy { return \u0026amp;Proxy{} } func (p *Proxy) Request() { // 延迟初始化真实对象 if p.realSubject == nil { fmt.Println(\u0026#34;Proxy: Lazy Initialzing RealSubject\u0026#34;) p.realSubject = \u0026amp;RealSubject{} } // 访问控制 fmt.Println(\u0026#34;Proxy: Checking Access\u0026#34;) time.Sleep(time.Second) // 模拟访问控制逻辑 // 调用真实对象的方法 p.realSubject.Request() // 日志记录 fmt.Println(\u0026#34;Proxy: Logging Request\u0026#34;) } func main() { proxy := NewProxy() // 通过代理对象访问真实对象 proxy.Request() } 组合模式(Composite) ✘ 它允许你将对象组合成树形结构来表示部分-整体的层次关系 组合模式让客户端可以统一地处理单个对象和对象组合 适用场景 文件系统：如目录和文件的管理 可以通过组合模式将文件夹视为组合节点 文件视为叶子节点 组织结构：如公司内部的部门和员工关系 可以通过组合模式将部门视为组合节点 员工视为叶子节点 优点 简化客户端代码：客户端可以一致地对待单个对象和对象组合 而不需要关心它们的具体类型 增强灵活性：可以在不修改现有代码的情况下轻松添加新的组件或修改现有组件的结构 提高可扩展性：支持递归组合 使得复杂的层次结构易于构建和维护 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 package main import ( \u0026#34;fmt\u0026#34; ) // 组件接口：文件系统节点 type FileSystemNode interface { Display(indent string) } // 叶子节点：文件 type File struct { name string } func (f *File) Display(indent string) { fmt.Println(indent + f.name) } // 组合节点：文件夹 type Folder struct { name string children []FileSystemNode } func (f *Folder) Display(indent string) { fmt.Println(indent + f.name) for _, child := range f.children { child.Display(indent + \u0026#34; \u0026#34;) } } func (f *Folder) Add(child FileSystemNode) { f.children = append(f.children, child) } // 客户端代码 func main() { // 创建文件 file1 := \u0026amp;File{name: \u0026#34;file1.txt\u0026#34;} file2 := \u0026amp;File{name: \u0026#34;file2.txt\u0026#34;} file3 := \u0026amp;File{name: \u0026#34;file3.txt\u0026#34;} // 创建文件夹 folder1 := \u0026amp;Folder{name: \u0026#34;Folder1\u0026#34;} folder2 := \u0026amp;Folder{name: \u0026#34;Folder2\u0026#34;} // 将文件添加到文件夹 folder1.Add(file1) folder1.Add(file2) folder2.Add(file3) // 将文件夹添加到另一个文件夹 rootFolder := \u0026amp;Folder{name: \u0026#34;Root\u0026#34;} rootFolder.Add(folder1) rootFolder.Add(folder2) // 显示文件系统结构 rootFolder.Display(\u0026#34;\u0026#34;) } /* 输出： Root Folder1 file1.txt file2.txt Folder2 file3.txt */ 享元模式(Flyweight) ✘ 它通过共享对象来减少内存使用和提高性能 享元模式的核心思想是将对象的共享部分(内部状态)与不可共享部分(外部状态)分离 从而减少重复对象的创建 享元模式的核心思想 共享对象 享元模式通过共享相同的内在状态(内部状态)来减少内存使用 分离状态 将对象的状态分为内部状态(可共享)和外部状态(不可共享) 工厂管理 使用工厂模式来管理和复用享元对象 示例 在数据库操作中 创建和销毁连接是非常耗时的操作 为了提高性能 通常会使用连接池来管理数据库连接 连接池的核心思想是： 复用连接：从连接池中获取连接 使用完后将连接释放回连接池 而不是销毁 减少开销：避免频繁创建和销毁连接 从而提高性能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // 享元接口：数据库连接 type Connection interface { Execute(query string) } // 具体享元：数据库连接对象 type ConcreteConnection struct { id int } func (c *ConcreteConnection) Execute(query string) { fmt.Printf(\u0026#34;Connection %d executing query: %s\\n\u0026#34;, c.id, query) } // 享元工厂：连接池 type ConnectionPool struct { connections map[int]Connection mutex sync.Mutex nextID int } func NewConnectionPool() *ConnectionPool { return \u0026amp;ConnectionPool{ connections: make(map[int]Connection), nextID: 1, } } // 获取连接对象 func (p *ConnectionPool) GetConnection() Connection { p.mutex.Lock() defer p.mutex.Unlock() if len(p.connections) \u0026gt; 0 { for id, conn := range p.connections { delete(p.connections, id) return conn } } // 创建新的连接对象 conn := \u0026amp;ConcreteConnection{id: p.nextID} p.nextID++ return conn } // 将连接对象释放回连接池 以便其他客户端可以复用这个连接对象 func (p *ConnectionPool) ReleaseConnection(conn Connection) { p.mutex.Lock() defer p.mutex.Unlock() if c, ok := conn.(*ConcreteConnection); ok { p.connections[c.id] = c } } // 客户端代码 func main() { pool := NewConnectionPool() conn1 := pool.GetConnection() conn1.Execute(\u0026#34;SELECT * FROM users\u0026#34;) pool.ReleaseConnection(conn1) conn2 := pool.GetConnection() conn2.Execute(\u0026#34;SELECT * FROM orders\u0026#34;) pool.ReleaseConnection(conn2) } /* Connection 1 executing query: SELECT * FROM users Connection 1 executing query: SELECT * FROM orders */ 装饰模式(Decorator) ✔ 它允许你动态地为对象添加行为或职责 而不需要修改对象的原始类 通过引入装饰者类 可以在运行时灵活地组合不同的功能 而不需要创建大量的子类 装饰者模式的核心思想是将对象包装在一个或多个装饰者中 每个装饰者都可以在调用被装饰对象的方法之前或之后添加额外的行为 优点 动态扩展功能 你可以在运行时为请求处理器添加日志记录和性能监控功能 而无需修改核心请求处理器的代码 单一职责原则 每个装饰器只负责一个特定的功能(如日志记录或性能监控) 符合单一职责原则 灵活性 可以轻松地添加或移除装饰器 而不会影响其他部分的代码 示例 假设你正在开发一个Web服务 其中有一个核心功能是处理用户请求 现在 你需要在不修改核心功能代码的情况下 为请求处理添加以下功能 日志记录：记录每个请求的详细信息 性能监控：记录每个请求的处理时间 使用装饰器模式 你可以轻松地实现这些功能 而无需修改原始请求处理逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 组件接口：请求处理器 type RequestHandler interface { HandleRequest(url string) string } type CoreRequestHandler struct{} func (handler *CoreRequestHandler) HandleRequest(url string) string { time.Sleep(100 * time.Millisecond) return fmt.Sprintf(\u0026#34;Response from %s\u0026#34;, url) } // 装饰器: 日志记录 type LoggingDecorator struct { handler RequestHandler } func (l *LoggingDecorator) HandleRequest(url string) string { fmt.Printf(\u0026#34;LoggingDecorator: Request to %s\\n\u0026#34;, url) response := l.handler.HandleRequest(url) fmt.Printf(\u0026#34;Logging: Response for %s: %s\\n\u0026#34;, url, response) return response } // 装饰器：性能监控 type PerformanceMonitorDecorator struct { handler RequestHandler } func (p *PerformanceMonitorDecorator) HandleRequest(url string) string { // 记录开始时间 start := time.Now() // 调用原始处理器 response := p.handler.HandleRequest(url) // 记录处理时间 duration := time.Since(start) fmt.Printf(\u0026#34;Performance: Request for %s took %v\\n\u0026#34;, url, duration) return response } func main() { // 创建请求处理器 handler := \u0026amp;CoreRequestHandler{} // 添加日志记录 loggingHandler := \u0026amp;LoggingDecorator{handler: handler} // 添加性能监控 monitorHandler := \u0026amp;PerformanceMonitorDecorator{handler: loggingHandler} // 处理请求 fmt.Println(monitorHandler.HandleRequest(\u0026#34;http://www.baidu.com\u0026#34;)) } 桥模式(Bridge) ✘ 它的核心思想是将抽象部分与实现部分分离 使它们可以独立变化 通过这种方式 桥接模式能够避免类的数量爆炸(即类的组合呈指数增长) 同时提高代码的可扩展性和可维护性 示例 假设你有两台电脑：一台 Mac 和一台 Windows 还有两台打印机：爱普生和惠普 这两台电脑和打印机可能会任意组合使用 刚开始功能会这样写 windows组合爱普生和惠普 mac组合爱普生和惠普 打印就调用自己的print方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import \u0026#34;fmt\u0026#34; // Mac + Epson type MacEpson struct{} func (m *MacEpson) Print() { fmt.Println(\u0026#34;Print request for mac\u0026#34;) fmt.Println(\u0026#34;Printing by a EPSON Printer\u0026#34;) } // Mac + HP type MacHp struct{} func (m *MacHp) Print() { fmt.Println(\u0026#34;Print request for mac\u0026#34;) fmt.Println(\u0026#34;Printing by a HP Printer\u0026#34;) } // Windows + Epson type WindowsEpson struct{} func (w *WindowsEpson) Print() { fmt.Println(\u0026#34;Print request for windows\u0026#34;) fmt.Println(\u0026#34;Printing by a EPSON Printer\u0026#34;) } // Windows + HP type WindowsHp struct{} func (w *WindowsHp) Print() { fmt.Println(\u0026#34;Print request for windows\u0026#34;) fmt.Println(\u0026#34;Printing by a HP Printer\u0026#34;) } 但是 如果引入新的打印机 代码量会成倍增长 所以 我们需要把计算机和打印机解耦 计算机的print的方法 就桥接到选择的打印机的print方法上 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 package main import \u0026#34;fmt\u0026#34; // 定义Printer接口 type Printer interface { PrintFile() } // 定义Epson打印机 type Epson struct{} func (e *Epson) PrintFile() { fmt.Println(\u0026#34;Printing by Epson printer\u0026#34;) } // 定义惠普打印机 type HP struct{} func (h *HP) PrintFile() { fmt.Println(\u0026#34;Printing by HP printer\u0026#34;) } // 定义Computer接口 type Computer interface { Print() SetPrinter(Printer) } // 定义Mac计算机 type Mac struct { printer Printer } func (m *Mac) Print() { fmt.Println(\u0026#34;Print request for Mac\u0026#34;) m.printer.PrintFile() } func (m *Mac) SetPrinter(p Printer) { m.printer = p } // 定义windows计算机 type Windows struct { printer Printer } func (w *Windows) Print() { fmt.Println(\u0026#34;Print request for Windows\u0026#34;) w.printer.PrintFile() } func (w *Windows) SetPrinter(p Printer) { w.printer = p } func main() { // 创建打印机实例 hpPrinter := \u0026amp;HP{} epsonPrinter := \u0026amp;Epson{} // 创建计算机实例 macComputer := \u0026amp;Mac{} winComputer := \u0026amp;Windows{} // Mac 使用 HP 打印机 macComputer.SetPrinter(hpPrinter) macComputer.Print() fmt.Println() // Mac 使用 Epson 打印机 macComputer.SetPrinter(epsonPrinter) macComputer.Print() fmt.Println() // Windows 使用 HP 打印机 winComputer.SetPrinter(hpPrinter) winComputer.Print() fmt.Println() // Windows 使用 Epson 打印机 winComputer.SetPrinter(epsonPrinter) winComputer.Print() fmt.Println() } 优点 解耦 抽象部分和实现部分可以独立变化 互不影响 修改实现部分不会影响抽象部分的代码 灵活性 可以动态地切换实现部分(例如 运行时更换实现) 可扩展性 新增抽象部分或实现部分时 不需要修改现有代码 避免类爆炸 通过组合代替继承 避免了类的数量呈指数增长 行为型模式 行为型模式Behavioral pattern 它主要关注对象之间的职责分配和通信方式 行为型模式的核心思想是通过定义对象之间的交互方式 来更好地实现系统的功能 同时降低对象之间的耦合度 中介者模式(Mediator) 它通过引入一个中介者对象来封装一组对象之间的交互 中介者模式的核心思想是 将对象之间的复杂交互集中到一个中介者对象中 从而减少对象之间的直接耦合 优点 减少耦合：对象之间不直接通信 而是通过中介者进行交互 减少了对象之间的耦合 集中控制：将对象之间的交互逻辑集中到中介者中 便于维护和扩展 简化对象职责：每个对象只需要关注自己的行为 而不需要知道其他对象的存在 示例 假设我们有一个聊天室系统 用户(同事类)之间通过聊天室(中介者)发送消息 用户之间不直接通信 而是通过聊天室来转发消息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 package main import \u0026#34;fmt\u0026#34; // 定义中介者接口 type Mediator interface { SendMessage(message string, sender Colleague) } // 具体中介者 type ChatRoom struct { users []Colleague } func (c *ChatRoom) Register(user Colleague) { c.users = append(c.users, user) } func (c *ChatRoom) SendMessage(message string, sender Colleague) { for _, user := range c.users { if user != sender { user.Receive(message) } } } // 定义同事类接口 type Colleague interface { Send(message string) Receive(message string) } // 具体同事类 type User struct { name string mediator Mediator } func (u *User) Send(message string) { fmt.Printf(\u0026#34;%s sends: %s\\n\u0026#34;, u.name, message) u.mediator.SendMessage(message, u) } func (u *User) Receive(message string) { fmt.Printf(\u0026#34;%s receives: %s\\n\u0026#34;, u.name, message) } func main() { // 创建中介者 chatRoom := \u0026amp;ChatRoom{} // 创建用户 alice := \u0026amp;User{name: \u0026#34;Alice\u0026#34;, mediator: chatRoom} bob := \u0026amp;User{name: \u0026#34;Bob\u0026#34;, mediator: chatRoom} charlie := \u0026amp;User{name: \u0026#34;Charlie\u0026#34;, mediator: chatRoom} // 注册用户到聊天室 chatRoom.Register(alice) chatRoom.Register(bob) chatRoom.Register(charlie) // 用户发送消息 alice.Send(\u0026#34;Hello, everyone!\u0026#34;) bob.Send(\u0026#34;Hi, Alice!\u0026#34;) charlie.Send(\u0026#34;Hey, Bob!\u0026#34;) } 观察者模式(Observer) ✔ 它定义了对象之间的一对多依赖关系 当一个对象(被观察者)的状态发生改变时 所有依赖它的对象(观察者)都会收到通知并自动更新 观察者模式的核心思想是 解耦被观察者和观察者 使得它们可以独立变化 优点 解耦：被观察者和观察者之间是松耦合的 它们可以独立变化 支持动态注册和移除观察者：可以在运行时动态地注册和移除观察者 符合开闭原则：新增观察者时 不需要修改被观察者的代码 示例 假设我们有一个天气站(被观察者) 当天气数据更新时 通知多个显示设备(观察者)更新显示内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 package main import \u0026#34;fmt\u0026#34; // 定义观察者接口 type Observer interface { Update(temperature float64, humidity float64, pressure float64) } // 定义被观察者接口 type Subject interface { RegisterObserver(o Observer) RemoveObserver(o Observer) NotifyObservers() } // 具体被观察者 type WeatherData struct { observers []Observer temperature float64 humidity float64 pressure float64 } func (w *WeatherData) RegisterObserver(o Observer) { w.observers = append(w.observers, o) } func (w *WeatherData) RemoveObserver(o Observer) { for i, observer := range w.observers { if observer == o { w.observers = append(w.observers[:i], w.observers[i+1:]...) break } } } func (w *WeatherData) NotifyObservers() { for _, observer := range w.observers { observer.Update(w.temperature, w.humidity, w.pressure) } } func (w *WeatherData) SetMeasurements(temperature float64, humidity float64, pressure float64) { w.temperature = temperature w.humidity = humidity w.pressure = pressure w.NotifyObservers() } // 具体观察者 type DisplayDevice struct { name string } func (d *DisplayDevice) Update(temperature float64, humidity float64, pressure float64) { fmt.Printf(\u0026#34;%s: Temperature=%.2f, Humidity=%.2f, Pressure=%.2f\\n\u0026#34;, d.name, temperature, humidity, pressure) } func main() { // 创建被观察者 weatherData := \u0026amp;WeatherData{} // 创建观察者 display1 := \u0026amp;DisplayDevice{name: \u0026#34;Display 1\u0026#34;} display2 := \u0026amp;DisplayDevice{name: \u0026#34;Display 2\u0026#34;} // 注册观察者 weatherData.RegisterObserver(display1) weatherData.RegisterObserver(display2) // 更新天气数据并通知观察者 weatherData.SetMeasurements(25.0, 65.0, 1013.0) weatherData.SetMeasurements(26.5, 70.0, 1012.5) // 移除一个观察者 weatherData.RemoveObserver(display1) // 再次更新天气数据 weatherData.SetMeasurements(27.0, 68.0, 1011.0) } 命令模式(Command) ✔ 它将请求封装为一个对象 从而使你可以用不同的请求对客户进行参数化 并且支持请求的排队、记录日志、撤销操作等功能 核心思想 将请求封装为对象：将每个请求(如方法调用)封装为一个独立的对象 解耦请求的发送者和接收者：发送者不需要知道接收者的具体实现 只需要通过命令对象来执行请求 支持扩展：可以轻松地添加新的命令 而不需要修改现有代码 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 定义命令接口 type Command interface { Execute() } // 具体命令 表示打印消息 type PrintCommand struct { message string } func (c *PrintCommand) Execute() { fmt.Println(\u0026#34;Executing PrintCommand:\u0026#34;, c.message) } // 具体命令 表示发送邮件 type EmailCommand struct { to string subject string body string } func (c *EmailCommand) Execute() { fmt.Printf(\u0026#34;Executing EmailCommand: Sending email to %s\\n\u0026#34;, c.to) fmt.Printf(\u0026#34;Subject: %s\\n\u0026#34;, c.subject) fmt.Printf(\u0026#34;Body: %s\\n\u0026#34;, c.body) } // 任务队列 用于存储和执行命令 type TaskQueue struct { commands []Command } func (tq *TaskQueue) AddCommand(cmd Command) { tq.commands = append(tq.commands, cmd) } func (tq *TaskQueue) ProcessCommands() { for _, cmd := range tq.commands { cmd.Execute() time.Sleep(1 * time.Second) // 模拟任务执行的时间 } tq.commands = nil // 清空任务队列 } func main() { // 创建任务队列 taskQueue := \u0026amp;TaskQueue{} // 添加任务到队列 taskQueue.AddCommand(\u0026amp;PrintCommand{message: \u0026#34;Hello, World!\u0026#34;}) taskQueue.AddCommand(\u0026amp;EmailCommand{ to: \u0026#34;user@example.com\u0026#34;, subject: \u0026#34;Welcome\u0026#34;, body: \u0026#34;Thank you for signing up!\u0026#34;, }) taskQueue.AddCommand(\u0026amp;PrintCommand{message: \u0026#34;Task queue is running...\u0026#34;}) // 处理任务队列 fmt.Println(\u0026#34;Processing task queue:\u0026#34;) taskQueue.ProcessCommands() // 添加更多任务 taskQueue.AddCommand(\u0026amp;PrintCommand{message: \u0026#34;Another task\u0026#34;}) taskQueue.AddCommand(\u0026amp;EmailCommand{ to: \u0026#34;admin@example.com\u0026#34;, subject: \u0026#34;Report\u0026#34;, body: \u0026#34;Here is the daily report.\u0026#34;, }) // 再次处理任务队列 fmt.Println(\u0026#34;\\nProcessing task queue again:\u0026#34;) taskQueue.ProcessCommands() } 迭代器模式(Iterator) 它提供了一种方法顺序访问一个聚合对象中的各个元素 而又不需要暴露该对象的内部表示 迭代器模式的核心思想是将遍历逻辑从聚合对象中分离出来 使得聚合对象和遍历逻辑可以独立变化 适用场景 集合类库：如Go的 slice、map 等集合类型 可以通过迭代器模式提供统一的遍历接口 数据库查询结果：数据库查询结果可以封装为一个聚合对象 并提供迭代器遍历查询结果 文件系统遍历：文件系统中的目录和文件可以封装为一个聚合对象 并提供迭代器遍历文件系统 树形结构遍历：树形结构(如二叉树、多叉树)可以提供多种遍历方式(如深度优先、广度优先) 示例 假设我们有一个集合类BookCollection 它包含多本书 我们需要实现一个迭代器 用于遍历这个集合 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 package main import \u0026#34;fmt\u0026#34; // 定义书籍结构体 type Book struct { Title string Author string } // 定义迭代器接口 type Iterator interface { HasNext() bool Next() *Book } // 具体迭代器 type BookIterator struct { books []*Book position int } func (b *BookIterator) HasNext() bool { return b.position \u0026lt; len(b.books) } func (b *BookIterator) Next() *Book { if b.HasNext() { book := b.books[b.position] b.position++ return book } return nil } // 定义聚合接口 type Aggregate interface { CreateIterator() Iterator } // 具体聚合 type BookCollection struct { books []*Book } func (b *BookCollection) CreateIterator() Iterator { return \u0026amp;BookIterator{books: b.books} } func main() { // 创建书籍集合 collection := \u0026amp;BookCollection{ books: []*Book{ {Title: \u0026#34;The Go Programming Language\u0026#34;, Author: \u0026#34;Alan A. A. Donovan\u0026#34;}, {Title: \u0026#34;Design Patterns\u0026#34;, Author: \u0026#34;Erich Gamma\u0026#34;}, {Title: \u0026#34;Clean Code\u0026#34;, Author: \u0026#34;Robert C. Martin\u0026#34;}, }, } // 创建迭代器 iterator := collection.CreateIterator() // 遍历集合 for iterator.HasNext() { book := iterator.Next() fmt.Printf(\u0026#34;Title: %s, Author: %s\\n\u0026#34;, book.Title, book.Author) } } 模板方法模式(Template Method) ✔ 它定义了一个算法的骨架 并将某些步骤延迟到子类中实现 模板方法模式的核心思想是 将算法的通用部分放在父类中 而将可变部分交给子类实现 通过模板方法模式 可以避免代码重复 并确保算法的结构不变 适用场景 框架设计 如Web框架中的请求处理流程(初始化、处理请求、返回响应等) 工作流引擎 如订单处理流程(创建订单、支付订单、发货订单等) 测试框架 如测试用例的执行流程(初始化、执行测试、清理资源等) 游戏开发 如游戏角色的行为流程(移动、攻击、防御等) 优点 代码复用 将算法的通用部分放在父类中 避免了代码重复 扩展性 新增子类时 只需要实现抽象方法 而不需要修改父类的代码 控制算法结构 父类控制算法的结构 确保算法的步骤不会被子类改变 示例 假设我们有一个饮料制作系统 支持制作咖啡和茶 咖啡和茶的制作过程有一些共同的步骤(如烧水、倒入杯子) 也有一些不同的步骤(如冲泡咖啡、泡茶) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 package main import \u0026#34;fmt\u0026#34; // 抽象类，定义饮料制作的模板方法 type Beverage interface { BoilWater() // 烧水 Brew() // 冲泡 PourInCup() // 倒入杯子 AddCondiments() // 添加调料 WantCondiments() bool // 是否添加调料（钩子方法） } // 模板方法 func MakeBeverage(b Beverage) { b.BoilWater() b.Brew() b.PourInCup() if b.WantCondiments() { b.AddCondiments() } } // 具体类：咖啡 type Coffee struct{} func (c *Coffee) BoilWater() { fmt.Println(\u0026#34;Boiling water\u0026#34;) } func (c *Coffee) Brew() { fmt.Println(\u0026#34;Brewing coffee\u0026#34;) } func (c *Coffee) PourInCup() { fmt.Println(\u0026#34;Pouring coffee into cup\u0026#34;) } func (c *Coffee) AddCondiments() { fmt.Println(\u0026#34;Adding sugar and milk\u0026#34;) } func (c *Coffee) WantCondiments() bool { return true } // 具体类：茶 type Tea struct{} func (t *Tea) BoilWater() { fmt.Println(\u0026#34;Boiling water\u0026#34;) } func (t *Tea) Brew() { fmt.Println(\u0026#34;Steeping tea\u0026#34;) } func (t *Tea) PourInCup() { fmt.Println(\u0026#34;Pouring tea into cup\u0026#34;) } func (t *Tea) AddCondiments() { fmt.Println(\u0026#34;Adding lemon\u0026#34;) } func (t *Tea) WantCondiments() bool { return false } func main() { // 制作咖啡 fmt.Println(\u0026#34;Making coffee:\u0026#34;) coffee := \u0026amp;Coffee{} MakeBeverage(coffee) // 制作茶 fmt.Println(\u0026#34;\\nMaking tea:\u0026#34;) tea := \u0026amp;Tea{} MakeBeverage(tea) } 策略模式(Strategy) ✔ 它定义了一系列算法 并将每个算法封装起来 使它们可以互相替换 策略模式的核心思想是将算法的使用与算法的实现分离 从而使得算法可以独立于客户端而变化 通过策略模式 可以在运行时动态地选择算法 而不需要修改客户端代码 适用场景 支付系统：如示例所示 支持多种支付方式 排序算法：支持多种排序算法(如快速排序、归并排序、冒泡排序等) 压缩算法：支持多种压缩算法(如ZIP、RAR、7z等) 路由算法：支持多种路由算法(如最短路径、最快路径、最少收费路径等) 优点 解耦：将算法的使用与算法的实现分离 使得算法可以独立于客户端而变化 易于扩展：新增算法时 只需要添加新的策略类 而不需要修改现有代码 动态选择算法：可以在运行时动态地选择算法 而不需要修改客户端代码 示例 假设我们有一个支付系统 支持多种支付方式(如信用卡支付、支付宝支付、微信支付等) 我们可以使用策略模式来实现支付方式的选择 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 package main import \u0026#34;fmt\u0026#34; // 定义策略接口 type PaymentStrategy interface { Pay(amount float64) } // 具体策略：信用卡支付 type CreditCardPayment struct{} func (c *CreditCardPayment) Pay(amount float64) { fmt.Printf(\u0026#34;Paying %.2f using Credit Card\\n\u0026#34;, amount) } // 具体策略：支付宝支付 type AlipayPayment struct{} func (a *AlipayPayment) Pay(amount float64) { fmt.Printf(\u0026#34;Paying %.2f using Alipay\\n\u0026#34;, amount) } // 具体策略：微信支付 type WechatPayment struct{} func (w *WechatPayment) Pay(amount float64) { fmt.Printf(\u0026#34;Paying %.2f using Wechat Pay\\n\u0026#34;, amount) } // 上下文 type PaymentContext struct { strategy PaymentStrategy } func (p *PaymentContext) SetStrategy(strategy PaymentStrategy) { p.strategy = strategy } func (p *PaymentContext) ExecutePayment(amount float64) { p.strategy.Pay(amount) } func main() { // 创建上下文 context := \u0026amp;PaymentContext{} // 使用信用卡支付 context.SetStrategy(\u0026amp;CreditCardPayment{}) context.ExecutePayment(100.0) // 输出: Paying 100.00 using Credit Card // 使用支付宝支付 context.SetStrategy(\u0026amp;AlipayPayment{}) context.ExecutePayment(200.0) // 输出: Paying 200.00 using Alipay // 使用微信支付 context.SetStrategy(\u0026amp;WechatPayment{}) context.ExecutePayment(300.0) // 输出: Paying 300.00 using Wechat Pay } 状态模式(State) 它允许对象在其内部状态改变时改变其行为 状态模式的核心思想是将对象的状态封装成独立的类 并将对象的行为委托给当前状态对象 通过状态模式 可以将复杂的条件逻辑分散到多个状态类中 从而使得代码更加清晰和易于维护 优点 清晰的状态转换逻辑：将状态转换逻辑分散到各个状态类中 避免了复杂的条件语句 符合开闭原则：新增状态时 只需要添加新的状态类 而不需要修改现有代码 易于扩展：可以轻松地添加新的状态和行为 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import \u0026#34;fmt\u0026#34; // 定义状态接口 type State interface { PressSwitch(context *Context) } // 上下文 type Context struct { state State } func (c *Context) SetState(state State) { c.state = state } func (c *Context) PressSwitch() { c.state.PressSwitch(c) } // 具体状态：开 type OnState struct{} func (o *OnState) PressSwitch(context *Context) { fmt.Println(\u0026#34;Turning the light off...\u0026#34;) context.SetState(\u0026amp;OffState{}) } // 具体状态：关 type OffState struct{} func (o *OffState) PressSwitch(context *Context) { fmt.Println(\u0026#34;Turning the light on...\u0026#34;) context.SetState(\u0026amp;OnState{}) } func main() { // 创建上下文并设置初始状态 context := \u0026amp;Context{state: \u0026amp;OffState{}} // 按下开关 context.PressSwitch() // 输出: Turning the light on... context.PressSwitch() // 输出: Turning the light off... context.PressSwitch() // 输出: Turning the light on... } 备忘录模式(Memento) 它允许在不破坏封装性的前提下 捕获并外部化一个对象的内部状态 以便稍后可以将该对象恢复到之前的状态 备忘录模式的核心思想是 将对象的状态保存到一个备忘录对象中 并在需要时从备忘录中恢复状态 优点 这种方式非常适合需要支持撤销操作或状态管理的场景 比如文本编辑器、游戏存档、事务回滚等 在Go语言中 备忘录模式可以通过接口和结构体的组合来实现 代码简洁且易于扩展 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 package main import \u0026#34;fmt\u0026#34; // 定义备忘录接口 type Memento interface { GetState() string } // 具体备忘录 type TextMemento struct { state string } func (t *TextMemento) GetState() string { return t.state } // 原发器 type Originator struct { state string } func (o *Originator) SetState(state string) { o.state = state } func (o *Originator) GetState() string { return o.state } func (o *Originator) CreateMemento() Memento { return \u0026amp;TextMemento{state: o.state} } func (o *Originator) RestoreMemento(m Memento) { o.state = m.GetState() } // 管理者 type Caretaker struct { mementos []Memento } func (c *Caretaker) AddMemento(m Memento) { c.mementos = append(c.mementos, m) } func (c *Caretaker) GetMemento(index int) Memento { if index \u0026lt; len(c.mementos) { return c.mementos[index] } return nil } func main() { // 创建原发器 editor := \u0026amp;Originator{} // 创建管理者 caretaker := \u0026amp;Caretaker{} // 编辑文本并保存状态 editor.SetState(\u0026#34;State 1\u0026#34;) caretaker.AddMemento(editor.CreateMemento()) // 创建一个备忘录对象，保存当前状态。 editor.SetState(\u0026#34;State 2\u0026#34;) caretaker.AddMemento(editor.CreateMemento()) editor.SetState(\u0026#34;State 3\u0026#34;) caretaker.AddMemento(editor.CreateMemento()) fmt.Println(editor.GetState()) // 这个时候的状态已经是 State 3 // 恢复到之前的状态 editor.RestoreMemento(caretaker.GetMemento(1)) fmt.Println(\u0026#34;Restored State:\u0026#34;, editor.GetState()) // 输出: Restored State: State 2 editor.RestoreMemento(caretaker.GetMemento(0)) fmt.Println(\u0026#34;Restored State:\u0026#34;, editor.GetState()) // 输出: Restored State: State 1 } 解释器模式(Interpreter) 它定义了一种语言的语法表示 并提供了一个解释器来解释这种语法 解释器模式通常用于处理类似编程语言、查询语言、规则引擎等场景 核心思想 定义语法规则：将语言的语法规则表示为一个抽象语法树(AST) 解释执行：通过解释器遍历抽象语法树 执行相应的操作 抽象语法树 抽象语法树(Abstract Syntax Tree-AST)是编译器和解释器中的一个核心概念 它是一种树形数据结构 用于表示源代码的语法结构 AST 之所以被称为抽象语法树 是因为它抽象掉了源代码中的一些具体细节 只保留了程序的逻辑结构 为什么叫 抽象语法树 抽象(Abstract) AST 并不包含源代码中的所有细节 比如括号、分号、空格等 它只关注程序的逻辑结构 例如 表达式 2 * (3 + 4) 的AST会抽象掉括号 只保留运算符和操作数的层次关系 语法(Syntax) AST 表示的是源代码的语法结构 而不是语义(即程序的含义) 例如 AST 可以表示一个if语句的语法结构 但不会解释if语句的具体行为 树(Tree) AST是一种树形数据结构 每个节点表示一个语法结构(如表达式、语句、函数等) 树的层次结构反映了源代码的嵌套关系 比如： 1 2 3 4 5 if x \u0026gt; 0 { print(Positive) } else { print(Non-positive) } 对应的AST如下: 1 2 3 4 5 6 7 8 9 10 11 12 13 IfStatement ├── Condition: BinaryExpression │ ├── Left: Identifier (x) │ ├── Operator: \u0026gt; │ └── Right: Number (0) ├── ThenBlock: BlockStatement │ └── Expression: CallExpression │ ├── Function: Identifier (print) │ └── Arguments: StringLiteral (\u0026#34;Positive\u0026#34;) └── ElseBlock: BlockStatement └── Expression: CallExpression ├── Function: Identifier (print) └── Arguments: StringLiteral (\u0026#34;Non-positive\u0026#34;) 适用场景 数据库查询引擎：如 MySQL、PostgreSQL 等数据库的查询解析和执行 规则引擎：如业务规则引擎 用于解析和执行规则 模板引擎：如Go的text/template用于解析和执行模板 数学表达式计算：如计算器应用程序 用于解析和计算数学表达式 示例 以Go语言里面的模板字符串为例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package main import ( \u0026#34;os\u0026#34; \u0026#34;text/template\u0026#34; ) func main() { // 定义模板字符串 const tmpl = `Hello, {{.Name}}! You are {{.Age}} years old.` // 解析模板 t, err := template.New(\u0026#34;example\u0026#34;).Parse(tmpl) if err != nil { panic(err) } // 定义数据 data := struct { Name string Age int }{ Name: \u0026#34;Alice\u0026#34;, Age: 25, } // 执行模板并输出结果 err = t.Execute(os.Stdout, data) if err != nil { panic(err) } } 这个是解释器模式的应用 我们需要了解内部的原理 然后自己手搓一个这样的模板字符串解析器出来 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) // 定义上下文 存储模板数据 type Context struct { Data map[string]interface{} } // 定义抽象表达式接口 type Expression interface { Interpret(ctx *Context) string } // 是文本表达式 表示普通文本 type TextExpression struct { text string } func (t *TextExpression) Interpret(ctx *Context) string { return t.text } // 是变量表达式 表示变量替换 type VariableExpression struct { key string } func (v *VariableExpression) Interpret(ctx *Context) string { value, ok := ctx.Data[v.key] if !ok { return \u0026#34;\u0026#34; } return fmt.Sprintf(\u0026#34;%v\u0026#34;, value) } // 是模板 包含多个表达式 type Template struct { expressions []Expression } func (t *Template) Interpret(ctx *Context) string { var result strings.Builder for _, expr := range t.expressions { result.WriteString(expr.Interpret(ctx)) } return result.String() } // 解析模板字符串并构建抽象语法树 func ParseTemplate(tmpl string) *Template { template := \u0026amp;Template{} start := 0 for { // 查找变量表达式的起始位置 startVar := strings.Index(tmpl[start:], \u0026#34;{{\u0026#34;) if startVar == -1 { // 如果没有变量表达式，剩下的都是普通文本 template.expressions = append(template.expressions, \u0026amp;TextExpression{text: tmpl[start:]}) break } // 添加普通文本 template.expressions = append(template.expressions, \u0026amp;TextExpression{text: tmpl[start : start+startVar]}) // 查找变量表达式的结束位置 endVar := strings.Index(tmpl[start+startVar:], \u0026#34;}}\u0026#34;) if endVar == -1 { // 如果没有结束符，直接退出 break } // 解析变量表达式 key := strings.TrimSpace(tmpl[start+startVar+2 : start+startVar+endVar]) template.expressions = append(template.expressions, \u0026amp;VariableExpression{key: key}) // 更新起始位置 start = start + startVar + endVar + 2 } return template } func main() { // 定义模板字符串 tmpl := \u0026#34;Hello, {{Name}}! You are {{Age}} years old.\u0026#34; // 解析模板并构建抽象语法树 template := ParseTemplate(tmpl) // 定义上下文数据 ctx := \u0026amp;Context{ Data: map[string]interface{}{ \u0026#34;Name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;Age\u0026#34;: 25, }, } // 解释执行模板并输出结果 result := template.Interpret(ctx) fmt.Println(result) // 输出: Hello, Alice! You are 25 years old. } 职责链模式(Chain of Responsibility) 是一种行为设计模式 它允许多个对象有机会处理请求 从而避免请求的发送者与接收者之间的耦合 责任链模式将这些对象连成一条链 并沿着这条链传递请求 直到有对象处理它为止 核心思想 解耦请求发送者和接收者：请求的发送者不需要知道具体由哪个对象处理请求 只需要将请求发送到链上即可 动态组合处理逻辑：可以动态地组合处理者 灵活地调整处理顺序或增加新的处理者 每个处理者只关心自己的职责：每个处理者只处理自己能处理的请求 不能处理的请求会传递给下一个处理者 适用场景 当一个请求需要经过多个对象处理 但具体由哪个对象处理不确定时 当需要动态指定处理请求的对象时 当希望避免请求发送者与接收者之间的紧密耦合时 实际应用场景 中间件 审批流程 示例 实现一下gin的中间件功能 中间件自己可以处理请求 可以拦截 可以放行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) // 模拟Gin的上下文 type Context struct { Request *http.Request Writer http.ResponseWriter handlers []HandlerFunc // 责任链中的处理函数 index int // 当前执行的处理函数索引 } // 定义处理函数类型 type HandlerFunc func(c *Context) // 调用责任链中的下一个处理函数 func (c *Context) Next() { c.index++ if c.index \u0026lt; len(c.handlers) { c.handlers[c.index](c) } } // 终止责任链的执行 func (c *Context) Abort() { c.index = len(c.handlers) // 直接跳到末尾 不再执行后续处理函数 } // 模拟Gin的引擎 type Engine struct { handlers []HandlerFunc // 全局中间件和责任链 } // 添加中间件到责任链 func (e *Engine) Use(middleware HandlerFunc) { e.handlers = append(e.handlers, middleware) } // 实现http.Handler接口 func (e *Engine) ServeHTTP(w http.ResponseWriter, r *http.Request) { c := \u0026amp;Context{ Request: r, Writer: w, handlers: e.handlers, index: -1, } c.Next() // 开始执行责任链 } // 示例中间件 1：日志记录 func LoggingMiddleware(c *Context) { fmt.Printf(\u0026#34;Request: %s %s\\n\u0026#34;, c.Request.Method, c.Request.URL.Path) c.Next() // 传递给下一个中间件 } // 示例中间件 2：认证检查 func AuthMiddleware(c *Context) { token := c.Request.Header.Get(\u0026#34;Authorization\u0026#34;) if token != \u0026#34;valid-token\u0026#34; { c.Writer.WriteHeader(http.StatusUnauthorized) c.Writer.Write([]byte(\u0026#34;Unauthorized\u0026#34;)) c.Abort() // 终止责任链 return } c.Next() // 传递给下一个中间件 } // 示例中间件 3：请求处理 func HelloHandler(c *Context) { c.Writer.WriteHeader(http.StatusOK) c.Writer.Write([]byte(\u0026#34;Hello, World!\u0026#34;)) } func main() { // 创建引擎 engine := \u0026amp;Engine{} // 添加中间件到责任链 engine.Use(LoggingMiddleware) engine.Use(AuthMiddleware) engine.Use(HelloHandler) // 启动 HTTP 服务器 fmt.Println(\u0026#34;Server is running on :9090\u0026#34;) fmt.Println(http.ListenAndServe(\u0026#34;:9090\u0026#34;, engine)) } 访问者模式(Visitor) 它允许你将算法与对象结构分离 访问者模式的核心思想是 将操作(算法)从对象结构中分离出来 使得可以在不修改对象结构的情况下定义新的操作 通过访问者模式 可以将对象结构的元素与作用于这些元素的操作解耦 从而使得操作可以独立变化 优点 解耦：将操作与对象结构分离 使得操作可以独立变化 扩展性：新增操作时 只需要添加新的访问者 而不需要修改对象结构。 符合开闭原则：对象结构对扩展开放 对修改关闭 示例 假设我们有一个文档对象模型(DOM) 包含多种元素(如文本、图片、表格等) 我们需要对这些元素进行不同的操作(如导出为PDF、导出为HTML等) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 package main import \u0026#34;fmt\u0026#34; // 定义访问者接口 type Visitor interface { VisitText(text *Text) VisitImage(image *Image) VisitTable(table *Table) } // 定义元素接口 type Element interface { Accept(visitor Visitor) } // 具体元素：文本 type Text struct { content string } func (t *Text) Accept(visitor Visitor) { visitor.VisitText(t) } // 具体元素：图片 type Image struct { src string } func (i *Image) Accept(visitor Visitor) { visitor.VisitImage(i) } // 具体元素：表格 type Table struct { rows int cols int } func (t *Table) Accept(visitor Visitor) { visitor.VisitTable(t) } // 具体访问者：导出为 PDF type PDFExportVisitor struct{} func (p *PDFExportVisitor) VisitText(text *Text) { fmt.Printf(\u0026#34;Exporting text to PDF: %s\\n\u0026#34;, text.content) } func (p *PDFExportVisitor) VisitImage(image *Image) { fmt.Printf(\u0026#34;Exporting image to PDF: %s\\n\u0026#34;, image.src) } func (p *PDFExportVisitor) VisitTable(table *Table) { fmt.Printf(\u0026#34;Exporting table to PDF: %d rows, %d cols\\n\u0026#34;, table.rows, table.cols) } // 具体访问者：导出为 HTML type HTMLExportVisitor struct{} func (h *HTMLExportVisitor) VisitText(text *Text) { fmt.Printf(\u0026#34;Exporting text to HTML: %s\\n\u0026#34;, text.content) } func (h *HTMLExportVisitor) VisitImage(image *Image) { fmt.Printf(\u0026#34;Exporting image to HTML: %s\\n\u0026#34;, image.src) } func (h *HTMLExportVisitor) VisitTable(table *Table) { fmt.Printf(\u0026#34;Exporting table to HTML: %d rows, %d cols\\n\u0026#34;, table.rows, table.cols) } // 是对象结构 type Document struct { elements []Element } func (d *Document) AddElement(element Element) { d.elements = append(d.elements, element) } func (d *Document) Accept(visitor Visitor) { for _, element := range d.elements { element.Accept(visitor) } } func main() { // 创建文档对象 document := \u0026amp;Document{} // 添加元素 document.AddElement(\u0026amp;Text{content: \u0026#34;Hello, World!\u0026#34;}) document.AddElement(\u0026amp;Image{src: \u0026#34;image.png\u0026#34;}) document.AddElement(\u0026amp;Table{rows: 3, cols: 2}) // 创建访问者 pdfVisitor := \u0026amp;PDFExportVisitor{} htmlVisitor := \u0026amp;HTMLExportVisitor{} // 导出为 PDF fmt.Println(\u0026#34;Exporting to PDF:\u0026#34;) document.Accept(pdfVisitor) // 导出为 HTML fmt.Println(\u0026#34;\\nExporting to HTML:\u0026#34;) document.Accept(htmlVisitor) } 其余常用模式 除开23种标准模式及简单工厂模式之外的常用设计模式 对象池模式(Object Pool Pattern) ✔ 创建型模式 对象池创建设计模式用于根据需求预期准备和保留多个实例 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 package pool type Pool chan *Object func New(total int) *Pool { p := make(Pool, total) for i :=0; i \u0026lt; total; i++ { p \u0026lt;- new(Object) } return \u0026amp;p } 用法 下面给出了一个关于对象池的简单生命周期示例 1 2 3 4 5 6 7 8 9 10 11 p := pool.New(2) select { case obj := \u0026lt;-p: obj.Do( /*...*/ ) p \u0026lt;- obj default: // No more objects left — retry later or fail return } 经验法则 对象池模式在对象初始化比对象维护成本更高的情况下非常有用 如果需求出现峰值 而不是稳定需求 则维护开销可能会超过对象池的优势 由于对象是预先初始化的 因此它对性能有积极影响 性能分析模式(Profiling Patterns) Timing Functions 包装函数并记录执行 在优化代码时 通常需要快速简单的时间测量 以此来验证假设 而不是使用profiler工具/框架 可以使用time包和defer语句执行时间测量 用法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // profile.go package profile import ( \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) // 计算函数执行的持续时间 func Duration(invocation time.Time, name string) { elapsed := time.Since(invocation) log.Printf(\u0026#34;%s lasted %s\u0026#34;, name, elapsed) } // main.go package main import ( \u0026#34;time\u0026#34; \u0026#34;package/profile\u0026#34; ) func Func1() { // Arguments to a defer statement is immediately evaluated and stored. // The deferred function receives the pre-evaluated values when its invoked. // time.Now() 会立即执行并存储 即传入的是该函数的开始执行时间 defer profile.Duration(time.Now(), \u0026#34;Func1\u0026#34;) time.Sleep(5 * time.Second) } func Func2() { defer profile.Duration(time.Now(), \u0026#34;Func2\u0026#34;) time.Sleep(3 * time.Second) } func main() { Func1() Func2() } /* 输出示例: 2025/04/02 12:54:16 Func1 lasted 5.0131114s 2025/04/02 12:54:19 Func2 lasted 3.0020849s */ Function Options 函数选项模式\nCircuit-Breaker 断路器模式\n参考文档 singleton-pattern-in-go\nGo24种设计模式\ngo-patterns\ngolang-design-pattern\n","date":"2023-04-21T11:43:42+08:00","permalink":"https://ilolicon.github.io/p/go-design-patterns/","title":"GO DESIGN PATTERNS"},{"content":"EMQX Docs\n安装 Docker安装 EMQX Docker官方镜像\nDocker安装EMQX非常简单 按照官方镜像文档说明创建容器即可\n注意事项\n容器安装的数据持久化 需要持久化文件 参考官方镜像说明文档即可 Docker Volume持久化参考(单机测试环境)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 创建所需数据卷 docker volume create emqx_data docker volume create emqx_etc docker volume create emqx_log # 启动容器 docker run -d --name=emqx --restart=always \\ # -v emqx_data:/opt/emqx/data \\ # -v效果类似与下面的--mount --mount source=emqx_data,target=/opt/emqx/data \\ # 挂载data目录 --mount source=emqx_etc,target=/opt/emqx/etc \\ # 挂载配置目录 --mount source=emqx_log,target=/opt/emqx/log \\ # 挂载日志目录 -p 1883:1883 \\ -p 8083:8083 \\ -p 8084:8084 \\ -p 8883:8883 \\ -p 18083:18083 \\ emqx/emqx:latest ","date":"2023-02-23T22:25:50+08:00","permalink":"https://ilolicon.github.io/p/mqtt/","title":"MQTT"},{"content":"配置选项问题 在我们编程中 我们会经常对一个对象(或是业务实体)进行相关的配置 比如下面这个业务实体\n1 2 3 4 5 6 7 8 type Server struct { Addr string Port string Protocol string Timeout time.Duration MaxConns int TLS *tls.Config } 在这个Server对象中 我们可以看到：\n要有监听的地址Addr和端口Port 这两个选项是必须配置的(当然可以设置默认值 这里举例我们认为没有默认值且不能为空) 然后 还有协议Protocol Timeout和MaxConns字段 这几个字段是不能为空的 但是可以有默认值 比如: 协议是tcp超时30s和最大连接数1024个 还有一个TLS安全链接 需要配置相关的证书和私钥 这个可以为空 针对上述这样的配置 我们需要有多种不同的创建配置Server的函数签名 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func NewDefaultServer(addr string, port int) (*Server, error) { return \u0026amp;Server{addr, port, \u0026#34;tcp\u0026#34;, 30 * time.Second, 100, nil}, nil } func NewTLSServer(addr string, port int, tls *tls.Config) (*Server, error) { return \u0026amp;Server{addr, port, \u0026#34;tcp\u0026#34;, 30 * time.Second, 100, tls}, nil } func NewServerWithTimeout(addr string, port int, timeout time.Duration) (*Server, error) { return \u0026amp;Server{addr, port, \u0026#34;tcp\u0026#34;, timeout, 100, nil}, nil } func NewTLSServerWithMaxConnAndTimeout(addr string, port, maxconns int, timeout time.Duration, tls *tls.Config) (*Server, error) { return \u0026amp;Server{addr, port, \u0026#34;tcp\u0026#34;, 30 * time.Second, maxconns, tls}, nil } 因为Go语言不支持重载函数 所以 你得用不同得函数名来应对不同的配置选项 上面方案的缺点：\n创建太多的NewServer函数 代码冗余 可扩展性差 配置对象方案(分离可选项) 要解决上面的问题 最常见的方式是使用一个配置对象 如下所示：\n1 2 3 4 5 6 type Config struct { Protocol string Timeout time.Duration Maxconns int TLS *tls.Config } 我们把那些非必须的选项都分离到一个结构体里 于是新的Server对象如下：\n1 2 3 4 5 type Server struct { Addr string Port int Cfg *Config } 于是 我们只需要一个NewServer()函数即可 在使用前需要构造Config对象\n1 2 3 4 5 6 7 8 9 func NewServer(addr string, port int, cfg *Config) (*Server, error) { //... } // Using the default configuratrion s, _ := NewServer(\u0026#34;localhost\u0026#34;, 9000, nil) cfg := ServerConfig{Protocol:\u0026#34;tcp\u0026#34;, Timeout: 60*time.Duration} s, _ := NewServer(\u0026#34;locahost\u0026#34;, 9000, \u0026amp;cfg) 上面这种分离可选项的方式 Config对象并不是必须的 所以 你需要判断其是否是nil或者是EmptyConfig{}\nBuilder模式 如果你是一个Java程序员 熟悉设计模式的一定会很自然的使用上Builder模式 比如如下代码:\n1 2 3 4 5 User user = new User.Builder() .name(\u0026#34;ilolicon\u0026#34;) .email(\u0026#34;97431110@qq.com\u0026#34;) .role(\u0026#34;admin\u0026#34;) .build(); 仿照上面这个模式 我们可以把上面的代码改写成如下代码(注：下面的代码没有考虑出错处理)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 使用一个builder类来做包装 type ServerBuilder struct { Server } func (sb *ServerBuilder) Create(addr string, port int) *ServerBuilder { sb.Server.Addr = addr sb.Server.Port = port // 其他代码设置其他成员的模式值 return sb } func (sb *ServerBuilder) WithProtocol(protocol string) *ServerBuilder { sb.Server.Protocol = protocol return sb } func (sb *ServerBuilder) WithMaxConns(maxconns int) *ServerBuilder { sb.MaxConns = maxconns return sb } func (sb *ServerBuilder) WithTimeout(timeout time.Duration) *ServerBuilder { sb.Timeout = timeout return sb } func (sb *ServerBuilder) WithTLS(tls *tls.Config) *ServerBuilder { sb.Server.TLS = tls return sb } func (sb *ServerBuilder) Build() Server { return sb.Server } 于是 我们可以这样去使用：\n1 2 3 4 5 6 sb := ServerBuilder{} server := sb.Create(\u0026#34;127.0.0.1\u0026#34;, 8080). WithProtocol(\u0026#34;udp\u0026#34;). WithMaxConns(1024). WithTimeout(30 * time.Second). Build() 上面这样的方式也很清楚 不需要额外的Config对象 使用链式的函数调用的方式来构造一个对象 只需要多增加一个Builder类\n但是这个Builder类似乎有点多余 我们似乎可以直接在Server上进行这样的Builder构造 事实也是如此 但是在处理错误的时候可能就有点麻烦(需要为Server结构增加一个error成员 破坏了Server结构体的\u0026quot;纯洁\u0026quot;) 不如一个包装类更好一些\n如果我们想省掉这个包装的结构体 那就就轮到FUNCTIONAL OPTIONS 函数式编程\nFunctional Options 函数选项模式的实现 主要有两种\n基于闭包的实现 基于接口的实现 基于闭包实现 1.定义一个函数类型Option\n1 type Option func(*Server) 2.闭包的方式定义如下一组函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func WithProtocol(proto string) Option { return func(s *Server) { s.Protocol = proto } } func WithTimeout(timeout time.Duration) Option { return func(s *Server) { s.Timeout = timeout } } func WithMaxConns(maxConns int) Option { return func(s *Server) { s.MaxConns = maxConns } } func WithTLS(tls *tls.Config) Option { return func(s *Server) { s.TLS = tls } } 以WithMaxConns()函数为例 传入一个参数maxConns 返回一个函数 这个函数会将参数maxConns赋值给Server对应的MaxConns字段\n当我们调用其中一个函数用WithMaxConns(30)时 其返回值时一个 func(s *Server) {s.MaxConns = 30}的函数 3.定义NewServer()函数\n函数参数是必填字段和可选字段(可变参数类型)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // NewServer先填上必须的字段 然后是可选字段 func NewServer(addr string, port int, opts ...Option) *Server { // 创建Server对象并填写可选项的默认值 s := \u0026amp;Server{ Addr: addr, Port: port, Protocol: \u0026#34;tcp\u0026#34;, Timeout: 30 * time.Second, MaxConns: 1024, TLS: nil, } // 对选项列表中的每项用for-loop来设置Server对象属性 for _, option := range opts { option(s) } return s } 首先 NewServer()函数当然opts是可变参数 可以传递上面的WithXXX()一个或多个函数 然后 创建Server对象 并填写可选项的默认值 如Timeout超时时间为30s 最后 for-loop循环opts可变参数 执行函数option去设置s对象中的各个属性 4.测试NewServer()函数\n1 2 3 4 5 6 7 8 9 10 func main() { s := NewServer(\u0026#34;127.0.0.1\u0026#34;, 8080) fmt.Printf(\u0026#34;Default Server: %v\\n\u0026#34;, s) s = NewServer(\u0026#34;127.0.0.1\u0026#34;, 8080, WithProtocol(\u0026#34;udp\u0026#34;)) fmt.Printf(\u0026#34;ServerWithProto: %v\\n\u0026#34;, s) s = NewServer(\u0026#34;127.0.0.1\u0026#34;, 8080, WithProtocol(\u0026#34;udp\u0026#34;), WithMaxConns(5000), WithTimeout(5*time.Second)) fmt.Printf(\u0026#34;ServerWithAll: %v\\n\u0026#34;, s) } 1 2 3 4 $ go run main.go Default Server : \u0026amp;{127.0.0.1 8080 tcp 30s 1024 \u0026lt;nil\u0026gt;} ServerWithProto: \u0026amp;{127.0.0.1 8080 udp 30s 1024 \u0026lt;nil\u0026gt;} ServerWithAll : \u0026amp;{127.0.0.1 8080 udp 5s 5000 \u0026lt;nil\u0026gt;} 基于接口实现 1.定义接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Server结构体 type Server struct { Addr string // 必填dd Port int // 必填 Protocol string // 非必填 Timeout time.Duration // 非必填 MaxConns int // 非必填 TLS *tls.Config // 非必填 可以为空 } // Option接口 定义需要实现的apply方法 type Option interface { apply(*Server) } Option接口定义apply(server *Server)方法 然后可选项需要实现接口\n2.可选项实现接口\n每个可选项都需要实现接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // ProtoOption 实现Option接口 type ProtoOption string func (p ProtoOption) apply(s *Server) { s.Protocol = string(p) } func WithProtocol(proto string) Option { return ProtoOption(proto) } // TimeoutOption 实现Option接口 type TimeoutOption time.Duration func (t TimeoutOption) apply(s *Server) { s.Timeout = time.Duration(t) } func WithTimeout(timeout time.Duration) Option { return TimeoutOption(timeout) } // MaxConnsOption 实现Option接口 type MaxConnsOption int func (m MaxConnsOption) apply(s *Server) { s.MaxConns = int(m) } func WithMaxConns(maxConns int) Option { return MaxConnsOption(maxConns) } 以可选项protocol的ProtoOption为例： 自定义类型ProtoOption实现Option接口的apply()方法\n3.封装函数将可选项包装为接口类型\n提供WithProtocol()函数将string类型的proto转换为ProtoOption类型 方便以Option接口的形式传递给函数使用\n4.定义NewServer()函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func NewServer(addr string, port int, opts ...Option) *Server { // 创建Server 并填写可选项的默认值 s := \u0026amp;Server{ Addr: addr, Port: port, Protocol: \u0026#34;udp\u0026#34;, Timeout: 30 * time.Second, MaxConns: 1024, TLS: nil, } for _, opt := range opts { opt.apply(s) } return s } for-loop循环opts可变参数 执行接口中的apply方法去设置s对象中的各个属性 注意：s一定要传递指针 否则无法修改对象属性\n1 2 3 4 5 6 7 func main() { s := NewServer(\u0026#34;127.0.0.1\u0026#34;, 8080) fmt.Printf(\u0026#34;Default Server: %v\\n\u0026#34;, s) s = NewServer(\u0026#34;127.0.0.1\u0026#34;, 9999, WithMaxConns(10240), WithTimeout(20*time.Second), WithProtocol(\u0026#34;tcp\u0026#34;)) fmt.Printf(\u0026#34;ALL Server: %v\\n\u0026#34;, s) } 1 2 Default Server: \u0026amp;{127.0.0.1 8080 udp 30s 1024 \u0026lt;nil\u0026gt;} ALL Server : \u0026amp;{127.0.0.1 9999 tcp 20s 10240 \u0026lt;nil\u0026gt;} 总结 三种解决方法：\n配置对象(分离可选项) Builder模式 函数选项模式(Functional Options) 使用较多 函数选项模式 优点：\n可读性强 将配置都转化为对应的函数项Option 扩展性好 新增参数只需要多增加一个方法 参考文档 Self-referential functions and the design of options\nGO 编程模式：FUNCTIONAL OPTIONS\n深入浅出 Golang函数选项编程模式\n","date":"2021-09-03T12:36:16+08:00","permalink":"https://ilolicon.github.io/p/go-functional-options/","title":"GO FUNCTIONAL OPTIONS"},{"content":" 环境准备 安装 官网下载安装\nWindwos下载go.msi安装 Linux下载go.tar.gz 1 2 3 4 5 解压: tar -xzvf go.tar.gz -C /usr/local/ 配置环境变量(windows安装会自动配置) go $PATH GOROOT =\u0026gt; go安装路径 GOPATH =\u0026gt; $HOME/go 配置 Go模块代理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 GO111MODULE=on # go模块管理 GOPROXY=https://goproxy.cn,direct # 下载第三方包网络有问题的时候设置代理 # Windows 1. 直接配置到环境变量(优先级高) =\u0026gt; 系统 - 高级设置 - 新增环境变量 2. 配置到go env go env -w GO111MODULE=on # 写入go环境变量 go env -w GOPROXY=https://goproxy.cn,direct # Linux # 配置脚本 /etc/profile.d/go.sh if [[ \u0026#34;x\u0026#34; == \u0026#34;x${GOROOT}\u0026#34; ]]; then export GOROOT=/usr/local/go export GOPATH=${HOME}/go export PATH=${PATH}:${GOROOT}/bin:${GOPATH}/bin fi 编辑器 1 2 3 vscode + 插件即可 ctrl + shift + p -\u0026gt; go install/update tools -\u0026gt; 全选安装插件 运行程序 1 2 3 4 5 6 7 8 9 // go工具链 go build hello.go // 编译 go run hello.go // 编译+运行 常用参数： -x // 打印执行命令 -n // 只打印编译过程 并不执行 -o // 执行程序输出名称 -work // 保留工作目录 基本语法 基本结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* 声明包 go要求每个源码都有属于的包 格式：package 包名 包名：目前阶段定义为main 声明包必须在源码的第一行 包声明前面可以包含注释 */ package main // 导入包：使用标准包或第三方包需要先导入 import ( \u0026#34;fmt\u0026#34; ) // 目前阶段认为 main函数为程序入口 func main() { fmt.Println(\u0026#34;Hello, Golang\u0026#34;) } 简单示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // var 定义变量r 类型为float64 值为10 var r float64 = 10 var confirm string // const定义常量 const pi float64 = 3.1415926 for { // 从控制台上读取数据 fmt.Print(\u0026#34;请输入半径：\u0026#34;) // 打印内容之后不会加换行 fmt.Scan(\u0026amp;r) // 计算圆形面积 fmt.Println(pi * r * r) // 打印内容之后自动换行 // 从控制台接收是否继续的数据 fmt.Print(\u0026#34;是否继续(y/n)?\u0026#34;) fmt.Scan(\u0026amp;confirm) if confirm != \u0026#34;y\u0026#34; { break } } } 基本组成元素 1 2 3 4 5 1. 标识符 2. 关键字 3. 字面量 4. 操作符 5. 分隔符 变量常量声明 变量声明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 变量声明: var // var 标识符 类型 package main import ( \u0026#34;fmt\u0026#34; ) // 定义全局变量 var version string = \u0026#34;1.1.1\u0026#34; // 显示赋值 func main() { // go中要求局部变量定义后必须使用 // 定义局部变量 // 未对局部变量进行显示复制 go会对变量设置默认值(零值) // string 零值： 空字符串 \u0026#34;\u0026#34; var funcVersion string // 省略类型 帮你徐显示设置默认值 go根据字面量或赋值的值类型进行推导 var name = \u0026#34;minho\u0026#34; // =\u0026gt; var name string = \u0026#34;minho\u0026#34; // 批量定义 没设置默认值需要指定类型 设置默认值可以不指定类型 var ( a1 int a2 string a3 int = 5 a4 string = \u0026#34;aaa\u0026#34; a5 = 5 a6 = \u0026#34;666\u0026#34; a9, a10 int ) var a7, a8 string // 类型一样 var a11, a12 string = \u0026#34;a11\u0026#34;, \u0026#34;a12\u0026#34; fmt.Println(funcVersion, version, name) fmt.Println(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12) } 常量声明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // 常量声明: const package main import ( \u0026#34;fmt\u0026#34; ) const version string = \u0026#34;2.2.2\u0026#34; func main() { // 常量必须显示设置默认值(因为常量定义之后就不能修改) const funcVersion string = \u0026#34;\u0026#34; const pi = 3.141592653 const ( a1 string = \u0026#34;222222\u0026#34; a2 int = 2 a3, a4 string = \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34; ) const a5, a6 = \u0026#34;111\u0026#34;, 1 const ( e1 = \u0026#34;aaa\u0026#34; e2 // const里面 只定义标识符 使用上一行的常量标识符的值来进行赋值 e3 e4 e5 = 1 e6 e7 ) fmt.Println(version, funcVersion, pi) fmt.Println(a1, a2, a3, a4, a5, a6) fmt.Println(e1, e2, e3, e4, e5, e6, e7) } const实现枚举 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // const + iota实现枚举 package main import \u0026#34;fmt\u0026#34; func main() { const ( e1 = iota // 0 iota 在小括号内初始化为0 每调用一次+1 e2 // 1 e3 // 2 ) // enum 枚举 e.g: 星期几 1、2、3、4、5、6、7 // iota 结合const使用 const ( a1 = iota // 0 在每个小括号内都会初始化 a2 a3 ) fmt.Println(e1, e2, e3) fmt.Println(a1, a2, a3) } 计算赋值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import \u0026#34;fmt\u0026#34; func main() { // 变量赋值：可以通过任意表达式计算结果赋值 var a1 = 10 var a2 = a1 + 10 var a3 = a1 + a2 // 变量/常量赋值 除了字面量 还可以是表达式 // 常量赋值：只能通过字面量/字面量计算结果/常量计算结果/常量经过某些函数计算的结果 赋值 const e1 = 10 const e2 = e1 + 10 const e3 = e1 * e2 var a4 = a3 + e3 // const a4 = a3 + e3 // 报错 a3是变量的计算结果 fmt.Println(a3) fmt.Println(e3) fmt.Println(a4) } 简短声明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import \u0026#34;fmt\u0026#34; func main() { // var xx int // 简短声明：通过值来推导标识符类型 // 问题： // 简短声明只能用在局部 // 多种数据类型使用同一个字面量标识 只能推导为默认类型 // 比如：整数 byte int int8 int16 int32 int 64 unit name := \u0026#34;minho\u0026#34; id := 1 // 只能默认推导为int 如果想定义id为int64 不能使用简短类型 fmt.Println(name, id) } 数据类型 基础数据类型 布尔类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 含义： 表示真假 类型名(标识符)：bool 初始化零值： false 内存占用： 1个字节 值： true(真)/false(假) 逻辑运算操作： 与 \u0026amp;\u0026amp; -\u0026gt; expr1 \u0026amp;\u0026amp; expr2 或 || -\u0026gt; expr1 || expr2 非 ！ -\u0026gt; !expr 关系运算： 等于 -\u0026gt; == 不等于 -\u0026gt; != 整数类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 整数: 1字节：0000 0000 有符号：可正/可负 -\u0026gt; 首位： 1负 0正 000 0000 -2^(n-1) ~ 2^(n-1) - 1 无符号：只表示\u0026gt;0 0000 0000 0 ~ 2^n - 1 0 ~ 255 int/uint // 32位机器=\u0026gt;4字节 64位机器=\u0026gt;8字节 byte // 1字节 字节类型 ascii字符 -\u0026gt; 整数 rune // 32字节 码点 unicode编码表 字符 -\u0026gt; 整数 int8/uint8 // 1字节 u开头的 无符号 int16/uint16 // 2字节 int32/uint32 // 4字节 int64/uint64 // 8字节 uintptr // 32位机器=\u0026gt;4字节 64位机器=\u0026gt;8字节 零值：0 字面量: 各种进制表示 操作： - 算术运算 + - * / % ++ -- - 关系运算 \u0026gt; \u0026lt; \u0026lt;= \u0026gt;= - 赋值运算 = += -+ *= /= %= int + int64 -\u0026gt; 强制类型转换：int(xx1) + xx2 小范围 -\u0026gt; 大范围 肯定无问题 大范围 -\u0026gt; 小范围 可能被截断 浮点类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 小数 类型名： float32 -\u0026gt; 32位(4字节) float64 -\u0026gt; 64位(8字节) 零值：0.0 -\u0026gt; 0 字面量：十进制的小数 操作： - 算术运算 + - * / ++ -- - 关系运算 \u0026gt; \u0026lt; \u0026lt;= \u0026gt;= - 浮点数：等于/不等于 |a-b|\u0026lt;精度 - 赋值运算 = += -+ *= /= // %f 修饰 // %n.mf =\u0026gt; n占位 m小数点保留位数(精度) 复数类型 1 // 略 字符串类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 string 零值：\u0026#34;\u0026#34; 空字符串 字面量： - 可解析字符串： \u0026#34;双引号\u0026#34; - 原生字符串： `反引号` 特殊字符： \\t tab \\r 回车 \\n 换行 ... 操作： 字符串连接： + 关系运算： \u0026gt; \u0026gt;= \u0026lt; \u0026lt;= == != 从左边第一个元素开始比较(byte) 不能确定继续比较下一个操作 赋值运算： = += 索引操作 =\u0026gt; byte 切片操作 =\u0026gt; byte 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package main import \u0026#34;fmt\u0026#34; func main() { var desc string = \u0026#34;a\\nb\u0026#34; var desc2 string = \u0026#34;a\\\\nb\u0026#34; var raw string = `a\\nb` // 原生字符串可以包含多行 var raw2 string = ` a\\nb fffds adadw weqejnfjsag ` fmt.Println(desc) fmt.Println(desc2) fmt.Println(raw) fmt.Println(raw2) s := \u0026#34;我叫\u0026#34; + \u0026#34;minho\u0026#34; // 索引： 0，1，2：我 3，4，5：叫 6：m ... // 索引操作和切片操作 一定要注意字符串的编码 // 切片的时候 如果是非ascii码的话 可能会产生乱码 fmt.Println(s) fmt.Println(s[1]) fmt.Printf(\u0026#34;%T, %c\\n\u0026#34;, s[6], s[6]) fmt.Println(s[0:5]) // 我�� 乱码 fmt.Printf(\u0026#34;%s\\n\u0026#34;, raw) } $ go run string.go \u0026gt;\u0026gt;\u0026gt; a \u0026gt;\u0026gt;\u0026gt; b \u0026gt;\u0026gt;\u0026gt; a\\nb \u0026gt;\u0026gt;\u0026gt; a\\nb \u0026gt;\u0026gt;\u0026gt; a\\nb fffds adadw weqejnfjsag \u0026gt;\u0026gt;\u0026gt; 我叫minho \u0026gt;\u0026gt;\u0026gt; 136 \u0026gt;\u0026gt;\u0026gt; uint8, m \u0026gt;\u0026gt;\u0026gt; 我�� \u0026gt;\u0026gt;\u0026gt; a\\nb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 重要: 索引和切片的时候 自己保证编码内容为ascii package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unicode/utf8\u0026#34; ) func main() { txt := \u0026#34;我爱中华人名共和国!\u0026#34; // 获取字符串长度 len =\u0026gt; 字节数量 fmt.Println(len(txt)) // 27 fmt.Println(utf8.RuneCountInString(txt)) // 10 获取字符长度 // 索引 切片 fmt.Printf(\u0026#34;%c\\n\u0026#34;, txt[27]) // txt[27] = \u0026#34;%\u0026#34; // 字符串不可变 不能赋值 // 遍历 for range for key, value := range txt { fmt.Printf(\u0026#34;%d: %T, %c\\n\u0026#34;, key, value, value) } // 切片 byte []byte // 切片 rune []rune bs := []byte(txt) // 类型转换 类似 int(\u0026#39;32\u0026#39;) 字节数量 rs := []rune(txt) // 字符的数量 可以转换为rune切片 再计算length fmt.Println(bs) fmt.Println(rs) // rune/byte 切片转字符串类型 fmt.Println(string(bs)) fmt.Println(string(rs)) } 类型转换 1 2 3 4 5 6 7 // 类型转换 // \u0026#34;123\u0026#34; -\u0026gt; int // int -\u0026gt; string // \u0026#34;12.2\u0026#34; -\u0026gt; float64 // float -\u0026gt; string 包：strconv 指针类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package main import \u0026#34;fmt\u0026#34; func main() { var num int = 65 num1 := num // 修改 num1 = 165 // 对num有无影响 fmt.Println(num, num1) // 65 165 } /* 函数/方法 调用函数 参数传递会拷贝(赋值过程) 在函数内部对拷贝后的对象修改 不影响外部 但是：真的想在函数内部修改传递的参数 如何解决？ 解决: 定义一个变量 存储对应变量的内存地址 pointerNum = 0x0005 // 存储num的内存地址 此时 通过pointerNum直接去修改内存中的数据 1. pointerNum是什么类型？ -\u0026gt; 统称为指针类型 int -\u0026gt; *int string -\u0026gt; *string type -\u0026gt; *type 2. 如何拿到num的地址？ -\u0026gt; 取引用 \u0026amp;varname 3. 如果通过pointerNum去操作num对应内存中的数据？ -\u0026gt; 解引用 赋值 *varname = xxx */ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package main import \u0026#34;fmt\u0026#34; func main() { var num int = 65 num1 := num // 修改 num1 = 165 // 对num有无影响 fmt.Println(num, num1) // 65 165 var pointNum *int // 定义 fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, pointNum, pointNum) // *int, \u0026lt;nil\u0026gt; pointNum = \u0026amp;num // 取引用（取内存地址赋值） fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, pointNum, pointNum) // *int, 0xc00001a098 *pointNum = 116 // pointNum是指针类型 可以直接修改值 fmt.Println(num) // 116 // 简短声明 pointNum2 := \u0026amp;num // 两个point指针存储的都是num的内存地址 fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, pointNum2, pointNum2) // *int, 0xc00001a098 *pointNum2 = 5757 // pointNum2指针指向num的内存地址 修改的是num的值 fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, num, num) // *int, 5757 fmt.Println(*pointNum, *pointNum2) // 5757, 5757 都指向num的值 // 先定义变量 -\u0026gt; 取引用(取地址) // new(T) 不用定义变量 pointer := new(int) fmt.Printf(\u0026#34;%T, %v, %v\\n\u0026#34;, pointer, pointer, *pointer) // *int, 0xc00001a110, 0 fmt.Printf(\u0026#34;%p\\n\u0026#34;, pointer) // 占位 } $ go run pointer.go \u0026gt;\u0026gt;\u0026gt; 65 165 \u0026gt;\u0026gt;\u0026gt; *int, \u0026lt;nil\u0026gt; \u0026gt;\u0026gt;\u0026gt; *int, 0xc00001a098 \u0026gt;\u0026gt;\u0026gt; 116 \u0026gt;\u0026gt;\u0026gt; *int, 0xc00001a098 // 了解：usafe包 复合数据类型 数组(array) 序列 由相同类型元素组成的一个有序的集 1 2 3 0123456 \u0026#34;abcdefg\u0026#34; ... 数组 由相同类型(任意类型)元素组成的一个固定长度的有序的集(一组固定长度的序列) 1 2 3 4 声明： [length]T [3]int // 和下面的数组[5]int类型不同 只是元素类型相同都是int [5]int 零值：由N个T类型的零值组成的数组(初始化) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { var nums [10]int fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, nums, nums) // [10]int, [0 0 0 0 0 0 0 0 0 0] var names [10]string fmt.Printf(\u0026#34;%T, %q\\n\u0026#34;, names, names) // [10]string, [\u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34;] // 字面量 初始化值 nums = [10]int{1, 2, 3} fmt.Println(nums) // [1 2 3 0 0 0 0 0 0 0] // 通过索引指定值 nums = [10]int{1: 1, 3: 2, 5: 3} fmt.Println(nums) // ... 语法糖 =\u0026gt; go编译过程中进行转换 // 简写 根据{}中的元素 自动推导length nums = [...]int{1, 2, 9: 3} fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, nums, nums) // [10]int, [0 0 0 0 0 0 0 0 0 0] // 内存: int字节数量 * 元素的数量 // 64位 8字节 * 10个元素 fmt.Println(unsafe.Sizeof(nums)) // 80 // 操作 // 算数运算 无 // 关系运算: == != nums2 := [10]int{1, 2} fmt.Println(nums == nums2) // false 每个元素都相等才相等 长度不一样则类型不同 不能比较 nums3 := [10]int{1, 2} fmt.Println(nums3 == nums2) // true // 相关函数 // 长度 fmt.Println(len(nums3)) // 10 // 索引 通过索引获取每个元素的值 // 左-\u0026gt;右：0, 1, 2, ..., len(array) - 1; 无反向索引(负索引) fmt.Println(nums[1], nums[9]) // 遍历数组元素 for i := 0; i \u0026lt; len(nums); i++ { fmt.Printf(\u0026#34;key：%v value: %v\\n\u0026#34;, i, nums[i]) } // for range遍历 for index, value := range nums { fmt.Println(index, value) } // 如果不使用index 用空白标识符 否则变量不使用 编译报错 // var value int for _, value := range nums { fmt.Println(value) } // 修改元素 fmt.Println(nums) nums[2] = 100 // 直接通过索引赋值 fmt.Println(nums) } 多维数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import \u0026#34;fmt\u0026#34; func main() { // [length]T // T 可以是任意类型 // T -\u0026gt; [5]int // 多维数组：数组本身的元素也是一个数组类型 var multi [3][5]int // T = [5]int =\u0026gt; 二维数组 fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, multi, multi) multi = [...][5]int{ // 也可以省略长度 {1, 3, 5, 6, 7}, // 1: [5]int{1, 2, 3, 4, 5} 大括号里面定义二维 可以省略类型 {2, 3, 4}, {1: 2, 4: 7}, } // 修改 fmt.Println(multi) fmt.Println(multi[1]) fmt.Println(multi[0][3]) multi[1] = [5]int{1, 1, 1, 1, 1} fmt.Println(multi) multi[0][3] = 1000 fmt.Println(multi) // 遍历 for i := 0; i \u0026lt; len(multi); i++ { for j := 0; j \u0026lt; len(multi[i]); j++ { fmt.Println(i, j, multi[i][j]) } } // range遍历 for index, value := range multi { for index2, value2 := range value { fmt.Println(index, index2, value2) } } } 切片(slice) 切片：由相同类型元素组成的长度可变的有续集 声明：[]T // 数组去掉长度\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 package main import \u0026#34;fmt\u0026#34; func main() { var nums []int // var nums []int = nil // nil切片 赋值为nil fmt.Printf(\u0026#34;%T, %v, %v\\n\u0026#34;, nums, nums, nums == nil) // []int, [], true // 内存 暂时不关注 // 字面量 nums = []int{} // 空切片 不等于nil fmt.Printf(\u0026#34;%T, %v, %v\\n\u0026#34;, nums, nums, nums == nil) // []int, [], false nums = []int{1, 2, 3, 4} fmt.Println(nums) nums = []int{1, 2, 3, 4, 5, 6, 7} // 长度可变 fmt.Println(nums) nums = []int{1: 1, 10: 11} // [0 1 0 0 0 0 0 0 0 0 11] fmt.Println(nums) // make([]int, length) // length: 切片元素的数量 // 赋值有5个元素的int类型零值组成的切片 nums = make([]int, 5) fmt.Println(nums) // make([]int, length, cap) // length: 元素数量 // cap: 容量 =\u0026gt; 底层数组的长度 // slice底层 =\u0026gt; 数组存储 数组长度固定 当length == cap 再添加本素 重新申请内存 拷贝 释放旧数组内存 // 切片长度增长(元素数量) 增长 =\u0026gt; 底层数组长度不够怎么办 =\u0026gt; 重新生成一个新的可以容纳更多元素的数组(拷贝原来数组中的元素) // 底层数组原长度：10 增加一个元素 增长：10 底层数组现长度：20 // 选择的元素：11 剩9个没有使用 nums = make([]int, 3, 10) fmt.Println(nums) // 切片操作 =\u0026gt; 数组 字符串 切片 numArray := [5]int{1, 3, 5, 7, 9} fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, numArray[1:3], numArray[1:3]) // [start:end] start \u0026lt;= end \u0026lt;= length // 数组切片赋值给切片 nums = numArray[1:3] fmt.Println(nums) // 容量 cap() nums = numArray[0:4] fmt.Printf(\u0026#34;%T, %v, %v, %v\\n\u0026#34;, nums, nums, len(nums), cap(nums)) // []int, [1 3 5 7], 4, 5 nums = numArray[1:] fmt.Printf(\u0026#34;%T, %v, %v, %v\\n\u0026#34;, nums, nums, len(nums), cap(nums)) // []int, [3 5 7 9], 4, 4 // 切片的切片操作 fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, nums[1:3], nums[1:3]) // 切片的赋值方式 // 1. 零值 nil切片 // 2. 字面量 // 3. make函数(指定容量 不指定容量) // 4. 切片操作(数组切片 切片切片) // 操作：不能进行== 和 !=运算 // 函数： len cap append copy // 元素的访问和修改： 通过索引 slice[i];slice[i] = value // 切片操作： // slice[start:end:cap_end] start \u0026lt;= end \u0026lt;= cap_end \u0026lt;= cap(slice) // array[start:end:cap_end] start \u0026lt;= end \u0026lt;= cap_end \u0026lt;= len(array) // 切片底层： // 数组地址 // 容量 // 长度 // 长度：len() 容量：cap() nums = []int{} fmt.Println(len(nums), cap(nums)) nums = []int{1, 2, 3} fmt.Println(len(nums), cap(nums)) nums = make([]int, 10) fmt.Println(len(nums), cap(nums)) // 10, 10 nums = make([]int, 0, 10) fmt.Println(len(nums), cap(nums)) // 0, 10 nums = numArray[1:3] // cap = length - start fmt.Println(numArray) // [1 3 5 7 9] fmt.Println(len(nums), cap(nums)) // 元素的访问和修改 fmt.Println(nums) nums[0] = 100 // 索引的范围：0,length-1 or 0,cap-1? // fmt.Println(nums[1]) // fmt.Println(nums[2]) // 运行时报错 索引范围是0，length-1 // 遍历 for i := 0; i \u0026lt; len(nums); i++ { fmt.Printf(\u0026#34;%v: %v\\n\u0026#34;, i, nums[i]) } for index, value := range nums { fmt.Printf(\u0026#34;%v: %v\\n\u0026#34;, index, value) } // 添加元素 nums = append(nums, 1) // 末尾追加 fmt.Println(nums) nums = append(nums, 100, 2, 3) // 追加多个元素 fmt.Println(nums) // 删除元素 // go中没有直接删除元素的方法 需要用到： 切片 + 解包 // 删除索引为0的(首) nums = nums[1:len(nums)] fmt.Println(nums) // 删除索引为length-1的(尾) nums = nums[:len(nums)-1] fmt.Println(nums) // 删除中间的(索引为i) // [0:i] + [i+1:len(nums)] // 1. 循环append // prefix := nums[0:1] // suffix := nums[2:len(nums)] // fmt.Println(prefix, suffix) // for _, value := range suffix { // prefix = append(prefix, value) // } // fmt.Println(prefix) // 2. 解包方式 go把切片元素展开 语法糖 fmt.Println(append(nums[0:1], nums[2:len(nums)]...)) // start:end start = 0 =\u0026gt; [:end] 省略 // start:end end = length =\u0026gt; [start:] // 容量 // 增长规则： \u0026lt;= 1024 n =\u0026gt; 2*n // \u0026gt; 1024 n =\u0026gt; n*(1+~0.25) nums = []int{} fmt.Println(len(nums), cap(nums)) // 0 0 nums = append(nums, 1) fmt.Println(len(nums), cap(nums)) // 1 1 nums = append(nums, 2) fmt.Println(len(nums), cap(nums)) // 2 2 nums = append(nums, 3) fmt.Println(len(nums), cap(nums)) // 3 4 nums = append(nums, 4) fmt.Println(len(nums), cap(nums)) // 4 4 nums = append(nums, 5) fmt.Println(len(nums), cap(nums)) // 5 8 // 如果可以预期切片的最大长度 可以通过make函数指定cap容量 减少申请内存的损耗 // start:end:cap_end numArray = [5]int{1, 3, 5, 7, 8} nums = numArray[1:3] // len = end - start; cap = len(底层数组) - start nums = append(nums, 1000) // 切片会共享底层数组 fmt.Println(numArray) // [1 3 5 1000 8] fmt.Println(nums) // [3 5 1000] fmt.Println(\u0026#34;#########\u0026#34;) nums = numArray[3:5] // [1000 8] nums = append(nums, 3) fmt.Println(numArray) // [1 3 5 1000 8] fmt.Println(nums) // [100 8 3] // [start:end:cap_end] 切片可以指定cap的位置(限制cap) // end \u0026lt;= cap_end \u0026lt;= 底层数组的长度 nums = numArray[1:3:4] // cap = cap_end - start fmt.Println(len(nums), cap(nums)) // 2 2 nums = append(nums, 999) fmt.Println(nums) fmt.Println(numArray) // len和cap一样 append会触发扩容 扩容不会影响原来的底层数组 生成新的底层数组 // 否则 会影响底层数组(改变底层数组的值) // 总结：如果使用数组来生成切片 那么操作切片(append扩容)根据容量的情况 会影响底层数组 或是生成新的底层数组 // 切片的切片操作 // [start:end] start \u0026lt;= end \u0026lt;= cap(nums); end小于等于容量cap fmt.Println(\u0026#34;###########\u0026#34;) nums = make([]int, 3, 10) nums[0] = 1 nums[1] = 2 nums[2] = 3 fmt.Println(nums) numsSlice := nums[1:5] // [2 3 0 0] fmt.Println(numsSlice) fmt.Println(len(numsSlice), cap(numsSlice)) // 1, 9 仍然共享底层数组 numsSlice = append(numsSlice, 100) fmt.Println(nums) // numsSlice扩容了一个元素100 nums值改变 [1 2 3] =\u0026gt; [1 2 100] 原因：共享了底层数组 // 限定cap numsSlice = nums[1:2:2] fmt.Println(numsSlice) fmt.Println(len(numsSlice), cap(numsSlice)) // copy函数(dst, src) 后面的切片拷贝到前面的切片 // copy：只赋值索引相同的元素 复制值不够：保留 复制只太多：剔除 并不扩容 dst := make([]int, 3) src := []int{2, 3, 4} // len(src) == len(dst) fmt.Println(src, dst) copy(dst, src) fmt.Println(src, dst) // [2 3 4] [2 3 4] // len(dst) \u0026gt; len(src) 保留未被覆盖部分 src = []int{200, 300} copy(dst, src) fmt.Println(src, dst) // [200 300] [200 300 4] // len(dst) \u0026lt; len(src) src = []int{1000, 2000, 3000, 4000} copy(dst, src) fmt.Println(src, dst) // [1000 2000 3000 4000] [1000 2000 3000] 长度并不会在拷贝过程中进行调整 // 通过copy来删除索引为i的元素 nums = []int{1, 2, 3, 4, 5} // 删除索引为2的 fmt.Println(nums[2:]) // [3 4 5] fmt.Println(nums[3:]) // [4 5] copy(nums[2:], nums[3:]) fmt.Println(nums[:len(nums)-1]) // [1 2 4 5 5] } 切片实现队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // 队列： 先进先出(消息队列) quene := []int{} 1 2 3 =\u0026gt; 1 2 3 进切片(添加到后面) append(1) append(2) append(3) 出切片 获取索引为0的元素 删除索引为0的元素 quene[1:] package main import \u0026#34;fmt\u0026#34; func main() { quene := []string{} var txt string for { fmt.Println(\u0026#34;请输入任务(exit退出,do执行):\u0026#34;) fmt.Scan(\u0026amp;txt) if txt == \u0026#34;exit\u0026#34; { break } else if txt == \u0026#34;do\u0026#34; { if len(quene) == 0 { fmt.Println(\u0026#34;无任务\u0026#34;) } else { fmt.Println(\u0026#34;执行：\u0026#34;, quene[0]) quene = quene[1:] } } else { quene = append(quene, txt) } } } 切片实现堆栈 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // 堆栈： 先进后出 (有优先级的场景) stack := []int{} 1 2 3 =\u0026gt; 3 2 1 进切片： append(1) append(2) append(3) 出切片： 获取索引为len()-1的元素 删除len()-1的元素 stack[:len(stack)-1] package main import \u0026#34;fmt\u0026#34; func main() { stack := []string{} var txt string for { fmt.Println(\u0026#34;请输入任务(exit退出,do执行):\u0026#34;) fmt.Scan(\u0026amp;txt) if txt == \u0026#34;exit\u0026#34; { break } else if txt == \u0026#34;do\u0026#34; { if len(stack) == 0 { fmt.Println(\u0026#34;无任务\u0026#34;) } else { fmt.Println(\u0026#34;执行：\u0026#34;, stack[len(stack)-1]) stack = stack[:len(stack)-1] } } else { stack = append(stack, txt) } } } // 切片 []T // T =\u0026gt; [3]int 数组 [][3]int // T =\u0026gt; []int 切片 [][]int 循环删除切片多个元素 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import \u0026#34;fmt\u0026#34; func main() { sli := []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} // 使用for循环遍历切片 并记录需要删除的元素的索引 indexesToDelete := []int{} for i, v := range sli { if v%2 == 0 { indexesToDelete = append(indexesToDelete, i) } } // 倒序遍历需要删除的元素的索引 因为删除元素后 切片的长度会发生变化 // 如果正序遍历 则可能产生索引越界 for i := len(indexesToDelete) - 1; i \u0026gt;= 0; i-- { sli = append(sli[:indexesToDelete[i]], sli[indexesToDelete[i]+1:]...) } fmt.Println(sli) // [1 3 5 7 9] } 映射(map) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 切片 或者 数组 访问元素是直接通过索引访问 // 如果我要找一个值 不知道索引的情况下 那就得把所有元素都遍历一遍 slice[i] array[i] 映射：// 定义key和value对的集 // (可能是有序的/可能是无序的 Go中是无序的：放入key的顺序与在内存中的顺序无关 与遍历无关) 含义： ID =\u0026gt; 数据 映射实现方式：hashtable(go的实现方式) treemap key: 通过key对value进行增删查改 key是唯一的 key类型的要求：可以进行 == !=判断 (不能为切片) value类型任意 定义：map[keyType]valueType 赋值： make: make(map[keyType]valueType) 字面量： map[keyType]valueType{} // 空map map[keyType]valueType{k1:v, k2:v, k3:v} 零值：nil 操作： 元素数量：len() 元素操作： 获取：mapName[key] key存在：mapName[key] =\u0026gt; 对应value值 key不存在：不会报错 返回对应valueType类型的零值 因此 不能通过零值来判断key否存在 如何判断key是否存在： value, ok := mapName[key] // 可以返回两个值 ok表示key是否存在 true/false value := mapName[key] 增： mapName[key] = value // 存在修改 不存在增加 改： mapName[key] = value 删： delete(mapName, key) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 package main import \u0026#34;fmt\u0026#34; func main() { // name =\u0026gt; count 记录每个学生上课次数 // key: string value: int var stats map[string]int fmt.Printf(\u0026#34;%T, %v, %v\\n\u0026#34;, stats, stats, stats == nil) // 赋值 stats = map[string]int{} // 空map 不等于nil fmt.Printf(\u0026#34;%T, %v, %v\\n\u0026#34;, stats, stats, stats == nil) stats = map[string]int{\u0026#34;minho\u0026#34;: 3, \u0026#34;kk\u0026#34;: 10} fmt.Printf(\u0026#34;%T, %v, %v\\n\u0026#34;, stats, stats, stats == nil) fmt.Println(len(stats)) // stats = make(map[string]int) // fmt.Printf(\u0026#34;%T, %v, %v\\n\u0026#34;, stats, stats, stats == nil) // 获取元素 fmt.Println(stats[\u0026#34;minho\u0026#34;]) fmt.Println(stats[\u0026#34;minho11\u0026#34;]) // key不存在 不报错 value := stats[\u0026#34;minho\u0026#34;] fmt.Println(value) value = stats[\u0026#34;minho11\u0026#34;] fmt.Println(value) value, ok := stats[\u0026#34;minho\u0026#34;] // 返回两个值 ok表示是否存在 true/false fmt.Println(value, ok) value, ok = stats[\u0026#34;minho11\u0026#34;] fmt.Println(value, ok) // 增加元素 stats[\u0026#34;karubin\u0026#34;] = 11 fmt.Println(stats) // 修改元素 stats[\u0026#34;karubin\u0026#34;] = 9 fmt.Println(stats) // 删除元素 stats[\u0026#34;xxx\u0026#34;] = 7 fmt.Println(stats) delete(stats, \u0026#34;xxx\u0026#34;) delete(stats, \u0026#34;xxxxxx\u0026#34;) // 删除的key如果不存在 不报错 fmt.Println(stats) // 遍历 for range for key := range stats { fmt.Println(key, stats[key]) } for key, value := range stats { fmt.Println(key, value) } } 显示初始化值 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;fmt\u0026#34; func main() { var nilSlice []int = make([]int, 0) var nilMap map[string]int = make(map[string]int) // 显式为切片和map进行初始化值 fmt.Println(append(nilSlice, 1)) // [1] fmt.Println(nilMap[\u0026#34;kk\u0026#34;]) nilMap[\u0026#34;kk\u0026#34;] = 1 // 没有初始化值 报错 nil map } 函数 为代码片段定义一个名称\n功能 1 2 1. 代码功能明确 2. 代码复用 定义/调用 1 2 3 func 函数名称(函数参数, ...) 返回值 { // 函数体 } 函数名称 1 // 需要满足标识符规范 函数参数(形参) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // 可以是任意多个 // 参数：参数名称(变量名) 参数类型 // 定义参数 就是定义一个变量 // 形参作用域：只能在该函数体内使用 // 多个参数使用逗号分割 // go里面没有参数默认值 // 多个连续参数类型一致 只保留连续参数中最后一个参数类型 前面n个参数类型省略 // 可变参数 package main import \u0026#34;fmt\u0026#34; // 无参 func sayHello() { fmt.Println(\u0026#34;Hello, Go\u0026#34;) } // 有参 func sayHi(name string) { fmt.Println(\u0026#34;Hi\u0026#34;, name) } func add(num1 int, num2 int) (int, string) { fmt.Println(num1 + num2) return num1 + num2, \u0026#34;add\u0026#34; } // 连续同类型参数省略类型 func merge(a1 bool, a2, a3, a4 string) { fmt.Println(a1, a2, a3, a4) } // 可变参数 // 变量名 ...T // 可变参数在一个函数内只能定义一次 func anyArgs(args ...string) { // 可以接收任意多个string类型的变量 // args是切片类型 } // 可变参数可以和固定参数结合使用 但只能放在最末尾 func addN(left, right int, args ...int) { sum := left + right for _, value := range args { sum += value } fmt.Println(sum) } func main() { addN(1, 2, 3, 4, 5, 6, 7) } 返回值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // 可以是任意多个 // 无返回值不定义 // 有一个返回值： 需定义返回值的类型 // 多个返回值：需定义所有返回值的类型 用逗号分割 ()包含 连续相同返回类型 同样可以省略 // 返回值可以定义名称(命名返回值) 命名返回值 建议在函数简单的时候使用 // 有返回值一定要用return关键字返回 package main import \u0026#34;fmt\u0026#34; // 无返回值 func sayHello() { fmt.Println(\u0026#34;Hello, Go\u0026#34;) } // 单个返回值 func add() int { return 2 + 3 } // 多个返回值 同类型 func calc() (int, int, int, int) { return 2 + 3, 2 - 3, 2 * 3, 2 / 3 } // 返回多个值 不同类型 func returnType() (int, bool, string, []int) { return 1, true, \u0026#34;string_return\u0026#34;, nil } // 命名返回值 // 将函数执行完成时的name返回 func returnName() (name string) { // return // 命名返回值 可以直接只写return 返回\u0026#34;\u0026#34; name = \u0026#34;returnName\u0026#34; return } func returnNameArgs() (name string, isBoby bool) { name = name + \u0026#34;Minho\u0026#34; return } func main() { sayHello() r := add() fmt.Println(r) num1, num2, _, num4 := calc() fmt.Println(num1, num2, num4) res1, res2, res3, res4 := returnType() fmt.Println(res1, res2, res3, res4) res := returnName() fmt.Printf(\u0026#34;%q\\n\u0026#34;, res) name, isBody := returnNameArgs() fmt.Printf(\u0026#34;%q, %v\\n\u0026#34;, name, isBody) // Minho false } 函数调用 1 2 3 4 5 6 7 8 9 10 11 // 函数名称(实参参数) 实参的数量 == 形参的数量 // 实参和形参：数量 需要一致 / 类型按顺序一致 / 数据按照顺序传递 // 函数调用 在栈上 一般是申请的连续的地址 // 闭包使用到的变量 go会存到堆中 该类变量生命周期边长 go tool compile -m -l xxx.go var xxx does not escape var xxx escapes to head // 逃逸到堆中 递归 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // 函数间接/直接调用自己 // 分治问题：将一个大问题拆分成N个相同解决方法的小问题 // 阶乘 package main import \u0026#34;fmt\u0026#34; // 递归实现阶乘 func fact(n int64) int64 { fmt.Println(\u0026#34;call\u0026#34;, n) if n == 0 || n == 1 { return 1 // 终止条件 没有的话会无限调用 调用深度(看语言层面是否有限制) } rt := n * fact(n-1) fmt.Println(\u0026#34;result\u0026#34;, n, rt) return rt } func main() { fmt.Println(fact(5)) // 120 } $ go run fact.go // 先进去的后得到结果 类似栈 \u0026gt;\u0026gt;\u0026gt; call 5 \u0026gt;\u0026gt;\u0026gt; call 4 \u0026gt;\u0026gt;\u0026gt; call 3 \u0026gt;\u0026gt;\u0026gt; call 2 \u0026gt;\u0026gt;\u0026gt; call 1 \u0026gt;\u0026gt;\u0026gt; result 2 2 \u0026gt;\u0026gt;\u0026gt; result 3 6 \u0026gt;\u0026gt;\u0026gt; result 4 24 \u0026gt;\u0026gt;\u0026gt; result 5 120 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 汉诺塔 package main import \u0026#34;fmt\u0026#34; // 将layer个盘子从t1移动到t3 借助t2 func tower(t1, t2, t3 string, layer int) { if layer == 1 { fmt.Printf(\u0026#34;%s -\u0026gt; %s\\n\u0026#34;, t1, t3) return } // 先将layer-1个从t1 移动到t2 借助t3 tower(t1, t3, t2, layer-1) // t1 -\u0026gt; t3 fmt.Printf(\u0026#34;%s -\u0026gt; %s\\n\u0026#34;, t1, t3) // 将layer-1个t2 移动到t3 借助t1 tower(t2, t1, t3, layer-1) } func main() { tower(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, 3) } 函数类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // 定义函数类型的变量 赋值 函数, 调用 =\u0026gt; 其他语言的高阶函数 package main import \u0026#34;fmt\u0026#34; func add(l, r int) int { return l + r } func mapFunc(list []int, tl func(int) int) []int { rt := []int{} for _, value := range list { rt = append(rt, tl(value)) } return rt } func tlAdd(n int) int { return n + 5 } func main() { fmt.Printf(\u0026#34;%T\\n\u0026#34;, add) // func(int, int) int // 定义函数类型的变量 var f func(int, int) int // 零值 nil f = add // 引用函数add fmt.Printf(\u0026#34;%T %v\\n\u0026#34;, f, f) fmt.Println(f(2, 3)) // 调用函数 5 // map filter reduce // 对切片进行操作 // map: 对切片中每个元素通过某种转换得到结果组成新的切片 // filter: 对切片的元素进行过滤 // reduce: 初始化元素 将1个元素与初始化元素 =\u0026gt; result + 2 =\u0026gt; result + 3 nums := []int{1, 2, 3, 4, 5} // map =\u0026gt; 新的切片 []int fmt.Println(mapFunc(nums, tlAdd)) } 匿名函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import \u0026#34;fmt\u0026#34; func mapFunc(list []int, tl func(int) int) []int { rt := []int{} for _, value := range list { rt = append(rt, tl(value)) } return rt } func main() { // 匿名函数：没有名字的函数 定义后直接赋值给某个变量 直接调用 // 往往做一些辅助性的功能(临时一个地方使用) 缩短作用域 // 匿名结构体 // 匿名接口 add := func(left, right int) int { return left + right } fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, add, add) fmt.Println(add(5, 5)) // tlAdd5 := func(n int) int { // return n + 5 // } nums := []int{1, 2, 3, 4, 5} fmt.Println(mapFunc(nums, func(n int) int { return n + 10 })) x := func(left, right int) int { return left + right }(5, 5) fmt.Println(x) func(left, right int) int { // 不要返回值 fmt.Println(left, right) return left + right }(11, 11) } 闭包 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // 在函数内部 会定义匿名函数 该匿名函数会引用外层函数的变量 package main import \u0026#34;fmt\u0026#34; // 生成一个新的函数 每次调用生成一个ID =\u0026gt; 从start开始 id的间隔是step // 面向切面编程 装饰器 // generateId执行完成后 start step不能被销毁 闭包(内层匿名函数使用了外层函数的局部变量)使他们的生命周期变长 func generateId(start, step int) func() int { return func() int { fmt.Printf(\u0026#34;start: %v\\n\u0026#34;, start) id := start start += step return id } } func main() { g1 := generateId(0, 1) fmt.Println(g1()) fmt.Println(g1()) fmt.Println(g1()) fmt.Println(g1()) fmt.Println(g1()) g100 := generateId(100, 100) fmt.Println(g100()) fmt.Println(g100()) fmt.Println(g100()) fmt.Println(g100()) } // 闭包：改变了变量的生命周期和作用域 // 变量的声明周期：从变量创建到销毁的过程 // 变量的作用域：变量可以使用的范围 类型 1 2 3 4 5 var t T tmp := t // 对tmp进行修改 可能影响到t =\u0026gt; 引用类型 // 反之 任何操作都不能影响t =\u0026gt; 值类型 值类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 int string bool [...]int // 数组 也是值类型 结构体 指针 pointer // 有争议 为了降低函数参数拷贝带来的内存翻倍 会使用指针进行传递 package main import \u0026#34;fmt\u0026#34; func main() { nums := [...]int{1, 2, 3, 4, 5} nums2 := nums fmt.Println(nums, nums2) // [1 2 3 4 5] [1 2 3 4 5] nums2[0] = 1000 fmt.Println(nums, nums2) // [1 2 3 4 5] [1000 2 3 4 5] } 引用类型 1 2 3 4 // 切片 // 映射 // 使用了指针 或 内存地址 值传递 1 2 3 4 5 6 7 形参 = 实参 // 把实参 赋值给了实参 =\u0026gt; 把实参的内存地址中的数据复制一份 赋值给形参 // 形参是实参的副本 // 在函数内对形参修改 不会对外面的实参有影响 // go中 不管值类型 还是引用类型 都会把实参对应内存地址的值复制一份 复制给形参 // 注意：当传递的是 引用类型的时候 比如切片 因为共享底层数组的关系 在函数内修改索引的值 会影响底层数组的值 从而影响实参的值 错误处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // go标准建议显式的将错误信息通过返回值返回给调用者 由调用者自行处理 func() (xxx1, xxx2, error) package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) /* 错误： 语法错误 =\u0026gt; 编译失败 运行时 =\u0026gt; 可恢复错误/不可恢复错误 网络问题失败 读取文件失败 写文件磁盘空间不足 ... */ func fact(n int64) (int64, error) { if n \u0026lt; 0 { return 0, errors.New(\u0026#34;计算错误\u0026#34;) } if n == 1 || n == 0 { return 1, nil } r, err := fact(n - 1) if err == nil { return n * r, nil } return 0, fmt.Errorf(\u0026#34;计算错误\u0026#34;) } func main() { var i int var err error // i, err := strconv.Atoi(\u0026#34;1.1.1.1\u0026#34;) i, err = strconv.Atoi(\u0026#34;1.1.1.1\u0026#34;) fmt.Println(i, err) fmt.Printf(\u0026#34;%T %v\\n\u0026#34;, err, err) } panic抛出错误 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main func fact(n int64) int64 { if n \u0026lt; 0 { panic(\u0026#34;n不能小于0\u0026#34;) } if n == 1 || n == 0 { return 1 } rt := n * fact(n-1) return rt } func main() { fact(-1) } 捕获错误 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // recover关键字 =\u0026gt; 需要放置在延迟执行内部 package main import \u0026#34;fmt\u0026#34; func fact(n int64) int64 { if n \u0026lt; 0 { panic(\u0026#34;n不能小于0\u0026#34;) } if n == 1 || n == 0 { return 1 } rt := n * fact(n-1) return rt } func main() { // defer 函数调用 defer func() { if errMsg := recover(); errMsg != nil { fmt.Println(errMsg) // 相当于捕获错误 } }() fmt.Println(fact(1)) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // 函数将错误返回 package main import ( \u0026#34;fmt\u0026#34; ) func fact(n int64) int64 { if n \u0026lt; 0 { panic(\u0026#34;n不能小于0\u0026#34;) } if n == 1 || n == 0 { return 1 } rt := n * fact(n-1) return rt } func testError() (err error) { // defer 函数调用 defer func() { if errMsg := recover(); errMsg != nil { err = fmt.Errorf(\u0026#34;%v\u0026#34;, errMsg) } }() fmt.Println(fact(1)) return } func main() { fmt.Println(testError()) } 延迟执行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // 执行函数 不管内部逻辑是否发生错误 都想要执行的代码 // 关键字：defer 后面必须跟函数调用 package main import \u0026#34;fmt\u0026#34; func fact(n int64) int64 { if n \u0026lt; 0 { panic(\u0026#34;n不能小于0\u0026#34;) } if n == 1 || n == 0 { return 1 } rt := n * fact(n-1) return rt } func main() { // defer 函数调用 defer fmt.Println(\u0026#34;main\u0026#34;) // 不管是否有错误 都在所在的函数退出的时候执行 defer func() { fmt.Println(\u0026#34;defer 1\u0026#34;) }() defer func() { fmt.Println(\u0026#34;defer 2\u0026#34;) }() defer func() { fmt.Println(\u0026#34;defer 3\u0026#34;) }() fmt.Println(fact(1)) } // $ go run panic.go // 同一个函数内多个defer 先定义的后执行 // 1 // defer 3 // defer 2 // defer 1 // main defer注意事项 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // defer内修改值 package main import \u0026#34;fmt\u0026#34; func test() (i int) { defer func() { // defer 函数退出前执行 这个时候返回2 // 除了error场景 不要在defer中使用修改返回值 i = 2 }() i = 1 return i } func main() { fmt.Println(test()) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 闭包陷阱 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;start\u0026#34;) for i := 0; i \u0026lt; 3; i++ { // 函数退出的时候 i的值为3 闭包陷阱 defer func() { fmt.Println(i) }() } fmt.Println(\u0026#34;end\u0026#34;) } // $ go run defer2.go // start // end // 3 // 3 // 3 // 注意：defer不要写在循环之内 作用域 作用域内定义变量只能被声明一次且变量必须使用 否则编译错误 在不同作用域可定义相同的变量 此时局部将覆盖全局 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package main import \u0026#34;fmt\u0026#34; var version string = \u0026#34;1.1.1\u0026#34; func main() { // main作用域 // 作用域： 变量的可使用范围 // {}显示的声明一个作用域范围 - 嵌套{}可以想象为一个树状图 // 1. 在某个作用域范围内定义的变量 可以在其作用域每使用；子孙定义的 父看不见 // 2. 若标识符在某个作用域中有定义 若子孙某层作用域内重新定义 则被覆盖 // 对内穿透 就近原则 对外不可见(类比Python作用域记忆) fmt.Println(\u0026#34;version1\u0026#34;, version) // 1.1.1 var funcVersion string = \u0026#34;2.2.2\u0026#34; var version string = \u0026#34;1.2.3\u0026#34; fmt.Println(\u0026#34;version2\u0026#34;, version) // 1.2.3 // funcVersion string = \u0026#34;2.3.4\u0026#34; // 报错 同一块作用域 不能重新定义 { // A{}块 fmt.Println(\u0026#34;version3\u0026#34;, version) // 1.2.3 version = \u0026#34;AAAAA\u0026#34; // 这里直接修改的 main.version 重新赋值变量 fmt.Println(\u0026#34;version4\u0026#34;, version) // AAAAA } fmt.Println(\u0026#34;version5\u0026#34;, version) // AAAAA { // B{}块 fmt.Println(\u0026#34;version6\u0026#34;, version) // AAAA main.version var version string = \u0026#34;BBBBB\u0026#34; // 在B块作用域内重新定义了一个version 没有改变main.version fmt.Println(\u0026#34;version7\u0026#34;, version) // BBBBB } fmt.Println(\u0026#34;version8\u0026#34;, version) // AAAAA fmt.Println(version, funcVersion) } $ go run scope.go \u0026gt;\u0026gt;\u0026gt; version1 1.1.1 \u0026gt;\u0026gt;\u0026gt; version2 1.2.3 \u0026gt;\u0026gt;\u0026gt; version3 1.2.3 \u0026gt;\u0026gt;\u0026gt; version4 AAAAA \u0026gt;\u0026gt;\u0026gt; version5 AAAAA \u0026gt;\u0026gt;\u0026gt; version6 AAAAA \u0026gt;\u0026gt;\u0026gt; version7 BBBBB \u0026gt;\u0026gt;\u0026gt; version8 AAAAA \u0026gt;\u0026gt;\u0026gt; AAAAA 2.2.2 显式作用域 1 2 显式声明作用域： {} 大括号 隐式作用域 1 2 3 4 5 隐式声明作用域： 1. 全局作用域 2. 包作用域 3. 文件作用域 4. if switch for select case语句块 流程控制 if 1 2 3 4 5 6 7 8 9 10 11 12 13 14 if expr1 { cmd1 } else if expr2 { cmd2 ... } else if exprn { cmdn } else { default_cmd } // if必须有 // else if任意多个 // esle 0个或1个 switch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;fmt\u0026#34; func main() { var value string fmt.Scan(\u0026amp;value) // 从console获取值 switch value { case \u0026#34;sg\u0026#34;: fmt.Println(\u0026#34;gre2\u0026#34;) case \u0026#34;us\u0026#34;: fmt.Println(\u0026#34;gre3\u0026#34;) case \u0026#34;tw\u0026#34;: fmt.Println(\u0026#34;gre4\u0026#34;) default: fmt.Println(\u0026#34;gre1\u0026#34;) } } for 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 package main import \u0026#34;fmt\u0026#34; func main() { // var s string = \u0026#34;My name is Minho\u0026#34; // for init; expr; end {} // 1 + 2 + ... + 100 var total int = 0 for i := 1; i \u0026lt;= 100; i++ { total += i } fmt.Println(total) total = 0 var i int = 1 for i \u0026lt;= 100 { // 类while写法 total += i i++ } fmt.Println(total) // var nums int = 0 // for { // 死循环 类似于python： while True: cmd // nums++ // fmt.Println(nums) // } // break for i := 1; i \u0026lt; 5; i++ { if i == 3 { break // 结束循环 } fmt.Println(i) } // continue for i := 1; i \u0026lt; 5; i++ { if i == 3 { continue // 跳过本次循环 下次继续 } fmt.Println(i) } } // continue break只能跳出或结束当前循环 // 配合label使用 可以跳出到指定label BEXIT: for i := 0; i \u0026lt; 3; i++ { for j := 0; j \u0026lt; 3; j++ { if j == 1 { break BEXIT // 直接跳出for循环 } } } CEXIT: for i := 0; i \u0026lt; 3; i++ { for j := 0; j \u0026lt; 3; j++ { if j == 1 { continue CEXIT // 直接跳出到for循环 } } } goto 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import \u0026#34;fmt\u0026#34; func main() { total, incr := 0, 0 START: // label表示 标识符: total += incr incr++ if incr \u0026lt;= 100 { goto START } goto END fmt.Println(total) // 此时 永远无法执行这个print语句 END: fmt.Println(\u0026#34;total:\u0026#34;, total) } 单步调试工具 dlv 1 2 3 $ dlv debug xxx.go # help查看完整帮助 # vscode有图形界面可以调试 debug模式 包管理/模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // 包 模块 代码main =\u0026gt; 分函数 =\u0026gt; 分文件 =\u0026gt; 分文件夹 // 代码整理(项目的组织方式) 第三方别人开发的包 -\u0026gt; github.com -\u0026gt; 下载 -\u0026gt; GOPATH src go工具： go build go install 第三方包地址 go get 第三方包地址 github.com/ilolicon/xxx // 下载第三方包 git/svn 第三方包查找地址： https://godoc.org/ https://gowalker.org/ 变量可见性： 首字母大小写的问题 首字母小写的变量只对包内可见 首字母大写才对外部的其他包可见(可以调用) // 包 包名：在同一个文件夹内 包名必须一致 main包：可编译为可执行的结果(二进制程序) package 定义为 main 功能代码：若功能不需要编译为可执行程序 -\u0026gt; 命名为非main -\u0026gt; 可以任意定义 -\u0026gt; 标识符规范(一般使用文件夹名称) 若不在同一个包下面调用不同文件中定义的函数 导入： - package包名和目录一致：导入目录路径(GOPATH src后面的目录路径) import \u0026#34;cmdb/user\u0026#34; - package包名和目录不一致：import \u0026#34;cmdb/idc\u0026#34; 注意 导入仍是路径 但是这个调用的包名则不一致 调用：通过包名.函数名称 // GO111MODULE GO111MODULE=on/off/auto on -\u0026gt; 启动module off -\u0026gt; 关闭module -\u0026gt; gopath + vendor auto -\u0026gt; 自动判断 依据：代码不再GOPATH目录 目录存在go.mod文件 -\u0026gt; 都满足为module 否则为gopath+vendor方式 GOPATH + vendor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 方案1：1.11 之前 gopath + vendor方式/其他开源方案 gopath: -\u0026gt; GOPATH(配置一个或者多个目录) // GOPATH=C:\\Users\\97431\\go // 代码必须放在GOPATH目录下 src -\u0026gt; 源码 bin -\u0026gt; 放二进制文件 pkg -\u0026gt; 第三方包(经过编译过的.a文件) // go install xx的时候会生成相关依赖的.a文件 -\u0026gt; 编译快 vendor: 主要解决多版本问题 优先调用vendor目录下面的版本(代码) vendor：可以放在任何目录 查找的时候： 当前目录查找vendor(无vendor/有vendor无包) -\u0026gt; 上一级目录 -\u0026gt; ... -\u0026gt; GOPATH vendor -\u0026gt; GOPATH -\u0026gt; 标准库 -\u0026gt; 报错 // 代码放在GOPATH目录下 可以在任意目录build go build . || go build user(GOPATH src下面的目录名) // cp $WORK\\b001\\exe\\a.out.exe C:\\GoWorkspace\\go\\bin\\user.exe // 将程序编译并拷贝到GOPATH的bin目录下 go install -x user(GOPATH src下面的目录名) // 导入包 /* GOPATH/ cmdb/ user/ main.go // 都在user包里面 调用user.go里面的函数 直接使用函数名称调用即可 user.go // 都在user包里面 */ package main func main() { // 在同一个包下面调用不同文件中定义的函数 -\u0026gt; 直接调用函数名称 add() modify() delete() find() } ------------------------------ /* GOPATH/ cmdb/ user/ user.go // 功能代码 idc/ idc.go // 功能代码 main.go */ package main import ( \u0026#34;cmdb/user\u0026#34; // GOPATH src后面的目录路径 ) func main() { // 在不同包下面调用不同文件中定义的函数 -\u0026gt; 先导入包 -\u0026gt; 通道包名.函数名称 // 但是这里会报错 =\u0026gt; 变量可见性问题 标识符首字符小写 只能包内使用 不能导出 user.add() user.modify() user.delete() user.find() } MODULE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 方案2：1.11及之后 GOMODULE(重点) // GO 1.11 MODULE 优势： - 不用设置GOPATH 代码可以任意放置 - 自动下载依赖管理 - 版本控制 - 不允许使用相对导入 - replace机制(网络问题goproxy 和 包重命名问题 现在很少使用) GO111MODULE // 初始化模块 go mod init 模块名称 // go mod init cmdb go mod tidy // 下载依赖的第三方模块 执行：go run . go build . // 模块名称命名 1. 远程仓库的命名称 cmdb -\u0026gt; github.com/ilolicon/cmdb // 简单 不能作为第三方包使用 2. 带上仓库地址：git mod init github.com/ilolicon/cmdb // github地址 + 用户名 + 账号名称 指定版本：依赖tag git/svn -\u0026gt; tag v0.x.x v1.x.x 下载指定版本：go get github.com/ilolicon/math@v1.0.0 或者手动修改go.mod文件 重新go mod tidy // GO111MODULE 导入包 同模块 package main import ( // 同模块 -\u0026gt; modulename(go mod init初始化时给出的模块名称)/目录路径 // go.mod文本文件 依赖 模块名称 可以直接修改 \u0026#34;cmdbxx/user\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { fmt.Println(\u0026#34;Hello, World\u0026#34;) user.Add() } ----------------------- package main import ( \u0026#34;cmdb/user\u0026#34; // 同模块 -\u0026gt; modulename/目录路径 \u0026#34;fmt\u0026#34; \u0026#34;github.com/beego/beego/v2/server/web\u0026#34; // 使用第三方模块 go mod tidy ) func main() { fmt.Println(\u0026#34;Hello, World\u0026#34;) user.Add() web.Run() } // 导入远程第三方包 package main import ( \u0026#34;fmt\u0026#34; // go mod tidy 会自动去下载 \u0026#34;github.com/ilolicon/math\u0026#34; ) func main() { fmt.Println(math.PI) fmt.Println(math.Add(5, 7)) } // math包设置 模块名以 github.com + 用户名 + 模块名 设置 // go mod init github.com/ilolicon/math package math const PI float32 = 3.141592653 func Add(l, r int) int { return l + r } // 包名冲突 使用别名解决 // 别名导入 import ( testmod/aaa/math\u0026#34; // 绝对路径导入 -\u0026gt; 还有相对路径导入 gomod禁用 bmath \u0026#34;testmod/bbb/math\u0026#34; // 别名直接在导入包前面设置即可 ) func main() { math.Add(1, 1) bmath.Add(1, 1) } // 点导入 import ( . \u0026#34;testmod/aaa/math\u0026#34; // 点导入 调用包内函数的变量 不用加包名 尽量不用 减少变量污染 ) func main() { Add(1, 1) } // 下划线导入 // 包导入不使用 会报错 可以使用下划线导入 // 不使用还导入 有什么作用？ -\u0026gt; 包初始化 执行包内初始化函数 func init() {} import ( _ \u0026#34;testmod/aaa/math\u0026#34; // 别名导入的特殊形式 注册机制会用到 ) 导入总结 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /* 导入包 绝对路径导入 GOPATH src下的目录 gomod 同模块 模块名称/路径 第三方模块 第三方模块名称/路径 别名导入 导入多个相同名称的包 下划线导入 包初始化 init 不要依赖他的顺序 相对路径导入 gomod中禁用 点导入 尽量不用 容易变量冲突 污染 */ init函数 1 2 3 4 5 6 // 导入包 会自动调用该包内的init函数 // 一个包内可以有任意多个 可以定义无数次 但建议只写1个 func init() { cmd // go定义的初始化函数 没有参数 没有返回值 包被导入的时候 自动执行 } 可见性 1 2 // 只能在包内可用：包内可见 变量名称小写 // 可以在包外使用：包外可见 变量名称大写 标准库及第三方库 标准库官网文档\nGolang标准库中文文档\nfmt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 fmt.Printf() /* 格式化的字符串 占位 后面的数据进行填充 占位符 %T %v %#V 与数据类型无关 打印变量类型 %v %#V 以可识别的格式打印 %s 字符串 %d 整数 %t 布尔值true|false */ package main import \u0026#34;fmt\u0026#34; func main() { var name = \u0026#34;minho\u0026#34; var id = 1 fmt.Printf(\u0026#34;name: %T, id: %T\\n\u0026#34;, name, id) fmt.Printf(\u0026#34;name: %v, id: %v\\n\u0026#34;, name, id) fmt.Printf(\u0026#34;name: %#v, id: %#v\\n\u0026#34;, name, id) fmt.Printf(\u0026#34;name: %s, id: %d\\n\u0026#34;, name, id) } $ go run debug.go \u0026gt;\u0026gt;\u0026gt; name: string, id: int \u0026gt;\u0026gt;\u0026gt; name: minho, id: 1 \u0026gt;\u0026gt;\u0026gt; name: \u0026#34;minho\u0026#34;, id: 1 \u0026gt;\u0026gt;\u0026gt; name: minho, id: 1 输入输出 1 2 3 4 5 6 7 8 9 10 // 输出 fmt.Println() fmt.Print() fmt.Printf -\u0026gt; 占位符 // 输入(从控制台获取输入) fmt.Scan // 先定义比变量 // fmt.Scan(\u0026amp;变量名) strconv 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // import \u0026#34;strconv\u0026#34; // strconv包实现了基本数据类型和其字符串表示的相互转换 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { // i, err := strconv.Atoi(\u0026#34;10\u0026#34;) // if err != nil { // panic(err) // } // fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, i, i) // 上面部分可以写在一行 if放在最前面 这样变量i err就成了if块的局部变量 if i, err := strconv.Atoi(\u0026#34;10\u0026#34;); err != nil { // string =\u0026gt; int panic(err) } else { fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, i, i) } // int =\u0026gt; string fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, strconv.Itoa(10), strconv.Itoa(10)) // string =\u0026gt; float64 f, err := strconv.ParseFloat(\u0026#34;12.2\u0026#34;, 64) if err != nil { panic(err) } fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, f, f) // float64 =\u0026gt; string fmt.Println(strconv.FormatFloat(12.2, \u0026#39;E\u0026#39;, -1, 64)) fmt.Println(strconv.FormatFloat(12.2, \u0026#39;f\u0026#39;, -1, 64)) // string =\u0026gt; int8 int16 int32 int64 -\u0026gt; ParseInt ParseUint // int8 int16 int32 int64 =\u0026gt; string -\u0026gt; FormatInt FormatUint } strings 用于操作字符的简单函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { fmt.Println(strings.Compare(\u0026#34;abc\u0026#34;, \u0026#34;ade\u0026#34;)) // -1 fmt.Println(strings.Contains(\u0026#34;abc\u0026#34;, \u0026#34;ab\u0026#34;)) // true fmt.Println(strings.Count(\u0026#34;abcabcabc\u0026#34;, \u0026#34;ab\u0026#34;)) // 3 fmt.Println(strings.EqualFold(\u0026#34;ab\u0026#34;, \u0026#34;AB\u0026#34;)) // true 比较 忽略大小写 fmt.Println(strings.Fields(\u0026#34;a b\\tc\\r\\nd\\fe\u0026#34;)) // [a b c d e] fmt.Println(strings.HasPrefix(\u0026#34;test.go\u0026#34;, \u0026#34;test\u0026#34;)) // true fmt.Println(strings.HasSuffix(\u0026#34;test.go\u0026#34;, \u0026#34;.exe\u0026#34;)) // false fmt.Println(strings.Index(\u0026#34;1abcabc\u0026#34;, \u0026#34;ab\u0026#34;)) // 1 字符在字符串中出现的位置(索引) 没找到返回-1 fmt.Println(strings.LastIndex(\u0026#34;1abcabc\u0026#34;, \u0026#34;ab\u0026#34;)) // 4 // 连接与分割 fmt.Println(strings.Join([]string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}, \u0026#34;-\u0026#34;)) // a-b-c fmt.Println(strings.Split(\u0026#34;a-b-c\u0026#34;, \u0026#34;-\u0026#34;)) // 分割为切片 fmt.Println(strings.SplitN(\u0026#34;a-b-c\u0026#34;, \u0026#34;-\u0026#34;, 2)) // [a b-c] fmt.Println(strings.Repeat(\u0026#34;*\u0026#34;, 20)) fmt.Println(strings.Replace(\u0026#34;abc,abc,abcd, abd\u0026#34;, \u0026#34;abc\u0026#34;, \u0026#34;xyz\u0026#34;, -1)) // -1 == ReplaceAll fmt.Println(strings.Trim(\u0026#34;bcaAbcdeacb\u0026#34;, \u0026#34;abc\u0026#34;)) // Abcde 左右都移除 // TrimLeft/TrimRight 和 TrimSuffix/TrimPreffix 区别 // TrimLeft/TrimRight 把给出的字符串中的每一个字符 都去目标字符串中移除 // TrimSuffix/TrimPreffix 把给出的字符串当作一个整体 去目标字符串中移除 fmt.Println(strings.TrimSpace(\u0026#34; abc abc\\r\\n\\f\u0026#34;)) // abc abc 去除前后空白字符 } // 类比 bytes包 一个对字符串操作 一个对字节切片操作 sync sync.atomic 1 2 3 4 5 6 7 8 // 原子操作 原子操作是指过程中不能中断的操作s Go语言sync/atomic包中提供了五类原子操作函数 其操作对象为整数型或整数指针 - Add* 增加/减少s - Load* 载入 - Store* 存储 - Swap* 更新 - CompareAndSwap* 比较第一个参数引用值是否与第二个参数值相同 若相同则将第一个参数值更新为第三个参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // 对共享内存操作 - 加锁 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var counter int var wg sync.WaitGroup var locker sync.Mutex wg.Add(10) for i := 0; i \u0026lt; 5; i++ { go func() { for x := 0; x \u0026lt; 10000; x++ { locker.Lock() counter += 1 locker.Unlock() } wg.Done() }() go func() { for x := 0; x \u0026lt; 10000; x++ { locker.Lock() counter -= 1 locker.Unlock() } wg.Done() }() } wg.Wait() fmt.Println(counter) // 不加go关键字使用协程 结果为0 // 使用go启动协程之后 对同一个内存(\u0026amp;counter)进行操作 会有冲突 需要加锁 或 原子操作 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // 原子操作 操作类型有限 使用较少 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; ) func main() { var counter int64 var wg sync.WaitGroup wg.Add(10) for i := 0; i \u0026lt; 5; i++ { go func() { for x := 0; x \u0026lt; 10000; x++ { atomic.AddInt64(\u0026amp;counter, 1) } wg.Done() }() go func() { for x := 0; x \u0026lt; 10000; x++ { atomic.AddInt64(\u0026amp;counter, -1) } wg.Done() }() } wg.Wait() fmt.Println(counter) } sync.Mutex/RWMutex 1 2 3 4 5 // sync.Mutex 互斥锁 // sync.RWMutex 读写锁 // obj =\u0026gt; 写write: g1 write; g2 write 需要加锁 不能同时写 互斥 =\u0026gt; 互斥锁 // obj =\u0026gt; 读read: g1 read; g2 write 正在写不让读 正在读不让写 =\u0026gt; 互斥锁 // obj =\u0026gt; 读read： g1 read; g2 read 正在读被其他读(可以允许 如果使用Mutex 有锁不会让其他协程读) =\u0026gt; 读写锁 sync.Map 1 2 // Go的内置类型 map 不是线程安全的 // sync.Map是线程安全的 但操作的类型都是接口类型 需要进行断言(类型转换) sync.Once 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 控制程序只执行一次 包括并发的情况下 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func conf() { fmt.Println(\u0026#34;conf\u0026#34;) } func main() { var once sync.Once // once.Do(conf) // once.Do(conf) // once.Do(conf) var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { once.Do(conf) // conf() wg.Done() }() } wg.Wait() } sync.Pool 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // sync.Pool // 需要资源 从池子里面获取 当池子中没有会进行创建并返回 有则直接复用 用完后归还 资源的重复利用 // 对象创建时耗费资源 // 网络连接池 // 数据库连接池 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { objPool := sync.Pool{ New: func() interface{} { fmt.Println(\u0026#34;new\u0026#34;) return \u0026#34;123456789\u0026#34; }, } obj := objPool.Get() fmt.Println(obj) obj2 := objPool.Get() fmt.Println(obj2) objPool.Put(obj) obj3 := objPool.Get() fmt.Println(obj3) // 直接打印123..9 不会调用打印new } // 自定义连接池结构体 type TCPPool struct { addr string pool *sync.Pool max int // 池子中保持的 最大连接数 超过报错 idle int // 池子中闲置的连接数量 min int // 池子中最小的连接数 poolCnt int // 池子的连接数量 count int // 总的连接数量 locker *sync.Mutex } runtime 1 2 3 4 5 6 7 // go doc runtime go运行时的一些配置信息 func GOMAXPROCS(n int) int // 配置GMP模型中 P的数量 func GOROOT() string // 获取Go的安装目录 func Gosched() // 让出时间片 func NumCPU() int // 获取CPU数量 func NumGoroutine() int // 获取协程数量 logr logrus 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package logger import ( \u0026#34;fmt\u0026#34; \u0026#34;path\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strconv\u0026#34; log \u0026#34;github.com/sirupsen/logrus\u0026#34; \u0026#34;gopkg.in/natefinch/lumberjack.v2\u0026#34; ) func RotateLogger(logName string) *lumberjack.Logger { cfg := global.CFG.Log return \u0026amp;lumberjack.Logger{ Filename: logName, MaxSize: cfg.MaxSize, MaxBackups: cfg.MaxBackups, LocalTime: cfg.LocalTime, Compress: cfg.Compress, } } func Logger(cfg *config.Config) *log.Logger { if cfg.ServerLog == \u0026#34;\u0026#34; || cfg.MaxSize == 0 { log.Fatal(\u0026#34;invalid configurations, please check\u0026#34;) } l := RotateLogger(cfg.ServerLog) logger := log.New() logger.SetOutput(l) level, err := log.ParseLevel(cfg.LogLevel) if err != nil { log.Fatalf(\u0026#34;invalid log level: %s\u0026#34;, cfg.LogLevel) } logger.SetLevel(level) logger.SetReportCaller(cfg.ReportCaller) logger.SetFormatter(\u0026amp;log.TextFormatter{ DisableColors: true, TimestampFormat: \u0026#34;2006-01-02 15:04:05\u0026#34;, CallerPrettyfier: func(f *runtime.Frame) (function string, file string) { return \u0026#34;\u0026#34;, fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, path.Base(f.File), strconv.Itoa(f.Line)) }, }) if err := l.Close(); err != nil { log.Fatal(err) } return logger } zap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package logger import ( \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; \u0026#34;gopkg.in/natefinch/lumberjack.v2\u0026#34; ) func Logger(cfg *config.Config) *zap.Logger { var ( customLevelEncoder = func(level zapcore.Level, encoder zapcore.PrimitiveArrayEncoder) { encoder.AppendString(level.String()) } customTimeEncoder = func(t time.Time, encoder zapcore.PrimitiveArrayEncoder) { encoder.AppendString(t.Format(\u0026#34;2006-01-02 15:04:05.000\u0026#34;)) } ) encoderConfig := zapcore.EncoderConfig{ MessageKey: \u0026#34;msg\u0026#34;, LevelKey: \u0026#34;level\u0026#34;, TimeKey: \u0026#34;time\u0026#34;, NameKey: \u0026#34;logger\u0026#34;, CallerKey: \u0026#34;caller\u0026#34;, StacktraceKey: \u0026#34;stacktrace\u0026#34;, LineEnding: zapcore.DefaultLineEnding, EncodeLevel: customLevelEncoder, EncodeTime: customTimeEncoder, EncodeDuration: zapcore.SecondsDurationEncoder, EncodeCaller: zapcore.ShortCallerEncoder, } var encoder zapcore.Encoder if cfg.Log.JsonFormat { encoder = zapcore.NewJSONEncoder(encoderConfig) } else { encoder = zapcore.NewConsoleEncoder(encoderConfig) } // 日志轮询 lumberjackLogger := \u0026amp;lumberjack.Logger{ Filename: cfg.Log.Filename, MaxSize: cfg.Log.MaxSize, MaxAge: cfg.Log.MaxAge, MaxBackups: cfg.Log.MaxBackups, Compress: cfg.Log.Compress, } var syncer zapcore.WriteSyncer if cfg.Log.LogInConsole { syncer = zapcore.NewMultiWriteSyncer(zapcore.AddSync(os.Stdout), zapcore.AddSync(lumberjackLogger)) } else { syncer = zapcore.AddSync(lumberjackLogger) } core := zapcore.NewCore(encoder, syncer, cfg.Log.UnmarshalLevel()) logger := zap.New(core) if cfg.Log.ShowLine { logger = logger.WithOptions(zap.AddCaller()) } return logger } 面向对象 自定义类型 1 2 3 4 5 6 7 8 9 - 想要自己定义一个由不同类型元素(属性 字段)组成一个复合类型 - 结构体 别名\u0026amp;重新定义 - 别名 与原有类型相同 无区别 不能定义新的方法 - 重新定义：将现有的类型进行重新定义 对新的类型提供一些方法 与原有类型的类型无关 具有原有类型特性 但是可以与原有类型进行相互转换 如：计数功能 int -\u0026gt; 计数类型; http包里的Header type Header map[string][]string 面向对象： 代码复用 =\u0026gt; 继承 组合 Go: 嵌入 =\u0026gt; 组合模式 定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 定义的关键字 var // 变量定义 const // 常量定义 func // 函数定义 type // 自定义类型定义 type TypeName Formatter 重定义：type Counter int 结构体：type User struct { 属性名称1 属性类型1 属性名称2 属性类型2 属性名称3 属性类型3 ... } 别名：type TypeName = Formatter type byte = uint8 type rune = int32 别名与重定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import \u0026#34;fmt\u0026#34; type Counter = int type Counter2 int func main() { var count Counter count = 10 fmt.Printf(\u0026#34;%T\\n\u0026#34;, count) // int var count2 Counter2 fmt.Printf(\u0026#34;%T %v\\n\u0026#34;, count2, count2) // main.Counter2 0 count2 += Counter2(count) // 可以与原类型进行类型转换 fmt.Println(count2) } 结构体 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 定义结构体 =\u0026gt; 类 =\u0026gt; 封装 /* type StructName struct { Field1 FieldType1 Field2 FieldType2 ... } type User struct { id int name string addr string tel string birthday string/uinxtime/time.Time 首选time created_at string/uinxtime/time.Time updated_at time.Time flag bool // 标识逻辑删除 status int // 1删除 0未删除 deleted_at *time.Time // 已删除: 删除时间 非nil 未删除：nil 指针零值 } */ type User struct { id int name string addr string tel string brithday time.Time createdAt time.Time updatedAt time.Time flag bool status int deletedAt *time.Time } // 类 构造器 =\u0026gt; 创建对应类的实例(对象/变量) // Go中无构造器的说法 // 函数 N(n)ew 结构体名称 构建结构体的(值/指针)对象 func NewUser(id int, name, addr, tel string, birtday time.Time) User { return User{ id: id, name: name, addr: addr, tel: tel, brithday: birtday, createdAt: time.Now(), updatedAt: time.Now(), flag: false, status: 0, deletedAt: nil, } } // 返回指针对象 func NewUserPoint(id int, name, addr, tel string, birtday time.Time) *User { return \u0026amp;User{ id: id, name: name, addr: addr, tel: tel, brithday: birtday, createdAt: time.Now(), updatedAt: time.Now(), flag: false, status: 0, deletedAt: nil, } } func main() { // 定义User类型的变量 var u User fmt.Printf(\u0026#34;%T\\n\u0026#34;, u) // main.User // 零值 =\u0026gt; 所有属性的零值组成的一个User类型的变量值 fmt.Printf(\u0026#34;%v\\n\u0026#34;, u) // 非nil fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u) // 赋值 字面量 // 设置值 按照结构体中属性定义额顺序设置 -\u0026gt; 需要给所有属性都进行赋值 u = User{1, \u0026#34;minho\u0026#34;, \u0026#34;成都\u0026#34;, \u0026#34;13424244434\u0026#34;, time.Now(), time.Now(), time.Now(), false, 0, nil} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u) // 指定名称赋值 未指定的属性名称 对应类型的零值进行初始化 u = User{id: 2, name: \u0026#34;KATHR1NE\u0026#34;} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u) // 属性进行访问和修改 fmt.Println(u.id, u.name) u.addr = \u0026#34;北京\u0026#34; fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u) // 结构体 值类型 赋值修改不影响原来的变量 // 指针类型的对象 var u3 *User fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, u3, u3) // 指针赋值 =\u0026gt; 取引用 \u0026amp; // new 申请空间并对元素使用0值进行初始化 取地址 赋值 u3 = \u0026amp;u fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u3) var u4 *User = new(User) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u4) // 字面量取引用 var u5 *User = \u0026amp;User{} // User{} User的零值 fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u5) // 与 new(User)一样 fmt.Println(\u0026#34;################\u0026#34;) u6 := NewUser(10, \u0026#34;lemon\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, time.Now()) u7 := NewUserPoint(11, \u0026#34;kathr1ne\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, time.Now()) fmt.Printf(\u0026#34;%T %v\\n\u0026#34;, u6, u6) fmt.Printf(\u0026#34;%T %v\\n\u0026#34;, u7, u7) } 匿名结构体 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 匿名结构体 =\u0026gt; 不定义名称 =\u0026gt; 不能再定义对应的变量 =\u0026gt; 只需要定义该种结构的一个变量 package main func main() { var user struct { id int name string } fmt.Printf(\u0026#34;%T\\n\u0026#34;, user) // struct {id: int name: string} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, user) // 对应类型的零值 } // 使用： // 程序的配置 // template =\u0026gt; 数据(匿名结构体) =\u0026gt; 传递给模板 new 和 make的区别 1 2 3 4 5 6 7 8 9 10 11 // new make make =\u0026gt; 创建对象 slice,map,chan new =\u0026gt; 返回指针 创建结构体指针对象 new 基本数据类型 var i int = 1 p := \u0026amp;i p := new(int) new(Struct) == \u0026amp;Struct{} =\u0026gt; New 结构体嵌套(嵌入/组合) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import \u0026#34;fmt\u0026#34; // 地址结构体 type Address struct { Province string City string Street string } // 定义用户信息 type User struct { Id int Name string Tel string Email string Addr Address // 嵌入Address结构体 即定义Address结构体的属性 - 命名嵌入 PAddr *Address } func main() { // 1. 定义 var u User var addr Address = Address{Province: \u0026#34;四川\u0026#34;, City: \u0026#34;成都\u0026#34;, Street: \u0026#34;高新\u0026#34;} // 2. 赋值 u = User{Id: 1, Name: \u0026#34;Minho\u0026#34;, Tel: \u0026#34;13308047517\u0026#34;, Email: \u0026#34;97431110@qq.com\u0026#34;, Addr: addr, PAddr: \u0026amp;addr} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u) // 3. 属性的访问和修改 fmt.Println(u.Id) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u.Addr) fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, u.PAddr, u.PAddr) u.Id = 100 u.Addr = Address{\u0026#34;北京\u0026#34;, \u0026#34;北京\u0026#34;, \u0026#34;海定区\u0026#34;} u.PAddr = \u0026amp;Address{\u0026#34;北京\u0026#34;, \u0026#34;北京\u0026#34;, \u0026#34;昌平区\u0026#34;} fmt.Println(u.Addr) fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, u.PAddr, u.PAddr) u.Addr.Street = \u0026#34;安静区\u0026#34; fmt.Println(u.Addr) u.PAddr.Street = \u0026#34;PP区\u0026#34; fmt.Println(u.PAddr.Street) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 // 匿名嵌入 不写属性名称 直接写类型 package main type Address struct { Provice string City string Street string } type User struct { Id int Name string Tel string Address // 匿名嵌入 自定义属性名Address(与类型名一致) 只能匿名嵌入一次 Street string // 属性名与匿名嵌入对象属性名相同 } type Company struct { Name string Province string } // 匿名嵌入两个对象 两个对象中有相同的属性名 type User2 struct { Id int Name string Tel string Street string Address Company } func main() { // 定义赋值访问 和命名嵌入基本一致 // 不一样的地方 // 当访问匿名嵌入对象的属性时可以省略嵌入对象的属性名 var u User fmt.Println(u.Street) // 优先查找当前对象 若无再查找匿名对象中的属性名 var u2 User2 fmt.Println(u2.Provice) // 多个匿名嵌入对象具有相同属性名 Go直接报错 语言层面 不知道选择哪个(二义性) Go限制开发者使用全路径 } // 建议 // 1. 不使用匿名嵌入 // 2. 使用匿名嵌入 访问属性的时候 使用全路径 // 可以匿名嵌入指针对象 方法 定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 方法：给特定类型定义的函数 只能由特定的类型进行调用 // 函数定义 func funcName(args) returns {} // 方法比函数多出 =\u0026gt; 接收者 // 接收者：指定函数属于哪个类型 只能由对应的类型进行调用 // 除了接收者 方法的参数/返回值 与go中的函数完全一致 // 方法定义 func (receiver) methodName(args) returns {} // 接收者也是一个参数： t T 参数类型 方法所属的类型 该方法只能由T类型的对象进行调用 // T 自定义类型 // t 变量名 在对象调用方法时用来传递调用的对象 1. 值接收者：t T 2. 指针接收者：t *T 3. 方法内不需要访问/修改t对象的属性 可以把t省略 保留类型T即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 package main import \u0026#34;fmt\u0026#34; type User struct { id int name string tel string email string } // 定义User的方法 返回用户名 func (u User) GetName() string { // u: 调用者的值拷贝 return \u0026#34;GetName:\u0026#34; + u.name } // 修改名称的方法 func (u User) SetName(name string) { u.name = name } // 指针接收者 func (u *User) PsetName(name string) { u.name = name } func (User) No() { fmt.Println(\u0026#34;No\u0026#34;) } func main() { u := User{name: \u0026#34;minho\u0026#34;} fmt.Println(u.GetName()) // 调用方法 对象.方法名称(参数) u.SetName(\u0026#34;karuin\u0026#34;) fmt.Println(u.GetName()) // GetName:minho // 调用PsetName // 语法糖：如果接收者时指针接收者 调用可以使用值对象 =\u0026gt; Go自动进行取引用 u.PsetName(\u0026#34;lemon\u0026#34;) // =\u0026gt; (\u0026amp;u).PsetName(\u0026#34;lemon\u0026#34;) fmt.Println(u.GetName()) // GetName:lemon p := \u0026amp;User{name: \u0026#34;MM\u0026#34;} // 语法糖 接收者是值接收者调用指针对象 =\u0026gt; 自动进行解引用 fmt.Println(p.GetName()) // fmt.Println((*p).GetName()) p.PsetName(\u0026#34;QQ\u0026#34;) fmt.Println(p.GetName()) p.No() } type Counter = int // 别名不能定义方法 // 重定义可以定义方法 type Counter int func (c *Counter) Incr() { (*c)++ } 可见性 1 2 3 // 与属性相同 // 首字母大写 =\u0026gt; 包外可见 // 首字母小写 =\u0026gt; 包内可见 方法表达式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package main type User struct { Name string } func (u User) GetName() string { return u.Name } func (u User) SetName(name string) { u.Name = name } func (u *User) PsetName(name string) { u.Name = name } func main() { // 定义 =\u0026gt; T类型 // 调用 =\u0026gt; T(值/指针)变量/对象/实例 // 访问方法 // T.方法名 // 定义对象 对象.方法名 // 方法表达式 // 值接收者类型 f := User.GetName fmt.Printf(\u0026#34;%T\\n\u0026#34;, f) // func(main.User) string 是一个函数类型 可以直接调用 参数为自定义User类型 fmt.Println(f(User{Name: \u0026#34;minho\u0026#34;})) // minho fmr.Println(User.GetName(User{Name: \u0026#34;XXXX\u0026#34;})) f2 := User.SetName // 多个参数 fmr.Printf(\u0026#34;%T\\n\u0026#34;, f2) // func(main.User, string) // 指针类型接收者 f3 := (*User).PsetName // 方法为指针接收者 调用者必须为对应类型的指针类型 User.PsetName报错 fmt.Printf(\u0026#34;%T\\n\u0026#34;, f3) f4 := (*User).GetName fmt.Printf(\u0026#34;%T\\n\u0026#34;, f4) // func(*main.User) string } // 如果定义了值接收者方法 Go会自动生成一个对应的指针接收者方法 方法值 1 2 3 4 5 6 7 // 代码接上 u = User{Name: \u0026#34;Minho\u0026#34;} m1 = u.GetName fmt.Printf(\u0026#34;%T\\n\u0026#34;, m1) // func() strirng fmt.Println(m1()) // 加括号执行 Minho 文件操作 1 2 3 4 5 6 // 相关包(常用) // os：文件操作 // filepath：文件路径 // bufio：带缓冲区IO // fs: 抽象包 1.15提供的 // ioutil: 提供工具函数 文件路径 1 2 // 相对路径 // 绝对路径 操作 1 2 3 4 5 6 7 8 9 10 11 // 文件内容：010101 []byte \u0026lt;=编码/解码=\u0026gt; string(utf8) 读文件 os.Open() // 文件必须存在 参数：路径 返回值：*File, error 读文件 Read([]byte) n, err ReadAt([]byte, int64) n, err 关闭文件 Close() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) func main() { path := \u0026#34;readfile.txt\u0026#34; file, err := os.Open(path) if err != nil { fmt.Println(\u0026#34;error:\u0026#34;, err) } else { defer file.Close() fmt.Println(\u0026#34;success\u0026#34;) // 读文件 data := make([]byte, 3) for { n, err := file.Read(data) if err != nil { // 出错 if err != io.EOF { fmt.Println(err) } break } else { fmt.Println(data[:n], string(data[:n])) } } // 读取文件内容到字节切片data中 // n:读取字节的数量 error: EOF 结束符 // n, err := file.Read(data) // fmt.Println(data, n, err) // fmt.Println(data[:n]) // fmt.Printf(\u0026#34;%q, %q\u0026#34;, string(data), string(data[:n])) // file.Close() } } 写文件 os.Crete() // 创建文件 go doc os.Create // 文件不存在 创建; 文件存在：清空 写： Write WriteString WriteAt 关闭文件： Close // copyFile package main import ( \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { // copyfile src dst if len(os.Args) != 3 { log.Fatal(\u0026#34;usage: copyfile srcfile dstfile\u0026#34;) } srcFile, dstFile := os.Args[1], os.Args[2] // 读取srcFile src, err := os.Open(srcFile) if err != nil { log.Fatal(err) } defer src.Close() // 写dstFile dst, err := os.Create(dstFile) if err != nil { log.Fatal(err) } defer dst.Close() bufferSize := 10 data := make([]byte, bufferSize) for { n, err := src.Read(data) if err != nil { if err != io.EOF { log.Fatal(err) } break } n, err = dst.Write(data[:n]) if err != nil { log.Fatal(err) } } } 追加文件 OpenFile os.OpenFile(path, os.O_CREATE|os.OWRONLY|os.O_APPEND, os.ModePerm) 文件指针 Seek(offset, whence) whence 0 文件开始位置 1 当前指针位置 2 文件末尾 offset 偏移 获取位置Seek(1, 0) // 将日志和文件结合起来 package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { file, err := os.OpenFile(\u0026#34;web.log\u0026#34;, os.O_CREATE|os.O_WRONLY|OS.O_APPEND, os.ModePerm) if err != nil { log.Fatal(err) } log.SetOutput(file) log.Print(\u0026#34;第一条日志\u0026#34;) } -- fmt.Print/Println/Printf // 输出内容 fmt.Sprint/Sprintln/Sprintf // 将字符串作为值返回 fmt.Fprint/Fprintln/Fprintf(io.Writer, 变量/模板, 变量) // 将内容写入文件 func main() { file, _ := os.Create(\u0026#34;file\u0026#34;) fmt.Fprint(file, 1, 2, 3) // 将1 2 3写入文件 fmt.Fprintln(file, 4, 5, 6) fmt.Fprintf(file, \u0026#34;My name is %s\\n\u0026#34;, \u0026#34;Minho\u0026#34;) } -- fmt.Scan // 从控制台扫描(读取)变量 fmt.Fscan // 从文件扫描 fmt.Sscan // 从字符串扫描 -- // 读取目录下的子文件(有可能是一个文件 有可能是一个目录) fmt.Println(file.Readdir(10)) fmt.Println(file.Readdirnames(10)) fmt.Println(file.Readdirnames(10)) // 10 读取10个文件或目录 fmt.Println(file.Readdirnames(-1)) // -1 读取所有文件或目录 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { file, err := os.Open(\u0026#34;.\u0026#34;) if err != nil { if os.IsNotExist(err) { fmt.Println(\u0026#34;文件不存在\u0026#34;) return } log.Fatal(err) } defer file.Close() files, err := file.Readdir(-1) for _, f := range files { // 文件信息 fmt.Println(f.IsDir(), f.Name(), f.Size(), f.ModTime(), f.Mode()) } } -- file, err := os.Stat(file/dir) // reutrn FileInfo // 判断文件是否存在 // os.Lstat =\u0026gt; 链接文件的信息 os.Stat =\u0026gt; 源文件的信息 os.IsExist(error) // 参数为：error类型 返回 bool os.IsNotExist(error) os.Remove(file) // 删除文件 os.Remove(dir) // 删除目录 os.Removeall(dir) // rm -rf 目录不为空也可以删除 os.Rename(\u0026#34;aa\u0026#34;, \u0026#34;bb\u0026#34;) // 文件重命名 os.Chmod(\u0026#34;aa\u0026#34;, 0600) // 设置权限 os.Mkdir(\u0026#34;xxx\u0026#34;, os.ModePerm) // 创建目录 os.MkdirAll(\u0026#34;x/y/z\u0026#34;, os.ModePerm) // mkdir -p -- io.Copy // 复制文件 io.MultiWriter() // 输出流(可以写数据的) io.MultiReader() // 输入流(可以读取数据的) 按照顺序读取所有文件中的内容 f1, _ := os.Create(\u0026#34;f1.txt\u0026#34;) f2, _ := os.Create(\u0026#34;f2.txt\u0026#34;) m := io.MultiWriter(f1, f2) m.Write([]byte(\u0026#34;abc\u0026#34;)) // 写到多个流 目录操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // filepath // go doc filepath filepath.Abs(\u0026#34;.\u0026#34;) // 获取绝对路径 filepath.Dir(\u0026#34;/root/cfg.ini\u0026#34;) // 获取文件目录 /root filepath.Base(\u0026#34;/root/cfg.ini\u0026#34;) // 获取文件名 cfg.ini filepath.Ext(\u0026#34;/root/cfg.ini\u0026#34;) // 获取文件后缀 .ini filepath.Join(\u0026#34;/root/mm\u0026#34;, \u0026#34;xx\u0026#34;, \u0026#34;ll.ini\u0026#34;) // 拼接路径 filepath.Split(\u0026#34;/root/cfg.ini\u0026#34;) // 分隔path /root/ cfg.ini filepath.Glob(\u0026#34;./*.go\u0026#34;) // 匹配文件 类似Unix通配符 filepath.Glob(\u0026#34;./*/*.txt\u0026#34;) // filepath.Walk 遍历目录 filepath.Walk(\u0026#34;.\u0026#34;, func(path string, fileInfo fs.FileInfo, err error) error {return nil}) 文件操作有关工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // go doc ioutil package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) func main() { // data, _ := ioutil.ReadFile(\u0026#34;alias.go\u0026#34;) // fmt.Println(string(data)) files, _ := ioutil.ReadDir(\u0026#34;.\u0026#34;) for _, info := range files { fmt.Println(info.Name()) } ioutil.WriteFile(\u0026#34;ioutil.txt\u0026#34;, []byte(\u0026#34;xxxx\u0026#34;), os.ModePerm) ioutil.WriteFile(\u0026#34;ioutil.txt\u0026#34;, []byte{57, 58, 59}, os.ModePerm) dir, _ := ioutil.TempDir(\u0026#34;.\u0026#34;, \u0026#34;temp_\u0026#34;) fmt.Println(dir) file, _ := ioutil.TempFile(\u0026#34;.\u0026#34;, \u0026#34;tempfile_\u0026#34;) defer file.Close() file.WriteString(\u0026#34;xxx\u0026#34;) } 带缓冲区IO 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 // 为提高性能 // 程序中定义(类似)切片 内部定义切片(指定切片的长度) 读取内容到切片 函数直接从切片中读取数据 当切片中数据读取完成后 再从硬盘读取 // 写数据类似 先写到切片 写满刷新到磁盘 可以主动刷新 bufio // go doc bufio Scanner Reader Writer // Scanner package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { // var txt string // fmt.Scan(\u0026amp;txt) // fmt.Scan 不带缓冲区IO 不接收空白和空格 // fmt.Println(\u0026#34;scan:\u0026#34;, txt) // 带缓冲区IO // 读取字符串数据 strconv scanner := bufio.NewScanner(os.Stdin) for scanner.Scan() { fmt.Println(\u0026#34;输入内容：\u0026#34;, scanner.Text()) fmt.Println(\u0026#34;输入内容：\u0026#34;, scanner.Bytes()) } fmt.Println(scanner.Err()) // 查看错误信息 } // Reader package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { file, _ := os.Open(\u0026#34;bufio.txt\u0026#34;) reader := bufio.NewReader(file) // defaultBufSize = 4096 4kb // bufio.NewReaderSize() data := make([]byte, 3) n, _ := reader.Read(data) fmt.Println(data[:n]) // linux strace 查看系统调用 n, _ = file.Read(data) fmt.Println(data[:n]) // isPrefix是True的话 还需要继续读取 表示一行还没有读取完整 // 在缓冲区中数据处理完成后若无换行就会返回isPrefix为True需要继续读取 ctx, isPrefix, err := reader.ReadLine() fmt.Println(string(ctx), isPrefix, err) } // Writer package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { file, _ := os.Create(\u0026#34;bufio.txt\u0026#34;) defer file.Close() writer := bufio.NewWriter(file) fmt.Println(writer.WriteString(\u0026#34;abcxyz\u0026#34;)) writer.Flush() // 将缓冲区数据刷新到磁盘 否则文件没用内容 } -- // go实现tailf命令 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) func main() { if len(os.Args) != 2 { log.Fatal(\u0026#34;usage: tailf xxx.log\u0026#34;) } file, err := os.Open(os.Args[1]) if err != nil { log.Fatal(err) } reader := bufio.NewReaderSize(file, 16) line := make([]byte, 0, 4096) for { data, isPrefix, err := reader.ReadLine() if err != nil { if err != io.EOF { log.Print(err) break } time.Sleep(time.Second) // break } else if isPrefix { line = append(line, data...) } else { if len(line) \u0026gt; 0 { fmt.Println(string(append(line, data...))) line = make([]byte, 0, 4096) } else { fmt.Println(string(data)) } } } } // 缓存算法：淘汰时间最早的 LRU缓存 几个结构体 1 2 3 4 5 6 7 8 9 10 // go doc strings type Builder struct{ ... } // 字符串变成流对象操作 type Reader struct{ ... } // ... func NewReader(s string) *Reader // go doc bytes.Reader // 在内存中对字节切片和字符串处理 // 拼接字符串：string.Builder byte.Buffer // 下载文件在内存中处理：bytes.Buffer // 不落盘 文件格式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 需要将数据落盘(磁盘存储) 网络传输 // 内存 =序列化=\u0026gt; []byte(string) =\u0026gt; 反序列化=\u0026gt; 内存 // 编码方式：gob csv json protocolbuffer 序列化和反序列化的方案 // 序列化(编码) // 反序列化(解码) 库： 编码：Marshal Encoder 解码：Unmarshal Decoder // 用哪种类型的数据编码 就解码为对应的数据类型 gob =\u0026gt; Go语言提供的编码 二进制编码方式 encoding/gob gob 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package main import ( \u0026#34;encoding/gob\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) // 属性名称都大写 // 序列化和反序列化需要访问属性 type User struct { Id int Name string Addr string } func main() { // 非go内置的基本类型和复合数据类型 需要注册 gob.Register(\u0026amp;User{}) users := []*User{ {1, \u0026#34;Minho\u0026#34;, \u0026#34;SC\u0026#34;}, {2, \u0026#34;lemon\u0026#34;, \u0026#34;SH\u0026#34;}, {3, \u0026#34;karubin\u0026#34;, \u0026#34;GD\u0026#34;}, } file, _ := os.Create(\u0026#34;data.gob\u0026#34;) // 编码 encoder := gob.NewEncoder(file) err := encoder.Encode(users) fmt.Println(err) file.Close() // 解码 file, _ = os.Open(\u0026#34;data.gob\u0026#34;) defer file.Close() decoder := gob.NewDecoder(file) user2 := make([]*User, 0) err = decoder.Decode(\u0026amp;user2) fmt.Println(err, user2) for _, u := range user2 { fmt.Printf(\u0026#34;%#v\\n\u0026#34;, u) } } csv 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;encoding/csv\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { file, _ := os.Open(\u0026#34;table.csv\u0026#34;) defer file.Close() reader := csv.NewReader(file) line, err := reader.Read() fmt.Println(err, line) line, err = reader.Read() fmt.Println(err, line) line, err = reader.Read() fmt.Println(err, line) line, err = reader.Read() fmt.Println(err, line) file, _ = os.Create(\u0026#34;table.csv\u0026#34;) writer := csv.NewWriter(file) writer.Write([]string{\u0026#34;A1\u0026#34;, \u0026#34;B1\u0026#34;, \u0026#34;C1\u0026#34;}) writer.Write([]string{\u0026#34;A2\u0026#34;, \u0026#34;B2\u0026#34;, \u0026#34;C2\u0026#34;}) writer.Write([]string{\u0026#34;A3\u0026#34;, \u0026#34;B3\u0026#34;, \u0026#34;C3\u0026#34;}) writer.Write([]string{\u0026#34;A4\u0026#34;, \u0026#34;B4\u0026#34;, \u0026#34;C4\u0026#34;}) writer.Flush() } 接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 数据 + 行为 =\u0026gt; 结构体属性 方法 // 都有类似的方法 os.File: read write strings.Builder: write strings.Reader: read bytes.Buffer: write read bytes.Reader: read bufio.Writer: write bufio.Reader: read bufio.Scanner: read 接口：对行为的抽象 行为抽象的对象 =\u0026gt; 实现行为的对象 // 定义 接口：定义的一些函数(0 1 n个) 签名：函数名称 参数列表 返回值列表 // 关键字：interface type TypeName Formatter type InterfaceName interface { 方法签名 } // 断言 =\u0026gt; 接口 // 对应类型的变量, ok := 接口类型变量.(类型) // switch 接口类型变量.(type) { // switch p := 接口类型变量.(type) // case GobPersistent: // case CsvPersistent: // case *JsonPersistent: // case *ProtobufPersistent: // default: // } // 如何实现一个可以接收任意类型变量的函数 定义/赋值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 package main import \u0026#34;fmt\u0026#34; type User struct { Id int Name string } // 定义一个持久化数据接口 // 行为：Save保存User切片 Load: 加载User切片 type Persistent interface { Save([]User, string) error Load(string) ([]User, error) } type GobPersistent struct{} // 定义了Persistent接口所有(一个也不能少 但是可以多)的方法 就叫Gobpersistent实现了Persistent接口 func (g GobPersistent) Save(users []User, path string) error { fmt.Println(\u0026#34;gob persistent Save\u0026#34;) return nil } func (g GobPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;gob persistent Load\u0026#34;) return nil, nil } type CsvPersistent struct{} func (c CsvPersistent) Save(users []User, path string) error { fmt.Println(\u0026#34;csv persistent Save\u0026#34;) return nil } func (c CsvPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;csv persistent Load\u0026#34;) return nil, nil } func call(persistent Persistent) { fmt.Println(\u0026#34;call:\u0026#34;) persistent.Save(nil, \u0026#34;\u0026#34;) persistent.Load(\u0026#34;\u0026#34;) } type JsonPersistent struct{} func (j *JsonPersistent) Save(users []User, path string) error { fmt.Println(\u0026#34;json persistent Save\u0026#34;) return nil } func (j *JsonPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;json persistent Load\u0026#34;) return nil, nil } type ProtobufPersistent struct{} func (p *ProtobufPersistent) Save(users []User, path string) error { fmt.Println(\u0026#34;protobuf persistent Save\u0026#34;) return nil } func (p ProtobufPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;protobuf persistent Load\u0026#34;) return nil, nil } func main() { var persistent Persistent // persistent := GobPersistent{} fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, persistent, persistent) // nil nil // 赋值/初始化 // 接口 不能直接通过接口类型初始化对象 // 需要使用实现行为(实现接口的所有方法 某个对象的类型定义了接口中所有的方法)的对象 persistent = CsvPersistent{} // 如果有接口后 只需要需改实现 fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, persistent, persistent) // Gobpersistent, Gobpersistent{} persistent.Save(nil, \u0026#34;\u0026#34;) // =\u0026gt; Gobpersistent-\u0026gt;Save persistent.Load(\u0026#34;\u0026#34;) // Gobpersistent-\u0026gt;Load call(persistent) // 多态 =\u0026gt; 某个对象赋值为不同对象 体现出不同的行为 fmt.Println(\u0026#34;多态\u0026#34;) call(GobPersistent{}) call(CsvPersistent{}) // 定义类型 与 接口 是否实现 无语法上直接关联 // 鸭子类型 // persistent为什么不直接定义为Gobpersistent？ // 改动代码非常麻烦 特别涉及到各种Gobpersistent参数传递的时候 // 指针对象 persistent = new(CsvPersistent) fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, persistent, persistent) persistent.Load(\u0026#34;\u0026#34;) persistent.Save(nil, \u0026#34;\u0026#34;) call(\u0026amp;CsvPersistent{}) call(\u0026amp;GobPersistent{}) // 疑问：为什么指针对象也有Save和Load方法 // 方法是值接收者 调用对象是一个指针 可以直接调用值接收者方法 -\u0026gt; 语法糖 指针对象会自动进行解引用 // 但是接口这一块并不是语法糖 // 指针类型接收者方法 如何赋值 fmt.Println(\u0026#34;指针接收者：\u0026#34;) persistent = new(JsonPersistent) persistent.Load(\u0026#34;\u0026#34;) persistent.Save(nil, \u0026#34;\u0026#34;) // persistent = JsonPersistent{} // persistent.Load(\u0026#34;\u0026#34;) // persistent.Save(nil, \u0026#34;\u0026#34;) // sonPersistent does not implement Persistent (Load method has pointer receiver) // 又有指针 又有值接收者方法 // ProtobufPersistent{} =\u0026gt; 未实现Save值接收者方法 // new(ProtobufPersistent) =\u0026gt; 可以 persistent = \u0026amp;ProtobufPersistent{} persistent.Load(\u0026#34;\u0026#34;) persistent.Save(nil, \u0026#34;\u0026#34;) // 接口方法是值接收者 会生成对应的指针接收者方法 // 接口方式是指针接收者 不会生成对应的值接收者方法 } 结构体赋值接口类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import \u0026#34;fmt\u0026#34; type User struct{} type Persistent interface { Save([]User, string) error Load(string) ([]User, error) } type GobPersistent struct { Version string } func (g GobPersistent) Save(u []User, path string) error { fmt.Println(\u0026#34;Save\u0026#34;) return nil } func (g GobPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;Load\u0026#34;) return nil, nil } func (g GobPersistent) Test() { fmt.Println(\u0026#34;Test\u0026#34;) } func main() { // 接口赋值不能省略类型 省略之后类型不一样 一个是接口类型 一个是结构体 var persistent Persistent = GobPersistent{} // var persistent = GobPersistent{} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, persistent) persistent.Save(nil, \u0026#34;\u0026#34;) // 正常调用 persistent.Load(\u0026#34;\u0026#34;) // 正常调用 // persistent.Test() // type Persistent has no field or method Test. 不能调用Test方法 Persistent接口无Test方法 =\u0026gt; 行为丢失 // fmt.Println(persistent.Version) // 不能获取Version属性 } 接口赋值接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 package main import ( \u0026#34;fmt\u0026#34; ) type User struct{} type Persistent interface { Save([]User, string) error Load(string) ([]User, error) } type GobPersistent struct { Version string } func (g GobPersistent) Save(u []User, path string) error { fmt.Println(\u0026#34;Save\u0026#34;) return nil } func (g GobPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;Load\u0026#34;) return nil, nil } func (g GobPersistent) Test() { fmt.Println(\u0026#34;Test\u0026#34;) } type Saver interface { Save([]User, string) error } type Loader interface { Load(string) ([]User, error) } type Dumper interface { Save([]User, string) error Dump() } func main() { var persistent Persistent = GobPersistent{} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, persistent) var saver Saver fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, saver, saver) saver = GobPersistent{} fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, saver, saver) saver.Save(nil, \u0026#34;\u0026#34;) saver = persistent // 接口对象赋值给另一个接口对象 fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, saver, saver) var loader Loader = persistent fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, loader, loader) // 没有实现Dump方法 无法赋值 // var dumper Dumper = persistent // 接口赋值可以使用自定义类型创建的对象赋值 或者 通过接口类型的变量进行赋值(需要实现对应的方法) // 接口赋值的过程中 会丢失一些方法 } 类型断言 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 package main import ( \u0026#34;fmt\u0026#34; ) type User struct{} type Persistent interface { Save([]User, string) error Load(string) ([]User, error) } type GobPersistent struct { Version string } func (g GobPersistent) Save(u []User, path string) error { fmt.Println(\u0026#34;Save\u0026#34;) return nil } func (g GobPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;Load\u0026#34;) return nil, nil } func (g GobPersistent) Test() { fmt.Println(\u0026#34;gob Test\u0026#34;) } type CsvPersistent struct { Version string } func (c CsvPersistent) Save(u []User, path string) error { fmt.Println(\u0026#34;Save\u0026#34;) return nil } func (c CsvPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;Load\u0026#34;) return nil, nil } func (c CsvPersistent) Test() { fmt.Println(\u0026#34;csv Test\u0026#34;) } type Saver interface { Save([]User, string) error } func main() { var persistent Persistent = GobPersistent{\u0026#34;1.1.1\u0026#34;} // 类型转换 // 断言：只能对接口类型做操作 转换为一个更具体的类型 // 对应类型的变量, ok := 接口类型变量.(类型) // persistent.Test() gobPersistent, ok := persistent.(GobPersistent) fmt.Printf(\u0026#34;%T, %#v, %T, %#v\\n\u0026#34;, ok, ok, gobPersistent, gobPersistent) gobPersistent.Test() fmt.Println(gobPersistent.Version) // user没有实现persistent接口 无法断言 // user, ok := persistent.(User) // fmt.Println(user, ok) csvPersistent, ok := persistent.(CsvPersistent) fmt.Printf(\u0026#34;%T, %#v, %T, %#v\\n\u0026#34;, ok, ok, csvPersistent, csvPersistent) // ok == false csvPersistent.Test() var saver Saver = persistent p, ok := saver.(Persistent) fmt.Printf(\u0026#34;%T, %#v, %T, %#v\\n\u0026#34;, ok, ok, p, p) p.Load(\u0026#34;\u0026#34;) g, ok := saver.(GobPersistent) fmt.Printf(\u0026#34;%T, %#v, %T, %#v\\n\u0026#34;, ok, ok, g, g) fmt.Println(g.Version) c, ok := saver.(CsvPersistent) fmt.Printf(\u0026#34;%T, %#v, %T, %#v\\n\u0026#34;, ok, ok, c, c) c.Test() } 多个类型断言 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // 多个类型断言 if...else / switch package main import \u0026#34;fmt\u0026#34; func main() { var persistent Persistent = \u0026amp;ProtobufPersistent{} // if g, ok := persistent.(GobPersistent); ok { // fmt.Println(\u0026#34;g\u0026#34;, g, ok) // } else if c, ok := persistent.(CsvPersistent); ok { // fmt.Println(\u0026#34;c\u0026#34;, c, ok) // } else if j, ok := persistent.(*JsonPersistent); ok { // fmt.Println(\u0026#34;j\u0026#34;, j, ok) // } else if p, ok := persistent.(*ProtobufPersistent); ok { // fmt.Println(\u0026#34;p\u0026#34;, p, ok) // } else { // fmt.Println(\u0026#34;error\u0026#34;) // } /* switch 接口类型变量.(type) { case GobPersistent: case CsvPersistent: case *JsonPersistent: case *ProtobufPersistent: default: } switch p := 接口类型变量.(type) { case GobPersistent: case CsvPersistent: case *JsonPersistent: case *ProtobufPersistent: default: } */ switch p := persistent.(type) { case GobPersistent: fmt.Println(\u0026#34;g\u0026#34;, p) case CsvPersistent: fmt.Println(\u0026#34;c\u0026#34;, p) case *JsonPersistent: fmt.Println(\u0026#34;j\u0026#34;, p) case *ProtobufPersistent: fmt.Println(\u0026#34;p\u0026#34;, p) default: fmt.Println(\u0026#34;error\u0026#34;) } } 接口嵌入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 package main import ( \u0026#34;fmt\u0026#34; ) type User struct{} type GobPersistent struct { Version string } func (g GobPersistent) Save(u []User, path string) error { fmt.Println(\u0026#34;Save\u0026#34;) return nil } func (g GobPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;Load\u0026#34;) return nil, nil } type Saver interface { Save([]User, string) error } type Loader interface { Load(string) ([]User, error) } type PersistentV2 interface { Saver Loader } type PersistentV3 interface { Saver Loader Dump() // V3这个接口 还需要实现Dump方法 } func main() { // 接口只有匿名嵌入 var persistentV2 PersistentV2 = GobPersistent{} fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, persistentV2, persistentV2) persistentV2.Load(\u0026#34;\u0026#34;) persistentV2.Save(nil, \u0026#34;\u0026#34;) } // 结构体当前使用接口嵌入 package main import ( \u0026#34;fmt\u0026#34; ) type User struct{} type Persistent interface { Save([]User, string) error Load(string) ([]User, error) } type GobPersistent struct { Version string } func (g GobPersistent) Save(u []User, path string) error { fmt.Println(\u0026#34;Save\u0026#34;) return nil } func (g GobPersistent) Load(path string) ([]User, error) { fmt.Println(\u0026#34;Load\u0026#34;) return nil, nil } type Storer struct { Persistent Persistent } type StorerV2 struct { Persistent // 匿名嵌入 } func main() { storer := Storer{GobPersistent{}} storer.Persistent.Load(\u0026#34;\u0026#34;) storer.Persistent.Save(nil, \u0026#34;\u0026#34;) storerV2 := StorerV2{GobPersistent{}} storerV2.Persistent.Load(\u0026#34;\u0026#34;) storerV2.Persistent.Save(nil, \u0026#34;\u0026#34;) storerV2.Load(\u0026#34;\u0026#34;) storerV2.Save(nil, \u0026#34;\u0026#34;) } 匿名接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import \u0026#34;fmt\u0026#34; func main() { var test = func() { fmt.Println(\u0026#34;匿名函数\u0026#34;) } var user struct { ID string Name string } // 匿名结构体 var saver interface { Save(string) error } // 匿名接口 fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, test, test) fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, user, user) fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, saver, saver) } 空接口及其使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 package main import \u0026#34;fmt\u0026#34; type EmptyStruct struct{} type EmptyInterface interface{} func main() { emptyStr := \u0026#34;\u0026#34; fmt.Println(emptyStr) emptySlice := make([]int, 0) fmt.Println(emptySlice) emptyMap := make(map[string]string) fmt.Println(emptyMap) emptyStruct := EmptyStruct{} fmt.Println(emptyStruct) // 空接口 var emptyInterface EmptyInterface // 空接口如何赋值? // 空接口没有定义任何的签名 任意对象都可以赋值给空接口 emptyInterface = 1 fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, emptyInterface, emptyInterface) emptyInterface = \u0026#34;123\u0026#34; fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, emptyInterface, emptyInterface) emptyInterface = true fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, emptyInterface, emptyInterface) emptyInterface = emptyStruct fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, emptyInterface, emptyInterface) emptyInterface = emptySlice fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, emptyInterface, emptyInterface) // 空接口 + 匿名 var empty interface{} // empty空接口的变量 fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, empty, empty) empty = 1 fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, empty, empty) empty = true fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, empty, empty) fmt.Println(\u0026#34;\u0026#34;) // fmt.Println 可以打印任意类型的变量 // 如何实现一个可以接收任意类型变量的函数 =\u0026gt; 使用空接口 fmt.Println(t(1)) fmt.Println(t(\u0026#34;\u0026#34;)) fmt.Println(t(true)) fmt.Println(t([]string{\u0026#34;1\u0026#34;, \u0026#34;@\u0026#34;})) fmt.Println(t(map[string]int{\u0026#34;1\u0026#34;: 1, \u0026#34;@\u0026#34;: 2})) // 如何实现一个可以接收任意数量 任意类型的函数 args(1, 2, 3) args(\u0026#34;abc\u0026#34;, 1, []string{}) } func t(args interface{}) string { return fmt.Sprintf(\u0026#34;%T\u0026#34;, args) } func args(args ...interface{}) { for i, arg := range args { fmt.Println(i, t(arg)) } } Json序列化/反序列化 1 2 3 1. Type, Value 2. 使用反射 3. 反射应用(内部实现使用反射)： json \\ xml encoding/json 1 go doc encoding/json 基本数据类型/json 转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 package main /* json: 格式化的字符串 GO =\u0026gt; Json 数值：number(int/float) =\u0026gt; 1.1 10 -10 字符串：string =\u0026gt; \u0026#34;\u0026#34; 布尔：bool =\u0026gt; true, false 数组：[]Type/[Length]Type =\u0026gt; [1, 2, 3, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;] 字典(Object):map[KTepy]Value =\u0026gt; {\u0026#34;key\u0026#34;: value, \u0026#34;key2\u0026#34;: value2} Go数据类型 与 Json字符串转换 Go数据类型 \u0026lt;=\u0026gt; Gob二进制字符串 Go数据类型 \u0026lt;=\u0026gt; xml字符串 Go数据类型 \u0026lt;=\u0026gt; Protobuffer 持久化/网络传输 =\u0026gt; 序列化： Go数据类型 =\u0026gt; 字符串(文本/二进制) =\u0026gt; 反序列化：字符串(文本/二进制) =\u0026gt; Go数据类型 编码规则 =\u0026gt; 库(包) */ import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { var ( number float64 = 1.1 name string = \u0026#34;minho\u0026#34; isBody bool = true users []string = []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;} scores map[string]int = map[string]int{\u0026#34;1\u0026#34;: 90, \u0026#34;2\u0026#34;: 80, \u0026#34;3\u0026#34;: 100} ) // 序列化为json字符串 b, err := json.Marshal(number) fmt.Printf(\u0026#34;%#v, %T, %#v\\n\u0026#34;, err, b, string(b)) b, err = json.Marshal(name) fmt.Printf(\u0026#34;%#v, %T, %#v\\n\u0026#34;, err, b, string(b)) b, err = json.Marshal(isBody) fmt.Printf(\u0026#34;%#v, %T, %#v\\n\u0026#34;, err, b, string(b)) b, err = json.Marshal(users) fmt.Printf(\u0026#34;%#v, %T, %#v\\n\u0026#34;, err, b, string(b)) b, err = json.Marshal(scores) fmt.Printf(\u0026#34;%#v, %T, %#v\\n\u0026#34;, err, b, string(b)) // Unmarshal 反序列化 jsonB := ` { \u0026#34;name\u0026#34;: \u0026#34;minho\u0026#34;, \u0026#34;age\u0026#34;: 30, \u0026#34;isBody\u0026#34;: true, \u0026#34;scores\u0026#34;: [1, 2, 3, 4] } ` var rs map[string]interface{} err = json.Unmarshal([]byte(jsonB), \u0026amp;rs) fmt.Printf(\u0026#34;%#v, %#v\\n\u0026#34;, err, rs) value, _ := rs[\u0026#34;name\u0026#34;] fmt.Printf(\u0026#34;%T\u0026#34;, value) // value是一个空接口 v, ok := value.(string) fmt.Printf(\u0026#34;%T, %T, %#v, %#v\\n\u0026#34;, v, ok, v, ok) } 自定义数据类型/json转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) // 需要设置属性与Json字符串中key的对应关系 // Id =\u0026gt; json.pk =\u0026gt; 通过结构体(属性)标签设置 // key1:\u0026#34;value1\u0026#34; key2:\u0026#34;value2\u0026#34; // json:\u0026#34;name\u0026#34; // 网络传输时 不需要将某个key进行序列化 `json:\u0026#34;-\u0026#34;` 结构体标签设置为- 序列化/反序列化不会携带该属性 // json:\u0026#34;-\u0026#34; 序列化和反序列化时忽略属性 // json:\u0026#34;name,type(string),omitempty\u0026#34; // omitempty 属性对应的值为零值在json字符串中不包含(忽略0值) type User struct { Id int `json:\u0026#34;pk,string\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Password string `json:\u0026#34;-\u0026#34;` IsBoy bool `json:\u0026#34;isBoy\u0026#34;` Scores []float64 `json:\u0026#34;scores\u0026#34;` Phone map[string]string `json:\u0026#34;phone\u0026#34;` } func main() { user := User{1, \u0026#34;minho\u0026#34;, \u0026#34;123#@\u0026#34;, true, []float64{1, 3, 4}, map[string]string{\u0026#34;tel\u0026#34;: \u0026#34;13308047517\u0026#34;}} b, err := json.Marshal(user) // 自定义属性是小写 json包无法访问属性 fmt.Printf(\u0026#34;%#v, %#v\\n\u0026#34;, err, string(b)) // 转换字典Object key是属性名称 value是值 jsonB := ` { \u0026#34;pk\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;minho\u0026#34;, \u0026#34;Password\u0026#34;: \u0026#34;123@abc\u0026#34;, \u0026#34;isBoy\u0026#34;: false, \u0026#34;phone\u0026#34;: {\u0026#34;mobile\u0026#34;: \u0026#34;12314341\u0026#34;} } ` var u User err = json.Unmarshal([]byte(jsonB), \u0026amp;u) fmt.Printf(\u0026#34;%#v, %#v\\n\u0026#34;, err, u) users := []User{ {1, \u0026#34;minho\u0026#34;, \u0026#34;123#@\u0026#34;, true, []float64{1, 3, 4}, map[string]string{\u0026#34;tel\u0026#34;: \u0026#34;13308047517\u0026#34;}}, {2, \u0026#34;minho2\u0026#34;, \u0026#34;123#@\u0026#34;, true, []float64{1, 3, 4}, map[string]string{\u0026#34;tel\u0026#34;: \u0026#34;13308047517\u0026#34;}}, {3, \u0026#34;minho3\u0026#34;, \u0026#34;123#@\u0026#34;, true, []float64{1, 3, 4}, map[string]string{\u0026#34;tel\u0026#34;: \u0026#34;13308047517\u0026#34;}}, } // 调试可以打印格式输出 网络传输不用 浪费字节 b, err = json.MarshalIndent(users, \u0026#34;\u0026#34;, \u0026#34;\\t\u0026#34;) fmt.Printf(\u0026#34;%#v, %s\\n\u0026#34;, err, string(b)) jsonB = ` [ { \u0026#34;pk\u0026#34;: \u0026#34;11\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;minho\u0026#34;, \u0026#34;isBoy\u0026#34;: true, \u0026#34;scores\u0026#34;: [ 1, 3, 4 ], \u0026#34;phone\u0026#34;: { \u0026#34;tel\u0026#34;: \u0026#34;13308047517\u0026#34; } }, { \u0026#34;pk\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;minho2\u0026#34;, \u0026#34;isBoy\u0026#34;: true, \u0026#34;scores\u0026#34;: [ 1, 3, 4 ], \u0026#34;phone\u0026#34;: { \u0026#34;tel\u0026#34;: \u0026#34;13308047517\u0026#34; } }, { \u0026#34;pk\u0026#34;: \u0026#34;33\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;minho3\u0026#34;, \u0026#34;isBoy\u0026#34;: true, \u0026#34;scores\u0026#34;: [ 1, 3, 4 ], \u0026#34;phone\u0026#34;: { \u0026#34;tel\u0026#34;: \u0026#34;13308047517\u0026#34; } } ] ` var us []User err = json.Unmarshal([]byte(jsonB), \u0026amp;us) fmt.Println(err, us) } 自定义嵌入结构体 转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type Addr struct { Street string `json:\u0026#34;street\u0026#34;` No string `json:\u0026#34;no\u0026#34;` } type User struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Addr Addr `json:\u0026#34;addr\u0026#34;` } func main() { u := User{ 1, \u0026#34;minho\u0026#34;, Addr{\u0026#34;成都\u0026#34;, \u0026#34;640000\u0026#34;}, } b, _ := json.MarshalIndent(u, \u0026#34;\u0026#34;, \u0026#34;\\t\u0026#34;) fmt.Println(string(b)) // 等于嵌入Object jsonB := ` { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;minho\u0026#34;, \u0026#34;addr\u0026#34;: { \u0026#34;street\u0026#34;: \u0026#34;成都\u0026#34;, \u0026#34;no\u0026#34;: \u0026#34;640000\u0026#34; } } ` var rs User json.Unmarshal([]byte(jsonB), \u0026amp;rs) fmt.Println(rs) } json.Valid 1 // 验证一个字符串是否是正确的json格式 对流的操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // 序列化到文件/从文件反序列化 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) type Addr struct { Street string `json:\u0026#34;street\u0026#34;` No string `json:\u0026#34;no\u0026#34;` } type User struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Addr Addr `json:\u0026#34;addr\u0026#34;` } func main() { u := User{1, \u0026#34;MInho\u0026#34;, Addr{\u0026#34;成都\u0026#34;, \u0026#34;10001\u0026#34;}} file, _ := os.Create(\u0026#34;user.json\u0026#34;) defer file.Close() encoder := json.NewEncoder(file) // Strout输出到控制台 err := encoder.Encode(u) fmt.Println(err) file, _ = os.Open(\u0026#34;user.json\u0026#34;) decoder := json.NewDecoder(file) var user User err = decoder.Decode(\u0026amp;user) fmt.Println(err, user) } json.RawMessage 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type User struct { Id int Name string Addr json.RawMessage } func main() { txt := `{ \u0026#34;id\u0026#34;: 100, \u0026#34;name\u0026#34;: \u0026#34;Minho\u0026#34;, \u0026#34;addr\u0026#34;: {\u0026#34;street\u0026#34;: \u0026#34;成都\u0026#34;, \u0026#34;no\u0026#34;: \u0026#34;10002\u0026#34;} }` var u User err := json.Unmarshal([]byte(txt), \u0026amp;u) fmt.Println(err, u) } MarshalJSON/UnmarshalJSON 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) type Date time.Time func (d Date) MarshalJSON() ([]byte, error) { return json.Marshal(time.Time(d).Format(\u0026#34;2006-01-02\u0026#34;)) } // UnmarshalJSON 一般要赋值 定义成指针类型接收者 func (d *Date) UnmarshalJSON(b []byte) error { var s string if err := json.Unmarshal(b, \u0026amp;s); err != nil { return err } if date, err := time.Parse(\u0026#34;2006-01-02\u0026#34;, s); err != nil { return err } else { *d = Date(date) } return nil } type User struct { Id int Name string Birthday time.Time Birthday2 Date } func main() { u := User{1, \u0026#34;\u0026#34;, time.Now(), Date(time.Now())} // 无法序列化Birthday2 b, err := json.MarshalIndent(u, \u0026#34;\u0026#34;, \u0026#34;\\t\u0026#34;) fmt.Println(string(b), err) txt := ` { \u0026#34;Id\u0026#34;: 2, \u0026#34;Name\u0026#34;: \u0026#34;Minho\u0026#34;, \u0026#34;Birthday\u0026#34;: \u0026#34;2021-08-20T17:34:58.3897013+08:00\u0026#34;, \u0026#34;Birthday2\u0026#34;: \u0026#34;2021-08-31\u0026#34; } ` var us User err = json.Unmarshal([]byte(txt), \u0026amp;us) fmt.Println(err, us) } // MarshalText / UnmarshalText // 与JSON区别是不需要再使用json.Marshal()函数转换 type Date2 time.Time func (d Date2) MarshalText() ([]byte, error) { return []byte(time.Time(d).Format(\u0026#34;2006-01-02\u0026#34;)), nil } func (d *Date2) UnmarshalText(b []byte) error { s = := string(b) if date, err := time.Parse(\u0026#34;2006-01-02\u0026#34;, s); err != nil { return err } else { *d = Date2(date) } return nil } 反射 1 2 3 4 5 // 反射是指在运行时动态的访问和修改任意类型对象的结构和成员 // 在go语言中提供reflect包提供反射的功能 // 每一个变量都有两个属性：类型(Type) 和值(Value) go doc reflect 通过反射实现简单的ORM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 // 生成结构体对应的建表SQL语句 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;strings\u0026#34; ) // sql:\u0026#34;type(text);size(32);pk;null;default()\u0026#34; type User struct { Id int Name string `sql:\u0026#34;type(text)\u0026#34;` Addr string `sql:\u0026#34;type(varchar);size(1024);null;default(成都)\u0026#34;` Desc string } func (u User) TableName() string { return \u0026#34;account\u0026#34; } type Department struct { Id int Name string Addr string } func snake(name string) string { return strings.ToLower(name) } func tableName(value reflect.Value) string { tableName := value.Elem().Type().Name() methodValue := value.MethodByName(\u0026#34;TableName\u0026#34;) if !methodValue.IsValid { return tableName } methodType := methodValue.Type() if 0 != methodType.NumIn() || 1 != methodType.Numout() { return tableName } if outType := methodType.out(0); outType.Kind() != reflect.String { return tableName } params := make([]reflect.Value, 0) rts := methodValue.Call(params) if res[0].String() != \u0026#34;\u0026#34; { return rts[0].string() } return tableName } func typeMapper(field reflect.StructField) string { kind := field.Type.Kind() tag := field.Tag.Get(\u0026#34;sql\u0026#34;) typeValue := \u0026#34;\u0026#34; sizeValue := \u0026#34;\u0026#34; defaultValue := \u0026#34;\u0026#34; switch kind { case reflect.Int: typeValue = \u0026#34;int\u0026#34; case reflect.String: typeValue = \u0026#34;varchar\u0026#34; sizeValue = \u0026#34;32\u0026#34; default: return \u0026#34;text\u0026#34; } pkValue := false nullValue := false for _, v := range strings.Split(tag, \u0026#34;;\u0026#34;) { if strings.HasPrefix(v, \u0026#34;type(\u0026#34;) { typeValue = v[5 : len(v)-1] } else if strings.HasPrefix(v, \u0026#34;size(\u0026#34;) { sizeValue = v[5 : len(v)-1] } else if strings.HasPrefix(v, \u0026#34;default(\u0026#34;) { defaultValue = v[8 : len(v)-1] } else if v == \u0026#34;pk\u0026#34; { pkValue = true } else if v == \u0026#34;null\u0026#34; { nullValue = true } } var builder strings.Builder builder.WriteString(typeValue) if typeValue == \u0026#34;varchar\u0026#34; { builder.WriteString(fmt.Sprintf(\u0026#34;(%s)\u0026#34;, sizeValue)) } // builder.WriteString(\u0026#34; \u0026#34;) // varchar(32) primary key not null default \u0026#34;\u0026#34;; if pkValue { builder.WriteString(\u0026#34; primary key\u0026#34;) } if !nullValue { builder.WriteString(\u0026#34; not null\u0026#34;) } if defaultValue != \u0026#34;\u0026#34; { builder.WriteString(\u0026#34; default \u0026#34;) if typeValue == \u0026#34;varchar\u0026#34; { builder.WriteString(fmt.Sprintf(`\u0026#34;%s\u0026#34;`, defaultValue)) } else { builder.WriteString(fmt.Sprintf(`%s`, defaultValue)) } } return builder.String() } func sqlDump(models ...interface{}) string { var builder strings.Builder for _, model := range models { t := reflect.TypeOf(model) v := reflect.ValueOf(model) if t.Kind() == reflect.Ptr \u0026amp;\u0026amp; t.Elem().Kind() == reflect.Struct { st := t.Elem() builder.WriteString(fmt.Sprintf(\u0026#34;CREATE TABLE `%s` (\\n\u0026#34;, snake(tableName(v)))) filedNum := st.NumField() if filedNum == 0 { log.Panicf(\u0026#34;%s field num is zero\u0026#34;, st.Name()) } for i := 0; i \u0026lt; filedNum; i++ { field := st.Field(i) // fmt.Println(field.Name, field.Type.Kind()) builder.WriteString(fmt.Sprintf(\u0026#34;\\t `%s` %s\u0026#34;, snake(field.Name), typeMapper(field))) if i != filedNum-1 { builder.WriteString(\u0026#34;,\u0026#34;) } builder.WriteString(\u0026#34;\\n\u0026#34;) } builder.WriteString(fmt.Sprintf(\u0026#34;) ENGINE=INNODB DEFAULT CHARSET utf8mb4;\\n\\n\u0026#34;)) } else { panic(\u0026#34;error\u0026#34;) } } return builder.String() } func main() { sql := sqlDump(new(User), new(Department)) fmt.Println(sql) } Go并发 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // OS: 进程/线程 进程：资源(内存/文件IO) 以进程为单位 进程是资源分配的最小单位 线程：执行的逻辑(主线程) 执行调用的是线程 线程是CPU调度的最小单元 协程：应用程序层面 用户态的调度(消耗小 性能很高) - 其他语言 第三方库 python2.7 =\u0026gt; gevent greentleet - Go 在语言层面就提供 goroutine // GMP模型 G =\u0026gt; 例程 goroutine M =\u0026gt; 执行代码的线程(CPU) P =\u0026gt; Processer 调度 上下文的切换 内存申请... P是连接G和M的(Go中的调度器) // runtime包 // 例程 go 函数调用 // 关键字 go goroutine执行切换： IO等待(IO阻塞) 到达执行时间(最大执行时间) 内核切换 主动让出(sleep) // main函数由GO调用器创建例程进行执行 =\u0026gt; 主例程 // 自己用go关键字加函数调用创建的例程 =\u0026gt; 工作例程 // 当主例程执行完成 自动结束所有工作例程 // 在某个例程里面 代码执行顺序依然按照逻辑关系按顺序执行 // 并发 goruntine =\u0026gt; 多个例程时 如何通信 并发通信 内存：变量 主例程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 打印A-Z func printChats(prefix string) { for c := \u0026#39;A\u0026#39;; c \u0026lt;= \u0026#39;Z\u0026#39;; c++ { fmt.Printf(\u0026#34;%s: %c\\n\u0026#34;, prefix, c) time.Sleep(time.Millisecond) } } func main() { // 至少有三个 // c1 c2交叉执行 c1 c2同时在执行 go printChats(\u0026#34;c1:\u0026#34;) go printChats(\u0026#34;c2:\u0026#34;) time.Sleep(3 * time.Millisecond) // 不等待 没有结果打印 因为主例程直接退出 // 问题： 能否等待工作例程结束后 再让主例程退出(主例程要等待某几个/或等待所有的工作例程结束) } 计数信号量/WaitGroup 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // 打印A-Z func printChats(wg *sync.WaitGroup, prefix string) { defer wg.Done() // stage B for c := \u0026#39;A\u0026#39;; c \u0026lt;= \u0026#39;Z\u0026#39;; c++ { fmt.Printf(\u0026#34;%s: %c\\n\u0026#34;, prefix, c) time.Sleep(time.Millisecond) } // stage C wg.Add(1) go childChars(wg, prefix) } func childChars(wg *sync.WaitGroup, prefix string) { defer wg.Done() for c := \u0026#39;A\u0026#39;; c \u0026lt;= \u0026#39;Z\u0026#39;; c++ { fmt.Printf(\u0026#34;child.%s: %c\\n\u0026#34;, prefix, c) time.Sleep(time.Millisecond) } } func main() { var wg sync.WaitGroup // 定义计数信号量 /* stage A go func() { stage B ... 有可能会报错 ... stage C } stage D */ // wg.Add(N) =\u0026gt; 启动例程之前执行 stage A阶段；在计数信号量中+N // wg.Done() =\u0026gt; 例程执行结束后调用(例程函数退出时) stage C； 如何保证wg.Done()一定执行 stage B + defer; 当函数执行结束对计数信号量减1 // wg.Wait() =\u0026gt; 启动所有例程后调用 等待计数为0之后执行(不是0的时候一直等待) wg.Add(1) // stage A go printChats(\u0026amp;wg, \u0026#34;c1\u0026#34;) wg.Add(1) // stage A go printChats(\u0026amp;wg, \u0026#34;c2\u0026#34;) // wg需要时指针 否则时两个wg 函数里面的wg Done减少计数的时候 不影响外面的wg fmt.Println(\u0026#34;Wait\u0026#34;) wg.Wait() // stage D fmt.Println(\u0026#34;Over\u0026#34;) // WaitGroup.Add数量 \u0026lt;= 例程数量 // 某些例程不需要等待结束 即可结束主例程(程序) } 闭包陷阱 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { wg := sync.WaitGroup{} wg.Add(2) for i := 0; i \u0026lt; 2; i++ { go func(i int) { prefix := fmt.Sprintf(\u0026#34;c%d\u0026#34;, i+1) for c := \u0026#39;A\u0026#39;; c \u0026lt;= \u0026#39;A\u0026#39;; c++ { fmt.Printf(\u0026#34;%s: %c\\n\u0026#34;, prefix, c) time.Sleep(time.Millisecond) } wg.Done() }(i) } fmt.Println(\u0026#34;Wait\u0026#34;) wg.Wait() fmt.Println(\u0026#34;Over\u0026#34;) } // 使用的是同一个wg变量 不用再传递指针 // go func匿名函数里面使用的i变量 需要参数传递进来 如果直接使用外部i变量 结果不确定(联想延迟执行) for循环执行完i=2 执行例程 输出结果中 prefix值为3 并发通信/加锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // 多个例程对同一个内存资源进行修改 未对资源进行同步限制 导致修改数据混乱 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // 从一个账户借钱/还钱 // 账户初始化500*10000 // 解决方法：借钱和还钱过程中不要中断 // 加锁 var money int = 500 * 10000 var locker sync.Mutex // 借钱 func borrow(m int) int { locker.Lock() defer locker.Unlock() if money \u0026lt; m { // 退出一定要释放锁 // locker.Unlock() return 0 } money -= m // locker.Unlock() return m } // 还钱 func payback(m int) { locker.Lock() defer locker.Unlock() money += m } func main() { // 2个人借钱 A/B wg := sync.WaitGroup{} for person := \u0026#39;A\u0026#39;; person \u0026lt;= \u0026#39;Z\u0026#39;; person++ { wg.Add(1) go func(person rune) { defer wg.Done() // 每次2000 m := borrow(2000) time.Sleep(2 * time.Microsecond) payback(m) }(person) } wg.Wait() fmt.Println(\u0026#34;money:\u0026#34;, money) } 并发通信/管道 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 管道 func main() { // CSP原理(顺序通信进程) // 队列 buffer区(线程/协程安全) -\u0026gt; 入队列 -\u0026gt; 出队列 // 类型 chan T T:Go不限制类型 但是常常放一些值类型 // 如果放一个切片(引用类型 修改会直接修改内存上面的值)到管道 其他例程从管道中读取切片后 对切片元素修改 会对放入端切片有影响 // 放置int类型元素的管道 var channel chan int fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, channel, channel) // 赋值 make函数 // 对应有对管道不通的读和写操作的例程 // make(chan T) 不带缓冲区的管道 // make(chan T, size) 带缓冲区的管道 长度size // 5 size =\u0026gt; 1 1 1 1 1 =\u0026gt; 1 缓冲区满 需要等待(阻塞) 如果Go检查无goroutine可以读 发生死锁 // 读 读空channel 如果Go检查无goroutine可以写 产生死锁 channel = make(chan int) // 如何写 go func() { time.Sleep(5 * time.Second) channel \u0026lt;- 4 }() // 如何读 e := \u0026lt;-channel fmt.Println(e) } channel实现WaitGroup 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // channel实现sync.WaitGroup // 需要提前知道你的程序需要起多少个例程 package main import \u0026#34;fmt\u0026#34; func main() { var channel chan int = make(chan int) // 初始化 for i := 0; i \u0026lt; 2; i++ { go func(i int){ for c := \u0026#39;A\u0026#39;; c \u0026lt;= \u0026#39;Z\u0026#39;; c++ { fmt.Printf(\u0026#34;%d, %c\\n\u0026#34;, i, c) } // 执行完例程之后写入数据 channel \u0026lt;- 0 }(i) } fmt.Println(\u0026#34;wait\u0026#34;) for i := 0; i \u0026lt; 2; i++ { \u0026lt;-channel } fmt.Println(\u0026#34;over\u0026#34;) } 带缓冲区channel 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 带缓冲区channel // channel跟队列类似 先进先出 func main() { // var channel chan string = make(chan string, 3) // var channel = make(chan string, 3) channel := make(chan string, 3) fmt.Println(len(channel)) // 0 channel \u0026lt;- \u0026#34;a\u0026#34; fmt.Println(len(channel)) // 1 channel \u0026lt;- \u0026#34;b\u0026#34; channel \u0026lt;- \u0026#34;c\u0026#34; fmt.Println(len(channel)) // 3 fmt.Println(\u0026lt;-channel) // a channel \u0026lt;- \u0026#34;d\u0026#34; fmt.Println(\u0026lt;-channel) // b fmt.Println(\u0026lt;-channel) // c fmt.Println(\u0026lt;-channel) // d go func() { time.Sleep(5 * time.Second) channel \u0026lt;- \u0026#34;x\u0026#34; }() fmt.Println(\u0026lt;-channel) // 死锁 管道为空 没有程序继续些数据 } 关闭管道 1 2 3 4 管道关闭之后 无法再写入数据 报错：panic: send on closed channel 管道关闭之后 可以读取数据 v, ok := \u0026lt;-channel 第二个值判断是否读取完数据 false无法再读取且此时v==0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // 不带缓冲区管道 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { channel := make(chan int) // bufferChannel := make(chan string, 3) go func() { time.Sleep(3 * time.Second) v, ok := \u0026lt;-channel // ok第二个参数 判断管道是否关闭 fmt.Println(v, ok) // 1 v, ok = \u0026lt;-channel fmt.Println(v, ok) // 0 }() // 关闭管道之后 还能读写吗 // 不能针对关闭的管道写数据 panic: send on closed channel // 针对已经关闭的管道可以进行读取 channel \u0026lt;- 1 // 关闭管道 close(channel) time.Sleep(5 * time.Second) } // 带缓冲区管道 package main import \u0026#34;fmt\u0026#34; func main() { bufferChannel := make(chan int, 3) bufferChannel \u0026lt;- 1 close(bufferChannel) // bufferChannel \u0026lt;- 2 // 关闭之后不能写 panic: send on closed channel v, ok := \u0026lt;-bufferChannel fmt.Println(v, ok) // 1 true v, ok = \u0026lt;-bufferChannel fmt.Println(v, ok) // 0 false } 管道循环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import \u0026#34;fmt\u0026#34; func main() { channel := make(chan int, 3) channel \u0026lt;- 1 channel \u0026lt;- 2 channel \u0026lt;- 3 close(channel) // 不关闭 range循环管道会报错 死锁 for v := range channel { fmt.Println(v) // 自动判断是否还能取到值 false } // 手动自己判断第二个值 // for { // if v, ok := \u0026lt;-channel; ok { // fmt.Println(v) // } else { // break // } // } } 并发下载图片示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) /* 要获取网站图片 1.jpg, 2.jpg, ... , n,jpg 下载 m.jpg - n.jpg */ // 模拟下载函数 func download(wg *sync.WaitGroup, name, path string) { defer wg.Done() time.Sleep(10 * time.Millisecond) fmt.Printf(\u0026#34;download %s to %s\\n\u0026#34;, name, path) } func main() { start := time.Now() wg := sync.WaitGroup{} m, n := 1, 100 for i := m; i \u0026lt;= n; i++ { wg.Add(1) go download(\u0026amp;wg, fmt.Sprintf(\u0026#34;%d.jpg\u0026#34;, i), fmt.Sprintf(\u0026#34;download/%d.jpg\u0026#34;, i)) } wg.Wait() fmt.Printf(\u0026#34;spend time: %s\\n\u0026#34;, time.Now().Sub(start)) } // 问题：需要下载数里很多怎么办？ 不能创建任意数量例程 // 固定N个例程区去请求 比如 每次10个(Pool) // 利用管道：生产者消费者模型 生产下载任务 -\u0026gt; 每次10worker消费 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Fiel struct { name string path string } func download(name, path string) { time.Sleep(10 * time.Millisecond) fmt.Printf(\u0026#34;download %s to %s\\n\u0026#34;, name, path) } func main() { start := time.Now() N := 10 m, n := 1, 100 channel := make(chan Fiel, N) wg := sync.WaitGroup{} // 生产者 // 生成下载图片的例程 wg.Add(1) go func(channel chan\u0026lt;- Fiel) { for i := m; i \u0026lt;= n; i++ { channel \u0026lt;- Fiel{fmt.Sprintf(\u0026#34;%d.jpg\u0026#34;, i), fmt.Sprintf(\u0026#34;download/%d.jpg\u0026#34;, i)} } close(channel) wg.Done() }() // 消费者 for i := 0; i \u0026lt;= N; i++ { // N个下载图片例程 wg.Add(1) go func(channel \u0026lt;-chan Fiel) { for f := range channel { download(f.name, f.path) } wg.Done() }() } wg.Wait() fmt.Println(time.Now().Sub(start)) } 管道类型/读写管道 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package main import \u0026#34;fmt\u0026#34; func main() { // 在某个函数中只需要读 或者只需要写的时候 // 为防止在只读函数中误写 在只写函数中误读 // 可以将管道声明为 只读 或 只写管道 // 更多用在函数 形参定义 // 赋值 channel := make(chan int, 10) var readChannel \u0026lt;-chan int // 只读管道 var writeChannel chan\u0026lt;- int // 只写管道 readChannel = channel writeChannel = channel writeChannel \u0026lt;- 1 writeChannel \u0026lt;- 2 fmt.Println(\u0026lt;-readChannel) fmt.Println(\u0026lt;-readChannel) // var ch chan\u0026lt;- int = make(chan int, 10) // 一般不这样声明 没有意义 } selectcase 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 多个管道进行读 某一个管道读取成功就执行对应逻辑 // 多个管道进行写 某一个管道写成功就执行对应逻辑 // 多个管道 某些进行读 某些进行写 某个管道 读/写成功 执行对应逻辑 // select case /* select { case value, ok := \u0026lt;-channel: case channel \u0026lt;- value: default: } */ channelV1 := make(chan int, 0) channelV2 := make(chan int, 0) go func() { time.Sleep(3 * time.Second) channelV1 \u0026lt;- 1 }() fmt.Println(\u0026#34;wait\u0026#34;, time.Now()) select { case v, ok := \u0026lt;-channelV1: fmt.Println(\u0026#34;channelV1:\u0026#34;, time.Now(), v, ok) case v, ok := \u0026lt;-channelV2: fmt.Println(\u0026#34;channelV2:\u0026#34;, time.Now(), v, ok) default: // 不会等待(case条件都没有读取数据 直接执行逻辑) 直接default 一般不会加 fmt.Println(\u0026#34;default\u0026#34;) } fmt.Println(\u0026#34;over\u0026#34;) } 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 生成随机5个0 5个1组成的数 package main import \u0026#34;fmt\u0026#34; func main() { zero := make(chan int) one := make(chan int) go func() { for i := 0; i \u0026lt; 5; i++ { zero \u0026lt;- 0 } }() go func() { for i := 0; i \u0026lt; 5; i++ { one \u0026lt;- 1 } }() for i := 0; i \u0026lt; 10; i++ { select { case \u0026lt;-one: fmt.Print(1) case \u0026lt;-zero: fmt.Print(0) } } } context上下文 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // go doc context // 事件广播 // ctx, cannel := context.WithCancel(ctx) // cannel() =\u0026gt; 广播消息 channel := make(chan int, 1) go func() { i := 0 for { channel \u0026lt;- i time.Sleep(2 * time.Second) i += 1 } }() // 让例程执行10s之后就退出 // 根事件 只能通过 context.Backgroud创建 // ctx, cannel := context.WithCancel(context.Background()) // go func() { // time.Sleep(10 * time.Second) // fmt.Println(\u0026#34;cannel\u0026#34;) // cannel() // 调用cannel就相当于向管道写入一个数据 // }() ctx, _ := context.WithTimeout(context.Background(), 10*time.Second) // 10s后中断 END: for { select { case \u0026lt;-ctx.Done(): // 从管道读取到数 说明结束 fmt.Println(\u0026#34;interrupt\u0026#34;) break END case v, ok := \u0026lt;-channel: if !ok { break END } else { fmt.Println(v) } } } } 简单的SocketServer server.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 监听IP和端口 addr := \u0026#34;:9999\u0026#34; // \u0026#34;0.0.0.0:9999\u0026#34; listener, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) if err != nil { log.Fatal(err) } for { // 获取客户端连接 conn, err := listener.Accept() if err != nil { fmt.Println(err) continue } time.Sleep(10 * time.Second) log.Println(\u0026#34;client：\u0026#34;, conn.RemoteAddr()) // 交互处理 fmt.Fprintf(conn, time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) // 关闭连接 conn.Close() } // 关闭服务器 listener.Close() } // 2021/08/27 11:41:26 client： 127.0.0.1:58934 // 2021/08/27 11:41:36 client： 127.0.0.1:58935 // 处理两个客户端连接 顺序执行没有并发 相差10s // 启动协程 处理客户端连接 此时服务端并发处理客户端请求 go func() { time.Sleep(10 * time.Second) log.Println(\u0026#34;client：\u0026#34;, conn.RemoteAddr()) // 交互处理 fmt.Fprintf(conn, time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) // 关闭连接 conn.Close() }() client.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 连接服务器 addr := \u0026#34;127.0.0.1:9999\u0026#34; conn, err := net.Dial(\u0026#34;tcp\u0026#34;, addr) if err != nil { log.Fatal(err) } start := time.Now() // 交互 bytes := make([]byte, 1024) n, err := conn.Read(bytes) // n 从byte里面读的数量 if err != nil { fmt.Println(err) } else { fmt.Println(string(bytes[:n])) } fmt.Println(time.Now().Sub(start)) // 关闭连接 conn.Close() } Go使用私有仓库 1 2 3 4 5 6 7 8 1. 配置GOPRIVATE变量 比如: go env -w GOPRIVATE=gitee.com 2. 配置SSH密钥(步骤省略) 3. 使用ssh替换https拉取依赖 # 使用环境变量$GOPRIVATE 需要提前export git config --global url.\u0026#34;git@$GOPRIVATE:\u0026#34;.insteadOf \u0026#34;https://$GOPRIVATE\u0026#34; Reference Link Blogs\n使用Viper解码自定义格式 String padding in Go Set indentaton on yaml.v3 Go slice tricks cheat sheet Github Issues\nYAML库关于等同json.RawMessage的Issue ","date":"2021-06-29T17:03:46+08:00","permalink":"https://ilolicon.github.io/p/golang/","title":"Golang"},{"content":" Container Evolution\n容器编排 ansible/saltstack 传统应用编排工具 docker docker compose docker单机编排 docker swarm docker主机加入docker swarm资源池 docker machine 完成docker主机加入docker swarm资源池的先决条件/预处理工具 mesos(idc os) + marathon 面向容器编排的框架 kubernetes(borg) 自动装箱(基于依赖 自动完成容器部署 不影响其可用性) 自我修复 水平扩展 服务发现和负载均衡 自动发布和回滚 密钥和配置管理 存储编排 任务批量处理运行 概述 概述\n组件 Kubernetes组件\n集群安装 二进制安装 参考kubeasz项目\nkubeadm安装 使用kubeadm引导集群\n图中docker组件可以替换为其他容器运行时组件(CRI) 参考：移除Dockershim的常见问题 CNI以flannel为例 主机环境预设 OS: Ubuntu 22.04 LTS Kubernetes: v1.29.13 Container Runtime(二选一即可) containerd 官方仓库containerd 或Docker社区提供的containerd.io DockerCE-27.5.0 和 cri-dockerd-0.3.16 测试环境说明 1master/2+node 也可以多master 根据自己环境安排 集群节点需要做时间同步 禁用swap swapoff -a systemctl \u0026ndash;type swap systemctl mask SWAP_DEV 禁用默认配置的iptables 加载br_netfilter模块 modprobe br_netfilter 写入/etc/modules(开机启动) 安装容器运行时 docker+cri-docekrd 安装docker-ce 1 2 3 4 5 6 7 8 9 10 11 apt -y install apt-transport-https ca-certificates curl software-properties-common curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add - add-apt-repository \u0026#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\u0026#34; apt update # 安装docker-ce apt -y install docker-ce # 进行完下面配置后 重启服务 systemctl restart docker ststemctl enable docker docker配置 kubelet需要让docker容器引擎使用systemd作为CGroup的驱动 其默认值为cgroupfs 我们还需要编辑docker的配置文件/etc/docker/daemon.json 参考下面配置 其中的registry-mirrors用于指明使用的镜像加速服务 参考国内无法下载Docker镜像的多种解决方案 提示: 自Kubernetes v1.22版本开始 未明确设置kubelet的cgroup driver时 则默认即会将其设置为systemd 1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://dockerpull.cn\u0026#34; ], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;200m\u0026#34; }, \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34; } 为docker设置代理(可选) Kubeadm部署Kubernetes集群的过程中 默认使用Google的Registry服务registry.k8s.io上的镜像 例如registry.k8s.io/kube-apiserver等 但国内部分用户可能无法访问到该服务 我们也可以使用国内的镜像服务来解决这个问题 例如registry.aliyuncs.com/google_containers 若选择使用国内的镜像服务 则配置代理服务的步骤为可选 设置代理配置 编辑/lib/systemd/system/docker.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 重要提示: # 节点网络(例如本示例中使用的192.168.0.0/16) # Pod网络(例如本示例中使用的10.244.0.0/16) # Service网络(例如本示例中使用的10.96.0.0/12)以及127网络等本地使用的网络 # 必须明确定义为不使用所配置的代理 否则将很有可能带来无法预知的本地网络通信故障 # 请将下面配置段中的 $PROXY_SERVER_IP 替换为你的代理服务器地址 # 将$PROXY_PORT 替换为你的代理服所监听的端口 # 另外还要注意所使用的协议http是否同代理服务器提供服务的协议相匹配 如有必要 请自行修改为https Environment=\u0026#34;HTTP_PROXY=http://$PROXY_SERVER_IP:$PROXY_PORT\u0026#34; Environment=\u0026#34;HTTPS_PROXY=http://$PROXY_SERVER_IP:$PROXY_PORT\u0026#34; Environment=\u0026#34;NO_PROXY=127.0.0.0/8,172.17.0.0/16,172.29.0.0/16,10.244.0.0/16,192.168.0.0/16,10.96.0.0/12,magedu.com,cluster.local\u0026#34; # 修改完配置重启服务 systemctl daemon-reload systemctl restart docker 安装cri-dockerd 直接去对应的Github项目下载对应的deb包安装 containerd 安装容器运行时containerd Ubuntu 2204上安装Containerd有两种选择 Ubuntu系统官方程序包仓库中的containerd Docker社区提供的containerd.io(本文选择该种方式) 安装并启动containerd.io 1 2 3 4 5 6 # 生成containerd.io相关程序包的仓库 这里以阿里云的镜像服务器为例 apt -y install apt-transport-https ca-certificates curl software-properties-common curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add - add-apt-repository \u0026#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\u0026#34; apt update apt-get -y install containerd.io 配置containerd.io 运行如下命令打印并保存如下配置 1 2 mkdir /etc/containerd containerd config default \u0026gt; /etc/containerd/config.toml 编辑生成的配置文件 完成如下几项相关的配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 1. 修改containerd使用SystemdCgroup [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.runtimes.runc] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.runtimes.runc.options] SystemdCgroup = true # 2. 配置Containerd使用国内Mirror站点上的pause镜像及指定的版本 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;] sandbox_image = \u0026#34;registry.aliyuncs.com/google_containers/pause:3.9\u0026#34; # 3. 配置Containerd使用国内的Image加速服务 以加速Image获取 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;docker.io\u0026#34;] endpoint = [\u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;https://registry.docker-cn.com\u0026#34;] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;registry.k8s.io\u0026#34;] endpoint = [\u0026#34;https://registry.aliyuncs.com/google_containers\u0026#34;] # 4. 配置Containerd使用私有镜像仓库 不存在要使用的私有ImageRegistry时 本步骤可省略 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;registry.minho.com\u0026#34;] endpoint = [\u0026#34;https://registry.minho.com\u0026#34;] # 5. 配置私有镜像仓库跳过tls验证 若私有ImageRegistry能正常进行tls认证 则本步骤可省略 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.configs] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.configs.\u0026#34;registry.minho.com\u0026#34;.tls] insecure_skip_verify = true # 6. 重启服务 systemctl restart containerd 配置crictl客户端 安装containerd.io时 会自动安装命令行客户端工具crictl 该客户端通常需要通过正确的unix sock文件才能接入到containerd服务 编辑配置文件/etc/crictl.yaml 添加如下内容即可 随后即可正常使用crictl程序管理Image/Container和Pod等对象 另外containerd.io还有另一个名为ctr的客户端程序可以使用 其功能也更为丰富 1 2 3 4 runtime-endpoint: unix:///run/containerd/containerd.sock image-endpoint: unix:///run/containerd/containerd.sock timeout: 10 debug: true 安装kubelet/kubeadm/kubectl 自v1.28版本开始 Kubernetes官方变更了仓库的存储路径及使用方式(不同的版本将会使用不同的仓库) 并提供了向后兼容至v1.24版本 因此 对于v1.24及之后的版本来说 可以使用如下有别于传统配置的方式来安装相关的程序包 以本示例中要安装的v1.29版本为例来说 配置要使用的程序包仓库 需要使用的命令如下 如若需要安装其它版本 则将下面命令中的版本号v1.29予以替换即可 1 2 3 4 5 apt-get update \u0026amp;\u0026amp; apt-get install -y apt-transport-https curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/deb/ /\u0026#34; | tee /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubelet kubeadm kubectl 安装完成后 要确保kubeadm等程序文件的版本 这将也是后面初始化Kubernetes集群时需要明确指定的版本号 整合kubelet和cri-dockerd 仅支持CRI规范的kubelet需要经由遵循该规范的cri-dockerd完成与docker-ce的整合 该步骤仅使用docker-ce和cri-dockerd运行时的场景中需要配置 配置cri-dockerd 配置cri-dockerd 确保其能够正确加载到CNI插件 编辑/usr/lib/systemd/system/cri-docker.service文件 确保其[Service]配置段中的ExecStart的值类似如下内容 1 ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd:// --network-plugin=cni --cni-bin-dir=/opt/cni/bin --cni-cache-dir=/var/lib/cni/cache --cni-conf-dir=/etc/cni/net.d --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9 需要添加的各配置参数(各参数的值要与系统部署的CNI插件的实际路径相对应) --network-plugin 指定网络插件规范的类型 这里要使用CNI --cni-bin-dir 指定CNI插件二进制程序文件的搜索目录 --cni-cache-dir CNI插件使用的缓存目录 --cni-conf-dir CNI插件加载配置文件的目录 --pod-infra-container-image Pod中的puase容器要使用的Image 默认为registry.k8s.io上的pause仓库中的镜像 不能直接获取到该Image时 要明确指定为从指定的位置加载 例如registry.aliyuncs.com/google_containers/pause:3.9 配置完成后重启服务systemctl restart cri-docker 配置kubelet 配置kubelet 为其指定cri-dockerd在本地打开的Unix Sock文件的路径 该路径一般默认为/run/cri-dockerd.sock 编辑文件/etc/sysconfig/kubelet 为其添加如下指定参数 若/etc/sysconfig目录不存在 则需要先创建该目录 KUBELET_KUBEADM_ARGS=\u0026quot;--container-runtime=remote --container-runtime-endpoint=/run/cri-dockerd.sock\u0026quot; 初始化第一个主节点 该步骤开始尝试构建Kubernetes集群的master节点 配置完成后 各worker节点直接加入到集群中的即可 由于kubeadm部署的Kubernetes集群上 集群核心组件kube-apiserver、kube-controller-manager、kube-scheduler和etcd等均会以静态Pod的形式运行 它们所依赖的镜像文件默认来自于registry.k8s.io这一Registry服务之上 但我们无法直接访问该服务 常用的解决办法有如下两种 使用能够到达该服务的代理服务 使用国内的镜像服务器上的服务 例如registry.aliyuncs.com/google_containers等 初始化master节点 在运行初始化命令之前先运行如下命令单独获取相关的镜像文件 而后再运行后面的kubeadm init命令 以便于观察到镜像文件的下载过程 若您选择使用的是docker-ce和cri-dockerd这一容器运行时环境 本文后续内容中使用的kubeadm命令 都需要额外添加--cri-socket=unix:///var/run/cri-dockerd.sock选项 以明确指定其所要关联的容器运行时 这是因为docker-ce和cri-dockerd都提供unix sock类型的socket地址 这会导致kubeadm在自动扫描和加载该类文件时无法自动判定要使用哪个文件 而使用containerd.io运行时 则不存在该类问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 下面的命令会列出类似如下的Image信息 由如下的命令结果可以看出 # 相关的Image都来自于registry.k8s.io 该服务上的Image通常需要借助于代理服务才能访问到 root@k8s-master01:~# kubeadm config images list registry.k8s.io/kube-apiserver:v1.29.13 registry.k8s.io/kube-controller-manager:v1.29.13 registry.k8s.io/kube-scheduler:v1.29.13 registry.k8s.io/kube-proxy:v1.29.13 registry.k8s.io/coredns/coredns:v1.11.1 registry.k8s.io/pause:3.9 registry.k8s.io/etcd:3.5.16-0 # 若需要从国内的Mirror站点下载Image # 还需要在命令上使用--image-repository选项来指定Mirror站点的相关URL # 例如 下面的命令中使用了该选项将Image Registry指向国内可用的Aliyun的镜像服务 # 其命令结果显示的各Image也附带了相关的URL root@k8s-master01:~# kubeadm config images list --image-repository=registry.aliyuncs.com/google_containers registry.aliyuncs.com/google_containers/kube-apiserver:v1.29.13 registry.aliyuncs.com/google_containers/kube-controller-manager:v1.29.13 registry.aliyuncs.com/google_containers/kube-scheduler:v1.29.13 registry.aliyuncs.com/google_containers/kube-proxy:v1.29.13 registry.aliyuncs.com/google_containers/coredns:v1.11.1 registry.aliyuncs.com/google_containers/pause:3.9 registry.aliyuncs.com/google_containers/etcd:3.5.16-0 # 运行下面的命令即可下载需要用到的各Image # 需要注意的是 如果需要从国内的Mirror站点下载Image # 同样需要在命令上使用--image-repository选项来指定Mirror站点的相关URL kubeadm config images pull --image-repository=registry.aliyuncs.com/google_containers --- [config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.29.13 [config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.29.13 [config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.29.13 [config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.29.13 [config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.11.1 [config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.9 [config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.16-0 而后即可进行master节点初始化 kubeadm init命令支持两种初始化方式 一是通过命令行选项传递关键的部署设定 另一个是基于yaml格式的专用配置文件(建议) 后一种允许用户自定义各个部署参数 在配置上更为灵活和便捷 下面分别给出了两种实现方式的配置步骤 建议读者采用第二种方式进行。 方式1 运行如下命令完成k8s-master01节点的初始化 需要注意的是 若使用docker-ce和cri-dockerd运行时 则还要在如下命令上明确配置使用--cri-socket=unix:///run/cri-dockerd.sock选项 1 2 3 4 5 6 7 8 kubeadm init \\ --control-plane-endpoint=\u0026#34;k8s-master01.minho.com\u0026#34; \\ --kubernetes-version=v1.29.13 \\ --pod-network-cidr=10.244.0.0/16 \\ --service-cidr=10.96.0.0/12 \\ --token-ttl=0 \\ --upload-certs \\ --cri-socket=unix:///run/cri-dockerd.sock 各选项含义 --image-repository 指定要使用的镜像仓库 默认为registry.k8s.io --kubernetes-version kubernetes程序组件的版本号 它必须要与安装的kubelet程序包的版本号相同 --control-plane-endpoint 控制平面的固定访问端点 可以是IP地址或DNS名称 会被用于集群管理员及集群组件的kubeconfig配置文件的API Server的访问地址 单控制平面部署时可以不使用该选项 --pod-network-cidr Pod网络的地址范围 其值为CIDR格式的网络地址 通常Flannel网络插件的默认为10.244.0.0/16 Calico插件的默认值为192.168.0.0/16 而Cilium的默认值为10.0.0.0/8 --service-cidr Service的网络地址范围 其值为CIDR格式的网络地址 kubeadm使用的默认为10.96.0.0/12 通常 仅在使用Flannel一类的网络插件需要手动指定该地址 --apiserver-advertise-address apiserver通告给其他组件的IP地址 一般应该为Master节点的用于集群内部通信的IP地址 0.0.0.0表示节点上所有可用地址 --token-ttl 共享令牌(token)的过期时长 默认为24小时 0表示永不过期 为防止不安全存储等原因导致的令牌泄露危及集群安全 建议为其设定过期时长 未设定该选项时 在token过期后 若期望再向集群中加入其它节点 可以使用如下命令重新创建token 并生成节点加入命令 kubeadm token create --print-join-command 提示：无法访问registry.k8s.io时 同样可以在上面的命令中使用--image-repository=registry.aliyuncs.com/google_containers选项 以便从国内的镜像服务中获取各Image 注意：若各节点未禁用Swap设备 还需要附加选项--ignore-preflight-errors=Swap 从而让kubeadm忽略该错误设定 方式二 kubeadm也可通过配置文件加载配置 以定制更丰富的部署选项 获取内置的初始配置文件的命令 kubeadm config print init-defaults 下面的配置示例 是以上面命令的输出结果为框架进行修改的 它明确定义了kubeProxy的模式为ipvs 并支持通过修改imageRepository的值修改获取系统镜像时使用的镜像仓库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: minho.comc4mu9kzd5q7ur ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: # 这里的地址即为初始化的控制平面第一个节点的IP地址 advertiseAddress: 172.29.7.1 bindPort: 6443 nodeRegistration: # 注意 使用docker-ce和cri-dockerd时 要启用如下配置的cri socket文件的路径 # criSocket: unix:///run/cri-dockerd.sock imagePullPolicy: IfNotPresent # 第一个控制平面节点的主机名称 name: k8s-master01.minho.com taints: - effect: NoSchedule key: node-role.kubernetes.io/master - effect: NoSchedule key: node-role.kubernetes.io/control-plane --- apiServer: timeoutForControlPlane: 4m0s # 将下面配置中的certSANS列表中的值 修改为客户端接入API Server时可能会使用的各类目标地址 certSANs: - kubeapi.minho.com - 172.29.7.1 - 172.29.7.2 - 172.29.7.3 - 172.29.7.253 apiVersion: kubeadm.k8s.io/v1beta3 # 控制平面的接入端点 我们这里选择适配到kubeapi.minho.com这一域名上 controlPlaneEndpoint: \u0026#34;kubeapi.minho.com:6443\u0026#34; certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers kind: ClusterConfiguration kubernetesVersion: v1.29.2 networking: # 集群要使用的域名 默认为cluster.local dnsDomain: cluster.local # service网络的地址 serviceSubnet: 10.96.0.0/12 # pod网络的地址 flannel网络插件默认使用10.244.0.0/16 podSubnet: 10.244.0.0/16 scheduler: {} --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration # 用于配置kube-proxy上为Service指定的代理模式 默认为iptables mode: \u0026#34;ipvs\u0026#34; 将上面的内容保存于配置文件中 例如kubeadm-config.yaml 而后执行如下命令即能实现类似前一种初始化方式中的集群初始配置 但这里将Service的代理模式设定为ipvs kubeadm init --config kubeadm-config.yaml --upload-certs 初始化完成后的操作步骤 对于Kubernetes系统的新用户来说 无论使用上述哪种方法 命令运行结束后 请记录最后的kubeadm join命令输出的最后提示的操作步骤 下面的内容是需要用户记录的一个命令输出示例 它提示了后续需要的操作步骤 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of the control-plane node running the following command on each as root: kubeadm join k8s-master01.minho.com:6443 --token tkzmlw.406h8d9g8x9sf8z1 \\ --discovery-token-ca-cert-hash sha256:a32fe9b88096c3c0c22570a486302f58d3c479a8f1ccaf74b8fa4538a1a9d904 \\ --control-plane --certificate-key 502f1f1c87aea5a99dea3ee197878159f06a1f4178a8e7610ed228e6629a9414 \\ --cri-socket=unix:///run/cri-dockerd.sock Please note that the certificate-key gives access to cluster sensitive data, keep it secret! As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \u0026#34;kubeadm init phase upload-certs --upload-certs\u0026#34; to reload certs afterward. Then you can join any number of worker nodes by running the following on each as root: kubeadm join k8s-master01.minho.com:6443 --token tkzmlw.406h8d9g8x9sf8z1 \\ --discovery-token-ca-cert-hash sha256:a32fe9b88096c3c0c22570a486302f58d3c479a8f1ccaf74b8fa4538a1a9d904 \\ --cri-socket=unix:///run/cri-dockerd.sock kubeadm init命令完整参考指南请移步官方文档 设定kubectl kubectl是kube-apiserver的命令行客户端程序 实现了除系统部署之外的几乎全部的管理操作 是kubernetes管理员使用最多的命令之一 kubectl需经由API server认证及授权后方能执行相应的管理操作 kubeadm部署的集群为其生成了一个具有管理员权限的认证配置文件/etc/kubernetes/admin.conf 它可由kubectl通过默认的$HOME/.kube/config的路径进行加载 当然 用户也可在kubectl命令上使用\u0026ndash;kubeconfig选项指定一个别的位置 下面复制认证为Kubernetes系统管理员的配置文件至目标用户(例如当前用户root)的家目录下 mkdir ~/.kube \u0026amp;\u0026amp; cp /etc/kubernetes/admin.conf ~/.kube/config 部署网络插件 Kubernetes系统上Pod网络的实现依赖于第三方插件进行 这类插件有近数十种之多 较为著名的有flannel、calico、canal和kube-router等 简单易用的实现为CoreOS提供的flannel项目 下面的命令用于在线部署flannel至Kubernetes系统之上 我们需要在初始化的第一个master节点k8s-master01上运行如下命令 以完成部署 kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml 而后使用如下命令确认其输出结果中Pod的状态为Running 类似如下命令及其输入的结果所示 kubectl get pods -n kube-flannel 验证master节点已经就绪 1 2 3 4 5 6 7 8 9 10 11 12 13 14 kubectl get nodes # 上述命令应该会得到类似如下输出 这表示k8s-master01节点已经就绪 NAME STATUS ROLES AGE VERSION k8s-master01.minho.com Ready control-plane 5d22h v1.29.12 # 若准备有其它的master节点 以构建高可用的控制平面 # 可按照初始化控制平面第一个节点时输出的信息 在额外的master节点上运行添加命令 以完成控制平面其它节点的添加 # 相关的命令是形如下在的相关信息 kubeadm join k8s-master01.minho.com:6443 \\ --token tkzmlw.406h8d9g8x9sf8z1 \\ --discovery-token-ca-cert-hash sha256:a32fe9b88096c3c0c22570a486302f58d3c479a8f1ccaf74b8fa4538a1a9d904 \\ --control-plane --certificate-key 502f1f1c87aea5a99dea3ee197878159f06a1f4178a8e7610ed228e6629a9414 \\ --cri-socket=unix:///run/cri-dockerd.sock 添加节点到集群中 下面的两个步骤 需要分别在k8s-node01、k8s-node02和k8s-node03上各自完成\n若未禁用Swap设备 编辑kubelet的配置文件/etc/default/kubelet 设置其忽略Swap启用的状态错误 内容如下：KUBELET_EXTRA_ARGS=\u0026quot;\u0026ndash;fail-swap-on=false\u0026quot; 将节点加入第二步中创建的master的集群中 要使用主节点初始化过程中记录的kubeadm join命令 再次提示 若使用docker-ce和cri-dockerd运行时环境 则需要在如下命令中额外添加--cri-socket=unix:///run/cri-dockerd.sock选项 1 2 3 kubeadm join k8s-master01.minho.com:6443 --token tkzmlw.406h8d9g8x9sf8z1 \\ --discovery-token-ca-cert-hash sha256:a32fe9b88096c3c0c22570a486302f58d3c479a8f1ccaf74b8fa4538a1a9d904 \\ --cri-socket=unix:///run/cri-dockerd.sock 验证节点添加结果 在每个节点添加完成后 即可通过kubectl验证添加结果 下面的命令及其输出是在所有的三个节点均添加完成后运行的 其输出结果表明三个Worker Node已经准备就绪 1 2 3 4 5 6 root@k8s-master01:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master01.minho.com Ready control-plane 5d22h v1.29.12 k8s-node01.minho.com Ready \u0026lt;none\u0026gt; 5d22h v1.29.12 k8s-node02.minho.com Ready \u0026lt;none\u0026gt; 5d22h v1.29.12 k8s-node03.minho.com Ready \u0026lt;none\u0026gt; 5d22h v1.29.12 测试应用编排及服务访问 到此为止 一个master/三个worker的kubernetes集群基础设施已经部署完成 用户随后即可测试其核心功能 例如 下面的命令可将demoapp以Pod的形式编排运行于集群之上 并通过在集群外部进行访问 1 2 3 4 5 6 7 kubectl create deployment demoapp --image=ikubernetes/demoapp:v1.0 --replicas=3 kubectl create service nodeport demoapp --tcp=80:80 # 而后 使用如下命令了解Service对象demoapp使用的NodePort 以便于在集群外部进行访问 root@k8s-master01:~# kubectl get svc -l app=demoapp NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE demoapp NodePort 10.100.84.12 \u0026lt;none\u0026gt; 80:30622/TCP 2s demoapp是一个web应用 因此 用户可以于集群外部通过http://NodeIP:30622这个URL访问demoapp上的应用 我们也可以在Kubernetes集群上启动一个临时的客户端 对demoapp服务发起访问测试 kubectl run client-$RANDOM --image=ikubernetes/admin-box:v1.2 --rm --restart=Never -it --command -- /bin/bash 而后 在打开的交互式接口中 运行如下命令 对demoapp.default.svc服务发起访问请求 验证其负载均衡的效果 root@client-3021 ~# while true; do curl demoapp.default.svc; sleep 1; done 清理部署的测试应用 kubectl delete deployments/demoapp services/demoapp 部署Add-ons(可选步骤) MetalLB 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 安装metalLB kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.9/config/manifests/metallb-native.yaml # 配置地址池 # IPAddressPool: 用来定义可分配的IP范围 # L2Advertisement: 在Layer2模式下通过ARP广播来承诺这些IP apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: default-pool namespace: metallb-system spec: addresses: - 192.168.1.240-192.168.1.250 --- apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: l2-adv namespace: metallb-system spec: ipAddressPools: - default-pool # 接下来就可以创建LoadBalancer类型的Service使用 Ingress Nginx Metrics Server Kuboard 配置对多集群的访问 配置对多集群的访问\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 添加集群信息 kubectl config --kubeconfig=config-demo set-cluster development --server=https://1.2.3.4 --certificate-authority=fake-ca-file # 添加用户信息 kubectl config --kubeconfig=config-demo set-credentials developer --client-certificate=fake-cert-file --client-key=fake-key-seefile # 添加上下文 kubectl config --kubeconfig=config-demo set-context dev-frontend --cluster=development --namespace=frontend --user=developer # 查看配置文件详情 # 直接打开文件或使用如下命令 kubectl config --kubeconfig=config-demo view # 设置当前上下文 kubectl config --kubeconfig=config-demo use-context dev-frontend # 使用--minify参数 来查看与当前上下文相关联的配置信息 kubectl config --kubeconfig=config-demo view --minify # 设置 KUBECONFIG 环境变量 export KUBECONFIG=\u0026#34;${KUBECONFIG}:config-demo:config-demo-2\u0026#34; 资源清单定义 创建资源的方法\napiserver仅接收json格式的资源定义\nyaml格式提供配置清单 apiserver可自动将其转换为json格式 而后再提交\n大部分资源的配置清单 主要都有五个主要的部分组成\napiversion\nkubectl api-versions # 所属API群组 标识方式: group/version 省略组名则为core group kind: 资源类别\nmetadata: 元数据\nname: 同一类别中 name需要唯一 namespace: 所属k8s的哪个名称空间 labels annotations 每个资源的引用PATH /api/${GROUP/VERSION}/namespace/${NAMESPACE}/${TYPE}/${NAME} spec(重要): 定义用户期望的状态 disired state\nstatus: 当前状态 current state 本字段由Kubernetes集群维护\n字段太多 可以借助kubectl explain --help命令查看详细信息\nkubectl explain pod kubectl explain pod.metadata Pod pods\n自主式Pod 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 apiVersion: v1 kind: Pod metadata: name: pod-demo namespace: default labels: app: myapp tier: frontend spec: containers: - name: myapp image: nginx:alpine - name: busybox image: busybox:latest command: - \u0026#34;/bin/sh\u0026#34; - \u0026#34;-c\u0026#34; - \u0026#34;sleep 3600\u0026#34; Pod资源 spec.containers \u0026lt;[]object\u0026gt;\n1 2 3 4 5 6 7 8 9 # kubectl explain pod.spec.containers - name: \u0026lt;string\u0026gt; image: \u0026lt;string\u0026gt; imagePullPolicy: \u0026lt;string\u0026gt; # Always Never IfNotPresent ... # 修改镜像中的默认应用 - command/args https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/ 标签\nkey = value key: 字母 数字 _ - . value: 可以为空 只能字母或数字开头及结尾 标签选择器\n等值关系: =、==、!=(不等于会筛选出不具有该标签的资源) 集合关系 KEY in (VALUE1,VALUE2,\u0026hellip;) KEY notin (VALUE1,VALUE2,\u0026hellip;) KEY # 存在这个KEY就行 !KEY # 不存在此键的资源 许多资源支持内嵌字段来使用标签选择器\nmatchLabels: 直接给定键值 matchExpressions: 基于给定的表达式来定义使用标签选择器 key: \u0026ldquo;KEY\u0026rdquo;, operator: \u0026ldquo;OPERATOR\u0026rdquo;, values: [VAL1,VAL2,VAL3,\u0026hellip;] 操作符 In、NotIn: values字段的值必须为非空列表 Exists、NotExists: values字段的值必须为空列表 spec.nodeSelector \u0026lt;map[striong]string\u0026gt;\n节点标签选择器 spec.nodeName \u0026lt;string\u0026gt; # 直接指定运行node\nannotations\n与label不同的地方在于 它不能用于挑选资源对象 仅用于为对象提供元数据 没有键长度/值长度限制 spec.restartPolicy\n重启策略: One of Always, OnFailure, Never. Default to Always Pod生命周期 pod-lifecycle\n状态\nPending # 调度尚未完成 Running # 运行状态 Failed Succeeded Unknown \u0026hellip; Pod生命周期中的重要行为\n初始化容器 按顺序同步执行 执行成功才会继续执行下一个 若某一个执行失败 会全部重新执行 初始化容器具有阻塞的特性 初始化容器不执行完成 则阻塞着主容器的启动 容器探测(自定义命令/TCP套接字发请求/HTTP应用层请求) start probe: 启动探测 liveness probe: 探测容器是否存活 readiness probe: 探测容器是否准备就绪 能对外提供服务 钩子 post start 启动后钩子 在初始化容器执行完成 开始初始化主容器时 就会启动 所以 并不保证在主容器启动命令执行完成后再执行 有可能启动命令耗时较久 但是post start钩子已经执行完成 pre stop 停止前钩子 preStop钩子延伸\n在k8s中 理想的状态是pod优雅释放 但并不是每一个pod都会如此顺利 pod卡死 处理不了优雅退出的命令或操作 优雅退出的逻辑有bug 陷入死循环 代码问题 导致执行的命令没有效果 对于以上问题 k8s的终止流程中还有一个 最多可以容忍的时间\u0026quot; 即grace period 在pod.spec.termiationGracePeriodSeconds字段定义 默认值为30s 当我们执行kubelet delete的时候 也可以加上--grace-period参数显示指定一个优雅退出时间来覆盖pod中的配置 如果我们配置的grace period超过时间之后 k8s就只能强制kill pod 值得注意的是 这与preStop hook和SIGTERM信号并行发生 k8s不会等待preStop hook的完成 如果你的应用程序完成关闭并在terminationGracePeriod完成之前退出 k8s会立即进入下一步 初始化容器 init-cotainers\ninit容器与普通容器非常像 除以下2点 init容器总是运行到成功完成为止 每个init容器都必须在下一个init容器启动之前成功完成 如果Pod的init容器失败 Kubernetes会不断的重启该Pod知道init容器成功为止 然后 如果Pod对应的restartPolicy为Never 它不会重新启动 initC与应用容器具备不同的镜像 可以把一些危险的工具放置在initC中 进行使用 initC多个之间时线形启动的 所以可以做一些延迟性的操作 initC不支持lifeycle 探针 其他与应用容器无异 实验 下面的例子定义了一个具有2个Init容器的简单Pod 第一个等待myservice启动 第二个等待mydb启动 一旦这两个Init容器都启动完成 Pod将启动spec节中的应用容器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 apiVersion: v1 kind: Pod metadata: name: initc-1 labels: app: initc spec: containers: - name: myapp-container image: busybox command: - \u0026#34;sh\u0026#34; - \u0026#34;-c\u0026#34; - \u0026#34;echo The app is running \u0026amp;\u0026amp; sleep 3600\u0026#34; initContainers: - name: init-myservice image: busybox command: - \u0026#34;sh\u0026#34; - \u0026#34;-c\u0026#34; - \u0026#34;until nslookup myservice; do echo waiting for myservice; sleep 2; done;\u0026#34; - name: init-mydb image: wangyanglinux/tools:busybox command: - \u0026#34;sh\u0026#34; - \u0026#34;-c\u0026#34; - \u0026#34;until nslookup mydb; do echo waiting for mydb; sleep2; done;\u0026#34; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # kubectl apply -f initc.yaml # 查看容器状态可以看到 目前卡在Init阶段 等待2个初始化容器的成功退出 # kubectl get -f initc.yaml NAME READY STATUS RESTARTS AGE initc-1 0/1 Init:0/2 0 35m # 查看容器日志看到 应用容器在等待初始化 因为初始化容器阻塞了应用容器 # kubectl logs -f initc-1 Defaulted container \u0026#34;myapp-container\u0026#34; out of: myapp-container, init-myservice (init), init-mydb (init) Error from server (BadRequest): container \u0026#34;myapp-container\u0026#34; in pod \u0026#34;initc-1\u0026#34; is waiting to start: PodInitializing # 也可以单独查看初始化容器的日志 # kubectl logs -f initc-1 -c init-myservice Server: 10.96.0.10 Address: 10.96.0.10:53 ** server can not find myservice.default.svc.cluster.local: NXDOMAIN ... waiting for myservice # 第二个初始化容器也被阻塞 # kubectl logs -f initc-1 -c init-db Error from server (BadRequest): container \u0026#34;init-mydb\u0026#34; in pod \u0026#34;initc-1\u0026#34; is waiting to start: PodInitializing 增加对应service后 则init容器成功执行 应用容器正常初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 --- apiVersion: v1 kind: Service metadata: name: myservice spec: ports: - protocol: TCP port: 80 targetPort: 9376 --- apiVersion: v1 kind: Service metadata: name: mydb spec: ports: - protocol: TCP port: 80 targetPort: 9377 Pod容器探针类型 配置探针\nkubectl explain pod.spec.containers.livenessProbe kubectl explain pod.spec.containers.readinessProbe\nexec Action httpGet Action tcpSocket Action Pod控制器 控制器 工作负载管理\nReplicaSet\nKubectl explain replicaset 用户期望副本数 标签选择器 Pod资源模版 不建议直接使用ReplicaSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp namespace: default spec: replicas: 2 selector: matchLabels: app: myapp release: canary template: metadata: name: myapp-pod labels: app: myapp release: canary environment: qa spec: containers: - name: myapp-container image: nginx:alpine ports: - name: http containerPort: 80 Deployment\n构建在ReplicaSet之上 而非Pod 实现滚动更新(多出或少于N个副本 控制更新粒度)、回滚 通常管理10个历史版本(ReplicaSet) 管理无状态应用最好的控制器 无状态(只关注群体、不关注个体)、持续运行应用 声明式管理(即可以创建 也可以更新 kubectl apply -f deployment.yaml) kubectl rollout history 查看滚动历史 kubectl rollout --help 查看rollout所有子命名帮助 注意：kubectl rollout restart deployment/abc # 重启Pod 实际是滚动更新 删掉重建新的Pod DaemonSet\nkubectl explain deployment.spec.strategy.rollingUpdate # 滚动更新策略 确保集群中的每一个节点(或部分满足条件的节点)精确运行一个Pod副本 通常用于一些系统级的后台任务 无状态、持续运行应用 Job\n只做一次 只要完成就正常退出 没完成才进行重构 执行一次性的作业 不需要持续在后台运行 执行完成就退出 Cronjob\n周期性Job StatefulSet\n管理有状态应用 每一个pod副本单独管理 拥有自己独有的标识和独有的数据集 TPR: Third Party Resources 1.2+ - 1.7\nCDE: Custom Defined Resources 1.8+\nOperator\nService Service代理 services-networking\nuserspace kube-proxy会监视Kubernetes控制平面对Service对象和Endpoints对象的添加和移除操作 对每个Service它会在本地Node上打开一个端口(随机选择) 任何连接到代理端口的请求 都会被代理到Service的后端Pods中的某个上面 使用哪个后端Pod是 kube-proxy 基于SessionAffinity来确定的 最后 它配置 iptables 规则 捕获到达该 Service 的clusterIP(是虚拟 IP)和Port的请求 并重定向到代理端口 代理端口再代理请求到后端Pod 默认情况下 用户空间模式下的kube-proxy通过轮转算法选择后端 流量来回在内核和用户空间切换 效率较低 iptables kube-proxy会监视Kubernetes控制节点对Service对象和Endpoints对象的添加和移除\n对每个Service 它会配置iptables规则 从而捕获到达该Service的clusterIP和端口的请求 进而将请求重定向到 Service 的一组后端中的某个Pod上面\n对于每个Endpoints对象 它也会配置iptables规则 这个规则会选择一个后端组合\n默认的策略是 kube-proxy在iptables模式下随机选择一个后端 使用iptables处理流量具有较低的系统开销 因为流量由Linux netfilter处理 而无需在用户空间和内核空间之间切换 这种方法也可能更可靠\n如果kube-proxy在iptables模式下运行 并且所选的第一个 Pod 没有响应 则连接失败\n这与用户空间模式不同: 在这种情况下 kube-proxy将检测到与第一个Pod的连接已失败 并会自动使用其他后端Pod 重试 可以使用Pod就绪探测器 验证后端Pod可以正常工作 以便iptables模式下的kube-proxy仅看到测试正常的后端 避免将流量通过kube-proxy发送到已知已失败的 Pod ipvs 特性状态： Kubernetes v1.11 [stable]\n在ipvs模式下 kube-proxy监视Kubernetes服务和端点 调用netlink接口创建相应的IPVS规则 并定期将IPVS规则与Kubernetes服务和端点同步 该控制循环可确保 IPVS 状态与所需状态匹配\n访问服务时 IPVS将流量定向到后端Pod之一\nIPVS代理模式基于类似于iptables模式的netfilter挂钩函数 但是使用哈希表作为基础数据结构 并且在内核空间中工作\n这意味着 与iptables模式下的kube-proxy相比 IPVS模式下的kube-proxy重定向通信的延迟要短 并且在同步代理规则时具有更好的性能 与其他代理模式相比 IPVS模式还支持更高的网络流量吞吐量 IPVS提供了更多选项来平衡后端Pod的流量\nrr: 轮询(Round-Robin) lc: 最少链接(Least Connection) 即打开链接数量最少者优先 dh: 目标地址哈希(Destination Hashing) sh: 源地址哈希(Source Hashing) sed: 最短预期延迟(Shortest Expected Delay) nq: 从不排队(Never Queue) 备注\n要在IPVS模式下运行kube-proxy必须在启动kube-proxy之前使IPVS在节点上可用 当kube-proxy以IPVS代理模式启动时 它将验证IPVS内核模块是否可用 如果未检测到IPVS内核模块 则kube-proxy将退回到以iptables代理模式运行 Service类型 ClusterIP: 通过集群的内部IP暴露服务 选择该值时服务只能够在集群内部访问 这也是默认的ServiceType NodePort: 通过每个节点上的IP和静态端口(NodePort)暴露服务 NodePort服务会路由到自动创建的ClusterIP服务 通过请求 \u0026lt;节点IP\u0026gt;:\u0026lt;节点端口\u0026gt; 你可以从集群的外部访问一个NodePort服务 Client -\u0026gt; NodeIP:NodePort -\u0026gt; ClusterIP:ServicePort -\u0026gt; PodIP:containerPort 为避免单Node压力过大 会在外面再加一层负载均衡 公有云环境: LBaaS(参考下面LoadBalancer类型) LoadBalancer: 使用云提供商的负载均衡器向外部暴露服务 外部负载均衡器可以将流量路由到自动创建的NodePort服务和ClusterIP服务上 ExternalName: 通过返回CNAME和对应值 可以将服务映射到externalName字段的内容(例如foo.bar.example.com) 无需创建任何类型代理 FQDN(CoreDNS 内部解析) CNAME -\u0026gt; FQDN(外部真正的FQDN ) Headless Services(无头Service) 有时不需要或不想要负载均衡 以及单独的Service IP 遇到这种情况 可以通过指定Cluster IP(spec.clusterIP)的值为 \u0026quot;None\u0026quot;来创建 Headless Service 你可以使用一个无头Service与其他服务发现机制进行接口 而不必与Kubernetes的实现捆绑在一起 对于无头Services并不会分配Cluster IP kube-proxy不会处理它们 而且平台也不会为它们进行负载均衡和路由 DNS如何实现自动配置 依赖于Service是否定义了选择算符 无头Service允许客户端直接连接到它所偏好的任一Pod 无头Service不使用虚拟IP地址和代理配置路由和数据包转发 相反 无头Service通过内部DNS记录报告各个Pod的端点IP地址 这些DNS记录是由集群的DNS服务所提供 要定义无头 Service 你需要将.spec.type设置为ClusterIP(这也是type的默认值) 并进一步将.spec.clusterIP设置为 None 流量策略 traffic-policies\n你可以设置.spec.internalTrafficPolicy和.spec.externalTrafficPolicy字段来控制kubernetes如何将流量路由到健康(\u0026ldquo;就绪\u0026rdquo;)的后端\n内部流量策略\n特性状态： Kubernetes v1.26 [stable] 你可以设置.spec.internalTrafficPolicy字段来控制来自内部源的流量如何被路由 有效值为Cluster和Local 将字段设置为Cluster会将内部流量路由到所有准备就绪的端点 将字段设置为Local仅会将流量路由到本地节点准备就绪的端点 如果流量策略为Local但没有本地节点端点 那么kube-proxy会丢弃该流量 外部流量策略\n你可以设置.spec.externalTrafficPolicy字段来控制从外部源路由的流量 有效值为Cluster和Local 将字段设置为Cluster会将外部流量路由到所有准备就绪的端点 将字段设置为Local仅会将流量路由到本地节点上准备就绪的端点 如果流量策略为Local并且没有本地节点端点 那么kube-proxy不会转发与相关Service相关的任何流量 会话亲和性 session-affinity\n在这些代理模型中 绑定到Service IP:Port的流量被代理到合适的后端 客户端不需要知道任何关于Kubernetes、Service或Pod的信息 如果要确保来自特定客户端的连接每次都传递给同一个Pod 你可以通过设置Service的 .spec.sessionAffinity为ClientIP来设置基于客户端IP地址的会话亲和性 默认为None 会话粘性超时 你还可以通过设置Service的.spec.sessionAffinityConfig.clientIP.timeoutSeconds来设置最大会话粘性时间 默认值为10800 即3小时 说明：在Windows上不支持为Service设置最大会话粘性时间 Ingress ingress\nService对后端特定类型Pod分类(label selector) Ingress基于上面的分类识别后端Pod 并生成配置信息注入到nginx(需要重载配置)/envoy/traefik等 ingress-controllers\n存储 kubernetes-storage\nkubectl explain pods.spec.volumes\nemptyDir # 临时目录 随pod删除而消失(生命周期同pod) gitRepo(clone到机器 修改不会同步 需要同步可以自己再做一个sidecar) hostPath # 宿主机路径 SAN(iSCSI\u0026hellip;)、NAS(nfs、cifs\u0026hellip;) 分布式存储 glusterfs、rdb、cephfs 云存储 EBS、Azure Disk\u0026hellip; 存储各类特性 元数据 configMap: 用于保存配置数据(明文) secret: 用于保存敏感数据(编码) downwardAPI: 容器在运行时从KubernetesAPI服务器获取有关它们自身的信息 真实数据 volume: 用于存储临时或者持久性数据 persistentVolume: 申请制的持久化存储 configMap configMap是一种 API 对象 用来将非机密性的数据保存到键值对中 使用时Pods可以将其用作环境变量、命令行参数或者存储卷中的配置文件 configMap将你的环境配置信息和容器镜像解耦 便于应用配置的修改 容器化配置应用方式 自定义命令行参数 args: [] 把配置文件直接打包至镜像 环境变量 CloudNative的应用程序一般可直接通过环境变量加载配置 通过entrypoint脚本来预处理变量为配置文件中的配置信息 存储卷 基于目录创建 文件准备 都放到同一个目录下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # game.properties enemies=aliens lives=3 enemies.cheat=true enemies.cheat.level=noGoodRotten secret.code.passphrase=UUDDLRLRBABAS secret.code.allowed=true secret.code.lives=30 # ui.properties color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNice # game-env-file.properties enemies=aliens lives=3 allowed=\u0026#34;true\u0026#34; # This comment and the empty line above it are ignored 从目录创建 1 2 3 4 5 # 从configMap目录创建 kubectl create configmap game-config --from-file=configMap/ # 查看内容 kubectl describe configmaps game-config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # kubectl get configmaps game-config -o yaml apiVersion: v1 data: game.properties: | enemies=aliens lives=3 enemies.cheat=true enemies.cheat.level=noGoodRotten secret.code.passphrase=UUDDLRLRBABAS secret.code.allowed=true secret.code.lives=30 ui.properties: | color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNice kind: ConfigMap metadata: creationTimestamp: \u0026#34;2025-05-06T11:17:42Z\u0026#34; name: game-config namespace: default resourceVersion: \u0026#34;15745032\u0026#34; uid: 339da6be-8725-4c71-895d-33b6b29937c1 基于文件创建 1 2 3 4 5 # 你可以使用 kubectl create configmap 基于单个文件或多个文件创建 ConfigMap kubectl create configmap game-config-2 --from-file=configMap/game.properties # 你可以多次使用 --from-file 参数 从多个数据源创建 ConfigMap kubectl create configmap game-config-2 --from-file=configMap/game.properties --from-file=configMap/ui.properties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 使用 --from-env-file 选项基于 env 文件创建 ConfigMap # Env 文件包含环境变量列表 其中适用以下语法规则: # Env 文件中的每一行必须为 VAR=VAL 格式 # 以＃开头的行(即注释)将被忽略 # 空行将被忽略 # 引号不会被特殊处理(即它们将成为 ConfigMap 值的一部分) # kubectl create configmap game-config-env-file --from-env-file=configMap/game-env-file.properties apiVersion: v1 data: allowed: \u0026#39;\u0026#34;true\u0026#34;\u0026#39; # 引号不会被特殊处理 enemies: aliens lives: \u0026#34;3\u0026#34; kind: ConfigMap metadata: creationTimestamp: \u0026#34;2025-05-06T11:31:12Z\u0026#34; name: game-config-env-file namespace: default resourceVersion: \u0026#34;15746741\u0026#34; uid: a01e6c70-2f32-4e3f-814b-72bbf45d79d2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 从 Kubernetes 1.23 版本开始 kubectl 支持多次指定 --from-env-file 参数来从多个数据源创建 ConfigMap # kubectl create configmap config-multi-env-files --from-env-file=configMap/game-env-file.properties --from-env-file=configMap/ui-env-file.properties data: allowed: \u0026#39;\u0026#34;true\u0026#34;\u0026#39; color: purple enemies: aliens how: fairlyNice lives: \u0026#34;3\u0026#34; textmode: \u0026#34;true\u0026#34; kind: ConfigMap metadata: creationTimestamp: \u0026#34;2025-05-06T11:36:40Z\u0026#34; name: config-multi-env-files namespace: default resourceVersion: \u0026#34;15747431\u0026#34; uid: 194d9181-713a-4cc8-8218-ad4c5900f77b 定义从文件创建时要使用的键 1 kubectl create configmap game-config-3 --from-file=\u0026lt;我的键名\u0026gt;=\u0026lt;文件路径\u0026gt; 根据字面值创建 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 你可以将 kubectl create configmap 与 --from-literal 参数一起使用 通过命令行定义文字值 # 你可以传入多个键值对 命令行中提供的每对键值在 ConfigMap 的 data 部分中均表示为单独的条目 # kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm apiVersion: v1 data: special.how: very special.type: charm kind: ConfigMap metadata: creationTimestamp: \u0026#34;2025-05-06T11:44:19Z\u0026#34; name: special-config namespace: default resourceVersion: \u0026#34;15748397\u0026#34; uid: 6952c791-32e6-4905-a45c-c6a1433779ff 在Pod中使用ConfigMap定义的环境变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: special.how: very --- apiVersion: v1 kind: ConfigMap metadata: name: env-config namespace: default data: log_level: INFO # pod-configmap-env-variable.yaml apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: ilolicon/demoapp:v1.0.0 command: [ \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;env\u0026#34; ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: LOG_LEVEL valueFrom: configMapKeyRef: name: env-config key: log_level restartPolicy: Never 将ConfigMap中的所有键值对配置为容器环境变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # configmap.yaml # 包含多个键值对 apiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: SPECIAL_LEVEL: very SPECIAL_TYPE: charm # pod.yaml apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: ilolicon/demoapp:v1.0.0 command: [ \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;env\u0026#34; ] envFrom: - configMapRef: name: special-config restartPolicy: Never 在Pod命令中使用ConfigMap定义的环境变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # pod.yaml apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: ilolicon/demoapp:v1.0.0 command: [ \u0026#34;/bin/echo\u0026#34;, \u0026#34;$(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)\u0026#34; ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: SPECIAL_LEVEL - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: SPECIAL_TYPE restartPolicy: Never 将ConfigMap数据添加到一个卷中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # pod.yaml apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: ilolicon/demoapp:v1.0.0 command: [ \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;ls /etc/config/ \u0026amp;\u0026amp; sleep 3600\u0026#34; ] volumeMounts: # 如果该容器镜像的 /etc/config 目录中有一些文件 卷挂载将使该镜像中的这些文件无法访问 - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: # 提供包含要添加到容器中的文件的 ConfigMap 的名称 name: special-config restartPolicy: Never 热更新 当已挂载的 ConfigMap 被更新时 所投射的内容最终也会被更新 这适用于 Pod 启动后可选引用的 ConfigMap 重新出现的情况 更新 ConfigMap 目前并不会触发相关Pod的滚动更新(对于不能自动热更新的应用程序来说 则需要重新部署获取最新配置) 可以通过修改Pod的annotations 的方式强制触发滚动更新 kubectl patch deployment \u0026lt;your's deployment\u0026gt; --patch '{\u0026quot;spec\u0026quot;:{\u0026quot;template\u0026quot;:{\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{\u0026quot;version/config\u0026quot;:\u0026quot;6666666\u0026quot;}}}}}' 更新 ConfigMap 后 使用该ConfigMap挂载的Env不会同步更新 使用该ConfigMap挂载的volume中的数据需要一段时间才能同步更新 从ConfigMap更新到新键映射到Pod的总延迟可能与 kubelet 同步周期(默认为1分钟) + kubelet 中 ConfigMap 缓存的 TTL (默认为1分钟)一样长 你可以通过更新 Pod 的一个注解来触发立即刷新 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 # demoapp-configmap.yaml # configmap更新后 # 1. 如果demoapp不支持自动更新配置 则需要重新重新触发滚动更新 重新触发方式：更新pod注解实现 # 2. 如果demoapp支持自动更新配置 则实时生效 无需重新发布应用 apiVersion: v1 data: config.yaml: | log_level: debug kind: ConfigMap metadata: name: demoapp-config # demoapp-hot-update-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: labels: app: demoapp-hot-update name: demoapp-hot-update spec: replicas: 1 selector: matchLabels: app: demoapp-hot-update template: metadata: labels: app: demoapp-hot-update spec: containers: - image: ilolicon/demoapp:v1.0.0 imagePullPolicy: Always name: demoapp volumeMounts: - name: config-volume mountPath: /opt/demoapp/ volumes: - name: config-volume configMap: name: demoapp-config --- apiVersion: v1 kind: Service metadata: name: demoapp-hot-update spec: selector: app: demoapp-hot-update ports: - protocol: TCP port: 80 targetPort: 80 不可改变 特性状态：Kubernetes v1.21 [stable] Kubernetes特性Immutable Secret和ConfigMap提供了一种将各个Secret和ConfigMap设置为不可变更的选项 对于大量使用ConfigMap的集群(至少有数万个各不相同的ConfigMap给Pod挂载)而言 禁止更改ConfigMap的数据有以下好处 保护应用 使之免受意外(不想要的)更新所带来的负面影响 通过大幅降低对kube-apiserver的压力提升集群性能 这是因为系统会关闭对已标记为不可变更的ConfigMap的监视操作 你可以通过将immutable字段设置为true创建不可变更的ConfigMap 1 2 3 4 5 6 7 apiVersion: v1 kind: ConfigMap metadata: ... data: ... immutable: true 一旦某ConfigMap被标记为不可变更 则无法逆转这一变化 也无法更改data或binaryData字段的内容 你只能删除并重建ConfigMap 因为现有的Pod会维护一个已被删除的ConfigMap的挂载点 建议重新创建这些Pods 限制 在Pod规约中引用某个ConfigMap之前 必须先创建这个对象 或者在Pod规约中将ConfigMap标记为optional 如果所引用的ConfigMap不存在 并且没有将应用标记为optional 则Pod将无法启动 同样 引用ConfigMap中不存在的主键也会令Pod无法启动 除非你将Configmap标记为optional 如果你使用envFrom来基于ConfigMap定义环境变量 那么无效的键将被忽略 Pod可以被启动 但无效名称将被记录在事件日志中InvalidVariableNames 日志消息列出了每个被跳过的键 1 2 3 # kubectl get events LASTSEEN FIRSTSEEN COUNT NAME KIND SUBOBJECT TYPE REASON SOURCE MESSAGE 0s 0s 1 dapi-test-pod Pod Warning InvalidEnvironmentVariableNames {kubelet, 127.0.0.1} Keys [1badkey, 2alsobad] from the EnvFrom configMap default/myconfig were skipped since they are considered invalid environment variable names. ConfigMap位于确定的名字空间中 每个ConfigMap只能被同一名字空间中的Pod引用 你不能将ConfigMap用于静态Pod 因为Kubernetes不支持这种用法 Secret Secret是一种包含少量敏感信息例如密码、OAUTH令牌或SSH密钥的对象 这样的信息可能会被放在Pod规约中或者镜像中 使用Secret意味着你不需要在应用程序代码中包含机密数据 Secret类似于ConfigMap但专门用于保存敏感数据 特性 Kubernetes通过仅仅将Secret分发到需要访问Secret的Pod所在机器节点来保障其安全性 Secret只会存储在几点的内存中 永不写入物理存储 这样从节点删除secret时就不需要擦除磁盘数据 从Kunernetes1.7版本开始 etcd会以加密形式存储Secret 一定程度的保证了Secret的安全性 类型 创建Secret时 你可以使用Secret资源的type字段或者与其等价的kubectl命令行参数(如果有的话)为其设置类型 Secret类型有助于对Secret数据进行编程处理 Kubernetes提供若干种内置的类型 用于一些常见的使用场景 针对这些类型 Kubernetes所执行的合法性检查操作以及对其所实施的限制各不相同 内置类型 用法 Opaque 用户定义的任意数据 kubernetes.io/service-account-token 服务账号令牌 kubernetes.io/dockercfg ~/.dockercfg 文件的序列化形式 kubernetes.io/dockerconfigjson ~/.docker/config.json 文件的序列化形式 kubernetes.io/basic-auth 用于基本身份认证的凭据 kubernetes.io/ssh-auth 用于 SSH 身份认证的凭据 kubernetes.io/tls 用于 TLS 客户端或者服务器端的数据 bootstrap.kubernetes.io/token 启动引导令牌数据 Opaque 当你未在Secret清单中显式指定类型时 默认的Secret类型是Opaque 当你使用kubectl来创建一个Secret时 你必须使用generic子命令来标明要创建的是一个Opaque类型的Secret 1 2 3 4 5 6 7 kubectl create secret generic empty-secret kubectl get secret empty-secret # 输出 # DATA列显示Secret中保存的数据条目个数 在这个例子中 0意味着你刚刚创建了一个空的Secret NAME TYPE DATA AGE empty-secret Opaque 0 22h Yaml资源清单创建 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: # 值经过base64编码 username: dXNlcm5hbWU= password: cGFzc3dvcmQ= # kubectl get secret mysecret -o yaml apiVersion: v1 data: password: cGFzc3dvcmQ= username: dXNlcm5hbWU= kind: Secret metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;password\u0026#34;:\u0026#34;cGFzc3dvcmQ=\u0026#34;,\u0026#34;username\u0026#34;:\u0026#34;dXNlcm5hbWU=\u0026#34;},\u0026#34;kind\u0026#34;:\u0026#34;Secret\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;name\u0026#34;:\u0026#34;mysecret\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;}} creationTimestamp: \u0026#34;2025-05-10T11:39:15Z\u0026#34; name: mysecret namespace: default resourceVersion: \u0026#34;16477137\u0026#34; uid: 6b70696f-dcd4-4b7d-a37e-8d1891b75077 type: Opaque Pod中使用Secret的数据定义环境变量 如果容器已经使用了在环境变量中的Secret 除非容器重新启动 否则容器将无法感知到Secret的更新 有第三方解决方案可以在Secret改变时触发容器重启 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # pod.yaml apiVersion: v1 kind: Pod metadata: name: envvars-multiple-secrets spec: containers: - name: envars-test-container image: ilolicon/demoapp:v1.0.0 env: - name: APP_USERNAME valueFrom: secretKeyRef: name: mysecret key: username - name: APP_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password # kubectl exec -it pods/envvars-multiple-secrets -- printenv | grep ^APP_ # 根据结果发现 secret使用时会自动解码 APP_USERNAME=username APP_PASSWORD=password Secret volume 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 apiVersion: v1 kind: Pod metadata: labels: name: secret-volume name: secret-volume-pod spec: volumes: - name: volumes-secret secret: secretName: mysecret containers: - image: ilolicon/demoapp:v1.0.0 name: demoapp volumeMounts: - name: volumes-secret mountPath: \u0026#34;/data\u0026#34; # kubectl exec -it pods/secret-volume-pod -- cat -n /data/{username,password} # /data 下面有2个文件 username和password 1 username 2 password # 挂载指定key及指定目录 spec: volumes: - name: volumes-secret secret: secretName: mysecret items: # 未做软连接 无法热更新 - key: username path: my-group/my-username # 进容器查看内容 cat /data/my-group/my-username username 为Secret键设置POSIX权限 1 2 3 4 5 6 spec: volumes: - name: volumes-secret secret: secretName: mysecret defaultMode: 0644 说明 如果使用JSON定义Pod或Pod模板 请注意JSON规范不支持数字的八进制形式 因为JSON将0400视为十进制的值400 在JSON中 要改为使用十进制的defaultMode 如果你正在编写YAML 则可以用八进制编写defaultMode 热更新 ENV/挂载子路径 都不能自动更新 除非容器重启 第三方方案可以监视Secret改变时 自动触发容器重启 当卷中包含来自Secret的数据 而对应的Secret被更新 Kubernetes会跟踪到这一操作并更新卷中的数据 更新的方式是保证最终一致性 不可改变 特性状态：Kubernetes v1.21 [stable] Kubernetes允许你将特定的Secret(和ConfigMap)标记为不可更改Immutable 禁止更改现有Secret的数据有下列好处 防止意外(或非预期的)更新导致应用程序中断 (对于大量使用Secret的集群而言 至少数万个不同的Secret供Pod挂载) 通过将Secret标记为不可变 可以极大降低kube-apiserver的负载 提升集群性能 kubelet不需要监视那些被标记为不可更改的Secret 1 2 3 4 5 6 7 8 # 你也可以更改现有的Secret 令其不可更改 apiVersion: v1 kind: Secret metadata: ... data: ... immutable: true downwardAPI downwardAPI卷用于为应用提供downwardAPI数据 在这类卷中 所公开的数据以纯文本格式的只读文件形式存在 downwardAPI数据: 将Pod和容器字段值暴露给容器中运行的代码的机制 downwardAPI是kubernetes中的一个功能 它允许容器在运行时从kubernetesAPI服务器获取有关它们自身的信息 这些信息可以作为容器内部的环境变量或文件注入到容器中 以便容器可以获取有关其运行环境的各种信息 如Pod名称/命名空间/标签等 提供容器元数据 动态配置 与Kubernetes环境集成 也可以注入env 或使用volume挂载 volume优势 会保持热更新特性 传递一个容器的资源到另一个容器中 扩展 downwardAPI提供了一种简单的方式 将pod和容器的元数据传递给它们内部运行的进程 但这种方式其实仅仅可以暴露一个pod自身的元数据传递给在它们内部运行的进程 这种方式仅仅可以暴露一个pod自身的元数据 而且只可以暴露部分元数据 还有另一种方式 从API服务器获取 Kubetneres API文档 1 2 3 4 5 6 7 8 9 10 11 12 13 # kubectl proxy --port=8080 # 获取swagger-ui配置 curl http://127.0.0.1:8080/openapi/v2 \u0026gt; k8s-swagger.json # 粘贴至swagger在线UI https://editor.swagger.io/ # 或run本地swagger-ui服务器 docker run --rm -d -p 80:8080 \\ -e SWAGGER_JSON=/k8s-swagger.json \\ -v $(pwd)/k8s-swagger.json \\ swaggerapi/swagger-ui Volume 数据的持久化方案 容器磁盘上的文件的生命周期是短暂的 这就使得在容器中运行重要应用时会出现一些问题 首先 当容器崩溃时 kubelet会重启它 但是容器中的文件将丢失 容器以干净的状态(镜像最初的状态)重新启动 其次 在Pod中同时运行多个容器时 这些容器之间通常需要共享文件 Kubernetes中的Volume抽象 就很好的解决了这些问题 部分最新版已启用 参考最新官方文档描述 awsElasticBlockStore azureDisk cephfs configMap downwardAPI emptyDir gitRepo glusterfs hostPath nfs persistentVolumeClaim secret \u0026hellip; emptyDir 对于定义了emptyDir卷的Pod 在Pod被指派到某节点时此卷会被创建 就像其名称所表示的那样emptyDir卷最初是空的 尽管Pod中的容器挂载emptyDir卷的路径可能相同也可能不同 但这些容器都可以读写emptyDir卷中相同的文件 当Pod因为某些原因被从节点上删除时 emptyDir卷中的数据也会被永久删除 说明: 容器崩溃并不会导致Pod被从节点上移除 因此容器崩溃期间emptyDir卷中的数据是安全的\nemptyDir的一些用途： 缓存空间 例如基于磁盘的归并排序 为耗时较长的计算任务提供检查点 以便任务能方便地从崩溃前状态恢复执行 在Web服务器容器服务数据时 保存内容管理器容器获取的文件 hostPath hostPath卷能将主机节点文件系统上的文件或目录挂载到你的Pod中 虽然这不是大多数Pod需要的 但是它为一些应用提供了强大的逃生舱 用途 运行一个需要访问节点级系统组件的容器 运行需要你访问Docker内部的容器 使用/var/lib/docker的hostPath 在容器中运行cAdvisor 使用/dev/cgroups的hostPath 例如一个将系统日志传输到集中位置的容器 使用只读挂载/var/log来访问这些日志 让存储在主机系统上的配置文件可以被静态Pod以只读方式访问 与普通Pod不同 静态Pod无法访问ConfigMap 静态Pod(Static Pod): 是由特定节点上的kubelet守护进程直接管理的Pod(/etc/kubernetes/manifests) 它并不经过常规的 APIServer -\u0026gt; ControllerManager -\u0026gt; kubelet的控制链路 警告： 使用hostPath类型的卷存在许多安全风险 如果可以 你应该尽量避免使用hostPath卷 例如 你可以改为定义并使用 local PersistentVolume\n如果你通过准入时的验证来限制对节点上特定目录的访问 这种限制只有在你额外要求所有hostPath卷的挂载都是只读的情况下才有效 如果你允许不受信任的Pod以读写方式挂载任意主机路径 则该Pod中的容器可能会破坏可读写主机挂载卷的安全性\n无论hostPath卷是以只读还是读写方式挂载 使用时都需要小心 这是因为：\n访问主机文件系统可能会暴露特权系统凭证(例如kubelet的凭证)或特权API(例如容器运行时套接字) 这些可以被用于容器逃逸或攻击集群的其他部分 具有相同配置的Pod(例如基于PodTemplate创建的Pod)可能会由于节点上的文件不同而在不同节点上表现出不同的行为 hostPath卷的用量不会被视为临时存储用量 你需要自己监控磁盘使用情况 因为过多的hostPath磁盘使用量会导致节点上的磁盘压力 hostPath卷类型 取值 行为 \u0026quot;\u0026quot; 空字符串(默认)用于向后兼容 这意味着在安装hostPath卷之前不会执行任何检查 DirectoryOrCreate 如果在给定路径上什么都不存在 那么将根据需要创建空目录 权限设置为0755 具有与kubelet相同的组和属主信息 Directory 在给定路径上必须存在的目录 FileOrCreate 如果在给定路径上什么都不存在 那么将在那里根据需要创建空文件 权限设置为0644 具有与kubelet相同的组和所有权 File 在给定路径上必须存在的文件 Socket 在给定路径上必须存在的UNIX套接字 CharDevice (仅Linux节点) 在给定路径上必须存在的字符设备 BlockDevice (仅Linux节点) 在给定路径上必须存在的块设备 注意 FileOrCreate模式不会创建文件的父目录 如果挂载文件的父目录不存在 Pod将启动失败 为了确保这种模式正常工作 你可以尝试分别挂载目录和文件 当Kubernetes按照计划添加资源感知调度时 将无法考虑hostPath使用的资源 底层主机上创建的某些文件或目录只能由root用户访问 此时 你需要在特权容器中以root身份运行进程 或者修改主机上的文件权限 以便能够从hostPath卷读取数据(或将数据写入到hostPath卷) PV/PVC 存储的管理是一个与计算实例的管理完全不同的问题 PersistentVolume子系统为用户和管理员提供了一组API 将存储如何制备的细节从其如何被使用中抽象出来 为了实现这点 Kubernetes引入了两个心的API资源 PersistentVolume PersistentVolumeClaim 持久卷(PersistentVolume PV) 是集群中的一块存储 可以由管理员事先制备 或者使用存储类(Storage Class)来动态制备 持久卷是集群级别的资源 就像节点也是集群资源一样 PV持久卷和普通的Volume一样 也是使用卷插件来实现的 只是它们拥有独立于任何使用PV的Pod的生命周期 此API对象中记述了存储的实现细节 无论其背后是NFS、iSCSI还是特定于云平台的存储系统 持久卷声明(PersistentVolumeClaim PVC) 表达的是用户对存储的请求 概念上与Pod类似 Pod会耗用节点资源 而PVC申领会耗用PV资源 Pod可以请求特定数量的资源(CPU和内存) 同样PVC申领也可以请求特定的大小和访问模式 例如 可以挂载为ReadWriteOnce、ReadOnlyMany、ReadWriteMany或ReadWriteOncePod 关联条件 容量: PV的值不小于PVC要求 可以大于 最好一致 读写策略(访问模式)：完全匹配 单节点读写：ReadWriteOnce / RWO 多节点只读：ReadOnlyMany / ROX 多节点读写：ReadWriteMany / RWX ReadWriteOncePod / RWOP: v1.29[stable] 卷可以被单个Pod以读写方式挂载 如果你想确保整个集群中只有一个Pod可以读取或写入该PVC 使用该方式 存储类：PV的类与PVC的类必须一致 不存在包容降级关系 回收策略(Reclaiming) 当用户不再使用其存储卷时 他们可以从API中将PVC对象删除 从而允许该资源被回收再利用 PersistentVolume对象的回收策略告诉集群 当其被从申领中释放时如何处理该数据卷 目前 数据卷可以被Retained(保留) Recycled(回收) Deleted(删除) 保留(Retain)\n回收策略Retain使得用户可以手动回收资源 当PersistentVolumeClaim对象被删除时 PersistentVolume卷仍然存在 对应的数据卷被视为\u0026quot;已释放(released)\u0026quot; 由于卷上仍然存在这前一申领人的数据 该卷还不能用于其他申领 管理员可以通过下面的步骤来手动回收该卷： 删除PersistentVolume对象 与之相关的、位于外部基础设施中的存储资产在PV删除之后仍然存在 根据情况 手动清除所关联的存储资产上的数据 手动删除所关联的存储资产 如果你希望重用该存储资产 可以基于存储资产的定义创建新的PersistentVolume卷对象 删除(Delete)\n对于支持Delete回收策略的卷插件 删除动作会将PersistentVolume对象从Kubernetes中移除 同时也会从外部基础设施中移除所关联的存储资产 动态制备的卷会继承其StorageClass中设置的回收策略 该策略默认为Delete 管理员需要根据用户的期望来配置StorageClass 否则PV卷被创建之后必须要被编辑或者修补 参阅更改PV卷的回收策略 回收(Recyle)\n警告: 回收策略Recycle已被废弃 取而代之的建议方案是使用动态制备 如果底层的卷插件支持 回收策略Recycle会在卷上执行一些基本的擦除(rm -rf /thevolume/*)操作 之后允许该卷用于新PVC申领 卷阶段(状态) 每个持久卷会处于以下阶段(Phase)之一：\nAvailable 卷是一个空闲资源 尚未绑定到任何申领 Bound 该卷已经绑定到某申领 Released 所绑定的申领已被删除 但是关联存储资源尚未被集群回收 Failed 卷的自动回收操作失败 你可以使用kubectl describe persistentvolume \u0026lt;name\u0026gt;查看已绑定到PV的PVC的名称\nPVC保护 PVC保护的目的是确保由Pod正在使用的PVC不会从系统中移除 因为如果被移除的话可能导致数据丢失 注意：当Pod状态为Pending并且Pod已经分配给节点 或Pod为Running状态时 PVC处于活动状态 当启用PVC保护功能时 如果用户删除了一个Pod正在使用的PVC 则该PVC不会被立即删除 PVC的删除将被推迟 直到PVC不再被任何的Pod使用 示例 配置Pod以使用PersistentVolume作为存储\nStorageClass 存储设备需支持RESTful风格的创建请求\n根据请求动态创建PV\nnfs-subdir-external-provisioner\n部署NFS服务器\n1 2 3 4 5 6 7 8 9 apt-get upate apt install -y nfs-kernerl-server mkdir /nfs/data chown nobody -R /nfs /etc/exports /nfs/data *(rw,sync,no_subtree_check) systemctl restart nfs-server showmount -e 192.168.56.75 部署nfs-client-provisioner 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 kind: Deployment apiVersion: apps/v1 metadata: name: nfs-client-provisioner namespace: nfs-storageclass spec: replicas: 1 selector: matchLabels: app: nfs-client-provisioner strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: eipwork/nfs-subdir-external-provisioner:v4.0.2 volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: k8s-sigs.io/nfs-subdir-external-provisioner - name: NFS_SERVER value: 192.168.56.75 - name: NFS_PATH value: /nfs/data volumes: - name: nfs-client-root nfs: # server: \u0026lt;YOUR NFS SERVER HOSTNAME\u0026gt; server: 192.168.56.75 # share nfs path path: /nfs/data --- apiVersion: v1 kind: ServiceAccount metadata: name: nfs-client-provisioner namespace: nfs-storageclass --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-client-provisioner-runner rules: - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;nodes\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;] - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;persistentvolumes\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;, \u0026#39;create\u0026#39;, \u0026#39;delete\u0026#39;] - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;persistentvolumeclaims\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;, \u0026#39;update\u0026#39;] - apiGroups: [\u0026#39;storage.k8s.io\u0026#39;] resources: [\u0026#39;storageclasses\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;] - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;events\u0026#39;] verbs: [\u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;patch\u0026#39;] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-client-provisioner subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: nfs-storageclass roleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: nfs-storageclass rules: - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;endpoints\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;, \u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;patch\u0026#39;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: nfs-storageclass subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: nfs-storageclass roleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: nfs-client namespace: nfs-storageclass provisioner: k8s-sigs.io/nfs-subdir-external-provisioner parameters: pathPattern: ${.PVC.namespace}/${.PVC.name} onDelete: delete 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # test-pod.yaml kind: PersistentVolumeClaim apiVersion: v1 metadata: name: test-claim spec: accessModes: - ReadWriteMany resources: requests: storage: 1Mi storageClassName: nfs-client --- kind: Pod apiVersion: v1 metadata: name: test-pod spec: containers: - name: test-pod image: ilolicon/demoapp:v1.0.0 volumeMounts: - name: nfs-pvc mountPath: /opt/demoapp/nfsdata restartPolicy: \u0026#39;Never\u0026#39; volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-claim StatefulSet控制器 CoreOS Operator\ncattle/pet # 一个关注群体 一个关注个体(和无状态应用的区别)\nPetSet(1.3) -\u0026gt; StatefulSet(1.5+)\nStatefulSet主要用于管理有以下特性的应用程序\n稳定且唯一的网络标识符 稳定且持久的存储 有序、平滑的部署和扩展 有序、平滑的终止和删除 有序的滚动更新 一般来说 一个典型的StatefulSet由三个组件组成\nhandless service # 无头服务 确保名称唯一 StatefulSet # 控制器 volumeClaimTemplate # 存储卷申请模版(不能使用同一存储卷 pod模版创建的存储卷都是一样的 所以需要卷申请模版) kubelet explain sts.spec.updateStrategy.rollingUpdate\npartition \u0026lt;inter\u0026gt; # 控制更新的Pod partition: N # 大于等于编号N的Pod将被更新 默认值: 0 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # 创建PV apiVersion: v1 kind: PersistentVolume metadata: name: nfspv1 spec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfs/pv1 server: 192.168.56.75 # statefulset apiVersion: v1 kind: Service metadata: name: myapp labels: app: myapp spec: ports: - port: 80 name: web # 无头服务 访问: \u0026lt;podName\u0026gt;.\u0026lt;svcName\u0026gt;.default.svc.cluster.local 可访问到具体pod地址 clusterIP: None selector: app: myapp --- apiVersion: apps/v1 kind: StatefulSet metadata: name: web spec: selector: matchLabels: app: myapp serviceName: myapp # kubectl explain statefulsets.apps.spec.serviceName replicas: 3 template: metadata: labels: app: myapp spec: containers: - name: myapp image: ilolicon/demoapp:v1.0.0 ports: - containerPort: 80 name: web volumeMounts: - name: config mountPath: /opt/demoapp/ volumeClaimTemplates: - metadata: name: config spec: accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] storageClassName: \u0026#34;nfs\u0026#34; resources: requests: storage: 1Gi 调度器 概念 kubernetes调度器\nPod QoS类\n为Pod和容器管理资源\nkube-scheduler是kubernetes的调度器 主要任务是把定义的Pod分配到集群的节点上 scheduler是作为单独的程序运行的 启动之后会一致监听API Server 获取PodSpec.NodeName为空的pod 对每个Pod都会创建一个binding 表明该pod应该放到哪个节点上 需要考虑的问题 公平：如何保证每个节点都能被分配资源 资源高效利用：集群所有资源最大化被使用 效率：调度的性能要好 能够尽快地对大批量的pod完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 除来kuberneres自带的调度器 你也可以编写自己的调度器 通过spec.schedulerName参数指定调度器的名字 可以为pod选择某个调度器进行调度 自定义调度器示例 1 2 3 4 5 6 7 8 9 10 11 apiVersion: v1 kind: Pod metadata: name: demoapp labels: name: demoapp spec: schedulerName: my-scheduler # 指定自定义调度器 containers: - name: pod-with-custom-scheduler iamge: ilolicon/demoapp:v1.0.0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 在 kubernetes Master 节点开启 apiServer 的代理 kubectl proxy --port=8001 #!/bin/bash # my-scheduler.sh SERVER=\u0026#39;localhost:8001\u0026#39; while true; do for PODNAME in $(kubectl --server $SERVER get pods -o json | jq \u0026#39;.items[] | select(.spec.schedulerName ==\u0026#34;my-scheduler\u0026#34;) | select(.spec.nodeName == null) | .metadata.name\u0026#39; | tr -d \u0026#39;\u0026#34;\u0026#39;) do NODES=($(kubectl --server $SERVER get nodes -o json | jq \u0026#39;.items[].metadata.name\u0026#39; | tr -d \u0026#39;\u0026#34;\u0026#39;)) NUMNODES=${#NODES[@]} CHOSEN=${NODES[$[ $RANDOM % $NUMNODES]]} curl --header \u0026#34;Content-Type:application/json\u0026#34; --request POST --data \u0026#39;{\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;Binding\u0026#34;,\u0026#34;metadata\u0026#34;: {\u0026#34;name\u0026#34;:\u0026#34;\u0026#39;$PODNAME\u0026#39;\u0026#34;},\u0026#34;target\u0026#34;: {\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;: \u0026#34;Node\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;\u0026#39;$CHOSEN\u0026#39;\u0026#34;}}\u0026#39; http://$SERVER/api/v1/namespaces/default/pods/$PODNAME/binding/ echo \u0026#34;Assigned $PODNAME to $CHOSEN\u0026#34; done sleep 1 done 调度过程 调度器分为几个部分 首先是过滤掉不满足条件的节点 这个过程称为预选(过滤) 然后通过对节点按照优先级排序 这个是优选(打分) 最后从中选择优先级最高的节点 如果中间任何一步骤有错误 就直接返回错误 预选 PodFitsResources: 节点上剩余的资源是否大于pod请求的资源 PodFitsHost: 如果pod指定来NodeName 检查节点名称是否和NodeName匹配 PodFitsHostPorts: 节点上已经使用的port是否和pod申请的port冲突 PodSelectorMatches: 过滤掉和pod指定的label不匹配的节点 NoDiskConflict: 已经mount的volume和pod指定的volume不冲突 除非它们都是只读 优选 如果在预选过程中没有合适的节点 pod会一直在pending状态 不断重试调度 直到有节点满足条件 经过这个步骤 如果有多个节点满足条件 就继续优先过程 按照优先级大小对节点排序 优先级由一系列键值对组成 键是该优先级项的名称 值是它的权重 这先优先级选项包括 LeastRequestedPriority: 通过计算CPU和Memory的使用率来决定权重 使用率越低权重越高 换句话说 这个优先级指标倾向于资源使用比例更低的节点 BalancedResourceAllocation: 节点上CPU和Memory使用率越接近 权重越高 这个应该和上面的一起使用 不应该单独使用 ImageLocalityPriority: 倾向于已经有要使用镜像的节点 镜像总大小值越大 权重越高 亲和性 节点亲和性 节点亲和性概念上类似于nodeSelector 它使你可以根据节点上的标签来约束Pod可以调度到哪些节点上 节点亲和性有两种 requiredDuringSchedulingIgnoredDuringExecution：调度器只有在规则被满足的时候才能执行调度 此功能类似于nodeSelector 但其语法表达能力更强 preferredDuringSchedulingIgnoredDuringExecution：调度器会尝试寻找满足对应规则的节点 如果找不到匹配的节点 调度器仍然会调度该Pod 说明：在上述类型中 IgnoredDuringExecution意味着如果节点标签在Kubernetes调度Pod后发生了变更 Pod 仍将继续运行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 apiVersion: v1 kind: Pod metadata: name: with-node-affinity spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: topology.kubernetes.io/zone operator: In values: - antarctica-east1 - antarctica-west1 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: registry.k8s.io/pause:2.0 上述示例含义： 节点必须包含一个键名为topology.kubernetes.io/zone的标签 并且该标签的取值必须为 antarctica-east1 或 antarctica-west1 节点最好具有一个键名为another-node-label-key且取值为another-node-label-value的标签 operator字段操作符 In NotIn Exists DoesNotExist Gt Lt NotIn和DoesNotExist可用来实现节点反亲和性行为 你也可以使用节点污点将Pod从特定节点驱逐 Pod间亲和性与反亲和性 Pod间亲和性与反亲和性使你可以基于已经在节点上运行的Pod的标签来约束Pod可以调度到的节点 而不是基于节点上的标签 Pod间亲和性与反亲和性的规则格式为\u0026quot;如果X上已经运行了一个或多个满足规则Y的Pod 则这个Pod应该(或者在反亲和性的情况下不应该)运行在X上\u0026quot; 这里的X可以是节点、机架、云提供商可用区或地理区域或类似的拓扑域 Y则是Kubernetes尝试满足的规则 你通过标签选择算符的形式来表达规则(Y) 并可根据需要指定选关联的名字空间列表 Pod在Kubernetes中是名字空间作用域的对象 因此Pod的标签也隐式地具有名字空间属性 针对Pod标签的所有标签选择算符都要指定名字空间 Kubernetes会在指定的名字空间内寻找标签 你会通过topologyKey来表达拓扑域(X)的概念 其取值是系统用来标示域的节点标签键 相关示例可参见常用标签、注解和污点 说明： Pod间亲和性和反亲和性都需要相当的计算量 因此会在大规模集群中显著降低调度速度 我们不建议在包含数百个节点的集群中使用这类设置\n说明： Pod反亲和性需要节点上存在一致性的标签 换言之 集群中每个节点都必须拥有与topologyKey匹配的标签 如果某些或者所有节点上不存在所指定的topologyKey标签 调度行为可能与预期的不同\n总结 调度策略 匹配标签 操作符 拓扑域支持 调度目标 nodeAffinity 主机 In/NotIn/Exists/DoesNotExist/Gt/Lt 否 指定主机 podAffinity POD In/NotIn/Exists/DoesNotExist 是 POD与指定POD同一拓扑域 podAnitAffinity POD In/NotIn/Exists/DoesNotExist 是 POD与指定POD不在同一拓扑域 容忍与污点 节点亲和性是Pod的一种属性 它使Pod被吸引到一类特定的节点(这可能出于一种偏好 也可能是硬性要求) **污点(Taint)**则相反——它使节点能够排斥一类特定的Pod 容忍度Toleration 是应用于Pod上的 容忍度允许调度器调度带有对应污点的Pod 容忍度允许调度但并不保证调度：作为其功能的一部分 调度器也会评估其他参数 污点和容忍度(Toleration)相互配合 可以用来避免Pod被分配到不合适的节点上 每个节点上都可以应用一个或多个污点 这表示对于那些不能容忍这些污点的Pod 是不会被该节点接受的 组成 key=value:effect\n每个污点有一个key和value作为污点的标签 其中value可以为空 effect描述污点的作用 当前的taint effect支持如下三个选项 NoSchedule: 表示k8s将不会将Pod调度到具有该污点的Node上 PreferNoSchedule: 表示k8s将尽量避免将Pod调度到具有该污点的Node上 NoExecute: 表示k8s将不会将Pod调度到具有该污点的Node上 同时会将Node上已经存在的Pod驱逐出去 设置和去除 1 2 3 4 5 6 7 8 # 给节点增加一个污点 kubectl taint nodes node1 key1=value1:NoSchedule # 节点说明中 查找Taints字段 kubectl describe pod pod-name # 移除上述污点 kubectl taint nodes node1 key1=value1:NoSchedule- 容忍 设置里污点的Node 将根据taint的effect: NoSchedule PreferNoSchedule NoExecute和Pod之间产生互斥的关系 Pod将在一定程度上不会被调度到Node上 但我们可以在Pod上设置容忍(Toleration) 意思是设置里容忍的Pod将可以容忍污点的存在 可以被调度到存在污点的Node上 容忍设置方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 tolerations: - key: \u0026#34;key1\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;value1\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; --- tolerations: - key: \u0026#34;key1\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;value1\u0026#34; effect: \u0026#34;NoExecute\u0026#34; tolerationSeconds: 3600 # tolerationSeconds: 这表示如果这个Pod正在运行 同时一个匹配的污点被添加到其所在的节点 # 那么Pod还将继续在节点上运行3600秒 然后被驱逐 # 如果在此之前上述污点被删除了 则Pod不会被驱逐 容忍的特殊类型 operator的默认是Equal 一个容忍度和一个污点相匹配是指它们有一样的键名和效果 并且 如果operator是Exists 此时容忍度不能指定value 或者 如果operator是Equal 则它们的值应该相等 特殊类型\n当不指定value时 表示容忍所有的污点value 1 2 3 - key: \u0026#34;key2\u0026#34; operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; 当不指定key值时 表示容忍所有的污点key 1 2 tolerations: - operator: \u0026#34;Exists\u0026#34; 当不指定effect值时 表示容忍所有的污点作用 1 2 3 tolerations: - key: \u0026#34;key\u0026#34; operator: \u0026#34;Exists\u0026#34; 有多个master存在时 防止资源浪费 可以如下设置 1 kubectl taint nodes Node-Name node-role.kubernetes.io/master=:PreferNoSchedule 基于污点的驱逐 当某种条件为真时 节点控制器会自动给节点添加一个污点 当前内置的污点包括： node.kubernetes.io/not-ready：节点未准备好 这相当于节点状况Ready的值为\u0026quot;False\u0026quot; node.kubernetes.io/unreachable：节点控制器访问不到节点 这相当于节点状况Ready的值为 \u0026ldquo;Unknown\u0026rdquo; node.kubernetes.io/memory-pressure：节点存在内存压力 node.kubernetes.io/disk-pressure：节点存在磁盘压力 node.kubernetes.io/pid-pressure：节点的PID压力 node.kubernetes.io/network-unavailable：节点网络不可用 node.kubernetes.io/unschedulable：节点不可调度 node.cloudprovider.kubernetes.io/uninitialized：如果kubelet启动时指定了一个\u0026quot;外部\u0026quot;云平台驱动 它将给当前节点添加一个污点将其标志为不可用 在cloud-controller-manager的一个控制器初始化这个节点后 kubelet将删除这个污点 在节点被排空时 节点控制器或者kubelet会添加带有NoExecute效果的相关污点 此效果被默认添加到node.kubernetes.io/not-ready和node.kubernetes.io/unreachable污点中 如果异常状态恢复正常 kubelet或节点控制器能够移除相关的污点 在某些情况下 当节点不可达时 API服务器无法与节点上的kubelet进行通信 在与API服务器的通信被重新建立之前 删除Pod的决定无法传递到kubelet 同时 被调度进行删除的那些Pod可能会继续运行在分区后的节点上 固定节点调度 指定节点调度 pod.spec.nodeName将Pod直接调度到指定的Node节点上 会跳过Scheduler的调度策略 该匹配规则时强制匹配 如果nodeName字段不为空 调度器会忽略该Pod 而指定节点上的kubelet会尝试将Pod放到该节点上 使用nodeName规则的优先级会高于使用nodeSelector或亲和性与非亲和性的规则 局限性 如果所指代的节点不存在 则Pod无法运行 而且在某些情况下可能会被自动删除 如果所指代的节点无法提供用来运行Pod所需的资源 Pod会失败 而其失败原因中会给出是否因为内存或CPU不足而造成无法运行 在云环境中的节点名称并不总是可预测的 也不总是稳定的 1 2 3 4 5 6 7 8 9 apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx nodeName: kube-01 # 该Pod只能运行在节点kube-01上 指定节点标签调度 将Pod分配给节点\n标签和选择运算符\npo.spec.nodeSelector通过kubernetes的label-selector机制选择节点 由调度器策略匹配label 而后调度Pod到目标节点 该匹配规则属于强制约束 1 2 3 4 5 6 7 8 # 列出集群节点及标签 kubectl get nodes --show-labels # 给节点添加标签 kubectl label nodes \u0026lt;node-name\u0026gt; disktype=ssd # 查找对应标签node kubectl get nodes -l disktype=ssd 1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: # 该Pod会调度到具有下面标签的节点上 disktype: ssd 认证及ServiceAccount 认证授权 认证(支持多种认证方式) # 认证插件 令牌认证 bearer token ssl认证(确认服务端/客户端身份) 双向证书认证(https) \u0026hellip; 授权检查(权限) # 授权插件 RBAC # kubeadm部署的集群强制开启RBAC \u0026hellip; 准入控制(关联的其他资源或操作 是否有权限 进一步补充授权机制) API Server需要信息去识别客户端的操作 user: username + uid group extra API(请求的Kubernetes API) Request Path kubectl proxy --port=8080 curl http://localhost:8080/api/v1/namespaces curl http://localhost:8080/apis/apps/v1/namespaces/default/deployments/myapp-deploy/ HTTP request verb GET POST PUT DELETE get list create update patch watch proxy redirect delete deletecollection Resources SubResources Namespace API Group ServiceAccount 访问APIServer的两种客户端 kubectl/dashborad 集群外部客户端(userAccount) pod 集群内部客户端(serviceAccount) kubectl explain pods.spec.serviceAccountName kubeconfig kubectl config view RBAC授权 授权插件 Node ABAC(Attribute-based access control) RBAC(Role-based access contro) Webhook K8S-RBAC role operations objects rolebinding user account OR service account role kubectl create role pods-reader --verb=get,list,watch --resource=pods --dry-run -o yaml 配置管理 Kustomize kustomize\nHelm helm\n模版debug 1 2 {{- $commonValues := mustDeepCopy .Values.common -}} {{ fail (printf \u0026#34;commonValues:%v\\n\u0026#34; (toYaml .Values | nindent 2 )) }} // 格式化打印对应值 方便debug 集群监控 书籍推荐 了解Google运维的秘密 SRE: Google运维解密 资源监控方案 Prometheus 无可挑剔的选择 需前置Prometheus相关知识 Kubernetes集群的监控方案主要有以下几种方案 Heapster: 已废弃 使用metrics-server代替 cAdvisor: cAdvisor是Google开源的容器资源监控和性能分析工具 它是专门为容器而生的 本身也支持Docker 在Kubernetes中 我们不需要单独去安装 cAdvisor作为kubectl内置的一部分程序 可以直接使用 kube-state-metrics: kube-state-metrics通过监听API Server生成有关资源对象的状态指标 比如: Deployment、Node、Pod 需要注意的是 kube-state-metrics只是简单提供一个metrics数据 并不会存储这些指标数据 我们可以使用Prometheus来抓取这些数据然后存储 metrics-server: metrics-server也是一个集群范围内的资源数据聚合工具 是Headster的替代 同样的 metrics-server也只是显示数据 并不提供数据存储服务 kube-state-metrics 和 metrics-server的区别： kube-state-metrics主要关注的是业务相关的一些元数据 比如 Deployment、Pod、副本状态等 metrics-server主要关注的是资源度量API的实现 比如 CPU、内存、文件描述符、请求延时等指标 手动安装Prometheus 资源清单文件 kubectl apply -f prometheus.yaml 因为是以NodePort暴露的服务 直接访问 http://任意节点IP:\u0026lt;NodePort\u0026gt; 就能看到熟悉的Prometheus UI 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 # kubectl create ns kube-ops # 暂时只配置对proemtheus的监控 apiVersion: v1 kind: ConfigMap metadata: name: prometheus-config namespace: kube-ops data: prometheus.yaml: | global: scrape_interval: 15s evaluation_interval: 15s scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] --- # PVC for prometheus 使用NFS演示 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: prometheus namespace: kube-ops spec: storageClassName: nfs-client accessModes: - ReadWriteMany resources: requests: storage: 10Gi --- # 创建ServiceAccount apiVersion: v1 kind: ServiceAccount metadata: name: prometheus namespace: kube-ops --- # 创建CllusterRole apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: prometheus rules: - apiGroups: - \u0026#34;\u0026#34; resources: - nodes - services - endpoints - pods - nodes/proxy verbs: - get - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - configmaps - nodes/metrics verbs: - get - nonResourceURLs: - /metrics verbs: - get --- # 创建ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: prometheus roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheus subjects: - kind: ServiceAccount name: prometheus namespace: kube-ops --- # 创建Deployment apiVersion: apps/v1 kind: Deployment metadata: name: prometheus namespace: kube-ops labels: app: prometheus spec: selector: matchLabels: app: prometheus template: metadata: labels: app: prometheus spec: serviceAccountName: prometheus containers: - name: prometheus image: prom/prometheus:v2.46.0 command: - /bin/prometheus args: - --config.file=/etc/prometheus/prometheus.yaml - --storage.tsdb.path=/prometheus - --storage.tsdb.retention.time=24h - --web.enable-admin-api - --web.enable-lifecycle ports: - containerPort: 9090 protocol: TCP name: http volumeMounts: - name: prometheus-config mountPath: /etc/prometheus - name: prometheus-storage mountPath: /prometheus # 只挂载卷中的一个子目录或子路径到容器中 而不是挂载整个卷 # 1. 避免数据污染 # 2. 多容器共享同一个PVC # 3. 数据隔离 subPath: prometheus resources: requests: cpu: 100m memory: 512Mi limits: cpu: 100m memory: 512Mi securityContext: runAsUser: 0 volumes: - name: prometheus-config configMap: name: prometheus-config - name: prometheus-storage persistentVolumeClaim: claimName: prometheus --- # 创建Service apiVersion: v1 kind: Service metadata: name: prometheus namespace: kube-ops labels: app: prometheus spec: selector: app: prometheus type: NodePort ports: - name: http port: 9090 targetPort: 9090 nodePort: 30000 监控集群应用 内置指标接口 直接配置静态配置service地址的内置指标接口 未内置指标接口 直接配置对应exporter的service地址的指标接口 监控集群节点 监控节点已有非常多的成熟方案 比如：Nagios Zabbix 甚至自己收集数据也可以 Kubernetes中 我们通过node_exporter来获取节点指标 node_exporter用于采集服务器节点的各种运行指标 包括：conntrack cpu diskstats filesystem loadavg memeinfo netstat等 详细内容参考官方repo文档 部署node-exporter 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 # 部署node-exporter的资源清单文件 # 注意事项：由于我们要获取到的数据是主机的监控指标数据 而node-exporter是运行在容器中的 所有在Pod中需要配置一些Pod的安全策略 # hostPID: true 允许容器访问主机的PID命名空间 # hostIPC: true 允许容器访问主机的IPC命名空间 # hostNetwork: true 允许容器使用主机的网络命名空间 # 另外 我们还将主机的/dev、/proc、/sys目录挂载到容器中 因为我们采集的很多节点数据都是通过这些目录下面的文件来获取的 # /proc/stat /proc/meminfo /proc/cpuinfo /proc/diskstats /proc/net/dev ... apiVersion: apps/v1 kind: DaemonSet metadata: name: node-exporter namespace: kube-ops labels: app: node-exporter spec: selector: matchLabels: app: node-exporter template: metadata: labels: app: node-exporter spec: hostPID: true hostIPC: true hostNetwork: true containers: - name: node-exporter image: prom/node-exporter:v1.9.1 ports: - containerPort: 9100 resources: requests: cpu: 200m securityContext: privileged: true args: - --path.procfs - /host/proc - --path.sysfs - /host/sys - --collector.filesystem.ignored-mount-points - \u0026#34;^/(sys|proc|dev|host|etc)($|/)\u0026#34; volumeMounts: - name: dev mountPath: /host/dev - name: proc mountPath: /host/proc - name: sys mountPath: /host/sys - name: rootfs mountPath: /rootfs tolerations: - key: node-role.kubernetes.io/control-plane operator: Exists effect: NoSchedule volumes: - name: dev hostPath: path: /dev - name: proc hostPath: path: /proc - name: sys hostPath: path: /sys - name: rootfs hostPath: path: / 配置基于Kubernetes的自动发现 kubernetes_sd_config\n在Kubernetes中 Prometheus通过与Kubernetes API集成 目前主要支持5种服务发现模式 node service pod endpoints / endpointslice ingress 通过制定kubernetes_sd_config的模式为node Prometheus就会自动从Kubernetes中发现所有的node节点并作为当前job监控的目标实例 发现的节点/metrics接口时默认的kubelet的HTTP接口 Promethehs去发现Node模式的服务的时候 访问的默认端口是10250(kubelet服务端口) 而现在该端口下面已经没有/metrics指标数据 因为上面配置指定了hostNetwork: true 所以每个节点都会监听9100端口 我们应该将这里的10250替换为9100 如何实现：使用Prometheus提供的relabel_configs中的replace能力 relabel可以在Prometheus采集数据之前 通过Target实例的metadata信息 动态重新写入Label的值 除此之外 还能根据Target实例的metadata信息 选择是否采集或忽略该Target实例/指标 添加一个action为labelmap 正则表达式__metadata_kubernetes_node_label_(.+)的配置 这里的意思是表达式中匹配的数据也添加到指标数据的Label标签中去 对于kubernetes_sd_config下面可用的标签如下： __metadata_kubernetes_node_name: 节点对象的名称 __metadata_kubernetes_node_label: 节点对象中的每个标签 __metadata_kubernetes_node_annitation: 来自节点对象的每个注解 __metadata_kubernetes_node_address: 每个节点地址类型的第一个地址(如果存在) 更多类型参考Prometheus官方文档 修改后的configmap如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 apiVersion: v1 kind: ConfigMap metadata: name: prometheus-config namespace: kube-ops data: prometheus.yaml: | global: scrape_interval: 15s evaluation_interval: 15s scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] - job_name: \u0026#39;kubernetes-nodes\u0026#39; kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__address__] regex: \u0026#39;(.+):10250\u0026#39; replacement: \u0026#39;${1}:9100\u0026#39; target_label: __address__ action: replace - action: labelmap regex: __meta_kubernetes_node_label_(.+) # 1.11+版本后 metrics端口为10250 需要使用https协议获取指标 - job_name: \u0026#39;kubernetes-kubelet\u0026#39; kubernetes_sd_configs: - role: node scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) 监控集群常用资源对象 容器监控 说到容器监控我们自然会想到cAdisor 我们前面说过cAdvisor已经内置在了kubelet组件中 所以我们不需要单独安装 cAdvisor的数据路径为/api/v1/nodes/\u0026lt;node\u0026gt;/proxy/metrics 同样 我们使用node的服务发现模式 因为每一个节点下面都有kubelet 自然都有cAdvisor采集到的数据指标 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # prometheus configmap配置参考 - job_name: \u0026#39;kubernetes-cadvisor\u0026#39; kubernetes_sd_configs: - role: node scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor apiserver监控 apiserver作为Kubernetes的最核心组件 对它的监控是非常必要的 对于apiserver的监控我们可以直接通过kubernetes的Service来获取 kubectl get svc kubernetes -n default 1 2 3 4 5 6 7 8 9 10 11 12 13 14 - job_name: \u0026#39;kubernetes-apiservers\u0026#39; kubernetes_sd_configs: - role: endpoints scheme: https # https协议 tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - source_labels: - __meta_kubernetes_namespace - __meta_kubernetes_service_name - __meta_kubernetes_endpoint_port_name action: keep # 使用endpoints的自动发现 会发现所有的endpoitns端点 我们只需要匹配kubernetes-apiserver 其余全部DROP regex: default;kubernetes;https Kubernetes系统组件指标 应用上面配置 就完成了对Kubernetes APIServer的监控 如果需要监控其他系统组件 比如：kube-controller-manager、kube-scheduler的话 需要注意 apiserver的service在default的namespace下 而其余组件服务在kube-system这个namespace下 如果我们想要监控这些组件 需要手动创建单独的Service 其中 kube-schedule的指标数据端口为10251 kube-controller-manager对应的指标数据端口为10252 Service监控 上面的apiservice实际上是一种特殊的Service 我们可以配置一个任务来专门发现普通类型的Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 - job_name: \u0026#39;kubernetes-service-endpoints\u0026#39; kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: - __meta_kubernetes_service_annotation_prometheus_io_scrape action: keep regex: true - source_labels: - __meta_kubernetes_service_annotation_prometheus_io_scheme action: replace target_label: __scheme__ regex: (https?) - source_labels: - __meta_kubernetes_service_annotation_prometheus_io_path action: replace target_label: __metrics_path__ regex: (.+) - source_labels: - __address__ - __meta_kubernetes_service_annotation_prometheus_io_port action: replace target_label: __address__ regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: - __meta_kubernetes_namespace action: replace target_label: kubernetes_namespace - source_labels: - __meta_kubernetes_service_name action: replace target_label: kubernetes_name 需要被监控的服务 如果本身实现了/metrics接口 则可以按照下面配置修改下Service配置即可进行自动发现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 apiVersion: v1 kind: Service metadata: name: demoapp namespace: default annotations: # 加上下面的annotations 则可以进行该服务的自动发现 prometheus.io/scrape: \u0026#34;true\u0026#34; prometheus.io/port: \u0026#34;80\u0026#34; spec: selector: app: demoapp ports: - protocol: TCP port: 80 targetPort: 80 kube-state-metrics 上面我们配置了自动发现Service(Pod也一样)的监控 但是这些监控数据都是应用内部的监控 需要应用本身内置/metrics接口 或者对应的exporter来暴露对应的指标数据\n但是 在Kubernetes集群上的Pod、DaemonSet、Deployment、Job、Crontab等各种资源对象的状态也需要监控 这也反应了使用这些资源部署的应用状态\n前面从集群拉取的指标(来自apiserver和kubelet中集成的cAdvisor) 并没有具体的各种资源对象的状态指标\n对于Prometheus来说 当然是需要引入新的exporter来暴露这些指标 Kubernetes提供了kube-state-metrics则可以实现该监控需求\n安装kube-state-metrics\n1 2 git clone git@github.com:kubernetes/kube-state-metrics.git kubectl apply -k examples/standard 修改service配置 自动监控指标 监控指标的相关文档 参考metics-documentation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/component: exporter app.kubernetes.io/name: kube-state-metrics app.kubernetes.io/version: 2.15.0 name: kube-state-metrics namespace: kube-system # 修改service 加上该配置 annotations: prometheus.io/scrape: \u0026#34;true\u0026#34; prometheus.io/port: \u0026#34;8080\u0026#34; spec: clusterIP: None ports: - name: http-metrics port: 8080 targetPort: http-metrics - name: telemetry port: 8081 targetPort: telemetry selector: app.kubernetes.io/name: kube-state-metrics Grafana的安装使用 Prometheus官方Dashboard展示能力较弱 展示推荐接Grafana 安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 apiVersion: apps/v1 kind: Deployment metadata: name: grafana namespace: kube-ops labels: app: grafana spec: revisionHistoryLimit: 10 selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: containers: - name: grafana image: grafana/grafana:12.0.1 imagePullPolicy: IfNotPresent ports: - containerPort: 3000 name: grafana env: - name: GF_SECURITY_ADMIN_USER value: admin - name: GF_SECURITY_ADMIN_PASSWORD value: admin9527 readinessProbe: failureThreshold: 3 httpGet: path: /api/health port: 3000 scheme: HTTP initialDelaySeconds: 60 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 30 livenessProbe: failureThreshold: 10 httpGet: path: /api/health port: 3000 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: limits: cpu: 100m memory: 256Mi requests: cpu: 100m memory: 256Mi volumeMounts: - mountPath: /var/lib/grafana subPath: grafana name: storage securityContext: fsGroup: 472 runAsUser: 472 volumes: - name: storage persistentVolumeClaim: claimName: grafana --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: grafana namespace: kube-ops spec: storageClassName: nfs-client accessModes: - ReadWriteOnce resources: requests: storage: 1Gi --- apiVersion: v1 kind: Service metadata: name: grafana namespace: kube-ops labels: app: grafana spec: type: NodePort ports: - name: http port: 3000 targetPort: 3000 nodePort: 30001 selector: app: grafana 如果由于卷权限问题 执行下面Job修改权限即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion: batch/v1 kind: Job metadata: name: grafana-chown namespace: kube-ops spec: template: spec: restartPolicy: Never containers: - name: grafana-chown command: [\u0026#34;chown\u0026#34;, \u0026#34;-R\u0026#34;, \u0026#34;472:472\u0026#34;, \u0026#34;/var/lib/grafana\u0026#34;] image: busybox imagePullPolicy: IfNotPresent volumeMounts: - name: storage subPath: grafana mountPath: /var/lib/grafana volumes: - name: storage persistentVolumeClaim: claimName: grafana 后续就是进行Grafana的数据源及模版配置等工作 Alertmanger 准备告警媒介 这里以dingding-webhoo为例 1 2 3 git clone git@github.com:timonwong/prometheus-webhook-dingtalk.git cd contrib/k8s kubectl apply -k . # 执行前修改为自己的测试配置 准备alertmanager配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 apiVersion: v1 kind: ConfigMap metadata: name: alertmanager-config namespace: kube-ops data: config.yaml: |- route: receiver: \u0026#39;default\u0026#39; group_wait: 30s group_interval: 5m repeat_interval: 30m group_by: - \u0026#39;cluster\u0026#39; - \u0026#39;alertname\u0026#39; routes: - receiver: \u0026#39;test\u0026#39; group_wait: 30s group_interval: 10m repeat_interval: 30m matchers: - severity=\u0026#34;P0\u0026#34; receivers: - name: \u0026#39;default\u0026#39; webhook_configs: - url: \u0026#39;http://alertmanager-webhook-dingtalk/dingtalk/webhook_mention_test/send\u0026#39; send_resolved: false - name: \u0026#39;test\u0026#39; webhook_configs: - url: \u0026#39;http://alertmanager-webhook-dingtalk/dingtalk/webhook_mention_test/send\u0026#39; send_resolved: false inhibit_rules: - source_matchers: - severity = \u0026#39;P0\u0026#39; target_matchers: - severity =~ \u0026#39;P1|P2|P3|P4|P5\u0026#39; equal: - \u0026#39;alertname\u0026#39; - \u0026#39;instance\u0026#39; - source_matchers: - alertname = InstanceDown target_matchers: - job = node_exporter equal: - \u0026#39;instance\u0026#39; 配置alertmanager容器并启动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 为了方便 我这里直接把alertmanager和prometheus部署在一起 - name: alertmanager image: prom/alertmanager:v0.28.1 imagePullPolicy: IfNotPresent args: - --config.file=/etc/alertmanager/config.yaml ports: - containerPort: 9093 protocol: TCP name: http volumeMounts: - name: alertmanager-config mountPath: /etc/alertmanager resources: requests: cpu: 100m memory: 512Mi limits: cpu: 100m memory: 512Mi volumes: - name: alertmanager-config configMap: name: alertmanager-config 在prometheus中配置alertmanager地址 1 2 3 4 5 6 # 更新promtehus配置的configmap alerting: alertmanagers: - static_configs: - targets: - localhost:9093 # 同一个Pod 直接使用localhost 告警测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 rule_files: - /etc/prometheus/rules.yaml # configmap 新增一个配置项 rules.yaml: | groups: - name: test-rules rules: - alert: NodeMemoryUsage expr: (node_memory_MemTotal_bytes - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)) / node_memory_MemTotal_bytes * 100 \u0026gt; 20 for: 2m labels: severity: P0 annotations: summary: \u0026#34;{{ $labels.instance }}: High Memory usage detected\u0026#34; description: \u0026#34;{{$labels.instance}}: Memory usage is above 20% (current value is: {{ $value }}\u0026#34; Prometheus Operator 经过上面手动编写Prometheus资源清单 我们完成了对Kubernetes相关资源的监控 但是还是有一些缺陷 比如：Promtheus、Alertmanager等组件服务本身的高可用；当然我们可以自己实现这些需求 我们也知道Prometheus在代码上就原生支持Kubernetes 我们可以通过服务发现的形式来自动监控集群 因此 我们可以使用另外一种更加高级的方式来部署Prometheus: prometheus-operator Operator模式 Operator参考：Operator模式\n介绍 上图是Prometheus-Operator官方提供的架构图 其中Operator是最核心的部分 作为一个控制器 它回去创建Prometheus、ServiceMonitor、Alertmanager以及PrometheusRule4个CRD资源对象 然后会一直监控并维持这4个资源对象的状态 prometheus资源对象就是作为Prometheus Server存在 ServiceMonitor就是exporter的各种抽象 Prometheus就是通过ServiceMonitor提供的metrics数据接口去pull数据 alertmanager资源对应Alertmanager的抽象 PrometheusRule是用来被Prometheus实例使用的报警规则文件 这样 我们要在集群中监控什么数据 就变成了直接去操作Kubernetes集群资源的对象 上图中的Service和ServiceMonitor都是Kubernetes的资源 一个ServiceMonitror可以通过labelSelector的方式去匹配一类Service Prometheus也可以通过labelSelector的发方式去匹配多个ServiceMonitor 通过prometheus-operator安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 git clone git@github.com:prometheus-operator/prometheus-operator.git kubectl create namespace monitoring # 在指定namespace安装 $ NAMESPACE=monitoring kustomize edit set namespace $NAMESPACE \u0026amp;\u0026amp; kubectl create -k . customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/prometheusagents.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/scrapeconfigs.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com created customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com created serviceaccount/prometheus-operator created clusterrole.rbac.authorization.k8s.io/prometheus-operator created clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created service/prometheus-operator created deployment.apps/prometheus-operator created PrometheusOperator通过Deployment的形式进行部署 为了能够让PrometheusOperator能够监听和管理Kubernetes资源 同时也创建了单独的ServiceAccount以及相关授权 使用Operator管理Prometheus 部署Prometheus实例 当集群中已经安装ProemtheusOperator之后 对于部署PromtheusServer实例变成了声明一个Prometheus资源 如下所示 我们在monitoring名称空间下创建了一个Prometheus实例 访问: kubectl port-forward statefulsets.apps/prometheus-inst 9090:9090 1 2 3 4 5 6 7 8 9 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: inst namespace: monitoring spec: resources: requests: memory: 400Mi 部署ServiceMonitor实例 让部署的Prometheus能够采集部署在Kubernetes下应用的监控数据 在原生的Prometheus配置方式中 我们在Prometheus配置文件中定义单独的Job 同时使用kubernetes_sd定义服务的自动发现 在PrometheusOperator中 则可以直接声明一个ServiceMonitor对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: demoapp namespace: monitoring labels: env: testing spec: namespaceSelector: matchNames: - default selector: matchLables: app: demoapp endpoints: - port: web # 如果target启用了监控BasicAuth认证 定义ServiceMonitor对象时 需要在endpoints配置中定义basicAuth basicAuth: password: name: basic-auth key: password username: name: basic-auth key: user # 其中 basicAuth 中关联名为 basic-auth为Secret对象 需要用户手动将认证信息保存到Secret中 APIVersion: v1 kind: Secret metadata: name: basic-auth data: # base64编码后的值 password: alsdhabdn== user: Jadquhwe== type: Opaque 关联Prometheus与ServiceMonitor Promtheus与ServiceMonitor之间的关联关系使用servicMonitorSelector定义 在Prometheus中通过标签选择当前需要监控的ServiceMonitor对象 为了能够让Prometheus关联到ServiceMonitor 需要在Promehteus定义中使用serviceMonitorSelector 我们可以通过标签选择当前Prometheus需要监控的ServiceMonitor对象 1 2 3 4 5 6 7 8 9 10 11 12 13 # 更新promteheus crd资源清单 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: inst namespace: monitoring spec: serviceMonitorSelector: matchLabels: env: testing resources: requests: memory: 400Mi 更新上面配置配置后 web界面可以看到Job配置 但是Prometheus的Target中并没有包含任何的监控对象 此时Promtheus Pod有报错日志 1 time=2025-06-09T16:29:10.559Z level=ERROR source=reflector.go:166 msg=\u0026#34;Unhandled Error\u0026#34; component=k8s_client_runtime logger=UnhandledError err=\u0026#34;pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User \\\u0026#34;system:serviceaccount:monitoring:default\\\u0026#34; cannot list resource \\\u0026#34;services\\\u0026#34; in API group \\\u0026#34;\\\u0026#34; in the namespace \\\u0026#34;default\\\u0026#34;\u0026#34; 这是因为我们默认创建的实例使用的是monitoring命名空间下的default账号 该账号并没有权限能够获取default命名空间下的任何资源信息 修复该问题 我们需要在monitoring的命名空间常见一个新的ServiceAccount账号 并且为该账号赋予相应的集群访问权限 1 2 3 4 5 $ kubectl get pods prometheus-inst-0 -o yaml # 默认使用的serviceAccount serviceAccount: default serviceAccountName: default 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # 创建新的具有相关权限的ServiceAccount apiVersion: v1 kind: ServiceAccount metadata: name: prometheus namespace: monitoring --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: prometheus rules: - apiGroups: [\u0026#34;\u0026#34;] resources: - nodes - services - endpoints - pods verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] - apiGroups: [\u0026#34;\u0026#34;] resources: - configmaps verbs: [\u0026#34;get\u0026#34;] - nonResourceURLs: [\u0026#34;/metrics\u0026#34;] verbs: [\u0026#34;get\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: prometheus roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheus subjects: - kind: ServiceAccount name: prometheus namespace: monitoring # 应用上面资源清单之后 修改prometheus实例的资源清单 使用新的ServiceAccount apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: inst namespace: monitoring spec: serviceAccountName: prometheus # 更新serviceAccount serviceMonitorSelector: matchLabels: env: testing resources: requests: memory: 400Mi 使用Operator管理监控配置 使用PrometheusRule定义告警规则 对于Prometheus而言 在原生的管理方式上 我们需要手动创建Prometheus的告警文件 并且通过在Prometheus配置中声明式加载 而在PrometheusOperator的模式中 告警规则通过定义声明式配置创建一个PrometheusRule资源 1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: monitoring.coreos.com/v1 kind: PrometheusRule metadata: labels: prometheus: demoapp role: alert-rules name: prometheus-demoapp-rules spec: groups: - name: ./demoapp.rules rules: - alert: DemoappAlert expr: demoapp_http_requests_total{handler=\u0026#34;/metrics\u0026#34;} \u0026gt; 1 创建PrometheusRule资源后 通过在Promtheus中使用ruleSelector通过标签选择需要关联的PrometheusRule即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: inst namespace: monitoring spec: serviceAccountName: prometheus serviceMonitorSelector: matchLabels: env: testing ruleSelector: matchLabels: role: alert-rules prometheus: demoapp resources: requests: memory: 400Mi 使用Operator管理Alertmanger实例 到目前为止 我们已经通过PrometheusOperator的自定义资源类型管理了Prometheus实例 监控配置以及告警规则等资源 通过PrometheusOperator将原本手动管理的工作 全部变成了声明式的管理模式 极大简化了Kubernetes下Prometheus运维管理的复杂度 我们继续使用Operator定义和管理Alertmanager相关的内容 创建Alertmanger资源清单 通过replicas可以控制Alertmanager的实例数 当replicas大于1时 PrometheusOperator会自动通过集群的方式创建Alertmaager 1 2 3 4 5 6 7 apiVersion: monitoring.coreos.com/v1 kind: Alertmanager metadata: name: inst namespace: monitoring spec: replicas: 3 修改Prometheus资源定义 配置alerting指定使用的Alertmanager资源即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: inst namespace: monitoring spec: serviceAccountName: prometheus serviceMonitorSelector: matchLabels: env: testing ruleSelector: matchLabels: role: alert-rules prometheus: demoapp alerting: alertmanagers: - name: alertmanager-example namespace: monitoring port: web resources: requests: memory: 400Mi 等待Prometheus重新加载后 我们可以看到PrometheusOperator在配置文件中添加了如下配置 通过服务发现规则 将Prometheus与Alertmanager自动关联 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 alerting: alert_relabel_configs: - separator: ; regex: prometheus_replica replacement: $1 action: labeldrop alertmanagers: - follow_redirects: true enable_http2: true scheme: http path_prefix: / timeout: 10s api_version: v2 relabel_configs: - source_labels: [__meta_kubernetes_service_name] separator: ; regex: alertmanager-example replacement: $1 action: keep - source_labels: [__meta_kubernetes_endpoint_port_name] separator: ; regex: web replacement: $1 action: keep kubernetes_sd_configs: - role: endpoints kubeconfig_file: \u0026#34;\u0026#34; follow_redirects: true enable_http2: true namespaces: own_namespace: false names: - monitoring 在PrometheusOperator中使用自定义配置 在PrometheusOperator中 我们通过声明式创建Prometheus、ServiceMonitor等自定义的资源类型来自动化部署和管理Promtehues的相关组件及配置 而在一些特殊的情况下 可能还是希望能够手动管理Prometheus配置文件 而非通过PrometheusOperator自动完成 为什么? 实际上PrometheusOperator对于Job的配置只适用于在Kubernetes中部署和管理的应用程序 如果你希望使用Prometheus监控一些其他的资源 例如 AWS或其他平台中的基础设施或应用 这些并不在PrometheusOperator的能力范围之内 为了能够在通过PrometheusOperator创建的Prometheus实例中使用自定义配置文件 我们只能创建一个不包含任何与配置文件内容相关的Prometheus实例 1 2 3 4 5 6 7 8 9 10 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: inst-cc namespace: monitoring spec: serviceAccountName: prometheus resources: requests: memory: 400Mi 如果查看新建的Prometheus的Pod实例的YAML定义 我们可以看到Pod中会包含一个volume配置 1 2 3 4 5 volumes: - name: config secret: defaultMode: 420 secretName: prometheus-inst-cc Prometheus的配置文件实例上是保存在名为prometheus-\u0026lt;name-of-prometheus-object\u0026gt;的Secret中 当用户创建的Prometheus中关联ServiceMonitor这类会影响配置文件内容的定义时 PromtheusOperator会自动管理 而如果Prometheus定义中不包含任何与配置有关的定义 那么Secret的管理权限就落到用户自己手中 1 2 3 4 5 6 # 使用该配置更新secret观察新建Prometheus实例的配置变化 # kubectl edit secret prometheus-inst-cc global: scrape_interval: 10s scrape_timeout: 10s evaluation_interval: 10s 通过kube-prometheus安装 Install using Kube-Prometheus\n安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 git clone git@github.com:prometheus-operator/kube-prometheus.git kubectl create -f manifests/setup -f manifest # 不止包含我们上面手动创建的相关资源 # 查看部署的Pod # kubectl get pods -n monitoring NAME READY STATUS RESTARTS AGE alertmanager-main-0 2/2 Running 0 2d23h alertmanager-main-1 2/2 Running 0 2d23h alertmanager-main-2 2/2 Running 0 2d23h blackbox-exporter-75c7985cb8-dq9vp 3/3 Running 0 2d23h grafana-664dd67585-wxrsp 1/1 Running 0 2d23h kube-state-metrics-75df9b9544-j9l7t 3/3 Running 0 2d23h node-exporter-9cflz 2/2 Running 0 2d23h node-exporter-d9zkn 2/2 Running 0 2d23h node-exporter-fh7sx 2/2 Running 0 2d23h node-exporter-zxswn 2/2 Running 0 2d23h prometheus-adapter-84c549f6b4-mwj8h 1/1 Running 0 2d23h prometheus-adapter-84c549f6b4-tg2sv 1/1 Running 0 2d23h prometheus-k8s-0 2/2 Running 0 2d23h prometheus-k8s-1 2/2 Running 0 2d23h prometheus-operator-6f9479b5f5-8r6sn 2/2 Running 0 2d23h 仔细观察我们发现kube-scheduler kube-controller-manager两个服务定义了ServiceMonior 但是没有管理到对应的监控目标 阅读ServiceMonitor的定义 我们发现原因是我们系统中根本就没有对应的Service 我们手动创建即可 服务端口参考: ports-and-protocols 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # serviceMonitor定义 # kube-controller-manager apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: labels: app.kubernetes.io/name: kube-controller-manager app.kubernetes.io/part-of: kube-prometheus name: kube-controller-manager namespace: monitoring spec: endpoints: - ... jobLabel: app.kubernetes.io/name namespaceSelector: matchNames: - kube-system selector: matchLabels: app.kubernetes.io/name: kube-controller-manager # kube-scheduler apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: labels: app.kubernetes.io/name: kube-scheduler app.kubernetes.io/part-of: kube-prometheus name: kube-scheduler namespace: monitoring spec: endpoints: - ... jobLabel: app.kubernetes.io/name namespaceSelector: matchNames: - kube-system selector: matchLabels: app.kubernetes.io/name: kube-scheduler 根据serviceMonitor定义 创建具有对应标签的Service资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 除了创建Service 还需要修改服务的默认监听地址 默认绑定127.0.0.1 # 修改: --address=127.0.0.1 -\u0026gt; --address=0.0.0.0 # kube-controller-manager apiVersion: v1 kind: Service metadata: namespace: kube-system name: kube-controller-manager labels: app.kubernetes.io/name: kube-controller-manager spec: selector: component: kube-controller-manager ports: - name: https-metrics port: 10257 targetPort: 10257 protocol: TCP # kube-scheduler apiVersion: v1 kind: Service metadata: namespace: kube-system name: kube-scheduler labels: app.kubernetes.io/name: kube-scheduler spec: selector: component: kube-scheduler ports: - name: https-metrics port: 10259 targetPort: 10259 protocol: TCP PrometheusOperator高级配置 经常上面操作之后 自带组件的相关监控都全部配置完成 但是 如果我们集群中有很多的Service/Pod 我们就需要一个个创建对应的ServiceMonitor对象么 为了解决这个问题 PrometheusOperator为我们提供了一个额外的抓取配置来解决这个问题 我们可以通过添加额外的配置来进行服务发现进行自动监控 和之前自定义的方式呢一样 我们想要在PrometheusOperator中去自动发现具有prometheus.io/scrape=true这个annotations的Service 之前我们定义的Prometheus配置如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 - job_name: \u0026#39;kubernetes-service-endpoints\u0026#39; kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme] action: replace target_label: __scheme__ regex: (https?) - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port] action: replace target_label: __address__ regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: namespace - source_labels: [__meta_kubernetes_service_name] action: replace target_label: service # 已由ServiceMonitor监控 - source_labels: [__meta_kubernetes_service_name] action: drop regex: kube-dns 要想自动发现集群中的Service 就需要我们在Service的annotation区域添加prometheus.io/scrape=true的声明 将上面的文件保存为prometheus-additional.yaml 然后通过这个文件创建一个对应的Secret对象 1 2 $ kubectl create secret generic additional-configs --from-file=manifests/prometheus-additional.yaml secret/additional-configs created 创建完成后 会将上面配置信息进行base64编码后作为prometheus-additional.yaml这个key对应的值存在 1 2 3 4 5 6 7 8 9 10 11 $ kubectl get secrets additional-configs -o yaml data: prometheus-additional.yaml: LSBqb2JfbmFtZTogJ2t1YmVybmV0ZXMtc2VydmljZS1lbmRwb2ludHMnCiAga3ViZXJuZXRlc19zZF9jb25maWdzOgogIC0gcm9sZTogZW5kcG9pbnRzCiAgcmVsYWJlbF9jb25maWdzOgogIC0gc291cmNlX2xhYmVsczogW19fbWV0YV9rdWJlcm5ldGVzX3NlcnZpY2VfYW5ub3RhdGlvbl9wcm9tZXRoZXVzX2lvX3NjcmFwZV0KICAgIGFjdGlvbjoga2VlcAogICAgcmVnZXg6IHRydWUKICAtIHNvdXJjZV9sYWJlbHM6IFtfX21ldGFfa3ViZXJuZXRlc19zZXJ2aWNlX2Fubm90YXRpb25fcHJvbWV0aGV1c19pb19zY2hlbWVdCiAgICBhY3Rpb246IHJlcGxhY2UKICAgIHRhcmdldF9sYWJlbDogX19zY2hlbWVfXwogICAgcmVnZXg6IChodHRwcz8pCiAgLSBzb3VyY2VfbGFiZWxzOiBbX19tZXRhX2t1YmVybmV0ZXNfc2VydmljZV9hbm5vdGF0aW9uX3Byb21ldGhldXNfaW9fcGF0aF0KICAgIGFjdGlvbjogcmVwbGFjZQogICAgdGFyZ2V0X2xhYmVsOiBfX21ldHJpY3NfcGF0aF9fCiAgICByZWdleDogKC4rKQogIC0gc291cmNlX2xhYmVsczogW19fYWRkcmVzc19fLCBfX21ldGFfa3ViZXJuZXRlc19zZXJ2aWNlX2Fubm90YXRpb25fcHJvbWV0aGV1c19pb19wb3J0XQogICAgYWN0aW9uOiByZXBsYWNlCiAgICB0YXJnZXRfbGFiZWw6IF9fYWRkcmVzc19fCiAgICByZWdleDogKFteOl0rKSg/OjpcZCspPzsoXGQrKQogICAgcmVwbGFjZW1lbnQ6ICQxOiQyCiAgLSBhY3Rpb246IGxhYmVsbWFwCiAgICByZWdleDogX19tZXRhX2t1YmVybmV0ZXNfc2VydmljZV9sYWJlbF8oLispCiAgLSBzb3VyY2VfbGFiZWxzOiBbX19tZXRhX2t1YmVybmV0ZXNfbmFtZXNwYWNlXQogICAgYWN0aW9uOiByZXBsYWNlCiAgICB0YXJnZXRfbGFiZWw6IGt1YmVybmV0ZXNfbmFtZXNwYWNlCiAgLSBzb3VyY2VfbGFiZWxzOiBbX19tZXRhX2t1YmVybmV0ZXNfc2VydmljZV9uYW1lXQogICAgYWN0aW9uOiByZXBsYWNlCiAgICB0YXJnZXRfbGFiZWw6IGt1YmVybmV0ZXNfbmFtZQo= kind: Secret metadata: creationTimestamp: \u0026#34;2025-06-18T07:50:33Z\u0026#34; name: additional-configs namespace: monitoring resourceVersion: \u0026#34;26440898\u0026#34; uid: 97ae179c-6516-4050-9b0a-c95596cf387e type: Opaque 然后我们只需要在声明prometheus的资源对象文件中添加这个额外的配置即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: labels: app.kubernetes.io/component: prometheus app.kubernetes.io/instance: k8s app.kubernetes.io/name: prometheus app.kubernetes.io/part-of: kube-prometheus app.kubernetes.io/version: 2.54.1 name: k8s namespace: monitoring spec: alerting: alertmanagers: - apiVersion: v2 name: alertmanager-main namespace: monitoring port: web enableFeatures: [] externalLabels: {} image: quay.io/prometheus/prometheus:v2.54.1 nodeSelector: kubernetes.io/os: linux podMetadata: labels: app.kubernetes.io/component: prometheus app.kubernetes.io/instance: k8s app.kubernetes.io/name: prometheus app.kubernetes.io/part-of: kube-prometheus app.kubernetes.io/version: 2.54.1 podMonitorNamespaceSelector: {} podMonitorSelector: {} probeNamespaceSelector: {} probeSelector: {} replicas: 2 resources: requests: memory: 400Mi ruleNamespaceSelector: {} ruleSelector: {} scrapeConfigNamespaceSelector: {} scrapeConfigSelector: {} securityContext: fsGroup: 2000 runAsNonRoot: true runAsUser: 1000 serviceAccountName: prometheus-k8s serviceMonitorNamespaceSelector: {} serviceMonitorSelector: {} version: 2.54.1 additionalScrapeConfigs: name: additional-configs key: prometheus-additional.yaml 在Prometheus UI的配置页面 已经看到有对应的配置信息 但是targets页面下却没有对应的监控任务 查看Prometheus的Pod日志 1 2 ts=2025-06-18T08:03:27.801Z caller=klog.go:116 level=error component=k8s_client_runtime func=ErrorDepth msg=\u0026#34;pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User \\\u0026#34;system:serviceaccount:monitoring:prometheus-k8s\\\u0026#34; cannot list resource \\\u0026#34;services\\\u0026#34; in API group \\\u0026#34;\\\u0026#34; at the cluster scope\u0026#34; ... 可以看到有很多错误日志出现 都是 xxx is forbidden 这说明是RBAC权限的问题 通过Prometheus资源对象的陪着你可以值得 Promtheus绑定了一个名为prometheus-k8s的ServiceAccount对象 而这个对象绑定的是一个名为promtheus-k8s的ClusterRole 查看ClusterRole的内容 我们可以看到明显没有对Service或者Pod的list权限 我们添加上对象的权限即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: creationTimestamp: \u0026#34;2025-06-13T12:48:39Z\u0026#34; labels: app.kubernetes.io/component: prometheus app.kubernetes.io/instance: k8s app.kubernetes.io/name: prometheus app.kubernetes.io/part-of: kube-prometheus app.kubernetes.io/version: 2.54.1 name: prometheus-k8s resourceVersion: \u0026#34;25082977\u0026#34; uid: 4cc3523b-1a2d-4682-bd6e-f23a11e661e7 rules: - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/metrics verbs: - get - nonResourceURLs: - /metrics - /metrics/slis verbs: - get 更新prometheus-k8s ClusterRole权限 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 - apiGroups: - \u0026#34;\u0026#34; resources: - nodes - services - endpoints - pods - nodes/proxy verbs: - get - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - configmaps - nodes/metrics verbs: - get - nonResourceURLs: - /metrics verbs: - get 数据持久化 目前的Promtheus 如裹我们重启Pod 则会丢失之前采集的数据 这是因为promeehteus这个CRD创建的Prometheus并没有做数据的持久化 直接查看生成的Prometheus Pod的挂载详情 我们发现Prometheus的数据目录/promtheus实际上是通过emptyDir进行挂载的 我们知道emptyDir挂载的数据的声明周期和Pod生命周期是一致的 如果Pod挂掉 数据也跟着丢失 线上的监控数据我们肯定需要做持久化 prometheus CRD资源也为我们提供了数据持久化的配置方法 由于我们的Prometheus最终是通过Statefulset控制器进行部署的 所以我们这里需要通过storageclass来做数据持久化 1 2 3 4 5 6 7 8 9 $ kubectl get pod prometheus-k8s-0 -o yaml ...... volumeMounts: - mountPath: /prometheus name: prometheus-k8s-db ...... volumes: - emptyDir: {} name: prometheus-k8s-db 这里使用我本地的nfs stroageclass 在prometheus CRD资源对象中添加如下配置 1 2 3 4 5 6 7 storage: volumeClaimTemplate: spec: storageClassName: nfs-client resources: requests: storage: 10Gi 更新服务之后 我们查看对应的pv/pvc/promtehus 可以看到已经进行了持久化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # POD volumes: - name: prometheus-k8s-db persistentVolumeClaim: claimName: prometheus-k8s-db-prometheus-k8s-1 volumeMounts: - mountPath: /prometheus name: prometheus-k8s-db subPath: prometheus-db # pv / pvc $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS VOLUMEATTRIBUTESCLASS REASON AGE pvc-c2cd37f7-9299-4c47-97a7-b841e4c28e9b 10Gi RWO Delete Bound monitoring/prometheus-k8s-db-prometheus-k8s-1 nfs-client \u0026lt;unset\u0026gt; 10m pvc-c6177fc6-74d5-4e1f-9213-86f90757b3d2 10Gi RWO Delete Bound monitoring/prometheus-k8s-db-prometheus-k8s-0 nfs-client \u0026lt;unset\u0026gt; 10m $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS VOLUMEATTRIBUTESCLASS AGE prometheus-k8s-db-prometheus-k8s-0 Bound pvc-c6177fc6-74d5-4e1f-9213-86f90757b3d2 10Gi RWO nfs-client \u0026lt;unset\u0026gt; 10m prometheus-k8s-db-prometheus-k8s-1 Bound pvc-c2cd37f7-9299-4c47-97a7-b841e4c28e9b 10Gi RWO nfs-client \u0026lt;unset\u0026gt; 10m 副本与分片 kube-prometheus 默认安装是高可用的2副本 如果需要修改为分片 需要修改prometheus crd定义 high-availability 1 2 3 4 5 6 # 启动的Pod数量为 replicas * shards replicas: 1 shards: 2 resources: requests: memory: 400Mi Reference ubuntu apt install speciffic version set-proxy-on-ubuntu-docker apt-get-like-yum-whatprovides\nkubetnetes kubectl-get-commponentstatus-shows-unhealthy\n","date":"2020-12-20T14:21:14+08:00","permalink":"https://ilolicon.github.io/p/kubernetes/","title":"Kubernetes"},{"content":"Prometheus监控系统 不稳定才是系统的恒态 稳定只是其中的一种特殊表现形式\n监控系统的基础概念 监控系统组件 指标数据的采集(抓取) 指标数据存储 存储持续写入性能 指标数据趋势分析及可视化 分析、预测 界面展示、直观查看 Zabbix自带 Open-Falcon/夜莺\u0026hellip; 通用的前台界面 如: Grafana 告警 基础、核心功能之一 表达式 -〉媒介(钉钉、微信、邮件\u0026hellip;) 监控体系(自底向上) 系统层监控(关键指标) 系统监控 CPU Load Memory Swap DiskIO Processes Kernel Parameters \u0026hellip; 网络监控 网络设备 工作负载 网络延迟 丢包率 \u0026hellip; 中间件及基础设施类系统监控 消息中间件: Kafka、RocketMQ、RabbitMQ等 Web服务容器: Tomcat、Jetty等 数据库及缓存系统: MySQL、PostgreSQL、MongoDB、ElasticSearch、Redis等 存储系统: Ceph等 应用层监控 用于衡量应用程序代码的状态和性能 业务层监控 用于衡量应用程序的价值(销售指标等) QPS、DAU日活、转化率 业务接口: 登陆数、注册数、订单量、支付量、搜索量等 云原生时代的可观测性 可观测性系统\n指标监控(Metrics): 随时间推移产生的一些与监控相关的可聚合数据点 日志监控(Logging): 离散式的日志或事件(结构化) 链路跟踪(Tracing): 分布式应用调用链跟踪(调用时长/性能) CNCF将可观测性和数据分析归类为一个单独的类别 划分成了5个子类\n监控系统 日志系统 分布式调用链跟踪系统 混沌工程系统: 结合监控系统提前发现问题 持续优化 Prometheus仅仅是可观测性中的一个纬度(指标监控)中的一个代表\n著名的监控方法论 Google的四个黄金指标\n常用于在服务级别帮助衡量终端用户体验、服务中断、业务影响等层面的问题 适用于应用及服务监控 四个黄金指标 延迟(Latency) 服务请求所需要的时长 如: HTTP请求平均延迟 需要区分失败请求和成功请求 流量(Traffic) 衡量服务的容量需求 如: 每秒处理的HTTP1请求数 数据库系统的事务数量 错误(Errors) 请求失败的速率 用于衡量错误发生的情况 显示失败(HTTP500) 隐式失败(返回错误内容/无效内容) 策略原因导致的失败(响应时间超过30ms请求视为失败) 饱和度(Saturation): 服务受限资源 衡量资源的使用情况 用于表达程序有多满 如: CPU 内存 I/O 磁盘等资源的使用情况(NodeExporter) Netflix的USE方法\n主要用于分析系统性能问题 指导用户快速识别资源瓶颈以及错误的方法 应用于主机指标监控 USE 使用率(Utilization) 关注资源的使用情况 主要包括但不限于CPU 内存 网络 磁盘等 100%的使用率通常是系统性能瓶颈的标志 饱和度(Saturation) 如CPU的平均运行排队长度 任何资源在某种程度上的饱和都可能导致系统性能的下降 错误(Error) 错误计数 如: 网卡在数据包传输过程中检测到的以太网网络冲突了14次 Weave Cloud的RED方法\nWeave Cloud基于Google的四个黄金指标的原则下 结合Prometheus以及Kubernetes容器实践 细化和总结的方法论 特别适合云原生应用以及微服务架构应用的监控和度量 在四大黄金指标的原则下 RED方法可以有效的帮助用户衡量云原生以及微服务应用下的用户体验问题 RED方法主要关注以下三种指标 (Request)Rate: 每秒钟接收的请求数 (Request)Errors: 每秒失败的请求数 (Request)Duration: 每个请求所花费的时长 Prometheus入门 What is Prometheus Monitoring Prometheus是一个时序(Time Series)数据库 但它的功能却并非止步于TSDB 而是一款设计用于进行目标(Target)监控的关键组件 结合其生态内的其他组件 如: Pushgateway Alertmanager Grafana等 可构成一个完整的IT监控系统 时序数据简介 时序数据是在一段时间内通过重复测量(measurement)而获得的观测值的集合 将这些观测值绘制于图形之上 它会有一个数据轴和一个时间轴 服务器指标数据、应用程序性能监控数据、网络数据等也都是时序数据 What does Prometheus do 基于HTTP call 从配置文件中指定的网络端点(Endpoint)上周期性获取指标数据 最简单的逻辑如下图 How does Prometheus work Prometheus支持通过三种类型的途径从目标上抓取(Scrape) 指标数据 Exporters Instrumentation(测量系统 内建Prometheus兼容的指标暴露器) Pushgateway(短生命周期任务 启动/结束时间不确定) Instrumentation(程序仪表) 任何能够支持Scrape指标数据的应用程序都首先要具有一个测量系统 在Prometheus的语境中 Instrumentation是指附加到应用程序中的那些用于暴露程序指标数据的客户端库 程序员借助于这些客户端库编写代码生成可暴露的指标数据 Exporters 对于那些未内建Instrumentation 且也不便于自行添加该类组件以暴露指标数据的应用程序来说 常用的办法是于待监控的目标应用程序外部运行u一个独立指标暴露程序 该类型的程序即统称为Exporter 换句话说 Exporter负责从目标应用程序上采集和聚合原始格式的数据 并转换或聚合为Prometheus格式的指标向外暴露 Prometheus站点上提供了大量的Exporter Pull and Push Prometheus同其它TSDB相比有一个非常典型的特征: 它主动从各Targers上拉取(pull) 数据 而非等待被监控端的推送(Push) 两种方式各有优劣 其中 Pull模型的优势在于: 集中控制: 有利于将配置集中在Prometheus Server上完成 包括指标及采集速率等 Prometheus的根本目标在于收集在Target上预先完成聚合的聚合型数据 而非一款由事件驱动的存储系统 Prometheus的生态组件 promtheus-architecture\nPrometheus负责时序型指标数据的采集及存储 但数据的分析/聚合及直观展示以及告警等功能并非由Prometheus Server负责 Prometheus生态包含多个组件 其中部分组件可选 Prometheus Server: 收集和存储时间序列数据 Prometheus监控系统的核心组件 Client Library: 客户端库 目的在于为那些期望原生提供Instrumentation功能的应用程序提供便捷的开发途径 Push Gateway: 接收那些通常由短期作业生成的指标数据的网关 并支持由Prometheus Server进行指标拉取操作 Exporters: 用于暴露现有应用程序或服务(不支持Instrumentation)的指标给Prometheus Server node_exporter blackbox_exporter mysql_exporter \u0026hellip; Alertmanager: 从Prometheus Server接收到告警通知后 通过去重 分组 路由等预处理功能后以高效向用户完成告警信息的发送 Data Visualization: Prometheus Web UI(内建 PromQL表达式浏览器) 及Grafana等 Service Discovery: 动态发现待监控的Target 从而完成监控配置的重要组件 在容器化环境尤为有用 该组件目前由Prometheus Server内建支持 Prometheus数据模型(Data Model) prometheus-data-model\nPrometheus仅用于以键值形式存储时序式的聚合数据 它并不支持存储文本信息 其中的键称为指标(Metric) 它通常意味着CPU速率 内存使用率或分区空闲比例等 同一指标可能为适配到多个目标或设备 因而他使用标签作为元数据 从而为Metric添加更多的信息描述维度 这些标签还可以作为过滤器进行指标过滤及聚合运算 指标类型(Metric Types) prometheus-metric-types\nPrometheus使用4种方法来描述监控的指标 Counter: 计数器 用于保存单调递增型的数据 例如: 站点访问次数等 不能为负值 也不支持减少 但可以重置回0 Gauge: 仪表盘 用于存储有着起伏特征的指标数据 例如: 内存使用情况等 Gauge是Counter的超集 但存在指标数据丢失的可能性 Counter能让用户确切了解指标随的变化状态 而Gauge则可能随时间流逝而精准度越来越低 Histogram: 直方图 它会在一段时间范围内对数据进行采样 并将其计入可配置的bucket中 Histigram能够存储更多的信息 包括样本值分布在每个bucket中的数量、所有样本值之和以及总的样本数量 从而Prometheus能够使用内置的函数进行如下操作: 计算样本平均值: 以值的总和除以值的数量 计算样本分为值: 分为数有助于了解符合特定标准的数据个数 如: 评估响应时长超过1s的请求比例 若超过20%即发送告警等 Summary: 摘要 Histogram的扩展类型 但它是直接由被检测端自行聚合计算出分位数 并将计算结果响应给Prometheus Server的样本采集请求 作业(Job)和实例(Instance) Instance: 能够接收Prometheus Server数据Scrape操作的每个网络网络端点(endpoint) 即为一个Instance(实例) 通常 具有类似功能的Instance的集合称为一个Job 如: 一个MySQL主从复制集群中的所有MySQL进程 Promtheus Query Language Prometheus提供了内置的数据查询语言PromQL(Prometheus Query Language) 支持用户进行实时的数据查询及聚合操作 PromQL支持处理两种向量 并内置提供了一组用于数据处理的函数 即时向量: 最近一次的时间戳上跟踪的数据指标 时间范围向量: 指定时间范围内的所有时间戳上的数据指标 Alerts 抓取到异常值后 Prometheus支持通过告警(Alert) 机制向用户发送反馈或警示 会触发用户能够及时采取应对措施 Prometheus Server仅负责生成告警指示 具体的告警行为由另一个独立的应用程序Alertmanager负责 告警指示由Prometheus Server基于用户提供的告警规则 周期性计算生成 Alertmanager接收到Prometheus Server发来的告警指示后 基于用户定义的**告警路由(route)向告警接收人(reveivers)**发送告警信息 Prometheus局限性 Prometheus是一款指标监控系统 不适合存储事件及日志等 它更多展示的是趋势性的监控 而非精准数据 Prometheus认为只有最近的监控数据才有查询的需要 其本地存储的设计初衷只是保存短期(如一个月)数据 因而不支持针对大量的历史数据进行存储 若需要存储长期的历史数据 建议基于远程存储机制将数据保存于InfluxDB或OpenTSDB Prometheus的集群机制成熟度不高 运行Prometheus rpm-repo\nCPU使用率\n每台主机CPU在5分钟内的平均使用率 (1 - avg(irate(node_cpu_second_total{mode=\u0026quot;idle\u0026quot;}[5m])) by (instance)) * 100 CPU饱和度\n跟踪CPU的平均负载就能获取到相关主机的CPU1饱和度 实际上 它是将主机上的CPU数量考虑在内的一段时间内的平均运行队列长度 平均负载少于CPU的数量是正常情况 而长时间内超过CPU数量则表示CPU毅然饱和 node_load1 \u0026gt; on(instance) 2 * count(node_cpu_seconds_total{mode=\u0026quot;idle\u0026quot;}) by (instance) 查询1分钟平均负载超过主机CPU数量两倍的时间序列 CPU瓶颈、程序BUG 控制平面 内存使用率\nnode_exporter暴露了多个以node_memory为前缀的指标 我们重点关注下面几个 node_memory_MemTotal_bytes node_memory_MemFree_bytes node_memory_Buffers_bytes node_memory_Cached_bytes 计算使用率 可用空间: 上面后三个指标之和 已用空间: 总空间减去可用空间 实用率: 已用空间除以总空间 Exporter exporters-and-integrans\nnode_exporter blackbox_exporter mysql_exporter \u0026hellip; 客户端库 应用程序自己并不会直接生成指标数据 这依赖于开发人员将相关的客户端库添加至应用程序中构建出的测量系统(instrumentation system)来完成 官方库语言支持: Go、Python、Java(或Scala)和Ruby 第三方库语言支持: Bash(pushgateway)、C、C++、C#、Node.js、Haskell、Erlang、Perl、PHP、Rust Exporter基础 对于那些非用户可直接控制的应用代码来说 为其添加客户端库以进行直接测量很难实现 操作系统内核就是一个典型的示例 它显然不太可能易于实现添加自定义代码并通过HTTP协议输出Prometheus格式的指标 但这一类程序一般都会通过某种接口输出其内在的指标 只不过这些指标可能有着特殊的格式 如: Linux内核的特有指标格式 或者SNMP指标格式等 这些指标需要对它进行适当的解析和处理以转换为可用的目标格式 Exporter就是完成此类转换功能的应用程序 Exporter独立运行于要获取其测量指标的应用程序之外 负责接收来自于Prometheus Server的指标获取请求 它通过目标应用程序(真正的目标)内置的指标接口获取指标数据 并将这些指标数据转换为可用的目标格式后响应给Prometheus Exporter更像是一对一的代理 它作为Prometheus Server的target存在 工作于应用程序的指标接口和Prometheus的文本指标格式之间转换数据格式 Exporter不存储也不缓存任何数据 PromQL PromQL简介 Prometheus基于指标名称(metrics name)以及附属的标签集(labelset)唯一定义一条时间序列 指标名称代表着监控目标上某类可测量属性的基本特征标识 标签则是这个基本特征上再次细分的多个可测量维度 基于PromQL表达式 用户可以针对指定的特征及其细分维度进行过滤、聚合、统计等运算 从而产生期望的计算结果 PromQL是Prometheus Server内置的数据查询语言 PromQL使用表达式(expression)来表达查询需求 根据其使用的指标和标签 以及时间范围 表达式的查询请求可灵活覆盖在一个或多个时间序列的一定范围内的样本之上 甚至是只包含单个时间序列的单个样本 Prometheus时间序列 时间序列数据: 按照时间顺序 记录系统、设备状态变化的数据 每个数据称为一个样本 数据采集以特定的时间周期进行 因而 随着时间流逝 将这些样本数据记录下来 将生成一个离散的样本数据序列 该序列也称为向量(Vector) 而将多个序列放在同一个坐标系内(以时间为横轴 以序列为纵轴) 将形成一个由数据点组成的矩阵 Prometheus数据模型 Prometheus中 每个时间序列都由指标名称(Metric Name)和标签(Label)来唯一标识 格式为\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...} 指标名称: 通常用于描述系统上要测量的某个特征 如: http_requests_total表示接收到的HTTP请求总数 支持使用字母、数字、下划线和冒号 且必须能匹配RE2规范的正则表达式 标签: 键值型数据 附加在指标名称之上 从而让指标能够支持多维度特征 可选 如: http_requests_total{method=\u0026quot;GET\u0026quot;} 和 http_request_total{method=\u0026quot;POST\u0026quot;}代表两个不同的时间序列 标签名称可使用字母、数字和下划线 切必须能匹配RE2规范的正则表达式 以 _ _ 为前缀的名称为Prometheus系统预留使用 Metric Name的表示方式有两种 后一种通常用于Prometheus内部 样本数据格式 Prometheus的每个数据样本由两部分组成 float64格式的数据 毫秒精度的时间戳 指标名称及标签使用注意事项 指标名称和标签的特定组合代表着一个时间序列 指标名称相同 但标签不同的组合分别代表着不同的时间序列 不同的指标名称自然更是标识不同的时间序列 PromQL支持基于定义的指标维度进行过滤和聚合 更改任何标签值 包括添加标签或删除标签 都会创建一个新的时间序列 应该尽可能保持标签的稳定性 否则很可能创建新的时间序列 更甚者会生成一个动态的数据环境 并使得监控的数据源难以跟踪 从而导致建立在该指标之上的图形、告警记录规则变得无效 PromQL的数据类型 PromQL的表达式中支持4种数据类型 即时向量(Instant Vector): 特定或全部的时间序列集合上 具有相同时间戳的一组样本值 称为即时向量 范围向量(Range Vector): 特定或全部的时间序列集合上 在指定的统一时间范围内的所有样本值 标量(Scalar): 一个浮点型(float64)的数据值 字符串(String): 支持使用单引号、双引号或反引号进行引用 但反引号中不会对转义字符串进行转义 时间序列选择器 即时向量与范围向量 PromQL的查询操作需要针对有限个时间序列上的样本数据进行 挑选出目标时间序列是构建表达式最为关键的一步 用户可以使用向量选择器表达式来挑选出给定指标名称下的所有时间序列或部分时间序列的即时(当前)样本值 或至过去某个时间范围内的样本值 前者称为即时向量选择器 后者称为范围向量选择器 即时向量选择器(Instant Vector Selectors): 返回0个、1个或多个时间序列上在给定时间戳(instant)上的各自的一个样本 该样本也可称为即时样本 范围向量选择器(Range Vector Selectors): 返回0个、1个或多个时间序列上在给定时间范围内的各自的一组样本 向量表达式使用要点 表达式的返回值类型亦是即时向量、范围向量、标量或字符串4种数据类型其中之一 但是有些使用场景要求表达式返回值必须满足特定条件 需要将返回值绘制成图形时 仅支持即时向量类型的数据 对于诸如rate一类的速率函数来说 其要求使用的必须是范围向量型的数据 由于范围向量选择器返回的是范围向量型数据 它不能用于表达式浏览器中图形绘制功能 否则表达式浏览器会返回相应错误 事实上 范围向量几乎总是结合速率类的函数rate一同使用 即时向量选择器 即时向量选择器由两部分组成 指标名称: 用于限定特定指标下的时间序列 即负责过滤指标 可选 匹配器(Matcher): 或称为标签选择器 用于过滤时间序列上的标签 定义在{}中 可选 定义即时向量选择器时 以上两个部分应该至少给出一个 于是将存在下面三种组合 仅给定指标名称 或者标签名称上使用空值匹配器: 返回给定指标下的所有时间序列各自的即时样本 如: http_requests_total/http_requests_total{} 仅给定匹配器: 返回所有符合给定匹配器的所有时间序列上的即时样本 注意: 这些时间序列可能有着不同的指标名称 如: {job=~\u0026quot;.*\u0026quot;, method=\u0026ldquo;GET\u0026rdquo;} 指标名称和匹配器的组合: 返回给定的指标下 且符合给定标签过滤器的所有时间序列上的即时样本 如: http_requests_total{methdo=\u0026ldquo;GET\u0026rdquo;} 匹配器(Matcher) time-series-selectors\n匹配器用于定义标签过滤条件 目前支持4种匹配操作符 =: Select labels that are exactly equal to the provided string. !=: Select labels that are not equal to the provided string. =~: Select labels that regex-match the provided string. !~: Select labels that do not regex-match the provided string. 注意事项 匹配到空标签值的匹配器时 所有未定义该标签的时间序列同样符合条件 如: http_requests_total{env=\u0026quot;\u0026quot;}会匹配到http_requests_total{method=\u0026quot;GET\u0026quot;} 正则表达式将执行完全锚定机制 它需要匹配指定的标签的整个值 向量选择器至少要包含一个指标名称 或者至少有一个不会匹配到空字符串的匹配器 如: {job=\u0026quot;\u0026quot;} 为非法的选择器 使用__name__做为标签名称 还能够对指标名称进行过滤(联邦集群时常用到) 如: {__name__=~\u0026quot;http_requests_.*\u0026quot;}能够匹配所有以http_requests_为前缀的所有指标 范围向量选择器 同即时向量选择器的唯一不同之处在于 范围向量选择器需要在表达式后紧跟一个方括号[]来表达需在时间序列上返回的样本所处的时间范围 时间范围: 以当前的时间为基准的时间点 只想过去一个特定的时间长度 如: [5m] 指过去5分钟之内 时间格式: 一个整数后紧跟一个时间单位(Time Durations) 可用单位: ms(毫秒)/s(秒)/m(分钟)/h(小时)/d(天)/w(周)/y(年) 必须使用整数时间 且能够将多个不同级别的单位进行组合 以时间单位由大到小排序 1h30m 1.5h 5h 10s 2d 需要注意的是 范围向量选择器返回的是一定时间范围内的数据样本 虽然不同时间序列的数据抓取时间点相同 但它们的时间戳并不会严格对齐 多个Target上的数据抓取需要分散在抓取时间点前后一定的时间范围内 以均衡Prometheus Server的负载 因而 Prometheus在趋势上准确 但并非绝对精准 偏移量修改器 默认情况下 即时向量选择器和范围向量选择器都以当前时间为基准时间点 而偏移量修改器能够修改该基准 偏移量修改器的使用方法是紧跟在选择器表达式之后使用offset关键字指定 http_requests_total offset 5m 表示获取以http_requests_total为指标名称的所有时间序列在过去5分钟时的即时样本 http_requests_total[5m] offset 1d 表示获取距此刻1天时间之前的5分钟之内的所有样本 PromQL指标类型 PromQL主要有四个指标类型 它们主要由Prometheus的客户端库使用 Counter: 计数器 单调递增 除非重置(如: 服务器或进程重启) Gauge: 仪表盘 可增可减的数据 Histogram: 直方图 将时间单位内的数据划分成不同的时间段 并各自评估其样本个数及样本值之和 因而可计算出分位数 可用于分析因异常值而引起的平均值过大的问题 分位数计算要使用专用的histogram_quantile函数 Summary: 类似直方图 但客户端会直接计算并上报分位数 Prometheus Server并不使用类型信息 而是将所有数据展平为时间序列 Counter和Gauge 通常 Counter的总数并没有直接作用 而使需要借助于rate、topk、increase和irate等函数来生成样本数据的变化状况(增长率) rate(hrrp_requests_total[2h]) 获取2小时内 该指标下各时间序列上的http总请求数的增长速率 topk(3, http_requests_total) 获取该指标下http请求总数排名前3的时间序列 irate(http_request_total[2h]) 高灵敏度函数 用于计算指标的瞬时速率 基于样本范围内的最后两个样本进行计算 相较于rate函数来说 irate更适合用于短期时间范围内的变化速率分析 Gauge用于存储其值可增可减的指标样本数据 常用于进行求和、取平均值、最小值、最大值等聚合计算 也会经常结合PromQL的predict_linear和delta函数使用 predict_linear(v range-vector, t, scaler)函数可以预测时间序列v在t秒后的值 它通过线性回归的方式来预测样本数据的Gauge变化趋势 delta(v range-vector)函数计算范围向量中每个时间序列元素的第一个值与最后一个值之差 从而展示不同时间点上的样本值差值 Histogram Histogram是一种对数据分布情况的图形展示 由一系列高度不等的长条图(bar)或线段表示 用于展示耽搁测度的值的分布 它一般用横轴表示某个指标维度的数据取值的分布状况 用纵轴表示样本统计的频率和频数 从而能够以二维图的形式展现数值的分布状况 为了构建Histogram 首先需要将值的范围进行分段 即将所有值的整个可用范围分成一系列连续、相邻(相邻出可以是等同值)但不重叠的间隔 而后统计每个间隔中有多少值 从统计学的角度看 分位数不能被聚合 也不能进行算数运算 对于Prometheus来说 Histogram会在一段时间范围内对数据进行采样(通常是请求持续时长或响应大小等) 并将其计入可配置的bucket(存储桶)中 Histogram事先将特定测度可能的取值范围分割为多个样本空间 并通过对落入bucket内的观测值进行计算以及求和操作 与常规的方式略有不同的是 Prometheus取值间隔的划分采用的是累积(Cumulative)区间间隔机制 及每个bucket中的样本均包含了其前面所有bucket中的样本 因而也称为累积直方图 可降低Histogram的维护成本 支持粗略计算样本值的分位数 单独提供了_sum和_count指标 从而支持计算平均值 Histogram类型的每个指标有一个基础指标名称\u0026lt;basename\u0026gt; 它会提供多个时间序列 \u0026lt;basename\u0026gt;_bucket{le=\u0026quot;\u0026lt;upper inclusive bound\u0026gt;\u0026quot;}: 观测桶的上边界 及样本统计区间；最大区间(包含所有样本)的名称为\u0026lt;basename\u0026gt;_bucket{le=\u0026quot;+Inf\u0026quot;} \u0026lt;basename\u0026gt;_sum: 所有样本观测值的总和 \u0026lt;basename\u0026gt;_count: 总的观测次数 它自身本质上是一个Counter类型的指标 累积间隔机制生成的样本数据需要额外使用内置的histogram_quantile()函数 即可根据Histogram指标来计算相应的分位数(quantile) 及某个bucket的样本数在所有样本数中所占的比例 histogram_quantile()函数在计算分位数时会假定每个区间内的样本满足线性分布状态 因为它的结果是一个预估值 并不完全准确 预估的准确度取决于bucket区间划分的粒度 粒度越大 准确度越低 Summary 指标类型是客户端库的特性 而Histogram在客户端仅是简单的桶划分和分桶计数 分位数的计算由Prometheus Server基于样本数据进行估算 因而其结果未必准确 甚至不合理的bucket划分会导致较大的误差 Summary是一种类似于Histogram的指标类型 但它在客户端于一段时间内默认10分钟)的每个采样点进行统计 计算并存储了分位数数值 Server端直接抓取相应值即可 但是 Summary不支持sum和avg一类的集合运算 而且其分位数由客户端计算并生成 Server端无法获取客户端未定义的分位数 而Histogram可通过PromQL任意定义 有着较好的灵活性 对于每个指标 Summary以指标名称\u0026lt;basename\u0026gt;为前缀 生成如下几个时间序列 \u0026lt;basename\u0026gt;{quantile=\u0026quot;\u0026lt;φ\u0026gt;\u0026quot;} 其中φ是分位点 其取值范围是(0\u0026lt;=φ\u0026lt;=1) 计数器类型指标 如下是几种典型的分位点 0、0.25、0.5、0.75和1几个分位点 0.5、0.9和0.99几个分位点 0.01、0.05、0.5、0.9和0.99几个分位点 \u0026lt;basename\u0026gt;_sum 抓取到的所有样本值之和 \u0026lt;basename\u0026gt;_count 抓取到的所有样本总数 PromQL运算 Prometheus的聚合函数 一般来说 单个指标的价值不大 监控场景中往往需要联合并可视化一组指标 这种联合机制即时指聚合操作 如: 将计数、求和、平均值、分位数、标准差及方差等统计函数应用于时间序列的样本之上生成具有统计学意义的结果等 对查询结果事先按照某种分类机制进行分组(groupby) 并将查询结果按组进行聚合计算也是较为常见的需求 如: 分组统计、分组求平均值、分组求和等 聚合操作由聚合函数针对一组值进行计算并返回单个值或少量几个值作为记过 Prometheus内置提供的11个聚合函数也称为聚合运算符 这些运算符仅支持应用于单个即时向量的元素 器返回值也是具有少量元素的新向量或标量 这些聚合运算符既可以基于向量表达式返回结果中的时间序列的所有标签维度进行分组聚合 也可以仅基于指定的标签维度分组后再进行分组聚合 聚合表达式 PromQL中的聚合操作语法格式可采用如下两种格式之一 \u0026lt;aggr-op\u0026gt;([parameter,]\u0026lt;vector expression\u0026gt;)[without|by(\u0026lt;label list\u0026gt;)] \u0026lt;aggr-op\u0026gt;[without|by(label list)]([parameter,]\u0026lt;vector expression\u0026gt;) 分组聚合: 先分组、在聚合 without: 从结果向量中删除由without指定的标签 未指定的那部分标签则用作分组标准 by: 功能和without相反 它仅使用by子句中指定的标签进行聚合 结果向量中出现但未被by子句执行的标签则会被忽略 为了保留上下文信息 使用by子句时需要显式指定其结果中原本出现的job、instance等一类的标签 事实上 各函数工作机制的不同之处也仅在于计算操作本身 PromQL对它们的执行逻辑相似 11个聚合函数 sum(): 对样本值求和 avg(): 对样本值求平均值 这是进行指标数据分析的标准方法 count(): 对分组内的时间序列进行数量统计 stddev(): 对样本值求标准差 以帮组用户了解数据的波动大小(或称之为波动程度) stdvar(): 对样本值求方差 它是求取标准差过程中的中间状态 min(): 求取样本值中的最小者 max(): 求取样本值中的最大者 topk(): 逆序返回分组内的样本值最大的前k个时间序列及其值 bottomk(): 顺序返回分组内样本值最小的前k个时间序列及其值 quanlite(): 分位数用于评估数据的分布状态 该函数会返回分组内指定的分位数的值 即数值落在小于等于执行的分位区间的比例 count_values(): 对分组内的时间序列的样本值进行数量统计 二元运算符 PromQL支持基本的算数运算和逻辑运算 这类运算支持使用操作符连接两个操作数 因而也称为二元运算符或二元操作符 支持的运算 两个标量间运算 即时向量和标量间的运算: 将运算符应用于向量上的每个样本 两个即时向量间的运算: 遵循向量匹配机制 将运算符用于两个即时向量间的运算时 可基于向量匹配模式定义器运算机制 算数运算 支持运算符: +、-、*、/、%(取模)、^(幂运算) 比较运算 支持运算符: ==、!=、\u0026gt;、\u0026lt;、\u0026gt;=、\u0026lt;= 逻辑/集合运算 支持的运算符: and、or、unless(除了) 目前 该运算仅允许在两个即时向量间进行 尚不支持标量参与运算 向量匹配 即时向量间的运算时PromQL的特色之一 运算时 PromQL会为左侧向量中的那个元素找到匹配的元素 其匹配行为有两种基本类型 一对一(One-to-One) 一对多或多对一(Many-to-One One-to-Many) 向量一对一匹配 one-to-one-vector-matches\n即时向量的一对一匹配 从运算符的两边表达式所获取的即时向量间一次比较 并找到唯一匹配(标签完全一致)的样本值 找不到匹配项的值则不会出现在结果中 匹配表达式语法 \u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; ignoring(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt; \u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; on(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt; ignore: 定义匹配检测时要忽略的标签 on: 定义匹配检测时只使用的标签 如: rate(http_requests_total{status_code=~\u0026quot;5.*\u0026quot;}[5m]) \u0026gt; .1*rate(http_requests_total[5m]) 左侧会生成一个即时向量 它计算出5xx响应码的各类请求的增长速率 除了status_code标签外 该指标通常还有其他标签 于是 status_code的值为500的标签同其他标签的每个组合代表一个时间序列 其相应的即时样本即为结果向量的一个元素 右侧会生成一个即时向量 它计算出所有标签组合所代表的各类请求的增长速率 计算时 PromQL会在操作符左右两侧的结果元素中找到标签完全一致的元素进行比较 其意义为: 计算出每类请求中的5xx响应码在该类请求中所占的比例 一对多/多对一匹配 many-to-one-and-one-to-many-vector-matches\n一对多/多对一匹配 一侧的每个元素 可与多侧的多个元素进行匹配 必须使用group_left或group_right明确指定哪侧为多侧 匹配表达式语法 \u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; ignoring(\u0026lt;label list\u0026gt;) group_left(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt; \u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; ignoring(\u0026lt;label list\u0026gt;) group_right(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt; \u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; on(\u0026lt;label list\u0026gt;) group_left(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt; \u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; on(\u0026lt;label list\u0026gt;) group_left(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt; 服务发现 Prometheus指标抓取的生命周期 发现 -\u0026gt; 配置 -\u0026gt; relabel -\u0026gt; 指标数据抓取 -\u0026gt; metrics relabel Prometheus Server监控Target 静态配置(static configs) 动态发现/Prometheus的服务发现(监控环境变化频繁/动态环境) 基于文件的服务发现 略优于静态配置 不依赖于任何第三方服务或平台 因而也是最简单和通用的实现方式 基于DNS的服务发现 基于API的服务发现: Kubernetes、Consul、Azure、\u0026hellip; 重新标记 target重新打标 mertric重新打标 为何要进行服务发现 Prometheus Server的数据抓取工作于Pull模型 因而 它必须事先知道各Target的位置 然后才能从相应的Exporter或Instrumentation中抓取数据 对于小型的系统环境来说 通过static_configs指定各Target便能解决问题 这也是最简单的配置方法 每个Targets用一个网络端点(ip:port)标识 对于中大型的系统环境或具有较强动态性的云计算环境来说 静态配置显然难以适用 Prometheus为此专门设计了一组服务发现机制 以便于能够基于服务注册中心(服务总线)自动发现、检测、分类可被监控的各Target 以及更新发生了变动的Target 指标抓取的生命周期 下图展示了Prometheus上进行指标抓取的简单生命周期 在每个scrape_interval期间 Prometheus都会检查执行的作业(Job) 这些作业首先会根据Job上指定的发现配置生成target列表 此即服务发现的过程 服务发现会返回一个Target列表 其中包含一组称为元数据的标签 这些标签都以__meta__为前缀 服务发现还会根据目标配置来设置其他标签 这些标签带有__前缀和后缀 包括__scheme__ __address__ __metrics_path__ 分别保存target支持使用的协议(http/https 默认http) target的地址以及指标的URI路径(默认为/metrics) 若URI路径中存在任何参数 则它们的前缀会设置为__param__ 这些目标列表金和标签会返回给Prometheus 其中的一些标签也可以配置中被覆盖 配置标签会在抓取的生命周期中被重复利用以生成其他标签 如: 指标上的instance标签的默认值就来自于__address__标签的值 对于发现的各目标 Prometheus提供了可以重新标记(relabel)目标的机会 它定义在job配置段的relabel_config配置中 常用于实现如下功能 将来自服务发现的元数据标签中的信息附加到指标的标签上 过滤目标 在这之后 便是数据抓取、以及指标返回的过程 抓取而来的指标在保存之前 还允许用户对指标重新打标并过滤 它定义在job配置段的metric_relabel_configs配置中 常用语实现如下功能 删除不必要的指标 从指标中删除敏感或不需要的标签 添加、编辑或修改指标的标签值或标签格式 可集成的服务发现机制 不同场景中 服务注册中心的指代也有所不同 共有云或私有IaaS云 自身保存有平台上的所有资源信息 其API Server便可以作为Prometheus的服务发现媒介 azure、ec2、digitalocean、gce、tencent cloud、alibaba cloud Prometheus也可以集成到多种不同的开源服务发现工具上 以动态发现需要监控的目标 Consul、Eureka Zookeeper Serverset或Airbnb Nerve等 Prometheus也可以很好的集成到Kubernetes平台上 通过其API Server动态发现各类被监控的Pod、Service、End point、Ingress和Node对象 它也支持基于dockerswarm和marathon两款编排工具进行服务发现机制 Prometheus还支持基于基于DNS、文件或HTTP的动态发现机制 对Target重新打标 relabel-config\n对target重新达标是在数据抓取之前动态重写target标签的强大工具 在每个数据抓取配置中 可以定义多个relabel步骤 他们将按照定义的顺序依次执行 对于发现的每个target Prometheus默认会执行如下操作 job的标签设定为其所属的job_name的值 __address__标签的值为该target的套接字地址\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; instance标签的值为__address__的值 __scheme__标签的值为抓取该target上指标时使用的协议(http或https) __metrics_path__标签的值为抓取该target上的指标时使用的URI路径 默认为/metrics __param_\u0026lt;name\u0026gt;标签的值为传递的URI参数中第一个名称为\u0026lt;name\u0026gt;的参数的值 重新打标记期间 还可以使用该target上以__meta__开头的元标签 各服务发现机制为其target添加的元标签会有所不同 重新标记完成后 该target上以__开头的所有标签都会被移除 若在relabel过程中需要临时存储标签值 则需要使用__tmp标签名称为前缀进行保存 依避免同Prometheus的内建标签冲突 relabel_config relabel_config\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # The source labels select values from existing labels. Their content is concatenated # using the configured separator and matched against the configured regular expression # for the replace, keep, and drop actions. [ source_labels: \u0026#39;[\u0026#39; \u0026lt;labelname\u0026gt; [, ...] \u0026#39;]\u0026#39; ] # Separator placed between concatenated source label values. [ separator: \u0026lt;string\u0026gt; | default = ; ] # Label to which the resulting value is written in a replace action. # It is mandatory for replace actions. Regex capture groups are available. [ target_label: \u0026lt;labelname\u0026gt; ] # Regular expression against which the extracted value is matched. [ regex: \u0026lt;regex\u0026gt; | default = (.*) ] # Modulus to take of the hash of the source label values. [ modulus: \u0026lt;int\u0026gt; ] # Replacement value against which a regex replace is performed if the # regular expression matches. Regex capture groups are available. [ replacement: \u0026lt;string\u0026gt; | default = $1 ] # Action to perform based on regex matching. [ action: \u0026lt;relabel_action\u0026gt; | default = replace ] relabel_configs \u0026lt;relabal_action\u0026gt;字段用于定义重新标记的行为 其可用取值如下 替换标签值 replace: 首先将source_labels中指定的各标签值进行串连 而后将regex字段中的正则表达式对源标签值进行匹配判定 若匹配 则将target_label字段中指定的标签值替换为replacement字段中保存的值 replacement可按需引用保存regex中的某个分组模式匹配到的值 默认保存整个regex匹配到的内容 进行值替换时 replacement字段中指定标签的值也支持以分组格式进行引用 hashmod: 将target_label的值设置为一个hash值 该hash则由models字段指定的hash模块对source_labels上各标签的串连值进行hash计算生成 删除指标: 该处的每个指标名称对应一个target keep: regex不能匹配到target上的source_labels上的各标签的串连值时 则删除该target drop: regex能匹配到target上的source_labels上的各标签的串连值时 则删除该target 创建或删除标签 labelmap: 将regex对所有的标签名进行匹配判定 而后将匹配到的标签的值赋给replacement字段指定的标签名之上 通常用于取出匹配的标签名的一部分生成新标签 labeldrop: 将regex对所有的标签名进行匹配判定 能够匹配到的标签将从该target的标签集中删除 labelkeep: 将regex对所有的标签名进行匹配判定 不能够匹配到的标签将从该target的标签集中删除 注意: 要确保在labeldrop或labelkeep操作后 余下的标签集依然能够唯一标识该指标 replace示例 下面示例将三个源标签的值按顺序串连后 由指定的正则表达式进行模式匹配 然后由replacement引用模式匹配的结果并加以改造 将其赋值给endpoint标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 - job_name: \u0026#34;nodes\u0026#34; file_sd_configs: - files: - targets/prometheus/node*.yaml relabel_configs: - source_labels: - __scheme__ - __address__ - __metrics_path__ regex: \u0026#34;(http|https)(.*)\u0026#34; separator: \u0026#34;\u0026#34; target_label: \u0026#34;endpoint\u0026#34; replacement: \u0026#34;${1}://${2}\u0026#34; action: replace labelmap示例 下面的示例 将regex指定的模式对target上所有的标签进行匹配判定 对于匹配到的标签名 它将以该标签名中匹配的部分为前缀 指定的_name为后缀生成新的标签名 而新标签的值则与其原标签的值相同 1 2 3 4 5 6 7 8 9 - job: \u0026#34;nodes\u0026#34; file_sd_configs: - fles: - targets/prometheus/node*.yaml relabel_configs: - regex: \u0026#34;(job|app)\u0026#34; replacement: \u0026#34;${1}_name\u0026#34; action: labelmap 对抓取到的metric重新打标 对metric重新打标时在数据抓取之后动态重写metric标签的工具 在每个数据抓取配置中 可以定义多个metric relabel步骤 它们按照定义的顺序依次执行 删除不必要的指标 从指标中删除敏感或不需要的标签 添加、编辑或修改指标的标签值或标签格式 对metric重新打标的配置格式与target重新打标的格式相同 但前者要定义在专用的metric_relabel_configs字段中 要注意的是 更改或添加标签会创建新的时间序列 应该明确地使用各个标签 并尽可能保持不变 以避免创建出一个动态的数据环境 标签是时间序列的唯一约束 删除标签并导致时间序列重复时 可能会导致系统出现问题 metric relabel删除示例 在source_label字段上 通过指标上的元标签__name__引用指标名称 而后由regex进行匹配判断 可使用drop action删除匹配的指标 或使用keep action仅保留匹配的指标 下面的示例 用于在相应的job上 在发现的各target上 删除以 go_info 为前缀的指标 1 2 3 4 5 6 7 8 9 10 - job_name: \u0026#34;nodes\u0026#34; file_sd_configs: - files: - targets/prometheus/node*.yaml metric_relabel_configs: - source_labels: - __name__ regex: \u0026#34;go_info.*\u0026#34; action: drop 查询持久化/可视化 grafana\n记录规则(recording rule) 告警规则(alert rule) Alertmanager 告警功能概述 Prometheus对指标的收集、存储同告警能力分数于Prometheus Server和Alertmanager两个独立的组件 前者仅负责基于告警规则生成告警通知 具体的告警操作由后者完成 alertmanager负责处理由客户端发来的告警通知 客户端通常是Prometheus Server 但它也支持接收来自其它工具的告警 alertmanager对告警通知进行分组、去重后 根据路由规则将其路由到不同的receiver 如: Email、钉钉、企业微信等 告警逻辑 首先要配置Prometheus成为Alertmanager的告警客户端 反过来 Alertmanager也是应用程序 它自身同样应该纳入Prometheus的监控目标 配置逻辑 在Alertmanager上定义receiver 他们通常是能够基于某个媒介接收告警信息的特定用户 Email、WeChat、Pagerduty和Webhook等是最为常见的发送告警信息的媒介 在不同的媒介上 代表告警信息接收人的地址表示方式也会有所不同 在Alertmanager上定义路由规则(route) 以便将收到的告警通知按需分别进行处理 alertmanager的route配置段支持定义树状路由表 入口位置成为根节点 每个字节点可以基于匹配条件定义出一个独立的路由分支 所有告警都将进入路由根节点 而后进行子节点遍历 若路由上的continue字段的值为false 则遇到第一个匹配的路由分支后即终止 否则将继续匹配后续的字节点 在Prometheus上定义告警规则生成告警通知 发送给Alertmanager Alertmanager特性 除了基本的告警通知能力外 Alertmanager还支持对告警进行去重、分组、抑制、静默和路由等功能 分组(Grouping): 将相似告警合并为单个告警通知的机制 在系统因大面积故障而出发告警潮时 分组机制能避免用户被大量的告警噪声淹没 进行导致关键信息的隐没 抑制(Inhibition): 系统中某个组件或服务故障而出发告警通知后 那些依赖于该组件或服务的其它组件或服务可能也会因此而触发告警 抑制便是避免类似的级联告警的一种特性 从而让用户能将精力集中于真正的故障所在 静默(Slience): 是指在一个特定的时间窗口内 即便接收到告警通知 Alertmanager也不会真正向用户发送告警信息的行为 通常 在系统例行维护期间 需要激活告警系统的静默特性 路由(Route): 用于配置Alertmanager如何处理传入的特定类型的告警通知 其基本逻辑是根据路由匹配规则的匹配结果来确定处理当前告警通知的路径和行为 告警规则 类似于记录规则 有着类似或相关联功能的告警规则同样可以组织为group 从而为规则名称提供名称空间 一个组内的每个告警必须有个名称 且在该组内必须唯一 alert: 告警规则的名称 expr: 基于PromQL表达式的告警触发条件(布尔表达式) 用于计算是否有时间序列可以满足该条件 可以使用由Recording rule定义的指标 for: 控制在出发告警之前 测试表达式的值必须为true的时长 表达式为true 但其持续时间为能满足for定义的时长时 相关的告警状态为pending状态 满足该时长之后 相关的告警将被触发 并转为firing状态 表达式的值为false时 告警将处于inactive状态 labels: 告警规则被激活时 相关时间序列上的所有标签都会添加到生成告警示例上 而labels则允许用户在告警上附加其它自定义的标签 该类标签值支持模版化 告警名称及其标签则为告警的标识 类似于时间序列的标识机制 annotations: 附加在告警之上的注解信息 其格式类似于标签 但不能被用于标识告警实例 经常用于存储告警摘要 且其值支持模版化 告警路由 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 [ receiver: \u0026lt;string\u0026gt; ] # The labels by which incoming alerts are grouped together. For example, # multiple alerts coming in for cluster=A and alertname=LatencyHigh would # be batched into a single group. # # To aggregate by all possible labels use the special value \u0026#39;...\u0026#39; as the sole label name, for example: # group_by: [\u0026#39;...\u0026#39;] # This effectively disables aggregation entirely, passing through all # alerts as-is. This is unlikely to be what you want, unless you have # a very low alert volume or your upstream notification system performs # its own grouping. # 分组时使用的标签 默认情况下 所有的告警都组织在一起 而一旦指定分组标签 则Alertmanager将按这些标签进行分组 [ group_by: \u0026#39;[\u0026#39; \u0026lt;labelname\u0026gt;, ... \u0026#39;]\u0026#39; ] # Whether an alert should continue matching subsequent sibling nodes. [ continue: \u0026lt;boolean\u0026gt; | default = false ] # DEPRECATED: Use matchers below. # A set of equality matchers an alert has to fulfill to match the node. match: [ \u0026lt;labelname\u0026gt;: \u0026lt;labelvalue\u0026gt;, ... ] # DEPRECATED: Use matchers below. # A set of regex-matchers an alert has to fulfill to match the node. match_re: [ \u0026lt;labelname\u0026gt;: \u0026lt;regex\u0026gt;, ... ] # A list of matchers that an alert has to fulfill to match the node. matchers: [ - \u0026lt;matcher\u0026gt; ... ] # How long to initially wait to send a notification for a group # of alerts. Allows to wait for an inhibiting alert to arrive or collect # more initial alerts for the same group. (Usually ~0s to few minutes.) # 发出一组告警通知的初始等待时长 允许等待一个抑制告警到达或收集属于同一组的更多初始告警 通常是0至数分钟 [ group_wait: \u0026lt;duration\u0026gt; | default = 30s ] # How long to wait before sending a notification about new alerts that # are added to a group of alerts for which an initial notification has # already been sent. (Usually ~5m or more. # 发送关于新告警的消息之前 需要等待多久 新告警将被添加到已经发送了初始通知的告警组中 一般在5分钟或以上 [ group_interval: \u0026lt;duration\u0026gt; | default = 5m ] # How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more). # 成功发送了告警后再次发送告警信息需要等待的时长 一般至少为3个小时 [ repeat_interval: \u0026lt;duration\u0026gt; | default = 4h ] # Times when the route should be muted. These must match the name of a # mute time interval defined in the mute_time_intervals section. # Additionally, the root node cannot have any mute times. # When a route is muted it will not send any notifications, but # otherwise acts normally (including ending the route-matching process # if the `continue` option is not set.) mute_time_intervals: [ - \u0026lt;string\u0026gt; ...] # Times when the route should be active. These must match the name of a # time interval defined in the time_intervals section. An empty value # means that the route is always active. # Additionally, the root node cannot have any active times. # The route will send notifications only when active, but otherwise # acts normally (including ending the route-matching process # if the `continue` option is not set). active_time_intervals: [ - \u0026lt;string\u0026gt; ...] # Zero or more child routes. # 自路由配置 routes: [ - \u0026lt;route\u0026gt; ... ] Prometheus Server高可用 Scaling and Federating Prometheus\nHow much RAM does Prometheus 2.x need for cardinality and ingestion\nAlertmanager高可用 alertmanager-HA\nPromQL Example 1 # 待更新 ","date":"2020-12-10T21:36:00+08:00","permalink":"https://ilolicon.github.io/p/prometheus/","title":"Prometheus"},{"content":"\n主机级虚拟化 Type1和Type2虚拟机管理程序区别\nType1 1 2 Type1虚拟机管理程序直接在主机的物理硬件上运行 它被称为裸机虚拟机管理程序 它不必预先加载底层操作系统 通过直接访问底层硬件而无需其他软件(例如操作系统和设备驱动程序) VMware ESXi Microsoft Hyper-V服务器 开源KVM \u0026hellip; Type2 1 2 Type2虚拟机管理程序通常安装在现有操作系统之上 它称为托管虚拟机管理程序 因为它依赖于主机预先安装的操作系统来管理对CPU/内存/存储和网络资源的调用 VMware Fusion Oracle VM VirtualBox 用于x86的Oracle VM Server Oracle Solaris Zones Parallels VMware Workstation \u0026hellip; 容器级虚拟化 Namespace man-namespaces\nnamespaces API\n1 2 3 4 5 clone() # Creating a child in a new namespace setns() # Joining an existing namespace unshare() # Leaving a namespace Linux Namespaces\nnamespace 系统调用参数 隔离内容 内核版本 UTS CLONE_NEWUTS 主机名和域名 2.6.19 IPC CLONE_NEWIPC 信号量/消息队列/共享内存 2.6.19 PID CLONE_NEWPID 进程编号 2.6.24 Network CLONE_NEWNET 网络设备/网络栈/端口等 2.6.29 Mount CLONE_NEWNS 挂载点(文件系统) 2.4.19 User CLONE_NEWUSER 用户和用户组 3.8 Control Groups man-cgroups\nlinux资源管理之cgroups简介\n1 2 3 4 cgroups是Linux内核提供的一种可以限制单个进程或者多个进程所使用资源的机制 可以对cpu/内存等资源实现精细化的控制 cgroups 的全称是control groups cgroups为每种可以控制的资源定义了一个子系统 典型的子系统介绍如下 blkio 块设备IO cpu CPU cpuacct CPU资源使用报告 cpuset 多处理器平台上的CPU集合(按核/按比例) devices 设备访问 freezer 挂起或恢复任务 memory 内存用量及报告 perf_event 对cgroup中的任务进行统一性能测试 net_cls cgroup中的任务创建的数据报文的类别标识符 LXC whats-a-linux-container\nLinuX Container lxc-create(创建namespace) template(拉取所需发行版的仓库相关包进行安装) 容器编排 machine + swarm + docker compose(单机编排) mesos + marathon kubernetes(k8s) Docker 1 2 3 4 # docker 容器引擎的发展 # LXC -\u0026gt; libcontainer -\u0026gt; runC -\u0026gt; libcontainer(docker研发的容器引擎 替换LXC) -\u0026gt; runC(容器运行时环境标准 Docker将RunC捐赠给OCI作为OCI容器运行时标准的参考实现) docker/containerd/runC分别是什么\nOCI Open Container Initiative\n由Linux基金会主导于2015年6月创立 旨在围绕容器格式和运行时制定一个开放的工业化标准 contains two specifications the Runtime Specification (runtime-spec) 运行时标准(规范) the Image Specification (image-spec) 镜像格式标准(规范) The Runtime Specification outlines how to run a \u0026ldquo;filesystem bundle\u0026rdquo; that is unpacked on disk At a high-level an OCI implementation would download an OCI Image then unpack that image into an OCI Runtime filesystem bundle runC runC\nOCF: Open Container Format runC: runc is a CLI tool for spawning and running containers on Linux according to the OCI specification docker architecture 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Client -\u0026gt; Daemon(REST API, over UNIX sockets or a network interface) Registry -\u0026gt; Host(https/http) Registry: 仓库名(repo name) + 标签(tag) 唯一标识一个镜像 -\u0026gt; nginx:1.14.0 -\u0026gt; nginx:latest(default 最新版) Images: An image is a read-only template with instructions for creating a Docker container Images：静态的 不会运行 Containers：动态 有生命周期 类似命令 /bin/ls - ls /etc - ls /var Moby docker-ee # 企业版 docker-ce # 社区版 docker objects docker objects\nimages containers networks volumes plugins other objects Images An image is a read-only template with instructions for creating a Docker container Often, an image is based on another image, with some additional customization You might create your own images or you might only use those created by others and published in a registry Containers A container is a runnable instance of an image You can create/start/stop/move or delete a container using the Docker API or CLI You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state docker install Install Docker Engine\n阿里云Mirrors docker-ce\ndocker-ce.repo 1 2 3 4 5 6 7 [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/stable # baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg 镜像加速 docker cn 阿里云官方镜像加速 中国科技大学 1 2 3 4 5 6 7 # 配置文件 /etc/docker/daemon.json # 更换镜像下载仓库链接 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;系统分配前缀.mirror.aliyuncs.com \u0026#34;] } docker cli docekr-reference\n1 2 3 docker --help # docker event state 涉及部分常用命令 docker event state docker image 1 Docker镜像含有启动容器所需的文件系统及其内容 因此 其用于创建并启动docker容器 docker image layer 采用分层构建机制 最底层为bootfs 其它为rootfs bootfs: 用于系统引导的文件系统 包括bootloader和kernel 容器启动完成后会被卸载以节约内存资源 rootfs: 位于bootfs之上 表现为docker容器的根文件系统 传统模式中 系统启动时 内核挂载rootfs时会首先将其挂载为只读模式(自检) 完整性自检完成后将其重新挂载为读写模式 docker中 rootfs由内核挂载为只读模式 而后通过联合挂载技术额外挂载一个可写层 docker image layer 位与下层的镜像成为父镜像(parent image) 最底层的称为基础镜像(base image) 最上层的为可读写层 其下的均为只读层 aufs Advanced Mult-Layered Unification Filesystem 高级多层统一文件系统 用于为Linux文件系统实现联合挂载 aufs是之前UnionFS的重新实现 2006年由Junjiro Okajima开发 Docekr最初使用aufs作为容器文件系统层 它目前仍作为存储后端之一来支持 aufs的竞争产品是overlayfs 后者自从3.18版本开始被合并到Linux内核 docker的分层镜像 除aufs之外 docker还支持btrfs/devicemapper/vfs等 Ubuntu系统下 docekr默认Ubuntu的aufs 而在CentOS7上 用的是devicemapper(新版默认使用overlay2) docekr registry 1 启动容器时 docker daemon 会试图从本地获取相关的镜像 本地镜像不存在时 其将从Registry中下载该镜像并保存到本地 Registry用于保存docker镜像 包括镜像的层次结构和元数据 用户可以自建Registry 也可以使用官方的Docker Hub 分类 Sponsor Registry: 第三方的registry 供客户和Docker社区使用(捐赠者) Mirror Registry: 第三方的registry 只让客户使用(云) Vendor Registry: 由发布Docker镜像的供应商提供的registry(redhat) Private Registry: 通过设有防火墙和额外安全层的私有实体提供的registry(自建) docker-registry/docker-distribution harbor registry(repository and index) Repository 由某特定的docker镜像的所有迭代版本组成的镜像仓库 一个Registry中可以存在多个Repository Repository可分为顶层仓库和用户仓库 用户仓库名称格式为用户名/仓库名 =\u0026gt; ilolicon/nginx 每个仓库可以包含多个Tag(标签) 每个标签对应一个镜像 Index 维护用户账户/镜像的校验以及公共命名空间的信息 相当于为Registry提供一个完成用户认证等功能的检索接口 docker hub DockerHub\nDocker Hub provides the following major features:\nRepositories: Push and pull container images Teams \u0026amp; Organizations: Manage access to private repositories of container images Docker Official Images: Pull and use high-quality container images provided by Docker Docker Verified Publisher Images: Pull and use high- quality container images provided by external vendors Builds: Automatically build container images from GitHub and Bitbucket and push them to Docker Hub Webhooks: Trigger actions after a successful push to a repository to integrate Docker Hub with other services docker pull pull-commandline\nquay.io\n1 2 3 4 5 6 7 8 9 $ docker pull \u0026lt;registry\u0026gt;[:port]/[\u0026lt;namespace\u0026gt;/]\u0026lt;name\u0026gt;:\u0026lt;tag\u0026gt; # e.g: # registry: quay.io # port: 443(没指定 默认) # namespace: coreos # name: flannel(repostory名称) # tag: v0.15.1-arm64 指定版本 $ docker pull quay.io/coreos/flannel:v0.15.1-arm64 Namespace Examples(\u0026lt;namespace/name\u0026gt;) organization redhat/kubernetes google/kubernetes login(user name) alice/application ilolicon/application role devel/database test/database prod/database 镜像的相关操作 镜像的生成途径\nDockerfile 基于容器制作 Docekr Hub automated builds(仍是基于Dockerfile) 另一种镜像分发方式\ndocker-save docker-load 容器虚拟化网络 容器虚拟化网络概述 容器虚拟化网络\n1 2 3 4 5 6 7 8 9 10 11 12 13 OVS: Open VSwitch SDN Overlay Network(叠加网络) # docker默认的三种网络 [ilolicon@master ~]$ docker network ls NETWORK ID NAME DRIVER SCOPE 78fa953ed316 bridge bridge local # 桥接 默认NAT桥 8ec55273feb2 host host local # 让容器直接使用宿主机的网络名称空间 9081fe29a218 none null local # 只有lo接口 没有其他网卡 [ilolicon@master ~]$ yum -y install bridge-utils [ilolicon@master ~]$ brctl show docker-docs:network overview\nClosed Container Bridged Container(NAT桥接网络 默认) Joined Container(联盟式容器网络 相对隔离 只是共享同一个网络名称空间) Open Container(开放式容器网络 共享宿主机网络名称空间) Bridged Containers 1 2 3 4 5 6 7 8 9 # Bridged Containers可以为docker run命令使用 # \u0026#34;--hostname HOSTNAME\u0026#34; 选项为容器指定主机名 $ docker run --rm --net bridge --hostname cloudnative.ilolicon.com busybox:latest hostname # \u0026#34;--dns DNS_SERVER_IP\u0026#34; 选项能够为容器指定所使用的dns服务器地址 $ docker run --rm --dns 8.8.8.8 --dns 8.8.4.4 busybox:latest nslookup docker.com # \u0026#34;--add-host HOSTNAME:IP\u0026#34; 选项能够为容器指定本地主机名解析项 $ docker run --rm --dns 172.16.0.1 --add-host \u0026#34;docker.com:172.16.0.100\u0026#34; busybox:latest cat /etc/hosts Opening Inbound Communication / Expose 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -p选项的使用格式 # 将指定的容器端口\u0026lt;containerPort\u0026gt; 映射至主机所有地址的一个动态端口 -p \u0026lt;containerPort\u0026gt; # 将指定的容器端口\u0026lt;containerPort\u0026gt; 映射至指定的主机端口\u0026lt;hostPort\u0026gt; -p \u0026lt;hostPort\u0026gt;:\u0026lt;containerPort\u0026gt; # 将指定的容器端口\u0026lt;containerPort\u0026gt; 映射至主机指定\u0026lt;ip\u0026gt;的动态端口 -p \u0026lt;ip\u0026gt;::\u0026lt;containerPort\u0026gt; # 将指定的容器端口\u0026lt;containerPort\u0026gt; 映射至主机指定\u0026lt;ip\u0026gt;的端口\u0026lt;hostPort\u0026gt; -p \u0026lt;ip\u0026gt;:\u0026lt;hostPort\u0026gt;:\u0026lt;containerPort\u0026gt; \u0026#34;动态端口\u0026#34; 指随机端口 具体的映射结果可使用docker port命令查看 Expose端口 还可以参考 -P 选项：暴露容器内部已指定的端口 Joined Container 联盟式容器是指使用某个已存在容器的网络接口的容器 接口被联盟内的各容器共享使用(NTS Network IPC) 联盟式容器彼此间虽然共享同一个网络名称空间 但其它内部名称空间如: User/Mount等还是隔离的 联盟式容器彼此间存在端口冲突的可能性 使用此种模式的网络模型情况 多个容器上的程序需要程序loopback接口互相通信 对某已存的容器的网络属性进行监控 1 2 3 4 5 6 7 # 创建一个监听于2222端口的http服务容器 $ docker run --name t1 -it --rm busybox / # ifconfig # 创建一个联盟式容器(--network指定使用t1的网络名称空间) 并查看其监听的端口 $ docker run --name t2 -it --rm --network container:t1 busybox / # ifconfig Open Container 1 2 3 # --network 指定 host # 直接使用宿主机的网络名称空间 无需再Expose端口 $ docker run --rm -it --network host busybox Closed Container 1 2 # --network none $ docker run --rm -it --network none busybox 自定义docker0桥的网络信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 编辑 /etc/docker/daemon.json 配置文件 { \u0026#34;bip\u0026#34;: \u0026#34;192.168.1.5/24\u0026#34;, \u0026#34;fixed-cidr\u0026#34;: \u0026#34;10.20.0.0/16\u0026#34;, \u0026#34;fixed-cidr-v6\u0026#34;: \u0026#34;2001:db8::/64\u0026#34;, \u0026#34;mtu\u0026#34;: \u0026#34;1500\u0026#34;, \u0026#34;default-gateway\u0026#34;: \u0026#34;10.20.1.1\u0026#34;, \u0026#34;default-gateway-v6\u0026#34;: \u0026#34;2001:db8:abcd::89\u0026#34;, \u0026#34;dns\u0026#34;: [\u0026#34;10.20.1.2\u0026#34;,\u0026#34;10.20.1.3\u0026#34;] } # 核心选项为bip 即bridge ip之意 # 用于指定docker0桥自身的IP地址 其他选项可以通过此地址计算得出 使用TCP套接字 1 2 3 4 5 6 7 # dockerd守护进程的C/S 其默认仅监听Unix Socket格式的地址 /var/run/docker.sock # 如果使用TCP套接字 需要修改 /etc/docekr/daemon.json 配置文件 # 也可向dockerd直接传递 \u0026#34;-H|--host\u0026#34;选项 { \u0026#34;hosts\u0026#34;: [\u0026#34;tcp://0.0.0.0:2375\u0026#34;, \u0026#34;unix:///var/run/docker.sock\u0026#34;] } 1 2 3 # dockerd使用TCP监听0.0.0.0:2375之后 客户端可以远程执行CLI $ docker -H x.x.x.x:2375 image ls $ docker -H x.x.x.x:2375 ps -a 创建自定义网络 1 2 3 4 5 6 7 8 # 创建自定义网络 $ docker network create -d bridge --subnet \u0026#34;172.26.0.0/16\u0026#34; --gateway \u0026#34;172.26.0.1\u0026#34; mybr0 # 使用自定义网络 [ilolicon@master ~]$ docker run -it --rm --name t1 --network mybr0 busybox / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:1A:00:02 inet addr:172.26.0.2 Bcast:172.26.255.255 Mask:255.255.0.0 docker存储卷 Why Data Volumes(存储卷) 1 2 3 4 5 6 Docker镜像由多个\u0026#34;只读层\u0026#34;叠加而成 启动容器时 Docker会加载只读镜像层并在镜像栈顶部添加一个\u0026#34;读写层\u0026#34; 如果运行中的容器修改了现有的一个已经存在的文件 那该文件将会从读写层下面的只读层复制到读写层 该文件的只读版本\u0026#34;仍然存在\u0026#34; 只是已经被读写层中该文件的副本所隐藏 此即\u0026#34;写时复制(COW)\u0026#34;机制 关闭并重启容器 其数据不受影响 但删除Docker容器 则其更改将会全部丢失 存在的问题 存储于联合文件系统中 不易于宿主机访问(效率低) 容器间数据共享不便 删除容器其数据会丢失 解决方案: \u0026ldquo;卷(volume)\u0026rdquo; 卷是容器上的一个或多个目录 此类目录可绕过联合文件系统 与宿主机上的某目录绑定(关联) Volume于容器初始化之时即会创建 由base image提供的卷中的数据会于此期间完成复制 Volume的初衷是独立于容器的生命周期实现数据持久化 因此删除容器之时既不会删除卷 也不会对哪怕未被引用的卷做垃圾回收操作(加选项可以) 卷为docker提供了独立于容器的数据管理机制 可以把镜像想象成静态文件 -\u0026gt; 例如 程序; 把卷类比为动态内容 -\u0026gt; 例如 数据; 于是 镜像可以重用 而卷可以共享 卷实现了程序(镜像) 和 数据(卷) 分离 以及 程序(镜像) 和 制作镜像的主机 分离; 用户制作镜像时无需再考虑镜像运行的容器所在的主机的环境 Data volumes 1 Docekr有两种类型的卷 每种类型都在容器中存在一个挂载点 但在其宿主机上的位置有所不同 Bind mount volume(绑定挂在卷) a volume that points to a user-specified location on the host file system Docker-managed volume(Docker管理卷) the Docker daemon creates managed volumes in a portion of the host\u0026rsquo;s file system that\u0026rsquo;s owned by Docker 1 2 3 4 5 6 7 8 9 10 # 在容器中使用Volumes # 为docker run命令使用-v选项即可使用Volume # Docker-managed volume $ docker run -it --name t1 -v /data busybox $ docker inspect -f {{.Mounts}} t1 # Bind-mount Volume $ docker run -it -v HOSTDIR:VOLUMEDIR --name t2 bustbox $ docker inspect -f {{.Mount}} t2 Sharing volumes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # There are tow ways to share volumes between containers # 多个容器的卷使用同一个主机目录 $ docker run -it --name t1 -v /docker/volumes/v1:/data busybox $ docker run -it --name t2 -v /docker/volumes/v1:/data busybox # 复制使用其他容器的卷 为docker run命令使用 --volumes-from 选项 $ docker run -it --name t3 -v /docker/volumes/v1:/data busybox $ docker run -it --name t4 --volumes-from t3 busybox # 如果有多个容器需要共享网络名称空间(UTS Network IPC) 以及需要共享存储卷 # 可以 事先创建一个 基础容器 其他的容器都加入该容器的网络名称空间(Joined Container) 并且复制该容器使用的卷(--volumes-from) $ docker run --name infracon -it -v /data/infracon/volume:/data busybox $ docker run --name nginx --network container:infracon --volumes-from infracon -it nginx $ docker run ... --network container:infracon --volumes-from infracon ... Dockerfile Dockerfile-reference\nDockerfile is nothing but the source code for building Docker images\nDocker can build images automatically by reading the instructions from a Dockerfile A Dockerfile is a text document than contains all the commands a user could call on the command line to assemble an image Using docker build users can create an automated build that executes several command-line instructions in succession Dockerfile Format Format # Comment (注释) INSTRUCTION arguments (指令及其参数 通常一行一个执行 太长使用\\换行) The instruction is not case-sensitive (指令大小写不敏感) However, convention is for them to be UPPERCASE to distinguish them from arguments more easily (一般约定使用大写 和参数区分开) Docker runs instructions in a Dockerfile in order (顺序执行) The first instruction must be FROM in order to specify the Base Image from which you are building (第一个非指数行 必须为FROM指令) .dockerignore file Before the docker CLI sends the context to the docker daemon, it looks for a file named .dockerignore in the root directory of the context If this file exists, the CLI modifies the context to exclude files and directories than match patterns in it The CLI interprets the .dockerignore file as a newline-separated list of patterns similar to the file globs of Unix shells Environment replacement Environment variables (declared with the ENV statement) can also be used in certain instructions as variables to be interpred by the Dockerfile Environment variables are notated in the Dockerfile either with $variable_name or ${variable_name} The ${variable_name} syntax also supports a few of the standard bash modifiers ${variable:-word} - 设置默认值 variable未设置或为空 则变量默认值为: word ${variable:+word} - 和 ${variable:-word} 相反 Docekrfile Instructions FROM FROM指令是最重要的一个且必须为Docekrfile文件开篇的第一个非注释行 用于为镜像文件构建过程指定基准镜像 后续的指令运行于此基准镜像所提供的运行环境 实践中 基准镜像可以是任何可用镜像文件 默认情况下 docekr build会在docker主机上查找指定的镜像文件 在其不存在时 则会从Docker Hub Registry上拉取所需的镜像文件 如果找不到执行的镜像文件 docker build会返回一个错误信息 Syntax FROM \u0026lt;repository\u0026gt;[:\u0026lt;tag\u0026gt;] 或 FROM \u0026lt;repository\u0026gt;@\u0026lt;digest\u0026gt; @符号指定hash码 确保base image不会被篡改 \u0026lt;repository\u0026gt; 指定作为 base image 的名称 \u0026lt;tag\u0026gt; base image 的标签 可选 省略时默认为latest MAINTANIER(deprecated) 用于让Docekrfile制作者提供本人的详细信息 Dockerfile并不限制MAINTANIER指令出现的位置 但推荐将其放置于FROM指令后 Syntax MAINTANIER \u0026lt;author's detail\u0026gt; \u0026lt;author's detail\u0026gt;可以是任何文本信息 但约定俗成地使用作者名称及其邮件地址 MAINTANIER \u0026quot;ilolicon \u0026lt;97431110@qq.com\u0026gt;\u0026quot; LABEL The LABEL instruction adds metadata to an image (可替换MAINTANIER 并可添加更多元数据信息)\nSyntax: LABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... The LABEL instruction adds metadata to an image A LABEL is a key-value pair To include spaces within a LABEL value, use quotes and backslashes as you would in command-line parsing An image can have more than one label You can specify multiple labels on a single line COPY 用于从Docker主机复制文件至创建的新镜像文件 Syntax COPY \u0026lt;src\u0026gt; ... \u0026lt;dest\u0026gt; 或 COPY [\u0026quot;\u0026lt;src\u0026gt;\u0026quot;, ..., \u0026quot;\u0026lt;dest\u0026gt;\u0026quot;] \u0026lt;src\u0026gt; 要复制的源文件或目录 支持使用通配符 \u0026lt;dest\u0026gt; 目标路径 即正在创建的image的文件系统路径 建议\u0026lt;dest\u0026gt;使用绝对路径 否则COPY指令则以WORKDIR为其起始路径 注意: 在路径中有空白符时 通常使用第二种格式 文件复制准则 \u0026lt;src\u0026gt;必须是build上下文中的路径 不能是其父目录中的文件 如果\u0026lt;src\u0026gt;是目录 则其内部文件或子目录会被递归复制 但是\u0026lt;src\u0026gt;目录本身不会被复制 如果指定多个\u0026lt;src\u0026gt; 或在\u0026lt;src\u0026gt;中使用了通配符 则\u0026lt;dest\u0026gt;必须是一个目录 且必须以/结尾 如果\u0026lt;dest\u0026gt;事先不存在 它将会被自动创建 这包括其父级目录 ADD ADD指令类似于COPY指令 ADD支持使用TAR文件和URL路径 Syntax ADD \u0026lt;src\u0026gt; ... \u0026lt;dest\u0026gt; 或 ADD [\u0026quot;\u0026lt;src\u0026gt;\u0026quot;, ..., \u0026quot;\u0026lt;dest\u0026gt;\u0026quot;] 操作准则 同COPY指令 URL 如果\u0026lt;src\u0026gt;为URL且\u0026lt;dest\u0026gt;不以/结尾 则\u0026lt;src\u0026gt;指定的文件将被下载并直接被创建为\u0026lt;dest\u0026gt; 如果\u0026lt;src\u0026gt;为URL且\u0026lt;dest\u0026gt;以/结尾 则文件名URL指定的文件将被下载并保存为\u0026lt;dest\u0026gt;/\u0026lt;filename\u0026gt; TAR 如果\u0026lt;src\u0026gt;是一个本地系统上的压缩格式的tar文件 它将被展开为一个目录 其行为类似于tar -x命令 然而 通道URL获取到的tar文件将不会自动展开 如果\u0026lt;src\u0026gt;有多个 或其间接或直接使用了通配符 则\u0026lt;dest\u0026gt;必须是一个以/结尾的目录路径 如果\u0026lt;dest\u0026gt;不以/结尾 则其将被视为一个普通文件 \u0026lt;src\u0026gt;的内容将被直接写入到\u0026lt;dest\u0026gt; WORKDIR 用于为Dockerfile中所有的RUN/CMD/ENTRYPOINT/COPY/ADD指令设置工作目录 Syntax WORKDIR \u0026lt;dirpath\u0026gt; 在Dockerfile中 WORKDIR指令可以出现多次 其路径也可以为相对路径 不过其是相对此前一个WODKDIR指令指定的路径 另外 WORKDIR也可调用由ENV指令定义的变量 e.g WORKDIR /var/log WORKDIR $STATEPATH VOLUME 用于在image中创建一个挂载点目录 以挂载Docker host上的卷或其他容器上的卷 Syntax VOLUME \u0026lt;mountpoint\u0026gt; 或 VOLUME [\u0026quot;\u0026lt;mountpoint\u0026gt;\u0026quot;] 如果挂载点目录路径下此前在文件存在 docker run命令会在挂载完成后将此前的所有文件复制到新挂载的卷中 EXPOSE 用于为容器打开指定要监听的端口 以实现与外部通信 Syntax EXPOSE \u0026lt;port\u0026gt;[/\u0026lt;protocol\u0026gt;] [\u0026lt;port\u0026gt;[/protocol]...] \u0026lt;protocol\u0026gt;用于指定传输层协议 可为tcp或udp二者之一 默认为TCP协议 EXPOSE指令可一次指定多个端口 EXPOSE 11211/udp 11211/tcp ENV 用于为镜像定义所需的环境变量 并可被Dockerfile文件中位与其后的其它指令(如ENV/ADD/COPY等)所调用 调用格式为 $variable_name 或 ${variable_name} Syntax ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; 或 ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... 第一种格式中: \u0026lt;key\u0026gt;之后的所有内容均会被视作其\u0026lt;value\u0026gt;的组成部分 因此 一次只能设置一个变量 第二种格式中: 可以一次设置多个变量 每个变量为一个\u0026lt;key\u0026gt;=\u0026lt;value\u0026gt;的键值对 如果\u0026lt;value\u0026gt;中包含空格 可以以反斜线\\进行转义 也可以通过对\u0026lt;value\u0026gt;加引号进行标识 另外 反斜线也用于续行 定义多个变量时 建议使用第二种方式 以便在同一层中完成所有功能 RUN 用于指定docker build过程中运行的程序 其可以是任何命令(基于base image提供) Syntax RUN \u0026lt;command\u0026gt; 或 RUN [\u0026quot;\u0026lt;executable\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param2\u0026gt;\u0026quot;] 第一种格式中 \u0026lt;command\u0026gt; 通常是一个shell命令 且以/bin/sh -c来运行它 这意味着此进程在容器中的PID不是1 不能接收Unix信号 因此 当使用docker stop \u0026lt;container\u0026gt;命令停止容器时 此进程接收不到SIGTERM信号 第二种语法格式中的参数是一个JSON格式的数组 其中\u0026lt;executable\u0026gt;为要运行的命令 后面的\u0026lt;paramN\u0026gt;为传递给命令的选项或参数 然而 此种格式指定的命令不会以/bin/sh -c来发起 因此常见的shell操作如变量替换以及通配符? *等替换将不会进行 不过如果要运行的命令依赖于此shell特性的话 可以将其替换为类似下面的格式 RUN [\u0026quot;/bin/sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;\u0026lt;executable\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param1\u0026gt;\u0026quot;] Json数组中 注意要使用双引号 CMD 类似于RUN指令 CMD指令也可用于运行任何命令或应用程序 不过 二者的运行时间点不同 RUN指令运行于映像文件构建过程中 而CMD指令运行于基于Dockerfile构建出的新映像文件启动一个容器时 CMD指令的首要目的在于为启动的容器指定默认要运行的程序 且其运行结束后 容器也将终止 不过CMD指定的命令可以被docker run的命令行选项所覆盖 在Docekrfile中 可以存在多个CMD指令 但仅最后一个会生效 Syntax CMD \u0026lt;command\u0026gt; 或 CMD [\u0026quot;\u0026lt;executable\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param2\u0026gt;\u0026quot;] 或 CMD [\u0026quot;\u0026lt;param1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param2\u0026gt;\u0026quot;] 前两种语法格式的意义同RUN 都三种则用于为ENTRYPOINT指令提供默认参数 ENTRYPOINT 类似CMD指令的功能 用于为容器指定默认运行程序 从而使得容器像是一个单独的可执行程序 与CMD不同的是 由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖 而且 这些命令行参数会被当作参数传递给ENTRYPOINT指令指定的程序 不过 docker run命令的--entrypoint选项的参数 可以覆盖ENTRYPOINT指令指定的程序 Syntax ENTRYPOINT \u0026lt;command\u0026gt; ENTRYPOINT [\u0026quot;\u0026lt;executable\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;param2\u0026gt;\u0026quot;] docker run命令传入的命令参数会覆盖CMD指令的内容 并且附加到ENTRYPOINT命令最后作为其参数使用 Dockerfile文件中也可以存在多个ENTRYPOINT指令 但仅有最后一个会生效 Tips: 使用ENTRYPOINT解决配置文件环境变量使用问题\n1 2 3 # 问题: nginx(或其他程序)配置文件有许多需要修改的配置 # 比如: root_dir / listen_ip / listen_port 等等 # 使用容器的情况下 如何更优的解决该问题? docker-entrypoint.sh refer:MySQL dokcer-entrypoint.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/sh # 根据变量(环境变量/自定义变量)生成配置文件 # 需要修改的 传入环境变量的方式 比如: APP_ENV: TEST|PROD|DEV # docker run -d --name=ngx --env PORT=8080 --env XX=XX --rm ngx:v1 IP=$(ip address show dev eth0 | awk \u0026#39;/inet /{split($2, ip, \u0026#34;/\u0026#34;);print ip[1]}\u0026#39;) cat \u0026gt; /etc/nginx/conf.d/www.conf \u0026lt;\u0026lt; EOF server { server_name ${HOSTNAME}; listen ${IP:-0.0.0.0}:${PORT:-80}; root ${NGX_DOC_ROOT:-/usr/share/nginx/html/}; } EOF # Dockerfile CMD指定的参数($@) 取代当前shell 成为 main-process exec \u0026#34;$@\u0026#34; Dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 FROM nginx:1.14-alpine LABEL maintainer=\u0026#34;ilolicon \u0026lt;97431110@qq.com\u0026gt;\u0026#34; ENV NGX_DOC_ROOT=\u0026#34;/data/www/html/\u0026#34; ADD index.html $NGX_DOC_ROOT ADD docker-entrypoint.sh /bin/ CMD [\u0026#34;/usr/sbin/nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off\u0026#34;] # CMD指令参数 传递给docker-entrypoint.sh脚本 脚本用$@获取全部参数 ENTRYPOINT [\u0026#34;/bin/docker-entrypoint.sh\u0026#34;] USER 用于指定运行image时或运行Dockerfile中任何RUN CMD 或 ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下 container的运行身份为root用户 Syntax USER \u0026lt;UID\u0026gt;|\u0026lt;UserName\u0026gt; 需要注意的是 \u0026lt;UID\u0026gt;可以为任意数字 但实践中其必须为/etc/passwd(容器中)中某用户的有效UID 否则docker run命令将运行失败 HEALTHCHECK HEALTHCHECK\nThe HEALTHCHECK instruction tells Docker how to test a container to check that it is still working This can detect cases such as a web server that is stuck in an infinite loop and unable to handle new connections, even though the server process is still running The HEALTHCHECK instruction has two forms HEALTHCHECK [OPTIONS] CMD command (check container health by running a command inside the container) HEALTHCHECK NONE (disable any healthcheck inherited from the base image) The options that can appear before CMD are: \u0026ndash;interval=DURATION (default: 30s) \u0026ndash;timeout=DURATION (default: 30s) \u0026ndash;start-period=DURATION (default: 0s) - 多少秒之后开始检测 等待container init的时间 \u0026ndash;retries=N (default: 3) The command’s exit status indicates the health status of the container. The possible values are: 0: success - the container is healthy and ready for use 1: unhealthy - the container is not working correctly 2: reserved - do not use this exit code - 预留 不要使用 For example HEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1 SHELL SHELL\nThe SHELL instruction allows the default shell used for the shell form of commands to be overridden The default shell on Linux is [\u0026quot;/bin/sh\u0026quot;, \u0026ldquo;-c\u0026rdquo;], and on Windows is [\u0026ldquo;cmd\u0026rdquo;, \u0026ldquo;/S\u0026rdquo;, \u0026ldquo;/C\u0026rdquo;] The SHELL instruction must be written in JSON form in a Dockerfile Syntax: SHELL [\u0026ldquo;executable\u0026rdquo;, \u0026ldquo;parameters\u0026rdquo;] The SHELL instruction can appear multiple times Each SHELL instruction overrides all previous SHELL instructions, and affects all subsequent instruction STOPSIGNAL STOPSIGNAL\nThe STOPSIGNAL instruction sets the system call signal that will be sent to the container to exit This signal can be a signal name in the format SIG\u0026lt;NAME\u0026gt;, for instance SIGKILL, or an unsigned number that matches a position in the kernel’s syscall table, for instance 9 The default is SIGTERM if not defined Syntax: STOPSIGNAL signal ARG ARG\nThe ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the --build-arg \u0026lt;varname\u0026gt;=\u0026lt;value\u0026gt; flag If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning [Warning] One or more build-args [foo] were not consumed. Syntax: ARG \u0026lt;name\u0026gt;[=\u0026lt;default value\u0026gt;] A Dockerfile may include one or more ARG instructions An ARG instruction can optionally include a default value: ARG user1=someuser ARG buildno=1 ⚠️ Warning It is not recommended to use build-time variables for passing secrets like github keys, user credentials etc. Build-time variable values are visible to any user of the image with the docker history command.\nRefer to the \u0026ldquo;build images with BuildKit\u0026rdquo; section to learn about secure ways to use secrets when building images.\nONBUILD 用于在Dockerfile中定义一个触发器 Dockerfile用于build映像文件 此映像文件亦可作为base image被另一个Dockerfile用作FROM指令的参数 并以之构建新的镜像文件 在后面的这个Dockerfile中的FROM指令在build过程中被执行时 将会触发创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 Syntax ONBUILD \u0026lt;INSTRUCTION\u0026gt; 尽管任何指令都可以注册成为触发器指令 但ONBUILD不能自我嵌套 且不会触发FROM和MAINTAINER指令 使用包含ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签 e.g: ruby:2.0-onbuild 在ONBUILD指令中使用ADD或COPY指令应该格外小心 因为新 构建过程的上下文在缺少指定的源文件时会失败 Docker资源限制 Limit a container\u0026rsquo;s resources\nBy default, a container has no resource constraints and can use as much of a given resource as the host’s kernel scheduler allows Docker provides ways to control how much memory, or CPU a container can use, setting runtime configuration flags of the docker run command Many of these features require your kernel to support Linux capabilities To check for support, you can use the docker info command OOME On Linux hosts, if the kernel detects that there is not enough memory to perform important system functions, it throws an OOME, or Out Of Memory Exception, and starts killing processes to free up memory 一旦发生OOME 任何进程都有可能被杀死 包括docker daemon在内 为此 Docker特地调整了docker daemon的OOM优先级 以免它被内核\u0026quot;正法\u0026quot; 但容器优先级并为调整 Memory Hogs OOM_ADJ OOM_SCORE Limit a container’s access to memory Docker can enforce hard memory limits, which allow the container to use no more than a given amount of user or system memory or soft limits, which allow the container to use as much memory as it needs unless certain conditions are met, such as when the kernel detects low memory or contention on the host machine Some of these options have different effects when used alone or when more than one option is set Most of these options take a positive integer, followed by a suffix of b, k, m, g, to indicate bytes, kilobytes, megabytes, or gigabytes Option Description -m or --memory= The maximum amount of memory the container can use. If you set this option, the minimum allowed value is 6m (6 megabytes). That is, you must set the value to at least 6 megabytes. --memory-swap * The amount of memory this container is allowed to swap to disk. See --memory-swap details. --memory-swappiness By default, the host kernel can swap out a percentage of anonymous pages used by a container. You can set --memory-swappiness to a value between 0 and 100, to tune this percentage. See --memory-swappiness details. --memory-reservation Allows you to specify a soft limit smaller than --memory which is activated when Docker detects contention or low memory on the host machine. If you use --memory-reservation, it must be set lower than --memory for it to take precedence. Because it is a soft limit, it does not guarantee that the container doesn’t exceed the limit. --kernel-memory The maximum amount of kernel memory the container can use. The minimum allowed value is 4m. Because kernel memory cannot be swapped out, a container which is starved of kernel memory may block host machine resources, which can have side effects on the host machine and on other containers. See --kernel-memory details. --oom-kill-disable By default, if an out-of-memory (OOM) error occurs, the kernel kills processes in a container. To change this behavior, use the --oom-kill-disable option. Only disable the OOM killer on containers where you have also set the -m/--memory option. If the -m flag is not set, the host can run out of memory and the kernel may need to kill the host system’s processes to free memory. \u0026ndash;memory-swap Using swap allows the container to write excess memory requirements to disk when the container has exhausted all the RAM that is available to it --memory-swap is a modifier flag that only has meaning if --memory is also set --memory-swap --memory 功能 正数S 正数M 容器可用总空间为S 其中ram为M swap为(S-M) 若S=M 则无可用swap资源 0 正数M 相当于未设置swap(unset) unset 正数M 若主机(Docker Host)启用了swap 则容器的可用swap为 2*M -1 正数M 若主机(Docker Host)启用了swap 则容器可使用最大至主机的所有swap空间的swap资源 ⚠️ 注意: 在容器内使用free命令可以看到的swap空间 并不具有其所展示出的空间指示意义\nCPU 深入Linux的进程优先级\nBy default, each container’s access to the host machine’s CPU cycles is unlimited You can set various constraints to limit a given container’s access to the host machine’s CPU cycles Most users use and configure the default CFS scheduler You can also configure the realtime scheduler. Configure the default CFS scheduler The CFS is the Linux kernel CPU scheduler for normal Linux processes. Several runtime flags allow you to configure the amount of access to CPU resources your container has. When you use these settings, Docker modifies the settings for the container’s cgroup on the host machine.\nOption Description --cpus=\u0026lt;value\u0026gt; Specify how much of the available CPU resources a container can use. For instance, if the host machine has two CPUs and you set --cpus=\u0026quot;1.5\u0026quot;, the container is guaranteed at most one and a half of the CPUs. This is the equivalent of setting --cpu-period=\u0026quot;100000\u0026quot; and --cpu-quota=\u0026quot;150000\u0026quot;. --cpu-period=\u0026lt;value\u0026gt; Specify the CPU CFS scheduler period, which is used alongside --cpu-quota. Defaults to 100000 microseconds (100 milliseconds). Most users do not change this from the default. For most use-cases, --cpus is a more convenient alternative. --cpu-quota=\u0026lt;value\u0026gt; Impose a CPU CFS quota on the container. The number of microseconds per --cpu-period that the container is limited to before throttled. As such acting as the effective ceiling. For most use-cases, --cpus is a more convenient alternative. --cpuset-cpus Limit the specific CPUs or cores a container can use. A comma-separated list or hyphen-separated range of CPUs a container can use, if you have more than one CPU. The first CPU is numbered 0. A valid value might be 0-3 (to use the first, second, third, and fourth CPU) or 1,3 (to use the second and fourth CPU). --cpu-shares Set this flag to a value greater or less than the default of 1024 to increase or reduce the container’s weight, and give it access to a greater or lesser proportion of the host machine’s CPU cycles. This is only enforced when CPU cycles are constrained. When plenty of CPU cycles are available, all containers use as much CPU as they need. In that way, this is a soft limit. --cpu-shares does not prevent containers from being scheduled in swarm mode. It prioritizes container CPU resources for the available CPU cycles. It does not guarantee or reserve any specific CPU access. 1 2 3 4 5 # If you have 1 CPU, each of the following commands guarantees the container at most 50% of the CPU every second. $ docker run -it --cpus=\u0026#34;.5\u0026#34; ubuntu /bin/bash # Which is the equivalent to manually specifying --cpu-period and --cpu-quota; $ docker run -it --cpu-period=100000 --cpu-quota=50000 ubuntu /bin/bash 测试 stress\n1 2 3 4 5 6 7 8 # 使用stress镜像 进行测试 $ docker run -ti --rm polinux/stress stress --cpu 1 --io 1 --vm 1 --vm-bytes 128M --timeout 1s --verbose # 显示容器的运行进程 $ docker top CONTAINER # 显示容器资源使用统计的实时流 $ docker stats ","date":"2020-06-12T12:10:00+08:00","permalink":"https://ilolicon.github.io/p/docker/","title":"Docker"},{"content":"RESTful API 设计指南\nDjangoRESTframework官网\nDjangoRESTframework 中文教程\nRESTful API API接口： 通过网络 规定了前后台信息交互规则的url链接 也就是前后台信息交互的媒介\n简介 1 2 3 4 5 6 REST 全称：Representational State Transfer 中文意思的表述(通常译为：表征性状态转移) RESTful是一种定义Web API接口的设计风格 尤其适用于前后端分离的应用模式中 这种风格的理念认为：后端开发任务就是提供数据的 对外提供的是数据资源的访问接口 所以在定义接口时 客户端访问的URL路径就表示这种要操作的数据资源 事实上 我们可以使用任何一个框架都可以实现符合restful规范的接口 规范 restful10条规范\n1.协议\n1 URL链接一般都采用https协议进行传输 注：采用https协议 可以提高数据交互过程中的安全性 2.接口特征性表现(一看就知道是API接口)\n用api关键字表示接口url\n1 2 3 - https://api.example.com - https://example.org/api/ # 如果确定API很简单 不会有进一步扩展 可以考虑放在主域名之下 3.多版本共存\n应该将API的版本放入URL(一种资源有多版本请况下)\n1 2 3 4 - https://api.example.com/v1/ - https://api.example.com/v2/ # 另一种做法是 将版本号放在HTTP头信息中 但不如放入URL方便和直观 4.数据即是资源 均使用名字(复数) - 重要\n接口一般都是完成前后台数据的交互 交互的数据我们称之为资源\n1 2 3 4 5 6 7 8 9 - https://api.example.com/v1/zoos - https://api.example.com/v1/animals - https://api.example.com/v1/employees 注：一般提倡用资源的复数形式 在URL链接中不要出现操作资源的动词 # 特殊的接口可以出现动词 因为这些接口一般没有一个明确的资源 或是动词就是接口的核心含义 - https://api.baidu.com/place/search - https://api.baidu.com/login 5.资源操作由请求方式决定(method) - 重要\n操作资源一般都会设计到增删改查 我们提供请求方式来标识这些动作\n1 2 3 4 5 6 - https://api.baidu.com/books - GET请求：获取所有书 - https://api.baidu.com/books/1 GET请求：获取主键为1的书 - https://api.baidu.com/books POST请求：新增一本书 - https://api.baidu.com/books/1 PUT请求：整体修改主键为1的书 - https://api.baidu.com/books/1 PATCH请求：局部修改主键为1的书 - https://api.baidu.com/books DELETE请求：删除主键为1的书 常用的HTTP动词有下面五个(括号里面是对应的SQL命令)\n1 2 3 4 5 - GET(SELECT): 从服务器取出资源(一项或多项资源) - POST(CREATE): 在服务器新建一个资源 - PUT(UPDATE): 在服务器更新资源(客户端提供改变后的完整资源) - PATCH(UPDATE): 在服务器更新资源(客户端提供改变的属性) - DELETE(DELETE): 从服务器删除资源 还有两个不常用的HTTP动词\n1 2 - HEAD: 获取资源的元数据 - OPTIONS: 获取信息 关于资源的哪些属性是客户端可以改变的 6.过滤信息\n1 2 3 4 5 6 7 # 如果记录数量很多 服务器不可能都将它们返回给用户 # API应该提供参数 过滤返回结果 - ?limit=10 指定返回记录的数量 - ?offset=10 指定返回记录的开始位置 - ?page=2\u0026amp;per_page=100 指定第几页，以及每页的记录数 - ?sortby=name\u0026amp;order=asc 指定返回结果按照哪个属性排序，以及排序顺序 - ?animal_type_id=1 指定筛选条件 7.状态码\n状态码完全列表\n服务器向用户返回的状态码和提示信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 常见的有以下一些(方括号中是该状态码对应的HTTP动词) 200 OK - [GET]：服务器成功返回用户请求的数据 该操作是幂等的（Idempotent） 201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功 202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务） 204 NO CONTENT - [DELETE]：用户删除数据成功 301 Moved Permanently 永久重定向 302 Found 暂时重定向 400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误 服务器没有进行新建或修改数据的操作 该操作是幂等的 401 Unauthorized - [*]：表示用户没有权限(令牌、用户名、密码错误) 403 Forbidden - [*] 表示用户得到授权(与401错误相对) 但是访问是被禁止的 404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录 服务器没有进行操作 该操作是幂等的 406 Not Acceptable - [GET]：用户请求的格式不可(比如用户请求JSON格式 但是只有XML格式) 410 Gone -[GET]：用户请求的资源被永久删除 且不会再得到的 422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时 发生一个验证错误 500 INTERNAL SERVER ERROR - [*]：服务器发生错误 用户将无法判断发出的请求是否成功 8.错误处理\n1 2 3 4 5 # 如果状态码是4xx 就应该向用户返回出错信息 # 一般来说 返回的信息中将error作为键名 出错信息作为键值即可 { error: \u0026#34;Invalid API key\u0026#34; } 9.返回结果\n针对不同操作 服务器向用户返回的结果应该符合以下规范\n1 2 3 4 5 6 GET /collection： 返回资源对象的列表(数组) GET /collection/resource： 返回单个资源对象 POST /collection： 返回新生成的资源对象 PUT /collection/resource： 返回完整的资源对象 PATCH /collection/resource： 返回完整的资源对象 DELETE /collection/resource： 返回一个空文档 10.Hypermedia API\n1 2 3 4 5 6 7 8 9 10 RESTful API最好做到Hypermedia 即返回结果中提供链接 连向其他API方法 使得用户不查文档 也知道下一步应该做什么 Hypermedia API的设计被称为HATEOAS Github的API就是这种设计 访问api.github.com会得到一个所有可用API的网址列表 { \u0026#34;current_user_url\u0026#34;: \u0026#34;https://api.github.com/user\u0026#34;, \u0026#34;authorizations_url\u0026#34;: \u0026#34;https://api.github.com/authorizations\u0026#34;, // ... } 其他\n1 2 3 1. API的身份认证应该使用OAuth 2.0框架 2. 服务器返回的数据格式 应该尽量使用JSON 避免使用XML DRF初识 安装 1 pip install djangorestframework==3.12.2 CBV源码 1 2 # ModelViewSet继承自View(django远程的View) # ModelViewSet -\u0026gt; APIView -\u0026gt; View View CBV简单实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # urls.py urlpatterns = [ path(\u0026#39;books/\u0026#39;, views.Books.as_view()), ] # views.py from django.views import View from django.http import JsonResponse class Books(View): def get(self, request): return JsonResponse({\u0026#39;c++\u0026#39;: 111}) \u0026#34;\u0026#34;\u0026#34; 127.0.0.1:8000/books/ GET 通过CBV实现GET请求方法 \u0026#34;\u0026#34;\u0026#34; as_view() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \u0026#34;\u0026#34;\u0026#34; 源码解读：切入口：as_view() 本质还是FBV: views.Books.as_view() -\u0026gt; as_view()返回一个函数对象 -\u0026gt; views.Books.view 如果请求过来 路径匹配上 会执行 views.Books.view的 view内存地址指向的函数对象 并把request参数传入(当次请求的request对象) -\u0026gt; view(request) \u0026#34;\u0026#34;\u0026#34; # as_view()本质 @classonlymethod def as_view(cls, **initkwargs): def view(request, *args, **kwargs): self = cls(**initkwargs) # cls是我们自己写的类 调用的时候自动注入(谁调用 注入谁) # self = LoginView(**initkwargs) 产生一个我们自己写的类的实例 if hasattr(self, \u0026#39;get\u0026#39;) and not hasattr(self, \u0026#39;head\u0026#39;): self.head = self.get self.request = request self.args = args self.kwargs = kwargs return self.dispatch(request, *args, **kwargs) \u0026#34;\u0026#34;\u0026#34; 以后 经常会需要看源码 但是在看Python源码的时候 一定要时刻提醒自己 面向对象属性方法查找顺序 mro 总结：看源码 只要看到了self.xxx 一定要问自己 当前这个self到底是谁 \u0026#34;\u0026#34;\u0026#34; return view # CBV的精髓 dispath def dispatch(self, request, *args, **kwargs): # Try to dispatch to the right method; if a method doesn\u0026#39;t exist, # defer to the error handler. Also defer to the error handler if the # request method isn\u0026#39;t on the approved list. # 获取当前请求的小写格式 然后比对当前请求方式是否合法 # get请求为例 if request.method.lower() in self.http_method_names: \u0026#34;\u0026#34;\u0026#34; 反射：通过字符串来操作对象的属性或方法 运行时获取类型定义信息 handler = getattr(自己写的类产生的对象, \u0026#39;get\u0026#39;, 当找不到get属性或者方法的时候就会用第三个参数) handler = 我们自己写的类里面的get方法 \u0026#34;\u0026#34;\u0026#34; handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed # 自动调用get方法 return handler(request, *args, **kwargs) APIView CBV简单实现 1 2 3 4 5 6 7 8 9 10 # urls.py # 也是as_view() 只不过被APIView(继承View)重写 path(\u0026#39;books_apiview/\u0026#39;, views.BooksAPIView.as_view()) # views.py from rest_framework.views import APIView class BooksAPIView(APIView): def get(self, request): return JsonResponse({\u0026#39;APIView\u0026#39;: 666}) as_view() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 \u0026#34;\u0026#34;\u0026#34; 源码解读：切入口还是 as_view() -\u0026gt; APIView的as_view() -\u0026gt; view 函数内存地址 \u0026#34;\u0026#34;\u0026#34; @classmethod # 类的绑定方法 def as_view(cls, **initkwargs): view = super().as_view(**initkwargs) # 调用父类的as_view方法 view.cls = cls view.initkwargs = initkwargs # 继承APIView的视图类会禁用csrf认证(drf会有自己的认证) # 添加装饰器的另一种方法 @方式是语法糖 本质就是传入一个被装饰函数给装饰器函数当作实参 return csrf_exempt(view) # 使用csrf装饰器 URL视图还可以这么写 path(\u0026#39;test/\u0026#39;, csrf_exempt(as_view)) \u0026#34;\u0026#34;\u0026#34; 发起请求 -\u0026gt; 路由匹配成功 -\u0026gt; view(request) -\u0026gt; 调用dispath() -\u0026gt; mro属性查找顺序 self.dispath会执行到APIView的dispath方法 而不再走View类的dispath -\u0026gt; 把请求方法转为小写 -\u0026gt; 通过反射去对象中查找 有没有改方法定义的属性 有则传入request并执行 \u0026#34;\u0026#34;\u0026#34; # APIView的disapth def dispatch(self, request, *args, **kwargs): self.args = args self.kwargs = kwargs # request参数是当次请求的request对象 # 请求过来 wsgi注入一个envrion字段 django把它包装成一个request对象 # 然后重新赋值的request 是初始化处理后的一个新的Request对象 request = self.initialize_request(request, *args, **kwargs) # 现在视图函数拿到的request 已经不是django原生给我们封装的request # 而是drf自己定义的request对象(mro) 以后视图函数再使用的request对象 就是这个新的drf定义的对象 self.request = request # 将新的request对象赋值给self.request 你视图函数里面 其他的方法 也可以从这个里面获取相关数据 self.headers = self.default_response_headers # deprecate? try: # 三大认证模块 self.initial(request, *args, **kwargs) # Get the appropriate handler method if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed # 响应模块 response = handler(request, *args, **kwargs) except Exception as exc: # 异常模块 response = self.handle_exception(exc) # 渲染模块 self.response = self.finalize_response(request, response, *args, **kwargs) return self.response # 封装drf自己的request对象 def initialize_request(self, request, *args, **kwargs): parser_context = self.get_parser_context(request) # django原来的request 被封装到Request里面 # self._request 原生的request # self.request drf封装的request # 返回DRF封装的Request类实例化之后的对象 return Request( request, # 原生的request对象 # 获取解析类 parsers=self.get_parsers(), authenticators=self.get_authenticators(), negotiator=self.get_content_negotiator(), parser_context=parser_context ) \u0026#34;\u0026#34;\u0026#34; 针对这个赋值： self.request = request # 将新的request对象赋值给self.request 你视图函数里面 其他的方法 也可以从这个里面获取相关数据(就是drf封装的当次请求的request) class MyCBV(VPIView): def get(self, request): .. def foo(self): print(self.request) # 视图函数中 其他方法 不用传参 也可以直接使用该对象 \u0026#34;\u0026#34;\u0026#34; Request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 \u0026#34;\u0026#34;\u0026#34; from rest_framework.request import Request 只要继承了APIView 视图类中的request对象 都是新的 也就是上面导入路径这个Request的对象(实例) 使用使用新的request对象 就像使用之前的request是一模一样的(因为重写了__getattr__方法) def __getattr__(self, attr): try: return getattr(self._request, attr) except AttributeError: return self.__getattribute__(attr) \u0026#34;\u0026#34;\u0026#34; class Request: \u0026#34;\u0026#34;\u0026#34; Wrapper allowing to enhance a standard `HttpRequest` instance. Kwargs: - request(HttpRequest). The original request instance. - parsers(list/tuple). The parsers to use for parsing the request content. - authenticators(list/tuple). The authenticators used to try authenticating the request\u0026#39;s user. \u0026#34;\u0026#34;\u0026#34; def __init__(self, request, parsers=None, authenticators=None, negotiator=None, parser_context=None): assert isinstance(request, HttpRequest), ( \u0026#39;The `request` argument must be an instance of \u0026#39; \u0026#39;`django.http.HttpRequest`, not `{}.{}`.\u0026#39; .format(request.__class__.__module__, request.__class__.__name__) ) # self._request 原生的request self._request = request self._data = Empty ... # restframework封装的request对象 \u0026#34;\u0026#34;\u0026#34; django封装的request对象没有.data {} 它是一个字典 - post请求不管使用什么编码(form/urlencoded/json) 传过来的数据 都在request.data - get请求 \u0026#34;\u0026#34;\u0026#34; request.data 取POST请求数据 django原生request(request.POST) drf封装后的Request对象(request.data) form 有数据 QueryDict 有数据 QueryDict urlencoded 有数据 QueryDict 有数据 QueryDict json 无数据 有数据 普通字典 取GET请求url中的数据 1 2 3 4 5 6 7 8 # drf Request类方法 # self._request.GET = request.query_params # django原来取： request.GET # drf取： request.query_params @property def query_params(self): return self._request.GET APIView的initial方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # dispath中调用 initial方法 # request参数 已经是新的request def initial(self, request, *args, **kwargs): ... # Ensure that the incoming request is permitted \u0026#34;\u0026#34;\u0026#34; perform_authentication 认证组件：检验用户 - 游客、合法用户、非法用户 游客： 代表检验通过 直接进入下一步校验(权限检验) 合法用户：代表校验通过 将用户存储再request.user中 再进入下一步校验(权限校验) 非法用户：代表校验失败 抛出异常 返回403权限异常结果 \u0026#34;\u0026#34;\u0026#34; self.perform_authentication(request) \u0026#34;\u0026#34;\u0026#34; check_permissions 权限组件：校验用户权限 - 必须登录、所有用户、登录读写游客只读、自定义用户角色 认证通过：可以进入下一步校验(频率认证) 认证失败：抛出异常 返回403权限异常结构 \u0026#34;\u0026#34;\u0026#34; self.check_permissions(request) \u0026#34;\u0026#34;\u0026#34; check_throttles 频率组件：限制视图接口被访问的频率次数 - 限制的条件(IP/id/唯一键)、频率周期时间(s/m/h)、频率的次数(3/s) 没有达到限制：正常访问接口 达到限制：限制时间之内不能访问 限制时间达到后 可以重新访问 \u0026#34;\u0026#34;\u0026#34; self.check_throttles(request) 补充 1 2 3 4 5 6 7 8 9 def add(x, y): return x + y # 由于Python中一切皆对象 所以都可以设置属性 取出属性 # Python源码中使用非常多 add.xyz = \u0026#39;xyz111\u0026#39; print(add(5, 5)) print(add.xyz) 序列化器 drf-Serializer\ndrf-Serializer-fileds\ndrf-Serializer-relations\nSerializer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026#34;\u0026#34;\u0026#34; 序列化：序列化器会把模型对象转换为字典 经过response以后变成json字符串 model对象 -\u0026gt; json 反序列化：把客户端发送过来的数据 经过request以后变成字典(框架封装) 序列化器可以把字典转成模型 json -\u0026gt; model对象 反序列化另一个作用：完成数据的校验功能(类似forms组件) \u0026#34;\u0026#34;\u0026#34; 1. Serializer类 必须写一个类继承它 想序列化什么字段就在里面写字段(source可以修改序列化出来的字段名 获取取属性 .跨表) 2. 序列化queryset(列表)对象和真正(单个)的对象 many=True的作用 instance=要序列化的对象(模型类对象 也就是模型类实例) 3. 反序列化 instance=要序列化的对象 data=request.data(新增没有instance参数) 4. 字段验证 序列化类中 给字段加属性(字段参数) 局部和全局钩子函数|字段参数的validaores=[] 视图函数中调用 序列化对象.is_valid(raise_exception=True)进行验证 raise_exception参数默认False 如果为True 验证不通过直接抛出异常 5. 反序列化数据保存 5.1 修改保存 -\u0026gt; 调用序列化对象的.save() -\u0026gt; 触发序列化类的.update方法 5.2 新增保存 -\u0026gt; 调用序列化对象的.save() -\u0026gt; 触发序列化类的.create方法 备注： 如果自定义序列化类不是继承的ModelSerializer 需要重写 .update方法和.create方法(可以很复杂) 如果反序列的数据中有需要保存到第三张表的 需要在重写的方法额外处理 6. ModelSerializer 跟Model做了对应 写法固定 字段参数直接用 extra_kwargs 其余用法和继承Serializer一摸一样(包括全局/局部钩子函数) 7. many=True 可以序列化多条的原因 8. 接口 鸭子类型 序列化 字段类型 SerializerFields\n序列化器字段\n1 2 3 4 5 # 完整字段见上面参考链接 CharField IntergerField DateField ... 字段参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 检验功能 非常类似forms组件 1. 自带字段选项校验(更多参考字段链接详细内容) - read_only - required 默认为True - max_length - validators 验证器功能列表 应将其应用于输入字段输入 并引发验证错误或简单地返回 ... 2. 局部钩子函数 3. 全局钩子函数 # 通用字段参数 read_only 表明该字段仅用于序列化输出 默认False write_only 表明该字段仅用于反序列化输入 默认False required 表明该字段在反序列化时必须输入 默认True default 反序列化时使用的默认值 allow_null 表明该字段是否允许传入None 默认Flase validators 该字段使用的验证器 error_messages 包含错误编号与错误信息的字典 label 用于HTML展示API页面时 显示的字段名称 help_text 用于HTML展示API页面时 显示的字段帮助提示信息 反序列化 修改数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 \u0026#34;\u0026#34;\u0026#34; PUT 127.0.0.1:8000/books/1 修改书籍主键为1的书籍信息 1. 写一个序列化的类 继承Serializer类 2. 在类中写想要反序列化的字段 3. 在视图类中使用 导入自定义序列化类 -\u0026gt; 实例化得到的序列化类对象(把要修改的对象 和 修改的数据传入) # instance=要修改的对象 # data=修改的数据 serializer = BookSerializer(instance=book, data=request.data) 4. 数据校验 # raise_exception参数默认为False # 如果为True 验证不通过直接抛出异常 serializer.is_valid(raise_exception=True) 4.1 如果校验通过 就保存 serializer.save() # 是序列化器的save()方法 4.2 如果校验不通过 返回错误信息 5. 如果字段的校验规则不够 可以自己写钩子函数(局部和全局 类似forms) \u0026#34;\u0026#34;\u0026#34; class BooksDetailView(APIView): def put(self, request, pk): response_msg = {\u0026#39;status\u0026#39;:100, \u0026#39;msg\u0026#39;:\u0026#39;成功\u0026#39;} # 找到这个对象 book = Book.objects.filter(pk=pk).first() # 直接用request.data的数据来修改原来的对象 -\u0026gt; 反序列化 serializer = BookSerializer(book, request.data) # 一定要数据验证(类似form表单验证) if serializer.is_valid(): # 直接调用报错 需要重写update方法 接口规范了子类的行为 鸭子类型 # NotImplementedError: `update()` must be implemented. serializer.save() # 验证通过则返回 response_msg[\u0026#39;data\u0026#39;] = serializer.data # return Response(serializer.data) else: response_msg[\u0026#39;status\u0026#39;] = 1001 response_msg[\u0026#39;msg\u0026#39;] = \u0026#39;数据校验失败\u0026#39; response_msg[\u0026#39;data\u0026#39;] = serializer.errors return Response(response_msg) # 直接继承Serializer没有update方法 需要重写 class BookSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) name = serializers.CharField(max_length=16, min_length=4) price = serializers.DecimalField(max_digits=5, decimal_places=2) author = serializers.CharField() publish = serializers.CharField() def update(self, instance, validated_data): # instance是book这个对象 # validated_data是校验后的数据 instance.name = validated_data.get(\u0026#39;name\u0026#39;) instance.price = validated_data.get(\u0026#39;price\u0026#39;) instance.author = validated_data.get(\u0026#39;author\u0026#39;) instance.publish = validated_data.get(\u0026#39;publish\u0026#39;) instance.save() # django ORM提供的 return instance 数据校验钩子函数 1 2 3 4 5 先自己字段参数验证 -\u0026gt; 如果该字段有局部钩子函数 走该函数验证该字段 -\u0026gt; 所有字段按照该顺序验证完成 看是否有全局钩子验证函数 -\u0026gt; 全局钩子函数验证(此时数据已经经过第一次校验 validated_data) -\u0026gt; 验证完成 局部钩子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from rest_framework import serializers from rest_framework.exceptions import ValidationError class BookSerializer(serializers.Serializer): ... def validate_price(self, data): \u0026#34;\u0026#34;\u0026#34; validate_字段名(通过反射获取该方法) 接收一个参数 :param data: 就是price 可以对任意单一字段自定义校验 :return: data \u0026#34;\u0026#34;\u0026#34; # print(data) # print(type(data)) if data \u0026gt; 10: return data # 校验失败 抛出异常 raise ValidationError(\u0026#39;价格太低\u0026#39;) 输出示例\n1 2 3 4 5 6 7 8 9 { \u0026#34;status\u0026#34;: 1001, \u0026#34;msg\u0026#34;: \u0026#34;数据校验失败\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;price\u0026#34;: [ \u0026#34;价格太低\u0026#34; ] } } 全局钩子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from rest_framework import serializers from rest_framework.exceptions import ValidationError class BookSerializer(serializers.Serializer): ... def validate(self, attrs): \u0026#34;\u0026#34;\u0026#34; 全局钩子：校验多个字段 :param attrs: 校验通过的数据(validated_data) :return: attrs \u0026#34;\u0026#34;\u0026#34; print(attrs) author = attrs.get(\u0026#39;author\u0026#39;) publish = attrs.get(\u0026#39;publish\u0026#39;) if author == publish: raise ValidationError(\u0026#39;作者名字和出版社一致\u0026#39;) return attrs 输出示例\n1 2 3 4 5 6 7 8 9 { \u0026#34;status\u0026#34;: 1001, \u0026#34;msg\u0026#34;: \u0026#34;数据校验失败\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;non_field_errors\u0026#34;: [ \u0026#34;作者名字和出版社一致\u0026#34; ] } } 参数validators(非钩子函数 字段选项验证器 较少使用) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def check_author(data): if data.startswith(\u0026#39;sb\u0026#39;): raise ValidationError(\u0026#39;作者名字不能以sb开头\u0026#39;) return data class BookSerializer(serializers.Serializer): ... # 使用字段参数：验证器 author = serializers.CharField(validators=[check_author]) \u0026#34;\u0026#34;\u0026#34; 加上上面的钩子函数和自带的字段验证 总共有三种验证数据的方式： 1. 字段参数自带的验证参数们 2. 局部钩子/全局钩子函数 3. 参数：validators 验证器 抛出无效数据的异常 .is_valid()方法使用可选的raise_exception标志 如果存在验证错误将会抛出一个serializers.ValidationError异常 这些异常由REST framework提供的默认异常处理程序自动处理 默认情况下将返回HTTP 400 Bad Request响应 \u0026#34;\u0026#34;\u0026#34; # 如果数据无效就返回400响应 serializer.is_valid(raise_exception=True) 输出示例\n1 2 3 4 5 6 7 8 9 { \u0026#34;status\u0026#34;: 100, \u0026#34;msg\u0026#34;: \u0026#34;数据校验失败\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;author\u0026#34;: [ \u0026#34;作者名字不能以sb开头\u0026#34; ] } } 序列化反序列化字段处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026#34;\u0026#34;\u0026#34; 问题：我们序列化的时候和反序列化的时候 使用的字段数目不全部一致 比如主键id 序列化展示 反序列化不应该输入 解决： 1. 写两个serializer类 一个用于序列化 一个用于反序列化 -\u0026gt; 冗余度非常高 麻烦 2. 字段参数解决 read_only 表明该字段仅用于序列化输出 默认False write_only 表名该字段仅用于反序列化输入 默认False \u0026#34;\u0026#34;\u0026#34; class BookSerializer(serializers.Serializer): \u0026#34;\u0026#34;\u0026#34; read_only=True - 序列化输出 有该字段 - 反序列化传入数据 不需要传该字段 错误的输入所有的read_only字段都将被忽略 write_only - 序列化输出 没有该字段 - 反序列化传入数据 必须传入该字段 否则校验失败 \u0026#34;\u0026#34;\u0026#34; id = serializers.IntegerField(read_only=True) publish = serializers.CharField(max_length=64, min_length=2, write_only=True) Choices字段显示名称处理 DRF处理模型中的选项字段\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026#34;\u0026#34;\u0026#34; drf反序列化的时候 无法取到get_fieldname_display()返回的可读字符串 目前会三种解决方法： - source参数 - serializers.SerializerMethodField() 字段 - 重写序列化器的 to_representation() 方法 注意：前面2种方法 等于重新定义了一个新的字段 此时无法反序列化 \u0026#34;\u0026#34;\u0026#34; # 1. source参数 gender = serializers.CharField(source=\u0026#39;get_gender_display\u0026#39;) # 该字段变只读 # 2. SerializerMethodField字段 # 3. 重写to_representation方法 不影响反序列化 class NodeSerializer(serializers.ModelSerializer): .../ def to_representation(self, instance): data = super().to_representation(instance) data.update(node_type=instance.get_node_type_display()) data.update(product_line=instance.get_product_line_display()) data.update(isp=instance.get_isp_display()) return data 其余API操作 查询所有数据 1 2 3 4 5 6 7 8 9 10 # URL path(\u0026#39;books/\u0026#39;, views.Books.as_view()) # View class Books(APIView): def get(self, request): books = Book.objects.all() # 序列化多条 需要加参数：many=True serializer = BookModelSerializer(instance=books, many=True) return Response(serializer.data) 新增数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # URL path(\u0026#39;books/\u0026#39;, views.Books.as_view()) # models.py class Books(APIView): def post(self, repost): # 修改才有instance 新增没有instance 只有data # 必须关键字传参 位置传参会给到第一个位置参数:instance book_ser = BookModelSerializer(data=repost.data) # 校验字段 if book_ser.is_valid(): book_ser.save() return Response(book_ser.data) return Response(book_ser.errors) # serializers.py 需要重写create()方法 class BookSerializer(serializers.Serializer): def create(self, validated_data): \u0026#34;\u0026#34;\u0026#34; :param validated_data: dict正好可以**解构 :return: \u0026#34;\u0026#34;\u0026#34; # 如果validated_data的数据 不是全部需要 # 就需要拿出来额外处理 不能直接双**解构 return Book.objects.create(**validated_data) 删除数据 1 2 3 4 5 6 7 8 9 10 11 from rest_framework.views import APIView from rest_framework.response import Response from rest_framework import status from .models import Book # 删除无需序列化器 class BooksDetail(APIView): def delete(self, request, pk): \u0026#34;\u0026#34;\u0026#34;删除一个数据\u0026#34;\u0026#34;\u0026#34; Book.objects.filter(pk=pk).delete() return Response(status=status.HTTP_204_NO_CONTENT) 自定义响应内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # utils.py class MyResponse: def __init__(self): self.status = 100 self.mgs = \u0026#39;success\u0026#39; @property def get_dict(self): return self.__dict__ # 使用的时候 实例化再修改属性即可 if __name__ == \u0026#39;__main__\u0026#39;: res = MyResponse() res.status = 101 res.msg = \u0026#39;数据校验失败\u0026#39; res.data = {\u0026#39;name\u0026#39;: \u0026#39;Minho\u0026#39;} print(res.get_dict) 模型类序列化器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BookModelSerializer(serializers.ModelSerializer): # ModelSerializer 也可以使用source参数 用法一样 pce = serializers.CharField(source=\u0026#39;publish.price\u0026#39;) class Meta: model = Book # 对应models.py中的表模型(要序列化哪个表的数据) # fields = \u0026#39;__all__\u0026#39; # __all__标识序列化所有字段 # fields = [\u0026#39;name\u0026#39;, \u0026#39;price\u0026#39;] # 只序列化指定字段 exclude = [\u0026#39;name\u0026#39;] # 跟fields不能都写 写哪个字段标识排除哪个字段 read_only_fields = [\u0026#39;price\u0026#39;] extra_kwargs = { \u0026#39;author\u0026#39;: {\u0026#39;write_only\u0026#39;: True} } \u0026#34;\u0026#34;\u0026#34; write_only_fields 弃用 -\u0026gt; 使用extra_kwargs解决 可以通过使用extra_kwargs选项快捷地在字段上指定任意附加的关键字参数 类似于：Serializer的 name = serializers.CharField(max_length=16, min_length=4) 示例： extra_kwargs = {\u0026#39;password\u0026#39;: {\u0026#39;write_only\u0026#39;: True}, \u0026#39;author\u0026#39;: {\u0026#39;write_only\u0026#39;: True},} 备注： 继承ModelSerializer之后 不用再自己重写 .update() 和 .create()方法 其他使用方式和继承Serializer 一摸一样 \u0026#34;\u0026#34;\u0026#34; 输出示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [ { \u0026#34;nid\u0026#34;: 1, \u0026#34;pce\u0026#34;: \u0026#34;129.11\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;红楼梦\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;129.11\u0026#34;, \u0026#34;publish\u0026#34;: \u0026#34;北京出版社\u0026#34; }, { \u0026#34;nid\u0026#34;: 3, \u0026#34;pce\u0026#34;: \u0026#34;192.45\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;192.45\u0026#34;, \u0026#34;publish\u0026#34;: \u0026#34;xx出版社\u0026#34; }, ] many=True源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 序列化多条数据的时候 需要传 many=True class Books(APIView): def get(self, request): # 序列化单条 book = Book.objects.all() books_one_ser = BookModelSerializer(instance=book) # 序列化多条 books = Book.objects.all() books_ser = BookModelSerializer(instance=books, many=True) print(type(books_one_ser)) print(type(books_ser)) return Response(books_ser.data) # many=True时 返回的结果跟不传 不是同一个类的对象 单条类型： \u0026lt;class \u0026#39;drftutorial.book.serializer.BookModelSerializer\u0026#39;\u0026gt; 多条类型： \u0026lt;class \u0026#39;rest_framework.serializers.ListSerializer\u0026#39;\u0026gt; \u0026#34;\u0026#34;\u0026#34; 对象的生成：先调用类的__new__方法 生成空对象 实例化：类名(参数) 调用类的__init__()方法 类的__new__方法 控制对象的生成 -\u0026gt; 由此猜测BookModelSerializer类的__new__方法做了处理 根据是否有many=True参数 生成不同的类对象 \u0026#34;\u0026#34;\u0026#34; class BaseSerializer(Field): ... def __new__(cls, *args, **kwargs): # We override this method in order to automatically create # `ListSerializer` classes instead when `many=True` is set. if kwargs.pop(\u0026#39;many\u0026#39;, False): return cls.many_init(*args, **kwargs) # 没有传many=True 正常实例化 return super().__new__(cls, *args, **kwargs) @classmethod def many_init(cls, *args, **kwargs): ... \u0026#34;\u0026#34;\u0026#34; 如果传入many=True 调用该方法 生成新得类对象 里面就是一个个得Serializer对象 \u0026#34;\u0026#34;\u0026#34; return list_serializer_class(*args, **list_kwargs) Serializer高级用法 关联字段\n一对多关系字段 source参数 1 2 3 4 5 6 7 8 9 10 source参数就是指定序列化对象的属性 该属性可以是模型类的字段属性 也可以是该模型类的方法(类方法本质也是类属性 本质一样） \u0026#34;\u0026#34;\u0026#34; source的使用 下面三个功能： 1. 可以改字段名字 xxx = serializers.CharField(max_length=32, source=\u0026#39;title\u0026#39;) 2. 可以.跨表取属性 publish = serializers.CharField(source=\u0026#39;publish.email\u0026#39;) 3. 可以执行方法 publish_date = serializers.DateTimeField(source=\u0026#39;test\u0026#39;) # test不是model类对应字段 而是自定义函数 \u0026#34;\u0026#34;\u0026#34; source=对象属性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026#34;\u0026#34;\u0026#34; 一对多关系字段： 1. 模型类__str__魔术方法 publish = serializers.CharField() -\u0026gt; book.publish -\u0026gt; 获取publish的__str__方法返回值 2. source参数用法 publish = serializers.CharField(source=\u0026#39;publish.email\u0026#39;) source参数可以直接取模型类的字段 2.1 更换序列化器显示的字段名称(隐藏真正的数据库字段) 用source与实际的数据库模块字段对应 xxx = serializers.CharField(max_length=32, source=\u0026#39;title\u0026#39;) 2.2 一对多关系中 可以取到关联关系表中的其他字段(跨表) publish = serializers.CharField(source=\u0026#39;publish.email\u0026#39;) \u0026#34;\u0026#34;\u0026#34; from rest_framework import serializers class BookSerializer(serializers.Serializer): # 这部分字段相当于隐藏了模型前缀 相当于取book得属性(包括方法) # book.xxx | book.price | book.publish_data... xxx = serializers.CharField(max_length=32, source=\u0026#39;title\u0026#39;) price = serializers.DecimalField(max_digits=8, decimal_places=2) publish_date = serializers.DateTimeField() # book.publish 外键关联字段 直接写 显示结果会显示__str__方法的结果 publish = serializers.CharField(source=\u0026#39;publish.email\u0026#39;) # book.authors None -\u0026gt; book.authors.all() source=对象方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # serializers.py from rest_framework import serializers class BookSerializer(serializers.Serializer): xxx = serializers.CharField(max_length=32, source=\u0026#39;title\u0026#39;) publish_date = serializers.DateTimeField(source=\u0026#39;test\u0026#39;) # models.py class Book(models.Model): title = models.CharField(max_length=32) def test(self): return \u0026#39;book.test method\u0026#39; \u0026#34;\u0026#34;\u0026#34; source指定的方法的return内容就是序列化的内容 \u0026#34;\u0026#34;\u0026#34; 输出示例\n1 2 3 4 { \u0026#34;xxx\u0026#34;: \u0026#34;红楼梦\u0026#34;, \u0026#34;publish_date\u0026#34;: \u0026#34;book.test method\u0026#34;, } 多对多关系字段 SerializerMethodField 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from rest_framework import serializers class BookSerializer(serializers.Serializer): ... authors = serializers.SerializerMethodField() def get_authors(self, obj): # obj: book对象 authors = obj.authors.all() # 跨表拿出所有作者 return [{\u0026#39;name\u0026#39;: author.name, \u0026#39;age\u0026#39;: author.age} for author in authors] \u0026#34;\u0026#34;\u0026#34; serializer通过字段取出多对多关系表数据： SerializerMethodField(method_name=None) 这是一个只读字段 它通过在附加的序列化器类上调用一个方法来获取其值 它可以用于将任何类型的数据添加到对象的序列化表示中 该字段会绑定一个方法 如果没有指定method_name 则默认为：get_\u0026lt;field_name\u0026gt;(self, obj): pass 该方法返回什么 序列化的字段就显示什么内容 \u0026#34;\u0026#34;\u0026#34; 输出示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \u0026#34;xxx\u0026#34;: \u0026#34;红楼梦\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;123.45\u0026#34;, \u0026#34;publish_date\u0026#34;: \u0026#34;2021-01-05T20:43:26Z\u0026#34;, \u0026#34;publish\u0026#34;: \u0026#34;南京出版社\u0026#34;, \u0026#34;authors\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;minho\u0026#34;, \u0026#34;age\u0026#34;: 25 }, { \u0026#34;name\u0026#34;: \u0026#34;kimi\u0026#34;, \u0026#34;age\u0026#34;: 46 } ] } 请求与响应 MDN HTTP教程\ndjango request-response\nRequest drf-request\nassert断言 补充\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # Rqeust类并没有继承django的 # CBV源码有部分解析 # 位置：from rest_framework.request import Request # Request部分关键源码 class Request: \u0026#34;\u0026#34;\u0026#34; Wrapper allowing to enhance a standard `HttpRequest` instance. Kwargs: - request(HttpRequest). The original request instance. - parsers(list/tuple). The parsers to use for parsing the request content. - authenticators(list/tuple). The authenticators used to try authenticating the request\u0026#39;s user. \u0026#34;\u0026#34;\u0026#34; def __init__(self, request, parsers=None, authenticators=None, negotiator=None, parser_context=None): assert isinstance(request, HttpRequest), ( \u0026#39;The `request` argument must be an instance of \u0026#39; \u0026#39;`django.http.HttpRequest`, not `{}.{}`.\u0026#39; .format(request.__class__.__module__, request.__class__.__name__) ) # 赋值django封装的request self._request = request # 获取属性处理 # 如果自己没有的 问django原生封装的request要 这个时候是self._request def __getattr__(self, attr): \u0026#34;\u0026#34;\u0026#34; If an attribute does not exist on this instance, then we also attempt to proxy it to the underlying HttpRequest object. \u0026#34;\u0026#34;\u0026#34; try: return getattr(self._request, attr) except AttributeError: return self.__getattribute__(attr) # request.data @property def data(self): if not _hasattr(self, \u0026#39;_full_data\u0026#39;): self._load_data_and_files() return self._full_data # __getattribute__ def __getattribute__(self, *args, **kwargs): # real signature unknown \u0026#34;\u0026#34;\u0026#34; Return getattr(self, name). \u0026#34;\u0026#34;\u0026#34; pass request.data 取POST请求数据 1 2 3 4 5 6 7 8 9 10 11 请求对象.data -\u0026gt; request.data 前端以三种编码方式传入的数据 都可以取出来(结果可能是QueryDict 或 字典) \u0026#34;\u0026#34;\u0026#34; 实现： from/urlencode 直接去取django原生封装的request取 json 去request.boby取出来 然后反序列化返回字典 json模块是否支持反序列化bytes格式 3.6以后才支持 否则要decode成字符串在反序列化 \u0026#34;\u0026#34;\u0026#34; django原生request(request.POST) drf封装后的Request对象(request.data) form 有数据 QueryDict 有数据 QueryDict urlencoded 有数据 QueryDict 有数据 QueryDict json 无数据 有数据 普通字典 requset.query_params 取GET请求url中的数据 1 2 3 4 5 6 7 8 # drf Request类方法 # self._request.GET = request.query_params # django原来取： request.GET # drf取： request.query_params @property def query_params(self): return self._request.GET Response 1 2 3 4 5 Response 是一个类 要使用 就要实例化(需要传参) Response(data=None, status=None, template_name=None, headers=None, exception=False, conetnt_type=None) drf-response\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 位置：from rest_framework.response import Response class Response(SimpleTemplateResponse): \u0026#34;\u0026#34;\u0026#34; An HttpResponse that allows its data to be rendered into arbitrary media types. \u0026#34;\u0026#34;\u0026#34; # 实例化参数 def __init__(self, data=None, status=None, template_name=None, headers=None, exception=False, content_type=None): \u0026#34;\u0026#34;\u0026#34; data: 响应数据 序列化器.data返回的字典 or 自定义返回字典内容 status: 响应状态码 template_name: drf默认提供的模板 可以修改(自定制) headers: 响应头 exception: 异常处理 content_type: 响应中 Content-Type标头告诉客户端实际返回的内容的内容类型 \u0026#34;\u0026#34;\u0026#34; pass \u0026#34;\u0026#34;\u0026#34; RESTframework提供了一个响应类Response 使用该类构造响应对象时 响应的具体数据内容会被转换(render渲染)成符合前端需求的类型 RESTframework提供了Renderer渲染器 用来根据请求头中的Accept(用户代理期望的MIME类型列表)来自动转换响应数据到对应格式 如果前端请求中未进行Accept声明 则会采用默认方式处理响应数据 我们可以通过配置来修改默认响应格式 \u0026#34;\u0026#34;\u0026#34; 从修改默认响应渲染类看drf配置解析顺序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # 可以在rest_framework.settings查找所有的drf默认配置项 DEFAULTS = { # Base API policies \u0026#39;DEFAULT_RENDERER_CLASSES\u0026#39;: [ # 默认响应渲染类 \u0026#39;rest_framework.renderers.JSONRenderer\u0026#39;, # json渲染器 \u0026#39;rest_framework.renderers.BrowsableAPIRenderer\u0026#39;, # 浏览API渲染器 ] ... } \u0026#34;\u0026#34;\u0026#34; 默认：浏览器响应成浏览器的格式 postman响应成json格式 - 通过配置实现 可以修改： 1. 局部使用 - 对某个视图类有效 2. 全局使用 - 对全部视图类有效 \u0026#34;\u0026#34;\u0026#34; 注意：drf有默认的配置文件 即rest_framework.settings 找的时候 先从项目的settings.py中找 -\u0026gt; 找不到采用自己默认的 # 全局：django项目settings.py配置 REST_FRAMEWORK = { \u0026#39;DEFAULT_RENDERER_CLASSES\u0026#39;: [ \u0026#39;rest_framework.renderers.JSONRenderer\u0026#39;, # 使浏览器访问也返回json数据 ] } # 局部：视图函数中修改(类属性) from rest_framework.renderers import JSONRenderer class TestView(APIView): # 局部对视图类做配置(类属性) renderer_classes = [\u0026#39;rest_framework.renderers.JSONRenderer\u0026#39;] def get(self, request): return Response({\u0026#39;msg\u0026#39;: \u0026#39;ok\u0026#39;}) # 总结：drf的配置信息查找顺序(源码：面向对象属性解析顺序) 先从自己类中找类属性配置 -\u0026gt; django项目的settings.py中的REST_FRAMEWORK = [] 命名空间配置 -\u0026gt; drf自己的默认配置 rest_framework.settings # django也有两套配置文件 # settings.py | django.conf.global_settings.py 思考：两套配置问价 如何 实现顺序的查找 - 类的继承可以实现 但是django这里不是 它是单个的模块 - django的实现：一个配置字典 先读取老的{key:value} 再读取新的{key:value} 字典特性：key不重复 新的key的value会覆盖老的 构造方式 1 2 3 4 5 6 7 8 9 10 11 from rest_framework.views import APIView from rest_framework.response import Response class TestView(APIView): def get(self, request): print(request) # 返回用了默认templates渲染 如果使用浏览器访问 需要注册rest_framework # 否则浏览器会访问api.html 提示: TemplateDoesNotExist return Response({\u0026#39;name\u0026#39;: \u0026#39;minho\u0026#39;}, status=201, headers={\u0026#39;token\u0026#39;: \u0026#39;xxx\u0026#39;}) 响应示例 1 2 3 4 5 6 7 8 9 HTTP 201 Created Allow: GET, HEAD, OPTIONS Content-Type: application/json Vary: Accept token: xxx { \u0026#34;name\u0026#34;: \u0026#34;minho\u0026#34; } 常用属性 1 2 3 4 5 6 7 8 1. Response().data 传给response对象的序列化后 但尚未render处理的数据 2. Response.status_code 状态码的数字 3. Response.content 经过render处理后的响应数据 响应data 1 2 3 4 5 \u0026#34;\u0026#34;\u0026#34; 响应内容： data就是你要返回的数据 是一个字典 可以是Serializer序列化后的字典 也可以是自定义的字典 \u0026#34;\u0026#34;\u0026#34; 响应status 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 \u0026#34;\u0026#34;\u0026#34; 响应状态码： 直接使用status定义的状态码 默认返回 200 OK 它把所有使用到的状态码都定义成了常量 将数字对应了更明确的标识符 return Response({\u0026#39;name\u0026#39;: \u0026#39;minho\u0026#39;}, status=status.HTTP_200_OK, headers={\u0026#39;token\u0026#39;: \u0026#39;xxx\u0026#39;}) \u0026#34;\u0026#34;\u0026#34; from rest_framework import status # status模块内容 def is_informational(code): return 100 \u0026lt;= code \u0026lt;= 199 def is_success(code): return 200 \u0026lt;= code \u0026lt;= 299 def is_redirect(code): return 300 \u0026lt;= code \u0026lt;= 399 def is_client_error(code): return 400 \u0026lt;= code \u0026lt;= 499 def is_server_error(code): return 500 \u0026lt;= code \u0026lt;= 599 HTTP_100_CONTINUE = 100 HTTP_101_SWITCHING_PROTOCOLS = 101 HTTP_200_OK = 200 HTTP_201_CREATED = 201 HTTP_202_ACCEPTED = 202 HTTP_203_NON_AUTHORITATIVE_INFORMATION = 203 HTTP_204_NO_CONTENT = 204 HTTP_205_RESET_CONTENT = 205 HTTP_206_PARTIAL_CONTENT = 206 HTTP_207_MULTI_STATUS = 207 HTTP_208_ALREADY_REPORTED = 208 HTTP_226_IM_USED = 226 HTTP_300_MULTIPLE_CHOICES = 300 HTTP_301_MOVED_PERMANENTLY = 301 HTTP_302_FOUND = 302 HTTP_303_SEE_OTHER = 303 HTTP_304_NOT_MODIFIED = 304 HTTP_305_USE_PROXY = 305 HTTP_306_RESERVED = 306 HTTP_307_TEMPORARY_REDIRECT = 307 HTTP_308_PERMANENT_REDIRECT = 308 HTTP_400_BAD_REQUEST = 400 HTTP_401_UNAUTHORIZED = 401 HTTP_402_PAYMENT_REQUIRED = 402 HTTP_403_FORBIDDEN = 403 HTTP_404_NOT_FOUND = 404 HTTP_405_METHOD_NOT_ALLOWED = 405 HTTP_406_NOT_ACCEPTABLE = 406 HTTP_407_PROXY_AUTHENTICATION_REQUIRED = 407 HTTP_408_REQUEST_TIMEOUT = 408 HTTP_409_CONFLICT = 409 HTTP_410_GONE = 410 HTTP_411_LENGTH_REQUIRED = 411 HTTP_412_PRECONDITION_FAILED = 412 HTTP_413_REQUEST_ENTITY_TOO_LARGE = 413 HTTP_414_REQUEST_URI_TOO_LONG = 414 HTTP_415_UNSUPPORTED_MEDIA_TYPE = 415 HTTP_416_REQUESTED_RANGE_NOT_SATISFIABLE = 416 HTTP_417_EXPECTATION_FAILED = 417 HTTP_418_IM_A_TEAPOT = 418 HTTP_422_UNPROCESSABLE_ENTITY = 422 HTTP_423_LOCKED = 423 HTTP_424_FAILED_DEPENDENCY = 424 HTTP_426_UPGRADE_REQUIRED = 426 HTTP_428_PRECONDITION_REQUIRED = 428 HTTP_429_TOO_MANY_REQUESTS = 429 HTTP_431_REQUEST_HEADER_FIELDS_TOO_LARGE = 431 HTTP_451_UNAVAILABLE_FOR_LEGAL_REASONS = 451 HTTP_500_INTERNAL_SERVER_ERROR = 500 HTTP_501_NOT_IMPLEMENTED = 501 HTTP_502_BAD_GATEWAY = 502 HTTP_503_SERVICE_UNAVAILABLE = 503 HTTP_504_GATEWAY_TIMEOUT = 504 HTTP_505_HTTP_VERSION_NOT_SUPPORTED = 505 HTTP_506_VARIANT_ALSO_NEGOTIATES = 506 HTTP_507_INSUFFICIENT_STORAGE = 507 HTTP_508_LOOP_DETECTED = 508 HTTP_509_BANDWIDTH_LIMIT_EXCEEDED = 509 HTTP_510_NOT_EXTENDED = 510 HTTP_511_NETWORK_AUTHENTICATION_REQUIRED = 511 响应template_name 1 2 3 4 \u0026#34;\u0026#34;\u0026#34; 响应模板名： 指定渲染的模板名字 可以自定义模板 基本用不到 了解即可 \u0026#34;\u0026#34;\u0026#34; 响应headers MDN HTTP消息头详解\n1 2 3 4 5 6 7 8 9 10 \u0026#34;\u0026#34;\u0026#34; 响应头： 可以往响应头放东西 就是一个字典 具体headers字段及含义 参考上面链接 \u0026#34;\u0026#34;\u0026#34; # Django设置头字段 # 要设置或删除响应中的头字段 请像对待字典一样对待它 \u0026gt;\u0026gt;\u0026gt; response = HttpResponse() \u0026gt;\u0026gt;\u0026gt; response[\u0026#39;Age\u0026#39;] = 120 \u0026gt;\u0026gt;\u0026gt; del response[\u0026#39;Age\u0026#39;] 响应content_type MDN Content-Type\nMedia Types\n1 2 3 4 \u0026#34;\u0026#34;\u0026#34; 响应编码格式： 请求也有 实体头部用于指示资源的MIME类型 media type \u0026#34;\u0026#34;\u0026#34; 封装Response对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 自己封装Response对象 from rest_framework.response import Response class APIResponse(Response): def __init__( self, code=100, msg=\u0026#39;success\u0026#39;, result=None, status=None, headers=None, **kwargs): dic = {\u0026#39;code\u0026#39;: code, \u0026#39;msg\u0026#39;: msg} if data: dic[\u0026#39;result\u0026#39;] = result dic.update(kwargs) # super() 对象来调用对应的绑定方法 会自动注入self super().__init__(data=dic, status=status, headers=headers) # 类来调用对象的绑定方法 这个方法就是一个普通函数 有几个参数传几个参数 # Response.__init__(data=dic, status=status, headers=headers) 视图家族 两个视图基类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 APIView # 继承django View GenericAPIView # 继承drf APIVIew 做了一些扩展 重要的如下 看源码重点关注 类属性： - queryset = None - serializer_class = None 类方法： - get_queryset() 常用 - get_object() 获取一条数据 - get_serializer() 常用 - get_setrializer_class() 内部来用 外部会重写(视图类中用到多个序列化器的时候) # get_object()源码解析 class GenericAPIView(views.APIView): ... def get_object(self): \u0026#34;\u0026#34;\u0026#34; Returns the object the view is displaying. You may want to override this if you need to provide non-standard queryset lookups. Eg if objects are referenced using multiple keyword arguments in the url conf. \u0026#34;\u0026#34;\u0026#34; # 返回所有数据queryset对象 会有过滤 queryset = self.filter_queryset(self.get_queryset()) # Perform the lookup filtering. # lookup_field = \u0026#39;pk\u0026#39; # lookup_url_kwarg = None \u0026#34;\u0026#34;\u0026#34; url路径 对应有名分组的名字 默认叫 pk 不对应则报错 如果需要修改：在自己的视图类 重写定义上面两个字段的其中一个 这里的lookup_url_kwarg 就是pk(默认) \u0026#34;\u0026#34;\u0026#34; lookup_url_kwarg = self.lookup_url_kwarg or self.lookup_field # {pk: 4} url有名分组 -\u0026gt; 关键字传参到对应的视图函数 filter_kwargs = {self.lookup_field: self.kwargs[lookup_url_kwarg]} # 根据pk=4 去queryset对象中get单个对象 obj = get_object_or_404(queryset, **filter_kwargs) # May raise a permission denied self.check_object_permissions(self.request, obj) return obj APIView 继承APIView实现5个常用接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # 前面视图类继承APIView写CBV 已经能比较快速的写出5个常用接口 # CBV代码如下： from rest_framework.views import APIView from rest_framework.response import Response from rest_framework import status from .models import Book from .serializers import BookSerializer class BooksDetail(APIView): def get(self, request, pk): \u0026#34;\u0026#34;\u0026#34;获取一个数据\u0026#34;\u0026#34;\u0026#34; book = Book.objects.filter(pk=pk).first() serializer = BookSerializer(instance=book) return Response(serializer.data) def put(self, request, pk): \u0026#34;\u0026#34;\u0026#34;修改一个数据\u0026#34;\u0026#34;\u0026#34; book = Book.objects.filter(pk=pk).first() serializer = BookSerializer(book, request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) def delete(self, request, pk): \u0026#34;\u0026#34;\u0026#34;删除一个数据\u0026#34;\u0026#34;\u0026#34; Book.objects.filter(pk=pk).delete() return Response(status=status.HTTP_204_NO_CONTENT) class BooksList(APIView): def get(self, request): \u0026#34;\u0026#34;\u0026#34;获取数据列表(所有数据)\u0026#34;\u0026#34;\u0026#34; books = Book.objects.all() serializer = BookSerializer(instance=books, many=True) return Response(serializer.data) def post(self, request): \u0026#34;\u0026#34;\u0026#34;新增一个数据\u0026#34;\u0026#34;\u0026#34; serializer = BookSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) GenericAPIVIew 源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class GenericAPIView(views.APIView): queryset = None serializer_class = None ... def get_queryset(self): assert self.queryset is not None, ( \u0026#34;\u0026#39;%s\u0026#39; should either include a `queryset` attribute, \u0026#34; \u0026#34;or override the `get_queryset()` method.\u0026#34; % self.__class__.__name__ ) queryset = self.queryset if isinstance(queryset, QuerySet): # Ensure queryset is re-evaluated on each request. queryset = queryset.all() return queryset \u0026#34;\u0026#34;\u0026#34; 看GenericAPIView源码发现 继承该类 需要覆盖2个类属性： - queryset -\u0026gt; QuertSet对象 - 指定使用哪个模型 - serializer_class -\u0026gt; 序列化器 - 指定使用哪个序列化器来序列化上面模型类对应的数据 看get_queryset(self)方法知道 queryset可以写两种写法 - queryset = Book.object.all() - queryset = Book.object # 源码会自己判断 \u0026#34;\u0026#34;\u0026#34; 继承GenericView实现上面APIView的接口功能 1 2 3 4 \u0026#34;\u0026#34;\u0026#34; 基于GenericAPIView实现上面5个接口 其实非常简单 通过源码我们发现下面规律 \u0026#34;\u0026#34;\u0026#34; 功能描述 APIView GenericView 获取所有数据 books = Book.objects.all() books = self.get_queryset() 获取单个数据 book = Book.objects.filter(pk=pk).first() book = self.get_object() 序列化所有数据 serializer = BookSerializer(instance=books, many=True) serializer = self.get_serializer(instance=books, many=True) 序列化单个数据 serializer = BookSerializer(instance=book) serializer = self.get_serializer(instance=book) 反序列化单个数据 serializer = BookSerializer(data=request.data) serializer = self.get_serializer(data=request.data) 删除数据 Book.objects.filter(pk=pk).delete() self.get_object().delete() 发现以上规律后 使用GenericView重写上面5个接口则非常简单 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 from rest_framework.generics import GenericAPIView from rest_framework.response import Response from rest_framework import status from .models import Book from .serializers import BookSerializer class BooksDetail(GenericAPIView): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request, pk): book = self.get_object() serializer = self.get_serializer(instance=book) return Response(serializer.data) def put(self, request, pk): book = self.get_object() serializer = self.get_serializer(book, request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) def delete(self, request, pk): self.get_object().delete() return Response(status=status.HTTP_204_NO_CONTENT) class BooksList(GenericAPIView): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request): books = self.get_queryset() serializer = self.get_serializer(instance=books, many=True) return Response(serializer.data) def post(self, request): serializer = self.get_serializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) \u0026#34;\u0026#34;\u0026#34; 继承GenericView重写这5个接口之后 有什么优势? 我们只要把具体方法里面的之前表达业务字段的变量(book/books) 替换成 通用的没有具体含义的变量(如：obj) 视图函数的代码实现就变得非常通用 如何通用? 我们需要序列化其他模型类里面的数据的时候 只需要完成下面三步即可完成CBV视图函数的代码编写 1. 赋值粘贴代码 2. 修改CBV类名(如：BookList -\u0026gt; UserList) 3. 重写赋值 queryset 和 serializer_class 两个类属性 \u0026#34;\u0026#34;\u0026#34; 问题： 这一步写完之后 虽然比较法方便 但是你会发现具体方法的代码既然都一样(冗余度大) 每次都要拷贝同样的代码 只是替换不同的数据模型以及对应模型的序列化器 那我们如果把这些方法通用的代码都封装为不同的Mixin类 然后CBV视图直接使用多继承的方式 岂不是更加方便和简介 \u0026#34;\u0026#34;\u0026#34; drf提供了5个视图扩展Mixin类 封装了上面的通用功能 后面使用 只需要多继承这些Mixin类 即可使用其封装好的方法 - 序列化所有数据 返回Response self.list - 序列化单个数据 返回Response self.retrieve - 反序列化一个数据(新增) 返回Response self.create - 反序列化一个数据(修改) 返回Response self.update - 删除一个数据 返回Response self.destroy \u0026#34;\u0026#34;\u0026#34; 五个视图扩展Mixin类 1 from rest_framework.mixins import * ListModelMixin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class ListModelMixin: \u0026#34;\u0026#34;\u0026#34; List a queryset. \u0026#34;\u0026#34;\u0026#34; def list(self, request, *args, **kwargs): queryset = self.filter_queryset(self.get_queryset()) page = self.paginate_queryset(queryset) if page is not None: serializer = self.get_serializer(page, many=True) return self.get_paginated_response(serializer.data) serializer = self.get_serializer(queryset, many=True) return Response(serializer.data) CreateModelMixin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class CreateModelMixin: \u0026#34;\u0026#34;\u0026#34; Create a model instance. \u0026#34;\u0026#34;\u0026#34; def create(self, request, *args, **kwargs): serializer = self.get_serializer(data=request.data) serializer.is_valid(raise_exception=True) self.perform_create(serializer) headers = self.get_success_headers(serializer.data) return Response(serializer.data, status=status.HTTP_201_CREATED, headers=headers) def perform_create(self, serializer): serializer.save() def get_success_headers(self, data): try: return {\u0026#39;Location\u0026#39;: str(data[api_settings.URL_FIELD_NAME])} except (TypeError, KeyError): return {} RetrieveModelMixin 1 2 3 4 5 6 7 8 class RetrieveModelMixin: \u0026#34;\u0026#34;\u0026#34; Retrieve a model instance. \u0026#34;\u0026#34;\u0026#34; def retrieve(self, request, *args, **kwargs): instance = self.get_object() serializer = self.get_serializer(instance) return Response(serializer.data) UpdateModelMixin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class UpdateModelMixin: \u0026#34;\u0026#34;\u0026#34; Update a model instance. \u0026#34;\u0026#34;\u0026#34; def update(self, request, *args, **kwargs): partial = kwargs.pop(\u0026#39;partial\u0026#39;, False) instance = self.get_object() serializer = self.get_serializer(instance, data=request.data, partial=partial) serializer.is_valid(raise_exception=True) self.perform_update(serializer) if getattr(instance, \u0026#39;_prefetched_objects_cache\u0026#39;, None): # If \u0026#39;prefetch_related\u0026#39; has been applied to a queryset, we need to # forcibly invalidate the prefetch cache on the instance. instance._prefetched_objects_cache = {} return Response(serializer.data) def perform_update(self, serializer): serializer.save() def partial_update(self, request, *args, **kwargs): kwargs[\u0026#39;partial\u0026#39;] = True return self.update(request, *args, **kwargs) DestroyModelMixin 1 2 3 4 5 6 7 8 9 10 11 class DestroyModelMixin: \u0026#34;\u0026#34;\u0026#34; Destroy a model instance. \u0026#34;\u0026#34;\u0026#34; def destroy(self, request, *args, **kwargs): instance = self.get_object() self.perform_destroy(instance) return Response(status=status.HTTP_204_NO_CONTENT) def perform_destroy(self, instance): instance.delete() Mixin类使用 基于GenericAPIView和5个Mixin类重写书籍管理接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 from rest_framework.mixins import CreateModelMixin, ListModelMixin from rest_framework.mixins import DestroyModelMixin, RetrieveModelMixin, UpdateModelMixin from rest_framework.generics import GenericAPIView from .models import Book from .serializers import BookSerializer class BooksDetail(RetrieveModelMixin, UpdateModelMixin, DestroyModelMixin, GenericAPIView): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request, pk): return self.retrieve(request, pk) def put(self, request, pk): return self.update(request, pk) def delete(self, request, pk): return self.destroy(request, pk) class BooksList(ListModelMixin, CreateModelMixin, GenericAPIView): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request): return self.list(request) def post(self, request): return self.create(request) 九个通用视图子类 1 2 3 4 5 \u0026#34;\u0026#34;\u0026#34; 上面使用多继承 继承对应方法的Mixin类和GenericView类重写几个接口 已经非常简介优雅 drf还提供了更方便的继承方法(drf自己完成对应的Mixin和GenericView的继承 你只需要按需继承drf提供的新的类即可) \u0026#34;\u0026#34;\u0026#34; from rest_framework.generics import * CreateAPIView 1 2 3 4 5 6 7 8 # 新增一个对象 POST class CreateAPIView(mixins.CreateModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for creating a model instance. \u0026#34;\u0026#34;\u0026#34; def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) ListAPIView 1 2 3 4 5 6 7 8 # 返回所有对象 GET class ListAPIView(mixins.ListModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for listing a queryset. \u0026#34;\u0026#34;\u0026#34; def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) RetrieveAPIView 1 2 3 4 5 6 7 8 # 返回一个对象 GET retrieve: 取回 class RetrieveAPIView(mixins.RetrieveModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for retrieving a model instance. \u0026#34;\u0026#34;\u0026#34; def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) DestroyAPIView 1 2 3 4 5 6 7 8 # 删除一个对象 DELETE class DestroyAPIView(mixins.DestroyModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for deleting a model instance. \u0026#34;\u0026#34;\u0026#34; def delete(self, request, *args, **kwargs): return self.destroy(request, *args, **kwargs) UpdateAPIView 1 2 3 4 5 6 7 8 9 10 11 # 更新一个对象 PUT/PATCH class UpdateAPIView(mixins.UpdateModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for updating a model instance. \u0026#34;\u0026#34;\u0026#34; def put(self, request, *args, **kwargs): return self.update(request, *args, **kwargs) def patch(self, request, *args, **kwargs): return self.partial_update(request, *args, **kwargs) ListCreateAPIView 1 2 3 4 5 6 7 8 9 10 11 12 # List 返回所有对象|新增一个对象 class ListCreateAPIView(mixins.ListModelMixin, mixins.CreateModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for listing a queryset or creating a model instance. \u0026#34;\u0026#34;\u0026#34; def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) RetrieveUpdateAPIView 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 限制删除单个对象 返回一个对象|更新一个对象 class RetrieveUpdateAPIView(mixins.RetrieveModelMixin, mixins.UpdateModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for retrieving, updating a model instance. \u0026#34;\u0026#34;\u0026#34; def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) def put(self, request, *args, **kwargs): return self.update(request, *args, **kwargs) def patch(self, request, *args, **kwargs): return self.partial_update(request, *args, **kwargs) RetrieveDestroyAPIView 1 2 3 4 5 6 7 8 9 10 11 12 # 限制更新单个对象 返回一个对象|删除一个对象 class RetrieveDestroyAPIView(mixins.RetrieveModelMixin, mixins.DestroyModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for retrieving or deleting a model instance. \u0026#34;\u0026#34;\u0026#34; def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) def delete(self, request, *args, **kwargs): return self.destroy(request, *args, **kwargs) RetrieveUpdateDestroyAPIView 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Detail 返回一个对象|更新一个对象|删除一个对象 class RetrieveUpdateDestroyAPIView(mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, GenericAPIView): \u0026#34;\u0026#34;\u0026#34; Concrete view for retrieving, updating or deleting a model instance. \u0026#34;\u0026#34;\u0026#34; def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) def put(self, request, *args, **kwargs): return self.update(request, *args, **kwargs) def patch(self, request, *args, **kwargs): return self.partial_update(request, *args, **kwargs) def delete(self, request, *args, **kwargs): return self.destroy(request, *args, **kwargs) 通用视图子类使用 根据接口需求继承这9个视图子类重写接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 \u0026#34;\u0026#34;\u0026#34; 这9个视图子类 都继承于GenericAPIView 然后根据不同的接口需求混入实现不同功能的Mixin类 并且实现对应的 get/post/put/patch/delete 方法 我们只需要根据我们接口需求 继承上面这9个视图子类的其中一个或几个即可 然后仅仅只需提供GenericAPIView视图需要的 queryset 和 serializer_class 两个类属性即可十分简洁的完成接口的书写 \u0026#34;\u0026#34;\u0026#34; # 使用9个视图子类中的其中2个重写5个书籍管理接口 from rest_framework.generics import ListCreateAPIView from rest_framework.generics import RetrieveUpdateDestroyAPIView from .models import Book from .serializers import BookSerializer class BooksDetail(RetrieveUpdateDestroyAPIView): queryset = Book.objects.all() serializer_class = BookSerializer class BooksList(ListCreateAPIView): queryset = Book.objects.all() serializer_class = BookSerializer \u0026#34;\u0026#34;\u0026#34; -\u0026gt; 发起请求 -\u0026gt; 路由匹配 -\u0026gt; CBV视图函数 -\u0026gt; as_view()执行返回view函数地址 -\u0026gt; view函数执行dispath方法 完成请求分发 -\u0026gt; dispath方法把此次请求的方法名转换为小写(request.method -\u0026gt; GET -\u0026gt; get -\u0026gt; getattr(self, get)) -\u0026gt; 通过反射getattr获取CBV视图函数的对应方法名称 -\u0026gt; 执行该方法 这个时候 我们继承的这9个视图子类 已经封装好了对应请求的方法 根据实例属性方法的查找是顺序 比如GET请求过来(request.method = GET)： -\u0026gt; 自己写的CBV视图类找对应的get方法 -\u0026gt; 没有找到(这个时候不用再自己提供这些方法) -\u0026gt; 往父类查找 -\u0026gt; 最终会在这9个视图子类找到对应封装的get方法执行 -\u0026gt; 通用视图子类执行自己的get方法 -\u0026gt; 然后调用Mixin类封装的方法序列化/反序列化数据 并返回响应 \u0026#34;\u0026#34;\u0026#34; 视图集ViewSet 1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; 使用上面通用视图子类 已经非常简洁的实现了5个接口 但是我们使用了2个CBV 而且对应的类属性都是一样的(queryset和serializer_calss) 我们是否可以直接合成一个? 问题：合成一个的问题在于 这两个CBV分别都有一个get方法 - 一个get 是获取所有数据 - 另一个get 是获取单个数据 如果能解决这个问题 那么就可以合并 如何解决? \u0026#34;\u0026#34;\u0026#34; ModelViewSet 使用ModelViewSet编写5个接口 需要注意路由的变化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # urls.py \u0026#34;\u0026#34;\u0026#34; 注意路由变化 使用ViewSet actions参数必须传入 简单看下源码发现 此时的as_view方法 已经被ViewSetMixin类重写 解决同一个get请求需要对应执行不同方法的问题 - 获取所有数据 {\u0026#39;get\u0026#39;: \u0026#39;list\u0026#39;} - 获取单个数据 {\u0026#39;get\u0026#39;: \u0026#39;retrieve\u0026#39;} \u0026#34;\u0026#34;\u0026#34; from django.urls import path from . import views urlpatterns = [ # 使用ViewSet actions参数必须传 是一个字典 {请求小写: 执行的方法名} # 当路径匹配上 并且是get请求 会执行BookModelViewSet类的list方法 其余同理 path(\u0026#39;books/\u0026#39;, views.BookModelViewSet.as_view(actions={\u0026#39;get\u0026#39;: \u0026#39;list\u0026#39;, \u0026#39;post\u0026#39;: \u0026#39;create\u0026#39;})), path(\u0026#39;books/\u0026lt;int:pk\u0026gt;/\u0026#39;, views.BookModelViewSet.as_view(actions={\u0026#39;get\u0026#39;: \u0026#39;retrieve\u0026#39;, \u0026#39;put\u0026#39;: \u0026#39;update\u0026#39;, \u0026#39;delete\u0026#39;: \u0026#39;destroy\u0026#39;})), ] # views.py \u0026#34;\u0026#34;\u0026#34;合并BookList CBV 和BookDetail CBV\u0026#34;\u0026#34;\u0026#34; from rest_framework.viewsets import ModelViewSet from .models import Book from .serializers import BookSerializer class BookModelViewSet(ModelViewSet): queryset = Book.objects.all() serializer_class = BookSerializer ViewSetMixin源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 \u0026#34;\u0026#34;\u0026#34; ViewSetMixin重写了as_view方法 核心代码 只要路由中配置了对应关系 比如 {\u0026#39;get\u0026#39;: \u0026#39;list\u0026#39;, \u0026#39;post\u0026#39;: \u0026#39;create\u0026#39;} 当get请求过来 就会执行对象的list方法 当post请求过来 就会执行对象的create方法 通过反射实现 把扩展Mixin类的 list create方法 拿过来赋值给当前ViewSet对象 \u0026#34;\u0026#34;\u0026#34; class ViewSetMixin: \u0026#34;\u0026#34;\u0026#34; This is the magic. Overrides `.as_view()` so that it takes an `actions` keyword that performs the binding of HTTP methods to actions on the Resource. For example, to create a concrete view binding the \u0026#39;GET\u0026#39; and \u0026#39;POST\u0026#39; methods to the \u0026#39;list\u0026#39; and \u0026#39;create\u0026#39; actions... view = MyViewSet.as_view({\u0026#39;get\u0026#39;: \u0026#39;list\u0026#39;, \u0026#39;post\u0026#39;: \u0026#39;create\u0026#39;}) \u0026#34;\u0026#34;\u0026#34; @classonlymethod def as_view(cls, actions=None, **initkwargs): ... def view(request, *args, **kwargs): self = cls(**initkwargs) if \u0026#39;get\u0026#39; in actions and \u0026#39;head\u0026#39; not in actions: actions[\u0026#39;head\u0026#39;] = actions[\u0026#39;get\u0026#39;] # {\u0026#39;get\u0026#39;: \u0026#39;list\u0026#39;, \u0026#39;post\u0026#39;: \u0026#39;create\u0026#39;} self.action_map = actions # Bind methods to actions # This is the bit that\u0026#39;s different to a standard view for method, action in actions.items(): # method: get | action: list # 反射获取属性：执行完handler赋值 handler就变成了list(Mixin类写好的)的内存地址 handler = getattr(self, action) # 反射设置属性：当前视图对象.get = list # 当get请求过来 CBV经过dispath分发 触发视图函数的.get方法 setattr(self, method, handler) # for循环执行完毕 对象.get -\u0026gt; list 对象.post -\u0026gt; create self.request = request self.args = args self.kwargs = kwargs # And continue as usual return self.dispatch(request, *args, **kwargs) ... return csrf_exempt(view) 继承ViewSetMixin的视图类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026#34;\u0026#34;\u0026#34; 通过上面源码的分析 我们知道使用ViewSet的时候 as_view需要一个actions参数 它会将请求方法(key)与你指定的执行函数(value)绑定 那么 继承ViewSetMixin的视图类 我们就可以改写路由 以及改写CBV提供的get/post等的方法名称 总结：继承ViewSetMixin视图类 配置好actions参数的映射关系 CBV方法名称可以任意 \u0026#34;\u0026#34;\u0026#34; urlpatterns = [ path(\u0026#39;books/\u0026#39;, views.BookModelViewSet.as_view(actions={\u0026#39;get\u0026#39;: \u0026#39;get_all_book\u0026#39;})) ] # ViewSetMixin一定要放在APIView前面 # 多继承属性查找顺序 让as_view方法先找ViewSetMixin的 class BookModelViewSet(ViewSetMixin, APIView): def get_all_book(self, request): books = Book.objects.all() serializer = BookSerializer(books, many=True) return Response(serializer.data) # drf内置提供了这些继承ViewSetMixin视图类的子类 ViewSet 1 2 3 4 5 6 7 # 继承APIview 就是上一步我们实现的 # 没有提供任何actions方法 需要我们写的代码是最多的 class ViewSet(ViewSetMixin, views.APIView): \u0026#34;\u0026#34;\u0026#34; The base ViewSet class does not provide any actions by default. \u0026#34;\u0026#34;\u0026#34; pass GenericViewSet 1 2 3 4 5 6 7 8 9 # 继承GenericView 可以使用GenericView的各种方法 # 涉及到序列化/数据库操作 尽量使用GenericView 方便 class GenericViewSet(ViewSetMixin, generics.GenericAPIView): \u0026#34;\u0026#34;\u0026#34; The GenericViewSet class does not provide any actions by default, but does include the base set of generic view behavior, such as the `get_object` and `get_queryset` methods. \u0026#34;\u0026#34;\u0026#34; pass ReadOnlyModelViewSet 1 2 3 4 5 6 7 8 # 只读视图集 只提供获取所有数据 和获取单个数据的方法 class ReadOnlyModelViewSet(mixins.RetrieveModelMixin, mixins.ListModelMixin, GenericViewSet): \u0026#34;\u0026#34;\u0026#34; A viewset that provides default `list()` and `retrieve()` actions. \u0026#34;\u0026#34;\u0026#34; pass ModelViewSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 前面使用的ModelViewSet 提供了5个接口的实现方法 \u0026#34;\u0026#34;\u0026#34; get - list/retrieve post - create put - update patch - partial_update delete - destroy \u0026#34;\u0026#34;\u0026#34; class ModelViewSet(mixins.CreateModelMixin, mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, mixins.ListModelMixin, GenericViewSet): \u0026#34;\u0026#34;\u0026#34; A viewset that provides default `create()`, `retrieve()`, `update()`, `partial_update()`, `destroy()` and `list()` actions. \u0026#34;\u0026#34;\u0026#34; pass 路由Routers 简单写法 在urls.py中配置\nFBV 1 path(\u0026#39;publishs/\u0026lt;int:pk\u0026gt;/\u0026#39;, views.detail) CBV 1 path(\u0026#39;publishs/\u0026lt;int:pk\u0026gt;/\u0026#39;, views.PublishDetail.as_view()) ViewSetMixin 1 2 3 4 # 一旦视图类继承ViewSetMixin之后 写法稍有不同 # as_view() 必须传入actions参数(位置或关键字传参) # ViewSetMixin重写as_view 比如get：通过反射取\u0026#39;list\u0026#39;函数 赋值给\u0026#39;get\u0026#39; path(\u0026#39;books/\u0026#39;, views.BookViewSet.as_view(actions={\u0026#39;get\u0026#39;: \u0026#39;list\u0026#39;, \u0026#39;post\u0026#39;: \u0026#39;create\u0026#39;})) Routers 1 2 对于视图集ViewSet 我们除了可以手动指明请求的方式与动作action之间的对应关系以外 还可以使用Routers来帮助我们快速实现路由信息 routers写法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 继承自ModelViewSet的路由Routers写法 # 1. 导入routers模块 from rest_framework import routers # 2. 该模块有两个类 实例化得到对象 # routers.DefaultRouter() -\u0026gt; 生成的路由更多 # routers.SimpleRouter() -\u0026gt; 生成两条路由 # router = routers.SimpleRouter() router = routers.DefaultRouter() # 3. 注册 # prefix: 路由前缀 不要加斜杠 # viewset: 继承自ModelViewSet的视图类 # basename: 别名 reverse反向解析使用 # router.register(prefix, viewset, basename=None) router.register(\u0026#39;books\u0026#39;, views.BookViewSet) # 4. 将router.urls自动生成的路由加到原路由中 4.1 urlpatterns += router.urls 4.2 urlpatterns = [path(\u0026#39;\u0026#39;, include(router.urls))] SimpleRouter和DefaultRouter 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34;SimpleRouter 自动生成2条路由\u0026#34;\u0026#34;\u0026#34; \u0026lt;URLPattern \u0026#39;^books/$\u0026#39; [name=\u0026#39;book-list\u0026#39;]\u0026gt;, \u0026lt;URLPattern \u0026#39;^books/(?P\u0026lt;pk\u0026gt;[^/.]+)/$\u0026#39; [name=\u0026#39;book-detail\u0026#39;]\u0026gt; \u0026#34;\u0026#34;\u0026#34;DefaultRouter 自动生成6条路由\u0026#34;\u0026#34;\u0026#34; # 这两条跟SimpleRouter一样 \u0026lt;URLPattern \u0026#39;^books/$\u0026#39; [name=\u0026#39;book-list\u0026#39;]\u0026gt;, \u0026lt;URLPattern \u0026#39;^books/(?P\u0026lt;pk\u0026gt;[^/.]+)/$\u0026#39; [name=\u0026#39;book-detail\u0026#39;]\u0026gt;, # 下面两条有名分组：format关键字传参 \u0026lt;URLPattern \u0026#39;^books\\.(?P\u0026lt;format\u0026gt;[a-z0-9]+)/?$\u0026#39; [name=\u0026#39;book-list\u0026#39;]\u0026gt;, # http://127.0.0.1:8000/books.json \u0026lt;URLPattern \u0026#39;^books/(?P\u0026lt;pk\u0026gt;[^/.]+)\\.(?P\u0026lt;format\u0026gt;[a-z0-9]+)/?$\u0026#39; [name=\u0026#39;book-detail\u0026#39;]\u0026gt;, # http://127.0.0.1:8000/books/5.json \u0026lt;URLPattern \u0026#39;^$\u0026#39; [name=\u0026#39;api-root\u0026#39;]\u0026gt;, # 根路径会显示出所有可以访问的地址 \u0026lt;URLPattern \u0026#39;^\\.(?P\u0026lt;format\u0026gt;[a-z0-9]+)/?$\u0026#39; [name=\u0026#39;api-root\u0026#39;]\u0026gt; # http://127.0.0.1:8000/books/books.api|.json action使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 作用：为了给继承自ModelViewSet的视图类中自定义的方法自动生成路由 # 如何使用? from rest_framework.response import Response from rest_framework.viewsets import ModelViewSet from rest_framework.decorators import action from .models import Book from .serializers import BookSerializer class BookViewSet(ModelViewSet): queryset = Book.objects.all() serializer_class = BookSerializer \u0026#34;\u0026#34;\u0026#34; action是一个带参装饰器 参数：methods -\u0026gt; 是一个列表 列表中放请求方式 methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;] 参数：detail -\u0026gt; 布尔类型 True/False 是否带pk - True: ^books/(?P\u0026lt;pk\u0026gt;[^/.]+)/get_one/$ 生成带pk的地址 - False: ^books/get_one/ 生成不带pk的地址 当朝生成的地址发送methods里面支持的请求 会执行下面的函数 \u0026#34;\u0026#34;\u0026#34; @action(methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;], detail=True) def get_one(self, request, pk): print(pk) # 截取1条 book = self.get_queryset()[:2] # 虽然只取1条 但是结果仍然是可迭代对象 不是单个对象 仍需设置many=True serializer = self.get_serializer(book, many=True) return Response(serializer.data) 认证组件 Authentication\n认证类的写法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026#34;\u0026#34;\u0026#34; drf认证得实现： 1. 写一个类 继承BaseAuthentication 注：不继承也可以 只要实现authenticate方法即可 它只是规定了子类的行为 不用一定继承它 2. 重写authenticate方法(实现认证得逻辑) 因为源码中 调用的时候 需要执行认证类的该方法 2.1 认证通过 返回两个值(self.user self.auth) - self.user最终给request.user 当前登录用户 - self.auth 2.2 认证失败 抛异常：AuthenticationFailed(推荐这个) or APIException 3. 使用 3.1 全局使用 settings.py配置 3.2 局部使用 视图类写类属性 看源码知道 全局或者局部配置的属性名字为 如：authentication_classes = [SessionAuthentication, BasicAuthentication] 需要是一个可迭代对象 可以配置多个 按顺序执行 类似配置认证装饰器 \u0026#34;\u0026#34;\u0026#34; 认证源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 \u0026#34;\u0026#34;\u0026#34; -\u0026gt; APIView -\u0026gt; dispath方法 -\u0026gt; self.initial(request, *args, **kwargs) -\u0026gt; self.initial里面包含： - 认证 self.perform_authentication(request) # 认证组件 - 权限 self.check_permissions(request) - 频率 self.check_throttles(request) \u0026#34;\u0026#34;\u0026#34; # 读：self.perform_authentication(request) class APIView(View): authentication_classes = api_settings.DEFAULT_AUTHENTICATION_CLASSES def initialize_request(self, request, *args, **kwargs): # 实例化Request类 传入authenticators认证器 return Request( request, parsers=self.get_parsers(), # 是一个列表 [认证类的对象, 认证类的对象, ...] authenticators=self.get_authenticators(), negotiator=self.get_content_negotiator(), parser_context=parser_context ) def get_authenticators(self): # 列表解析式 去自己的authentication_classes(可迭代对象)取auth 然后直接auth() 执行 # 这里authentication_classes是一个APIView的类属性 取的默认配置 # 列表中是一堆对象(认证类实例) 视图类中配置的authentication_classes = [类名] return [auth() for auth in self.authentication_classes] def initial(self, request, *args, **kwargs): self.perform_authentication(request) self.check_permissions(request) self.check_throttles(request) def perform_authentication(self, request): # 就一句话 需要去drf的Request类中查找user属性(方法) # 进源码看 实际是一个方法 用@property包装成了一个属性 request.user class Request: @property def user(self): if not hasattr(self, \u0026#39;_user\u0026#39;): with wrap_attributeerrors(): # 上下文管理 # 刚开始来 没有_user 走self._authenticate self._authenticate() # 核心 # 有用户 直接返回用户 return self._user # 做认证 核心 def _authenticate(self): # self.authenticators Request类实例化(APIView的dispath的时候实例化的)的时候传入的参数 # 这个参数的类型：是配置的一堆认证类产生的认证类对象组成的list # 遍历拿到一个个认证器(认证类的实例化后得到的对象) 进行认证 for authenticator in self.authenticators: try: # 认证器(对象)调用authenticate(认证类对象(认证类自动注入的self), request请求对象) 所以自定义类实现该方法的时候 需要一个形参接收该self(request请求对象) # 返回值：登录用户与认证的信息组成的tuple # try语句 认证失败抛出异常 user_auth_tuple = authenticator.authenticate(self) # 这里的self是request请求对象 except exceptions.APIException: self._not_authenticated() raise # 返回值的处理 if user_auth_tuple is not None: self._authenticator = authenticator # 如果有返回值 将 登录用户 与 登录认证 分别保存到 request.user request.auth self.user, self.auth = user_auth_tuple return # 如果返回值user_auth_tuple为空 代表认证通过 # 但是没有登录用户与登录信息 代表匿名用户(游客) self._not_authenticated() 自定义认证类 简单登录实现 1 测试简单存了一个token值到服务端数据库 仅为测试方便类似session 认证测试模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.db import models class User(models.Model): username = models.CharField(max_length=32) password = models.CharField(max_length=256) user_type = models.IntegerField(choices=((1, \u0026#39;超级用户\u0026#39;), (2, \u0026#39;普通用户\u0026#39;), (3, \u0026#39;二笔用户\u0026#39;))) age = models.IntegerField() register_time = models.DateField() gender_choices = [(1, \u0026#39;男\u0026#39;), (2, \u0026#39;女\u0026#39;), (3, \u0026#39;其他\u0026#39;)] gender = models.IntegerField(choices=gender_choices) class UserToken(models.Model): \u0026#34;\u0026#34;\u0026#34;垂直分表(库)|水平分表(库)\u0026#34;\u0026#34;\u0026#34; token = models.CharField(max_length=64) # 一对一关联到User表 一对一：就是垂直分表 user = models.OneToOneField(to=\u0026#39;User\u0026#39;, on_delete=models.CASCADE) 认证视图函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import uuid from rest_framework.views import APIView from rest_framework.response import Response from . import models class LoginView(APIView): def post(self, request): username = request.data.get(\u0026#39;username\u0026#39;) password = request.data.get(\u0026#39;password\u0026#39;) user = models.User.objects.filter(username=username, password=password).first() if user: # 登录成功 生成一个随机字符串 token = uuid.uuid4() # 存到UserToken表中 # models.UserToken.objects.create(token=token, user=user) # 这种方式每次登录都会记录一条 不好 有记录 更新即可 # update_or_create 没有就新增 有就更新 models.UserToken.objects.update_or_create(defaults={\u0026#39;token\u0026#39;: token}, user=user) return Response({\u0026#39;status\u0026#39;: 100, \u0026#39;msg\u0026#39;: \u0026#39;登录成功\u0026#39;, \u0026#39;token\u0026#39;: token}) return Response({\u0026#39;status\u0026#39;: 101, \u0026#39;msg\u0026#39;: \u0026#39;用户名或密码错误\u0026#39;}) 实现自定义认证类 编写自定义认证类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from rest_framework.authentication import BaseAuthentication from rest_framework.exceptions import AuthenticationFailed from .models import UserToken from django.db import models \u0026#34;\u0026#34;\u0026#34; 访问URL 需要写法token参数： 127.0.0.1:8000/books/?token=147f71b0-7665-4a06-a178-24fbe98c9332 \u0026#34;\u0026#34;\u0026#34; class MyAuthentication(BaseAuthentication): def authenticate(self, request): # 认证逻辑 # 如果认证通过 返回元组(user, auth) token = request.query_params.get(\u0026#39;token\u0026#39;) if token: try: user_token = UserToken.objects.get(token=token) # 这里返回(user对象, token) 不一定返回user对象 # 可以返回字符串(user_token.user.username)或其他 返回对象 后面方便request.user使用 return user_token.user, token except models.ObjectDoesNotExist: # 如果认证失败 抛出AuthenticationFailed异常 raise AuthenticationFailed(\u0026#39;认证失败\u0026#39;) raise AuthenticationFailed(\u0026#39;请求地址中需要携带token\u0026#39;) 使用自定义认证类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class BookViewSet(ModelViewSet): authentication_classes = [MyAuthentication] # 局部配置 queryset = Book.objects.all() serializer_class = BookSerializer @action(methods=[\u0026#39;get\u0026#39;], detail=False) def get_one(self, request): print(request.user) # user - minho print(request.auth) # token - 147f71b0-7665-4a06-a178-24fbe98c9332 book = self.get_queryset()[:1] serializer = BookSerializer(book, many=True) return Response(serializer.data) # 全局配置 settings.py # 可以有多个 顺序执行配置的认证类 \u0026#34;\u0026#34;\u0026#34; 需要注意：如果配置多个认证类 要把返回两个值的放到最后 因为request.user request.auth会一直重复覆盖 \u0026#34;\u0026#34;\u0026#34; REST_FRAMEWORK = { \u0026#34;DEFAULT_AUTHENTICATION_CLASSES\u0026#34;: [\u0026#39;app01.authentication.MyAuthentication\u0026#39;] } \u0026#34;\u0026#34;\u0026#34; 全局配置这里有一个问题： 全局配置后 所有视图都会进行认证 包括登录视图 还没登录就进行认证... 这里需要对登录视图做局部配置 登录视图不需要任何认证 \u0026#34;\u0026#34;\u0026#34; class LoginView(APIView): authentication_classes = [] # 局部禁用认证 置为空列表实现 内置认证类 BasicAuthentication 1 2 3 4 5 # 针对用户名/密码的HTTP基本身份验证 class BasicAuthentication(BaseAuthentication): pass \u0026#34;\u0026#34;\u0026#34; HTTP Basic authentication against username/password. \u0026#34;\u0026#34; RemoteUserAuthentication 1 2 3 4 5 6 7 8 9 class RemoteUserAuthentication(BaseAuthentication): pass \u0026#34;\u0026#34;\u0026#34; REMOTE_USER authentication. To use this, set up your web server to perform authentication, which will set the REMOTE_USER environment variable. You will need to have \u0026#39;django.contrib.auth.backends.RemoteUserBackend in your AUTHENTICATION_BACKENDS setting \u0026#34;\u0026#34;\u0026#34; SessionAuthentication 1 2 3 4 class SessionAuthentication(BaseAuthentication): pass \u0026#34;\u0026#34;\u0026#34; Use Django\u0026#39;s session framework for authentication. \u0026#34;\u0026#34;\u0026#34; TokenAuthentication 1 2 3 4 5 6 7 8 9 class TokenAuthentication(BaseAuthentication): pass \u0026#34;\u0026#34;\u0026#34; Simple token based authentication. Clients should authenticate by passing the token key in the \u0026#34;Authorization\u0026#34; HTTP header, prepended with the string \u0026#34;Token \u0026#34;. For example: Authorization: Token 401f7ac837da42b97f613d789819ff93537bee6a \u0026#34;\u0026#34;\u0026#34; 权限组件 1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; -\u0026gt; APIView -\u0026gt; dispath方法 -\u0026gt; self.initial(request, *args, **kwargs) -\u0026gt; self.initial里面包含： - 认证 self.perform_authentication(request) - 权限 self.check_permissions(request) # 权限组件 在APIView里面 比认证简单一些 而且在认证之后执行 可以拿到request.user - 频率 self.check_throttles(request) \u0026#34;\u0026#34;\u0026#34; 权限需要和认证配合使用 给认证的用户 分配不同的权限 权限源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class APIView(View): def check_permissions(self, request): \u0026#34;\u0026#34;\u0026#34; Check if the request should be permitted. Raises an appropriate exception if the request is not permitted. \u0026#34;\u0026#34;\u0026#34; for permission in self.get_permissions(): # 权限类的对象 放到列表中 # 执行权限类的has_permission方法 # 从原理这里的判断可以看出 返回值应该是 True/False # 权限通过：True 不通过：False # 在认证之后执行 可以拿到request.user if not permission.has_permission(request, self): self.permission_denied( request, message=getattr(permission, \u0026#39;message\u0026#39;, None), code=getattr(permission, \u0026#39;code\u0026#39;, None) ) 自定义权限类 编写 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026#34;\u0026#34;\u0026#34; 1. 继承BasePermission 2. 重写has_permission 2.1 返回True: 有权限 2.2 返回Flase: 无权限 \u0026#34;\u0026#34;\u0026#34; from rest_framework.permissions import BasePermission class UserPermission(BasePermission): # request drf的request对象 # view 自己写的视图类对象 也有view.request 可以操作更多属性 def has_permission(self, request, view): \u0026#34;\u0026#34;\u0026#34; 实现：不是超级用户 不能访问 由于已经认证过 request.user可以直接取到当前登录用户 if request.user.user_type == 1: return True return False 如果该字段使用了choice 通过get_字段名_display()就能取出后面的备注信息 print(request.user.get_user_type_display()) \u0026#34;\u0026#34;\u0026#34; return True if request.user.user_type == 1 else False 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from .serializers import BookSerializer from .models import Book from .authentication import MyAuthentication from .authentication import UserPermission class BookViewSet(ModelViewSet): authentication_classes = [MyAuthentication] permission_classes = [UserPermission] # 视图类里面局部使用 queryset = Book.objects.all() serializer_class = BookSerializer # 全局使用 settings.py REST_FRAMEWORK = { \u0026#34;DEFAULT_AUTHENTICATION_CLASSES\u0026#34;: [\u0026#39;app01.authentication.MyAuthentication\u0026#39;], \u0026#39;DEFAULT_PERMISSION_CLASSES\u0026#39;: [\u0026#39;rest_framework.permissions.AllowAny\u0026#39;], } # 全局使用之后 部分视图需要局部禁用 permission_classes = [] 输出示例\n1 2 3 { \u0026#34;detail\u0026#34;: \u0026#34;You do not have permission to perform this action.\u0026#34; } 内置权限类 IsAdminUser 1 2 3 4 5 6 7 8 # 使用django的Auth模块 class IsAdminUser(BasePermission): \u0026#34;\u0026#34;\u0026#34; Allows access only to admin users. \u0026#34;\u0026#34;\u0026#34; def has_permission(self, request, view): return bool(request.user and request.user.is_staff) IsAuthenticated 1 2 3 4 5 6 7 class IsAuthenticated(BasePermission): \u0026#34;\u0026#34;\u0026#34; Allows access only to authenticated users. \u0026#34;\u0026#34;\u0026#34; def has_permission(self, request, view): return bool(request.user and request.user.is_authenticated) IsAuthenticatedOrReadOnly 1 2 3 4 5 6 7 8 9 10 11 class IsAuthenticatedOrReadOnly(BasePermission): \u0026#34;\u0026#34;\u0026#34; The request is authenticated as a user, or is a read-only request. \u0026#34;\u0026#34;\u0026#34; def has_permission(self, request, view): return bool( request.method in SAFE_METHODS or request.user and request.user.is_authenticated ) 其余自带权限类参考drf.permissions模块\n频率组件 1 可以对接口访问的频次进行限制 以减轻服务器压力 自定义IP频率限制类 继承BaseThrottle BaseThrottle源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class BaseThrottle: \u0026#34;\u0026#34;\u0026#34; Rate throttling of requests. \u0026#34;\u0026#34;\u0026#34; def allow_request(self, request, view): \u0026#34;\u0026#34;\u0026#34; Return `True` if the request should be allowed, `False` otherwise. \u0026#34;\u0026#34;\u0026#34; # 该方法判断是否限次 没有限次可以请求返回True 限次了不可以请求返回False raise NotImplementedError(\u0026#39;.allow_request() must be overridden\u0026#39;) def get_ident(self, request): \u0026#34;\u0026#34;\u0026#34; Identify the machine making the request by parsing HTTP_X_FORWARDED_FOR if present and number of proxies is \u0026gt; 0. If not use all of HTTP_X_FORWARDED_FOR if it is available, if not use REMOTE_ADDR. \u0026#34;\u0026#34;\u0026#34; xff = request.META.get(\u0026#39;HTTP_X_FORWARDED_FOR\u0026#39;) remote_addr = request.META.get(\u0026#39;REMOTE_ADDR\u0026#39;) num_proxies = api_settings.NUM_PROXIES if num_proxies is not None: if num_proxies == 0 or xff is None: return remote_addr addrs = xff.split(\u0026#39;,\u0026#39;) client_addr = addrs[-min(num_proxies, len(addrs))] return client_addr.strip() return \u0026#39;\u0026#39;.join(xff.split()) if xff else remote_addr def wait(self): \u0026#34;\u0026#34;\u0026#34; Optionally, return a recommended number of seconds to wait before the next request. \u0026#34;\u0026#34;\u0026#34; # 限次后调用 限制还需要等多久才能再次访问 返回等待时间的seconds return None 自定制频率限制类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 \u0026#34;\u0026#34;\u0026#34; 自定义的逻辑 1. 取出访问者IP 2. 判断当前IP在不在访问字典里 2.1 不在 添加进去 并且直接返回True 表示第一次访问 2.2 在字典里 继续往下走 3. 循环判断当前IP的列表 有值 并且当前时间减去列表的最后一个时间大于60s 把这种数据pop掉 这样列表中只有60s以内的访问记录 4. 判断 4.1 当列表小于3 说明一分钟以内访问不足三次 把当前时间插入列表第一个位置 返回True 顺序通过 4.2 当大于等于3 说明一分钟内访问超过三次 返回False验证失败 \u0026#34;\u0026#34;\u0026#34; # 频率限制 自定制 import time from rest_framework.throttling import BaseThrottle class IPThrottle(BaseThrottle): # 这里我们的访问字典放在了内存里 重启就会被清空 # 源码提供的放在了django缓存 VISIT_DIC = {} # 定义成类属性 所有对象都用这一个 def __init__(self): # 不能设置为类属性 每个IP的列表不一样 self.hisroty_list = [] # type: list def allow_request(self, request, view): ip = request.META.get(\u0026#39;REMOTE_ADDR\u0026#39;) ctime = time.time() if ip not in self.VISIT_DIC: self.VISIT_DIC[ip] = [ctime] return True # 当前访问者的时间列表拿出来 self.history_list = self.VISIT_DIC[ip] # while ctime - history_list[-1] \u0026gt; 60: # history_list.pop() while True: if ctime - self.history_list[-1] \u0026gt; 60: # 循环把时间列表最后一个与当前时间差大于60s的移除 self.history_list.pop() else: break # 把全部大于60s的时间移除之后break if len(self.history_list) \u0026lt; 3: # 3 就是配置文件里面配置一分钟可以访问多少次 self.history_list.insert(0, ctime) return True else: return False def wait(self): # history_list = [第三次 第二次 第一次访问时间戳] # 返回该IP还需要等待多少秒可以访问 ctime = time.time() return 60-(ctime - self.history_list[-1]) # 使用 1. 局部使用 在视图类里使用 throttle_classes = [MyThrottles,] 2. 全局使用 settings.py REST_FRAMEWORK = { \u0026#39;DEFAULT_THROTTLE_CLASSES\u0026#39;:[\u0026#39;app01.utils.MyThrottles\u0026#39;,] } 继承SimpleRateThrottle SimpleRateThrottle源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class SimpleRateThrottle(BaseThrottle): \u0026#34;\u0026#34;\u0026#34; A simple cache implementation, that only requires `.get_cache_key()` to be overridden. The rate (requests / seconds) is set by a `rate` attribute on the View class. The attribute is a string of the form \u0026#39;number_of_requests/period\u0026#39;. Period should be one of: (\u0026#39;s\u0026#39;, \u0026#39;sec\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;min\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;hour\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;day\u0026#39;) Previous request information used for throttling is stored in the cache. \u0026#34;\u0026#34;\u0026#34; cache = default_cache timer = time.time cache_format = \u0026#39;throttle_%(scope)s_%(ident)s\u0026#39; scope = None THROTTLE_RATES = api_settings.DEFAULT_THROTTLE_RATES def __init__(self): # 通过反射找rate if not getattr(self, \u0026#39;rate\u0026#39;, None): self.rate = self.get_rate() # self.rate = \u0026#39;3/m\u0026#39; # self.num_requests = 3 # self.duration = 60 self.num_requests, self.duration = self.parse_rate(self.rate) def get_cache_key(self, request, view): \u0026#34;\u0026#34;\u0026#34; Should return a unique cache-key which can be used for throttling. Must be overridden. May return `None` if the request should not be throttled. \u0026#34;\u0026#34;\u0026#34; # 必须重写 返回谁 用什么做key raise NotImplementedError(\u0026#39;.get_cache_key() must be overridden\u0026#39;) def get_rate(self): \u0026#34;\u0026#34;\u0026#34; Determine the string representation of the allowed request rate. \u0026#34;\u0026#34;\u0026#34; if not getattr(self, \u0026#39;scope\u0026#39;, None): msg = (\u0026#34;You must set either `.scope` or `.rate` for \u0026#39;%s\u0026#39; throttle\u0026#34; % self.__class__.__name__) raise ImproperlyConfigured(msg) try: # 去配置文件取配置的scope值 \u0026#39;3/m\u0026#39; return self.THROTTLE_RATES[self.scope] except KeyError: msg = \u0026#34;No default throttle rate set for \u0026#39;%s\u0026#39; scope\u0026#34; % self.scope raise ImproperlyConfigured(msg) def parse_rate(self, rate): \u0026#34;\u0026#34;\u0026#34; Given the request rate string, return a two tuple of: \u0026lt;allowed number of requests\u0026gt;, \u0026lt;period of time in seconds\u0026gt; \u0026#34;\u0026#34;\u0026#34; if rate is None: return (None, None) num, period = rate.split(\u0026#39;/\u0026#39;) # rate: \u0026#39;3/m\u0026#39; -\u0026gt; \u0026#39;3\u0026#39;, \u0026#39;m\u0026#39; num_requests = int(num) duration = {\u0026#39;s\u0026#39;: 1, \u0026#39;m\u0026#39;: 60, \u0026#39;h\u0026#39;: 3600, \u0026#39;d\u0026#39;: 86400}[period[0]] # period取字符串索引0 min:m mmmmm:m return (num_requests, duration) # (3, 60) def allow_request(self, request, view): \u0026#34;\u0026#34;\u0026#34; Implement the check to see if the request should be throttled. On success calls `throttle_success`. On failure calls `throttle_failure`. \u0026#34;\u0026#34;\u0026#34; if self.rate is None: return True # 获取key(IP userID ...) self.key = self.get_cache_key(request, view) if self.key is None: return True # django缓存 # 1. 导包：from django.core.cache import cache # 2. 添加缓存：cache.set(key, value, exp) # 3. 获取缓存： cache.get(key, default_value) # 初次访问缓存为空 self.history = [] 是存放时间的列表 self.history = self.cache.get(self.key, []) # 获取当前时间 存到self.now self.now = self.timer() # Drop any requests from the history which have now passed the # throttle duration while self.history and self.history[-1] \u0026lt;= self.now - self.duration: self.history.pop() if len(self.history) \u0026gt;= self.num_requests: return self.throttle_failure() return self.throttle_success() def throttle_success(self): \u0026#34;\u0026#34;\u0026#34; Inserts the current request\u0026#39;s timestamp along with the key into the cache. \u0026#34;\u0026#34;\u0026#34; self.history.insert(0, self.now) self.cache.set(self.key, self.history, self.duration) return True def throttle_failure(self): \u0026#34;\u0026#34;\u0026#34; Called when a request to the API has failed due to throttling. \u0026#34;\u0026#34;\u0026#34; return False def wait(self): \u0026#34;\u0026#34;\u0026#34; Returns the recommended next request time in seconds. \u0026#34;\u0026#34;\u0026#34; # 计算下一次访问需要等待的时间 if self.history: remaining_duration = self.duration - (self.now - self.history[-1]) else: remaining_duration = self.duration available_requests = self.num_requests - len(self.history) + 1 if available_requests \u0026lt;= 0: return None return remaining_duration / float(available_requests) 继承SimpleRateThrottle自定义限制key 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from rest_framework.throttling import SimpleRateThrottle class MyThrottle(SimpleRateThrottle): \u0026#34;\u0026#34;\u0026#34; SimpleRateThrottle 已经提供了其他方法 只需要重写get_cache_key即可 \u0026#34;\u0026#34;\u0026#34; scope = \u0026#39;sss\u0026#39; # scope配置限制的关键字 def get_cache_key(self, request, view): # 该方法返回什么 就以什么为key -\u0026gt; 以key来限制访问频率 key对应的value是一个时间列表 # 这里返回客户端IP 就以IP限制访问次数 # 如果返回一个固定值 所有人都共有一个key的限制 return xxx print(\u0026#34;IP\u0026#34;, request.META.get(\u0026#39;REMOTE_ADDR\u0026#39;)) return request.META.get(\u0026#39;REMOTE_ADDR\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 自定义频率限制(IP user_id) 1. 继承SimpleRateThrottle 2. 重写get_cache_key 返回什么 就以什么为key进行限制(最好唯一 key对应的值是一个时间列表) 3. scope字段 需要与setting中对应 配置访问频率限制 \u0026#39;scope_name\u0026#39;: \u0026#39;5/m\u0026#39; \u0026#34;\u0026#34;\u0026#34; 内置的频率限制 1 2 3 4 5 6 7 8 9 10 from rest_framework.throttling import * # drf默认配置 \u0026#39;DEFAULT_THROTTLE_CLASSES\u0026#39;: [] # Throttling \u0026#39;DEFAULT_THROTTLE_RATES\u0026#39;: { \u0026#39;user\u0026#39;: None, \u0026#39;anon\u0026#39;: None, }, AnonRateThrottle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;\u0026#34;\u0026#34; 限制所有匿名未认证用户 使用IP区分用户 使用DEFAULT_THROTTLE_RATES[\u0026#39;anon\u0026#39;] 来限制频次 \u0026#34;\u0026#34;\u0026#34; class AnonRateThrottle(SimpleRateThrottle): \u0026#34;\u0026#34;\u0026#34; Limits the rate of API calls that may be made by a anonymous users. The IP address of the request will be used as the unique cache key. \u0026#34;\u0026#34;\u0026#34; scope = \u0026#39;anon\u0026#39; def get_cache_key(self, request, view): if request.user.is_authenticated: return None # Only throttle unauthenticated requests. return self.cache_format % { \u0026#39;scope\u0026#39;: self.scope, \u0026#39;ident\u0026#39;: self.get_ident(request) } UserRateThrottle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026#34;\u0026#34;\u0026#34; 限制认证用户 使用user id区分 使用DEFAULT_THROTTLE_RATES[\u0026#39;user\u0026#39;] 来限制频次 \u0026#34;\u0026#34;\u0026#34; class UserRateThrottle(SimpleRateThrottle): \u0026#34;\u0026#34;\u0026#34; Limits the rate of API calls that may be made by a given user. The user id will be used as a unique cache key if the user is authenticated. For anonymous requests, the IP address of the request will be used. \u0026#34;\u0026#34;\u0026#34; scope = \u0026#39;user\u0026#39; def get_cache_key(self, request, view): if request.user.is_authenticated: ident = request.user.pk else: ident = self.get_ident(request) return self.cache_format % { \u0026#39;scope\u0026#39;: self.scope, \u0026#39;ident\u0026#39;: ident } ScopedRateThrottle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 \u0026#34;\u0026#34;\u0026#34; 限制用户对于每个视图的访问频次 使用ip或者user id \u0026#34;\u0026#34;\u0026#34; class ScopedRateThrottle(SimpleRateThrottle): \u0026#34;\u0026#34;\u0026#34; Limits the rate of API calls by different amounts for various parts of the API. Any view that has the `throttle_scope` property set will be throttled. The unique cache key will be generated by concatenating the user id of the request, and the scope of the view being accessed. \u0026#34;\u0026#34;\u0026#34; scope_attr = \u0026#39;throttle_scope\u0026#39; def __init__(self): # Override the usual SimpleRateThrottle, because we can\u0026#39;t determine # the rate until called by the view. pass def allow_request(self, request, view): # We can only determine the scope once we\u0026#39;re called by the view. self.scope = getattr(view, self.scope_attr, None) # If a view does not have a `throttle_scope` always allow the request if not self.scope: return True # Determine the allowed request rate as we normally would during # the `__init__` call. self.rate = self.get_rate() self.num_requests, self.duration = self.parse_rate(self.rate) # We can now proceed as normal. return super().allow_request(request, view) def get_cache_key(self, request, view): \u0026#34;\u0026#34;\u0026#34; If `view.throttle_scope` is not set, don\u0026#39;t apply this throttle. Otherwise generate the unique cache key by concatenating the user id with the \u0026#39;.throttle_scope` property of the view. \u0026#34;\u0026#34;\u0026#34; if request.user.is_authenticated: ident = request.user.pk else: ident = self.get_ident(request) return self.cache_format % { \u0026#39;scope\u0026#39;: self.scope, \u0026#39;ident\u0026#39;: ident } 使用 限制匿名用户每分钟访问5次 1 2 3 4 5 6 7 8 9 10 11 REST_FRAMEWORK = { \u0026#39;DEFAULT_THROTTLE_CLASSES\u0026#39;: [\u0026#39;rest_framework.throttling.AnonRateThrottle\u0026#39;,], \u0026#39;DEFAULT_THROTTLE_RATES\u0026#39;: { \u0026#39;anon\u0026#39;: \u0026#39;5/m\u0026#39;, }, } # 使用 second minute hour day来置命周期 # 可以全局使用 局部使用 # 局部使用 设置视图使用的频率限制类 访问频次仍在全局配置 throttle_classes = [AnonRateThrottle] 限制登陆用户每分钟访问10次 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 REST_FRAMEWORK = { \u0026#39;DEFAULT_THROTTLE_CLASSES\u0026#39;: [\u0026#39;rest_framework.throttling.UserRateThrottle\u0026#39;,], \u0026#39;DEFAULT_THROTTLE_RATES\u0026#39;: { \u0026#39;user\u0026#39;: \u0026#39;10/m\u0026#39;, }, } # 可以全局使用 局部使用 # 限制登陆用户 局限在于需要使用Django Amdin的那一套认证 # 多个频率类同时使用 REST_FRAMEWORK = { \u0026#39;DEFAULT_THROTTLE_CLASSES\u0026#39;: [ \u0026#39;rest_framework.throttling.UserRateThrottle\u0026#39;, \u0026#39;rest_framework.throttling.AnonRateThrottle\u0026#39; ], \u0026#39;DEFAULT_THROTTLE_RATES\u0026#39;: { \u0026#39;user\u0026#39;: \u0026#39;10/m\u0026#39;, \u0026#39;anon\u0026#39;: \u0026#39;5/m\u0026#39; }, } 输出示例\n1 2 3 { \u0026#34;detail\u0026#34;: \u0026#34;Request was throttled. Expected available in 48 seconds.\u0026#34; } 解析组件 1 2 3 4 5 6 7 8 9 10 from rest_framework.parsers import * # 看下对应解析器源码即可 # 默认配置如下 \u0026#39;DEFAULT_PARSER_CLASSES\u0026#39;: [ \u0026#39;rest_framework.parsers.JSONParser\u0026#39;, \u0026#39;rest_framework.parsers.FormParser\u0026#39;, \u0026#39;rest_framework.parsers.MultiPartParser\u0026#39; ] 过滤 Filtering\n过滤django-filter DjangoFilterBackend\n1 2 3 4 \u0026#34;\u0026#34;\u0026#34; 对于列表数据 可能需要根据字段进行过滤 我们可以通过添加django-filter扩展来增强支持 \u0026#34;\u0026#34;\u0026#34; 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 不是drf内置 需要安装 pip install django-filter # 注册app INSTALLED_APPS = [ ... \u0026#39;django_filters\u0026#39;, ] # 全局配置：在配置文件中增加过滤后端的配置 REST_FRAMEWORK = { ... \u0026#39;DEFAULT_FILTER_BACKENDS\u0026#39;: [\u0026#39;django_filters.rest_framework.DjangoFilterBackend\u0026#39;] } # 在视图中添加filter_fields属性 指定可以过滤的字段 class Bks(ListAPIView): queryset = Book.objects.all() serializer_class = BookSerializer filter_fields = [\u0026#39;title\u0026#39;, \u0026#39;price\u0026#39;] # 配置可以按照哪个字段来过滤 # http://127.0.0.1:8000/bks/?price=8 Django Admin管理其他Model 1 2 3 4 5 6 # admin.py from django.contrib import admin from app01.midels import Book admin.site.register(Book) 排序OrderingFilter OrderingFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026#34;\u0026#34;\u0026#34; 在类视图中设置filter_backends 使用rest_frameworks.OrderingFilter过滤器 RESTframework会在请求的查询字符串参数中检查是否包含了ordering参数 如果包含了ordering参数 则按照ordering参数指明的排序字段对数据集进行排序 前端可以传递的ordering参数的可选字段值 需要在ordering_fields中声明 \u0026#34;\u0026#34;\u0026#34; from rest_framework.filters import OrderingFilter from django_filters.rest_framework import DjangoFilterBackend class Bks(ListAPIView): queryset = Book.objects.all() serializer_class = BookSerializer # 因为局部配置回覆盖全局配置 所以需要重新把过滤组件核心类再次声明 # 否则过滤功能会失效 filter_backends = [OrderingFilter, DjangoFilterBackend] # 局部配置 filter_fields = [\u0026#39;title\u0026#39;, \u0026#39;price\u0026#39;] ordering_fields = [\u0026#39;id\u0026#39;, \u0026#39;price\u0026#39;] # http://127.0.0.1:8000/bks/?ordering=-id # -id 表示针对id字段进行倒叙排序 # id 表示针对id字段进行升序排序 搜索SearchFilter SearchFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 使用 from rest_framework.filters import OrderingFilter, SearchFilter class Bks(ListAPIView): queryset = Book.objects.all() serializer_class = BookSerializer filter_backends = [SearchFilter] search_fields = [\u0026#39;title\u0026#39;, \u0026#39;=price\u0026#39;] # http://127.0.0.1:8000/bks/?search=8.00 \u0026#34;\u0026#34;\u0026#34; 默认情况下 搜索将使用不区分大小写的部分匹配 搜索参数可以包含多个搜索项 其应该是空格和/或逗号分隔 如果使用多个搜索术语 则仅当所有提供的术语都匹配时才在列表中返回对象 可以通过在search_fields前面添加各种字符来限制搜索行为 \u0026#39;^\u0026#39; 以指定内容开始 \u0026#39;=\u0026#39; 完全匹配 \u0026#39;@\u0026#39; 全文搜索(目前只支持Django的MySQL后端) \u0026#39;$\u0026#39; 正则搜索 \u0026#34;\u0026#34;\u0026#34; 异常处理 1 2 # 只要出异常 按照固定的信息返回 # 就算出错 我们也要返回json数据 然后再里面提示error信息 异常处理部分源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # dispath方法 做了异常捕获 class APIView(View): def dispatch(self, request, *args, **kwargs): .../ try: self.initial(request, *args, **kwargs) # Get the appropriate handler method if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed response = handler(request, *args, **kwargs) except Exception as exc: response = self.handle_exception(exc) self.response = self.finalize_response(request, response, *args, **kwargs) return self.response # Exception handling \u0026#39;EXCEPTION_HANDLER\u0026#39;: \u0026#39;rest_framework.views.exception_handler\u0026#39;, \u0026#39;NON_FIELD_ERRORS_KEY\u0026#39;: \u0026#39;non_field_errors\u0026#39;, # exception_handler异常处理源码 from rest_framework.views import exception_handler def exception_handler(exc, context): \u0026#34;\u0026#34;\u0026#34; Returns the response that should be used for any given exception. By default we handle the REST framework `APIException`, and also Django\u0026#39;s built-in `Http404` and `PermissionDenied` exceptions. Any unhandled exceptions may return `None`, which will cause a 500 error to be raised. \u0026#34;\u0026#34;\u0026#34; if isinstance(exc, Http404): exc = exceptions.NotFound() elif isinstance(exc, PermissionDenied): exc = exceptions.PermissionDenied() if isinstance(exc, exceptions.APIException): headers = {} if getattr(exc, \u0026#39;auth_header\u0026#39;, None): headers[\u0026#39;WWW-Authenticate\u0026#39;] = exc.auth_header if getattr(exc, \u0026#39;wait\u0026#39;, None): headers[\u0026#39;Retry-After\u0026#39;] = \u0026#39;%d\u0026#39; % exc.wait if isinstance(exc.detail, (list, dict)): data = exc.detail else: data = {\u0026#39;detail\u0026#39;: exc.detail} set_rollback() return Response(data, status=exc.status_code, headers=headers) return None # 没有处理的异常返回None 引发500 Error # raise_uncaught_exception if response is None: self.raise_uncaught_exception(exc) def raise_uncaught_exception(self, exc): if settings.DEBUG: .../ raise exc # 未处理的异常 直接raise 自定义异常处理方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \u0026#34;\u0026#34;\u0026#34; 自定义异常处理 1. 处理drf未处理的异常 2. 记录错误日志 自定义：统一接口的返回 \u0026#34;\u0026#34;\u0026#34; # 自定义异常处理方法 from rest_framework.views import exception_handler from rest_framework.response import Response from rest_framework import status def my_exception_handler(exc, context): response = exception_handler(exc, context) \u0026#34;\u0026#34;\u0026#34; 两种情况 1. None drf没有处理 2. Response对象 \u0026#34;\u0026#34;\u0026#34; if not response: return Response(data={\u0026#39;status\u0026#39;: 0, \u0026#39;msg\u0026#39;: str(exc)}, status=status.HTTP_400_BAD_REQUEST) # return response return Response(data={\u0026#39;status\u0026#39;:0, \u0026#39;msg\u0026#39;: response.data.get(\u0026#39;detail\u0026#39;)}, status=response.status_code) \u0026#34;\u0026#34;\u0026#34; 如果需要分得更细 再去捕获判断： if isinstance(exc, ZeroDivisionError): pass # 替换为自定义响应对象 return APIResponse(code=0, msg=\u0026#39;error\u0026#39;, result=str(exc)) return APIResponse(code=0, msg=\u0026#39;error\u0026#39;, result=ret.data) \u0026#34;\u0026#34;\u0026#34; 书籍管理接口详细 模型类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 from django.db import models class BaseModel(models.Model): is_delete = models.BooleanField(default=False) # auto_now_add=True 只要记录创建 不需要手动插入时间 自动把当前时间插入 create_time = models.DateTimeField(auto_now_add=True) # auto_now=True 只要更新 就会把当前时间插入 last_update_time = models.DateTimeField(auto_now=True) # import datetime # datetime.datetime.now一定不要加()执行 否则时间都是项目创建的时间 # create_time = models.DateTimeField(default=datetime.datetime.now) class Meta: # 单个字段有索引:db_index=True 有唯一:unique=True 直接配在字段参数中 # 多个字段 有联合索引:index_together 联合唯一:unique_together abstract = True # 抽象表 不在数据库中建立表 class Book(BaseModel): # help_text admin管理后台的网页提示 name = models.CharField(max_length=32, verbose_name=\u0026#39;书名\u0026#39;, help_text=\u0026#39;这里填书名\u0026#39;) price = models.DecimalField(max_digits=8, decimal_places=2) # 一对多的关系一但确立 关联字段写在多的一方 # to_field 默认不屑 关联到主键 # db_constraint=False 控制是否应该在数据库中为这个外键创建一个约束 默认值是True publish = models.ForeignKey(to=\u0026#39;Publish\u0026#39;, on_delete=models.DO_NOTHING, db_constraint=False) # 对对多 跟作者 关联字段写在查询次数多的一方 # 三种创建方式 根据实际选取选择 # 第三张表 只有关联字段 用自动创建 # 第三张表 有扩展字段 需要手动写 authors = models.ManyToManyField(to=\u0026#39;Author\u0026#39;, db_constraint=False) class Meta: verbose_name_plural = \u0026#39;书籍\u0026#39; # admin中显示 def __str__(self): return self.name @property def publish_name(self): return self.publish.name def author_list(self): return [{\u0026#39;name\u0026#39;: author.name, \u0026#39;gender\u0026#39;: author.get_gender_display()} for author in self.authors.all()] class Publish(BaseModel): name = models.CharField(max_length=32) addr = models.CharField(max_length=32) def __str__(self): return self.name class Author(BaseModel): name = models.CharField(max_length=32) gender = models.IntegerField(choices=((1, \u0026#39;男\u0026#39;), (2, \u0026#39;女\u0026#39;), (3, \u0026#39;其他\u0026#39;))) # 一对一关系 写在查询频率高的以方 # OneToOneField的本质就是ForeignKey+unique=True authordetail = models.OneToOneField(to=\u0026#39;AuthorDetail\u0026#39;, db_constraint=False, on_delete=models.CASCADE) class AuthorDetail(BaseModel): phone = models.CharField(max_length=11) \u0026#34;\u0026#34;\u0026#34; # on_delete models.CASCADE 删除关联数据 与之关联也删除 models.DO_NOTHING 删除关联数据 引发错误IntegrityError 不采取任何行动 如果你的数据库后端强制执行引用完整性 这将导致一个 IntegrityError models.PROTECT 删除关联数据 引发错误ProtectedError models.SET_NULL 删除关联数据 与之关联的值设置null(前提是FK字段需要设置可为空) models.SET_DEFAULT 删除关联数据 与之关联的值设置为默认值(前提FK字段需要设置默认值) models.SET 删除关联数据 1. 与之关联的值设置为指定值 设置：models.SET(值) 2. 与之关联的值设置为可执行对象的返回值 设置：models.SET(可执行对象) # 表断关联 1. 表之间没有外键关联 但是有外键逻辑关联(有外键字段 没有设置约束) db_constraint 2. 断关联后不会影响数据库查询效率 但是会极大的提高数据库增删改效率(不影响增删改查操作) 3. 断关联一定要通过逻辑保证表之间数据的安全 不要出现脏数据(代码控制) 4. 断关联 5. 级联关系 作者没了 详情也没：on_delete=models.CASCADE 出版社没了 书还是哪个出版社出版：on_delete=models.DO_NOTHING 部门没了 员工没有部门(空部门)：null=True, on_delete=models.SET_NULL 部门没了 员工进入默认部门(默认值)：default=0, on_delete=models.SET_DEFAULT \u0026#34;\u0026#34;\u0026#34; CBV视图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 from rest_framework.views import APIView from rest_framework.response import Response from . import models from . import serializers class BookAPIView(APIView): def get(self, request, *args, **kwargs): # 查所有 books = models.Book.objects.all().filter(is_delete=False) serializer = serializers.BookModelSerializer(books, many=True) return Response(serializer.data) # 查一个 取pk实现 def post(self, request, *args, **kwargs): \u0026#34;\u0026#34;\u0026#34;具备增单条 和增多条的功能\u0026#34;\u0026#34;\u0026#34; if isinstance(request.data, dict): # 增单条 serializer = serializers.BookModelSerializer(data=request.data) serializer.is_valid(raise_exception=True) serializer.save() return Response(serializer.data) elif isinstance(request.data, list): # 增多条 现在serializer类型为：ListSerialzer serializer = serializers.BookModelSerializer(data=request.data, many=True) print(type(serializer)) serializer.is_valid(raise_exception=True) serializer.save() \u0026#34;\u0026#34;\u0026#34; 新增 -\u0026gt; ListSerializer.save() -\u0026gt; create() def create(self, validated_data): return [self.child.create(attrs) for attrs in validated_data] 增多条：循环新增 self.child: BookModelSerialzer \u0026#34;\u0026#34;\u0026#34; return Response(serializer.data) def put(self, request, *args, **kwargs): # 改一个 if kwargs.get(\u0026#39;pk\u0026#39;, None): book = models.Book.objects.filter(pk=kwargs.get(\u0026#39;pk\u0026#39;)).first() # partial=True允许局部更新 serializer = serializers.BookModelSerializer(book, data=request.data, partial=True) serializer.is_valid(raise_exception=True) serializer.save() return Response(serializer.data) else: # 修改多个 需要新建一个BookListSerializer 并重写 update()方法 # 规定数据格式：request.data: [{id:1, name=xx, price:xxx}, {id:2, name=xx, price:xxx},] # 处理传入的数据：对象列表[book1, book2] 修改的数据列表：[{name:xx,price:xx}, {}] # 方案1：for循环一个个修改 # 方案2：重写ListSerializer的update方法 book_list = [] modify_data = [] for item in request.data: pk = item.pop(\u0026#39;id\u0026#39;) book = models.Book.objects.get(pk=pk) book_list.append(book) modify_data.append(item) # 第一种方案 for循环实现 # for k, v in enumerate(modify_data): # serializer = serializers.BookModelSerializer(book_list[k], data=v) # serializer.is_valid(raise_exception=True) # serializer.save() # 调ListSerializer的update方法 改到自己的 # return Response(\u0026#39;succ\u0026#39;) # 第二种方案 重写ListSerializer的update() serializer = serializers.BookModelSerializer(instance=book_list, data=modify_data, many=True) serializer.is_valid(raise_exception=True) serializer.save() # 调ListSerializer的update方法 改到自己的 return Response(serializer.data) def delete(self, request, *args, **kwargs): # 单个删除 和批量删除 pk = kwargs.get(\u0026#39;pk\u0026#39;) pks = [] if pk: # 单条删除 pks.append(pk) else: # 不管单条删除还是多条删除 都用多条删除 # 多条删除 {\u0026#39;pks\u0026#39;: [1, 2, 3]} pks = request.data.get(\u0026#39;pks\u0026#39;) # 把id_delete设置为True # res返回受影响的行数 res = models.Book.objects.filter(pk__in=pks, is_delete=False).update(is_delete=True) if res: return Response(data={\u0026#39;msg\u0026#39;:\u0026#39;删除成功 删除%s条数据\u0026#39; % res}) return Response(data={\u0026#39;msg\u0026#39;:\u0026#39;没有要删除的数据\u0026#39;}) 序列化器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 from rest_framework import serializers from . import models # 写一个类 继承ListSerializer 重写update class BookListSerialzier(serializers.ListSerializer): def create(self, validated_data): return super().create(validated_data) def update(self, instance, validated_data): print(instance) print(validated_data) # 保存数据 # self.child: 是BookModelSerializer对象 # return [self.child.update(对象, 字典) for attrs in validated_data] return [self.child.update(instance[i], attrs) for i, attrs in enumerate(validated_data)] # 如果序列化的是数据库的表 尽量用ModelSerializer class BookModelSerializer(serializers.ModelSerializer): # 关联字段显示name # 第一种方案：source(只序列化可以 反序列化有问题) # publish = serializers.CharField(source=\u0026#39;publish.name\u0026#39;) # 第二种方案：models中写方法 也可以使用SerializerMethodField字段 class Meta: # many=True的时候 用这个类实例化(源码) list_serializer_class = BookListSerialzier model = models.Book # fields = \u0026#39;__all__\u0026#39; # 联表嵌套深度 用得少 # depth = 0 # fields = (\u0026#39;name\u0026#39;, \u0026#39;price\u0026#39;, \u0026#39;authors\u0026#39;, \u0026#39;publish\u0026#39;) fields = (\u0026#39;id\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;price\u0026#39;, \u0026#39;authors\u0026#39;, \u0026#39;author_list\u0026#39;, \u0026#39;publish\u0026#39;, \u0026#39;publish_name\u0026#39;) read_only_fileds = (\u0026#39;publish_name\u0026#39;, \u0026#39;author_list\u0026#39;) extra_kwargs = { \u0026#39;publish\u0026#39;: {\u0026#39;write_only\u0026#39;: True}, \u0026#39;authors\u0026#39;: {\u0026#39;write_only\u0026#39;: True} } 序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \u0026#34;\u0026#34;\u0026#34; 序列化输出结果 由于设置 read_only 和 write_only字段 序列化只展示read_only字段 不展示write_only字段 反序列化需要给write_only字段 不需要给read_only字段 \u0026#34;\u0026#34;\u0026#34; [ { \u0026#34;name\u0026#34;: \u0026#34;Python\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;131.88\u0026#34;, \u0026#34;author_list\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;minho\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;男\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;kimi\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;女\u0026#34; } ], \u0026#34;publish_name\u0026#34;: \u0026#34;南京出版社\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;js\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;78.00\u0026#34;, \u0026#34;author_list\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;kimi\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;女\u0026#34; } ], \u0026#34;publish_name\u0026#34;: \u0026#34;东京出版社\u0026#34; } ] # source参数可以更改关系字段显示名字 # 但是反序列化会报错 The `.create()` method does not support writable dotted-source fields by default. Write an explicit `.create()` method for serializer `api.serializers.BookModelSerializer`, or set `read_only=True` on dotted-source serializer fields. 反序列化 1 2 3 4 5 6 7 8 9 10 \u0026#34;\u0026#34;\u0026#34; 反序列化传入json数据 提交post 注意：此时反序列化关系字段为 authors[id] 和 publish(id) \u0026#34;\u0026#34;\u0026#34; { \u0026#34;name\u0026#34;: \u0026#34;数据结构\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;99.00\u0026#34;, \u0026#34;authors\u0026#34;: [2], \u0026#34;publish\u0026#34;: 2 } 总结 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # book其实是5个表(自动生成多对多关系表) - 一对一关系 其实是ForeignKey uniqe=True - on_delete: 级联删除 设置为空 什么都不干 设置成默认值 - 联合索引 联合唯一 - 日期类型参数：auto_now_add 和 auto_now - 基表：abstract # book - 单条查询 批量查询(判断kwargs.get(\u0026#39;pk\u0026#39;)处理) - 单条新增 批量新增(生成序列化对象 many=True -\u0026gt; ListSerializer -\u0026gt; 循环掉self.child.save) - 单条修改 批量修改(自定义BookListSerializer 继承ListSerializer: 重写update方法 因为ListSerizlizer没有实现) class Meta: # many=True的时候 用这个类实例化(源码) list_serializer_class = BookListSerialzier # 关联自定义BookListSerializer - 单条删除 批量删除(is_delete) 同一用批量删除 pk__in=[1, 2, 3] 分页器 drf内置三个分页器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from rest_framework.pagination import PageNumberPagination from rest_framework.pagination import LimitOffsetPagination from rest_framework.pagination import CursorPagination \u0026#34;\u0026#34;\u0026#34; def默认配置 DEFAULT_PAGINATION_CLASS: None # 默认不分页 PAGE_SIZE: None # 每页显示数目 配置分页需要配置此参数才能生效 \u0026#34;\u0026#34;\u0026#34; # settings.py REST_FRAMEWORK = { ... \u0026#39;PAGE_SIZE\u0026#39;: 2, } class BookView(ListAPIView): # 局部配置分页 pagination_class = PageNumberPagination queryset = models.Book.objects.all() serializer_class = serializers.BookModelSerializer # 如何使用APIView分页 class BookView(APIView): def get(self, request, *args, **kwargs): # 实例化得到一个分页器对象 books = models.Book.objects.all() page_cursor = MyPageNumberPagination() # paginate_queryset进去筛选数据 books = page_cursor.paginate_queryset(books, request, view=self) # 得到上一页下一页的url next_url = page_cursor.get_next_link() prev_url = page_cursor.get_previous_link() print(next_url) print(prev_url) serializer = serializers.BookModelSerializer(books, many=True) return Response(serializer.data) PageNumberPagination 1 2 3 4 5 6 7 # 页码分页 基本分页 # 继承 并配置4个重要参数 class MyPageNumberPagination(PageNumberPagination): page_size = 2 # 默认每页显示数量 page_query_param = \u0026#39;aaa\u0026#39; # /api/books2/?aaa=2 查询key page_size_query_param = \u0026#39;size\u0026#39; # /api/books2/?aaa=2\u0026amp;size=5 每页显示条数 max_page_size = 5 # 每页最大显示数量 配合上一个参数 LimitOffsetPagination 1 2 3 4 5 6 # 偏移分页 class MyLimitOffsetPagination(LimitOffsetPagination): default_limit = 3 # 默认每页显示数量 limit_query_param = \u0026#39;limit\u0026#39; # 每页数量 offset_query_param = \u0026#39;offset\u0026#39; # 偏移位置 max_limit = 200 # limit最大可以设置数量 CursorPagination 1 2 3 4 5 # 效率高 只能选择往前走 或者往后走(只有上一页下一页) class MyCursorPagination(CursorPagination): cursor_query_param = \u0026#39;cursor\u0026#39; # 查询参数 page_size = 3 # 每页显示的条数 ordering = \u0026#39;-id\u0026#39; # 排序字段 默认-created 没有该字段需要修改配置 自动生成接口文档 1 2 3 4 5 # drf可以自动帮助我们生成接口文档 # 接口文档以网页的方式呈现 # 自动接口文档生成的是继承自 APIView 及其子类的视图 ** # 额外了解：swagger 安装coreapi 1 2 # drf生成接口文档需要coreapi库的支持 pip install coreapi 路由配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 配置路由 from django.urls import path from rest_framework.documentation import include_docs_urls urlpatterns = [ ... path(\u0026#39;docs/\u0026#39;, include_docs_urls(title=\u0026#39;API文档\u0026#39;)) ] # 报错: AttributeError: \u0026#39;AutoSchema\u0026#39; object has no attribute \u0026#39;get_link\u0026#39; # 在settings.py添加配置 REST_FRAMEWORK = { \u0026#39;DEFAULT_SCHEMA_CLASS\u0026#39;: \u0026#39;rest_framework.schemas.coreapi.AutoSchema\u0026#39;, } 文档描述说明的定义位置 单一方法的视图 1 2 3 # 单一方法的视图 可以直接使用类视图的文档字符串 class BookListView(ListAPIView): \u0026#34;\u0026#34;\u0026#34;返回所有图书信息\u0026#34;\u0026#34;\u0026#34; 多个方法的视图 1 2 3 4 5 6 7 8 9 # 包含多个方法的视图 在类视图的文档字符串中 分开方法定义 class BookListView(ListAPIView): \u0026#34;\u0026#34;\u0026#34; get: 返回所有图书信息 post: 新增图书 \u0026#34;\u0026#34;\u0026#34; 视图集ViewSet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 对于视图集 仍在类视图的文档字符串中分开定义 但是应该使用action名称区分 # 视图及ViewSet中的retrieve名称 在接口文档网站中叫做read # 参数的Description需要在模型类或序列化类的字段中以help_text选项定义 # verbose_name help_text class BookListView(ModelViewSet): \u0026#34;\u0026#34;\u0026#34; list: 返回图书列表数据 retrieve: 返回图书详情数据 latest: 返回最新的图书数据 read: 修改图书的阅读量 \u0026#34;\u0026#34;\u0026#34; JWT认证 JsonWebToken入门教程\n1 2 3 4 5 6 7 8 在用户注册或登录后 我们想记录用户的登录状态 或者为用户创建身份认证的凭证 我们不在使用Session认证机制 而是用Json Web Token(本质就是token)认证机制 \u0026#34;\u0026#34;\u0026#34; JsonWebToken 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准(RFE 7519) 该token被设计为紧凑且用于分布式站点的单点登录(SSO)场景 JWT的声明一般被用来在身份提供者和服务者间传递被认证的用户身份信息 以便于从资源服务器获取资源 也可以额外的增加一些其他业务逻辑所必须的声明信息 该token页可以直接被用于认证 也可被加密 不能被篡改 但是你可以拿出来用 只要没有你过期 -\u0026gt; 爬虫 \u0026#34;\u0026#34;\u0026#34; JWT数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 三段信息 Header.Payload.Signature \u0026#34;\u0026#34;\u0026#34; Header - 头部 Payload - 负载 Signature - 签名 \u0026#34;\u0026#34;\u0026#34; # 原理 \u0026#34;\u0026#34;\u0026#34; 1. JWT分三段式：Header.Payload.Signature 2. 头和体是可逆加密 让服务器可以反解出user对象 签名是不可逆加密 保证整个token的安全性 3. 头体签名有三部分 都是采用json格式的字符串进行加密 可逆加密一般采用base64算法 不可逆加密一般采用hash(md5)算法 4. Header中的内容是基本信息：公司信息 项目组信息 token采用的加密方式信息 5. Payload中的内容是关键信息：用户主键 用户名 签发时客户端信息(设备号 地址) 过期时间 6. Signature中的内容时安全信息：头的加密结果 + 体的加密结果 + 服务器不对外公开的安全码进行加密 \u0026#34;\u0026#34;\u0026#34; Header 1 2 3 4 5 6 7 8 9 10 11 12 13 # Header 部分是一个JSON 对象 描述JWT的元数据 通常是下面的样子: { \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } \u0026#34;\u0026#34;\u0026#34; 上面代码中 alg属性表示签名的算法(algorithm) 默认是 HMAC SHA256(写成 HS256) typ属性表示这个令牌(token) 的类型(type) JWT令牌统一写为JWT 最后 将上面的 JSON对象使用 Base64URL算法 转成字符串 \u0026#34;\u0026#34;\u0026#34; Payload 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Payload部分也是一个JSON对象 用来存放实际需要传递的数据 JWT规定了7个官方字段 供选用 iss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 # 除了官方字段 你还可以在这个部分定义私有字段 比如： { \u0026#34;sub\u0026#34;: \u0026#34;1234567890\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;admin\u0026#34;: true } \u0026#34;\u0026#34;\u0026#34; 注意 JWT默认是不加密的 任何人都可以读到 所以不要把秘密信息放在这个部分 这个JSON对象也要使用 Base64URL算法 转成字符串 \u0026#34;\u0026#34;\u0026#34; Signature 1 2 3 4 5 6 7 8 9 10 11 12 \u0026#34;\u0026#34;\u0026#34; Signature 部分是对前两部分的签名 防止数据篡改 首先 需要指定一个密钥(secret) 这个密钥只有服务器才知道 不能泄露给用户 然后 用Header里面指定的签名算法(默认是 HMAC SHA256) 按照下面的公式产生签名 \u0026#34;\u0026#34;\u0026#34; HMACSHA256( base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), secret) # 算出签名以后 把Header Payload Signature三个部分拼成一个字符串 每个部分之间用\u0026#34;点\u0026#34;(.)分隔 就可以返回给用户 Base64URL 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026#34;\u0026#34;\u0026#34; 前面提到 Header和Payload串型化的算法是 Base64URL 这个算法跟Base64算法基本类似 但有一些小的不同 JWT 作为一个令牌(token) 有些场合可能会放到URL 比如 api.example.com/?token=xxx Base64有三个字符 -\u0026gt; + / = 在URL里面有特殊含义 所以要被替换掉 =被省略 +替换成- /替换成_ 这就是 Base64URL算法 \u0026#34;\u0026#34;\u0026#34; 检验 1 2 3 4 5 \u0026#34;\u0026#34;\u0026#34; 1. 将token按 . 拆分为三个字符串 第一段：头加密字符串 一般不需要做任何处理 2. 第二段 体加密字符串 要反解出用户主键 通过主键从User表中就能得到登录用户 过期时间和设备信息都是安全信息 确保token没有过期 且是同一设备来的 3. 再用第一段 + 第二段 + 服务器安全码 不可逆hash(md5等)加密 与第三段签名字符串进行碰撞校验 通过后才能代表第二段校验得到的user对象就是合法的登录用户 \u0026#34;\u0026#34;\u0026#34; DRF项目的JWT认证开发流程 1 2 3 4 5 6 7 \u0026#34;\u0026#34;\u0026#34; 1. 用账号密码访问登录接口 登录接口逻辑中掉用签发token算法 得到token 返回给客户端 客户端自己存到cookies中 2. 校验token的算法应该写在认证类(在认证类中调用) 全局配置给认证组件 所有视图函数类请求 都会进行认证校验 所以请求带token过来 就会反解出user对象 在视图类中用request.user就能访问登录的用户 注：登录接口需要做 认证 + 权限 两个局部禁用 \u0026#34;\u0026#34;\u0026#34; 第三方JWT的使用 1 2 3 4 5 6 7 8 9 10 11 # 官网 https://jpadilla.github.io/django-rest-framework-jwt/ # 第三方写好的 pip install djangorestframework-jwt # 使用 \u0026#34;\u0026#34;\u0026#34; 1. 基于django的Auth模块 2. 使用自己的认证模块 \u0026#34;\u0026#34;\u0026#34; 继承DjangoUser表扩展 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026#34;\u0026#34;\u0026#34; 继承django 原生的User表 最好一开始就使用 \u0026#34;\u0026#34;\u0026#34; # 继承AbstractUser表 扩展字段 from django.db import models from django.contrib.auth.models import AbstractUser class User(AbstractUser): phone = models.CharField(max_length=11) icon = models.ImageField(upload_to=\u0026#39;icon\u0026#39;, default=\u0026#39;icon/default.png\u0026#39;) # ImageField依赖pillow模块 # settings.py配置 # 扩展django自带的user表 AUTH_USER_MODEL = \u0026#39;api.User\u0026#39; # 配置头像相关 MEDIA_URL = \u0026#39;/media/\u0026#39; MEDIA_ROOT = os.path.join(BASE_DIR, \u0026#39;media\u0026#39;) # 开发MEDIA文件 from django.views.static import serve # django内置给你的一个视图函数 类似默认开了static静态文件的路由 from django,urls import re_path from django.conf import settings # 以后取配置文件都用这个 内置 比较全 urlpatterns = [ re_path(\u0026#39;media/?P\u0026lt;path\u0026gt;.*\u0026#39;, serve, {\u0026#39;document_root\u0026#39;: settings.MEDIA_ROOT}) ] # 执行数据库迁移 # 创建超级用户 进行测试 # 国际化 LANGUAGE_CODE = \u0026#39;zh-Hans\u0026#39; TIME_ZONE = \u0026#39;Asia/Shanghai\u0026#39; USE_I18N = True USE_L10N = True USE_TZ = False # 时区 登录认证简单使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 from rest_framework_jwt.views import JSONWebTokenAPIView # 基类 继承APIView # 都继承JSONWebTokenAPIView from rest_framework_jwt.views import ObtainJSONWebToken from rest_framework_jwt.views import RefreshJSONWebToken from rest_framework_jwt.views import VerifyJSONWebToken # 1. urls.py配置路由即可简单快速使用登录接口获取jwt token from django.contrib import admin from django.urls import path from rest_framework_jwt.views import ObtainJSONWebToken urlpatterns = [ path(\u0026#39;admin/\u0026#39;, admin.site.urls), path(\u0026#39;login/\u0026#39;, ObtainJSONWebToken.as_view()), # 正确登录获取jwt token ] # 2. views.py 局部使用jwt认证 from rest_framework.views import APIView from rest_framework.response import Response from rest_framework_jwt.authentication import JSONWebTokenAuthentication class BookBiew(APIView): authentication_classes = [JSONWebTokenAuthentication] # 局部配置jwt认证 def get(self, request): print(request.user, request.user.email) print(request.auth) return Response(\u0026#39;ok\u0026#39;) # 3. 在请求headers带认证参数 否则为匿名用户AnonymousUser(return None) Authorization JWT jwt_value \u0026#34;\u0026#34;\u0026#34; 注意：这个时候 如果请求headers中不带认证参数 源码直接return None 相当于匿名用户AnonymousUser访问 这个时候 如果视图函数允许匿名用户访问 那么此时不带jwt token也可以访问成功 可以通过通过认证类：JSONWebTokenAuthentication 和权限类：IsAuthenticated 来控制用户登录以后才能访问某些接口 如果用户不等录就可以访问 只需要把权限类：IsAuthenticated去掉即可 \u0026#34;\u0026#34;\u0026#34; # 4. 禁止匿名用户访问 from rest_framework.permissions import IsAuthenticated class BookBiew(APIView): authentication_classes = [JSONWebTokenAuthentication] \u0026#34;\u0026#34;\u0026#34;配置权限 IsAuthenticated 只允许认证通过的用户访问\u0026#34;\u0026#34;\u0026#34; permission_classes = [IsAuthenticated] def get(self, request): return Response(\u0026#39;ok\u0026#39;) 自定制JWT认证去除headers前缀 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 自定义重写jwt认证类 重写get_jwt_value方法 去掉认证前缀 JWT token.xx.xx from rest_framework import HTTP_HEADER_ENCODING from rest_framework_jwt.authentication import JSONWebTokenAuthentication class MyToken(JSONWebTokenAuthentication): def get_jwt_value(self, request): auth = request.META.get(\u0026#39;HTTP_AUTHORIZATION\u0026#39;, b\u0026#39;\u0026#39;) if isinstance(auth, str): auth = auth.encode(HTTP_HEADER_ENCODING) return auth # 视图函数局部配置 authentication_classes = [MyToken] # 除此之外 还可以修改前缀 settings.py JWT_AUTH = { # \u0026#39;JWT_AUTH_HEADER_PREFIX\u0026#39;: \u0026#39;JWT\u0026#39;, JWT自带配置 认证请求headrs需要带前缀 \u0026#39;JWT_AUTH_HEADER_PREFIX\u0026#39;: \u0026#39;aaa\u0026#39;, # aaa token.xx.xx } 手动签发JWT 1 2 3 4 5 6 7 8 9 10 11 12 # 可以拥有原生登录基于Model类user对象签发JWT from rest_framework_jwt.settings import api_settings jwt_payload_handler = api_settings.JWT_PAYLOAD_HANDLER jwt_encode_handler = api_settings.JWT_ENCODE_HANDLER palyload = jwt_payload_handler(user) # 把user传入 得到payload token = jwt_encode_handler(palyload) # 把payload传入 得到token # 把三段信息解析出payload 判断认证是否篡改 是否过期 # 通过payload转成user对象 payload = jwt_decode_handler(jwt_value) 登录接口返回数据格式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026#34;\u0026#34;\u0026#34; 控制登录接口返回的数据格式 第一种方案：自己写登录接口 第二种方案：用内置 \u0026#34;\u0026#34;\u0026#34; # jwt的配置响应数据格式 \u0026#39;JWT_RESPONSE_PAYLOAD_HANDLER\u0026#39;: \u0026#39;rest_framework_jwt.utils.jwt_response_payload_handler\u0026#39; # jwt_response_payload_handler源码 # 可以重写该方法 控制返回数据的格式(返回什么 前端登录接口就能看到什么) def jwt_response_payload_handler(token, user=None, request=None): return { \u0026#39;token\u0026#39;: token } \u0026#34;\u0026#34;\u0026#34;自定义控制登录jwt登录接口返回数据格式\u0026#34;\u0026#34;\u0026#34; # 1. 重写jwt_response_payload_handler方法 def jwt_response_payload_handler(token, user=None, request=None): return { \u0026#39;token\u0026#39;: token, \u0026#39;msg\u0026#39;: \u0026#39;登录成功\u0026#39;, \u0026#39;status\u0026#39;: 100, \u0026#39;username\u0026#39;: user.username } # 2. 配置 settings.py JWT_AUTH = { # \u0026#39;JWT_AUTH_HEADER_PREFIX\u0026#39;: \u0026#39;JWT\u0026#39;, JWT自带配置 认证请求headrs需要带前缀 \u0026#39;JWT_AUTH_HEADER_PREFIX\u0026#39;: \u0026#39;aaa\u0026#39;, \u0026#39;JWT_RESPONSE_PAYLOAD_HANDLER\u0026#39;: \u0026#39;api.utils.jwt_response_payload_handler\u0026#39;, # JWT控制返回数据格式 } 返回结果示例\n1 2 3 4 5 6 { \u0026#34;token\u0026#34;: \u0026#34;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoxLCJ1c2VybmFtZSI6Im1pbmhvIiwiZXhwIjoxNjE0ODMwNzgzLCJlbWFpbCI6Ijk3NDMxMTEwQHFxLmNvbSJ9.90l3F4oTT0gWfcgdc0LH9euZYygyWinHF4Ec-kwra-U\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;登录成功\u0026#34;, \u0026#34;status\u0026#34;: 100, \u0026#34;username\u0026#34;: \u0026#34;minho\u0026#34; } 基于JWT自定制认证类 基于BaseAuthentication 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import jwt from rest_framework.authentication import BaseAuthentication from rest_framework.exceptions import AuthenticationFailed from rest_framework_jwt.utils import jwt_decode_handler from api import models class MyJwtAuthentication(BaseAuthentication): def authenticate(self, request): jwt_value = request.META.get(\u0026#39;HTTP_AUTHORIZATION\u0026#39;) if jwt_value: try: # jwt提供了三段token 取出用payload的方法 并且有校验功能 payload = jwt_decode_handler(jwt_value) except jwt.ExpiredSignature: raise AuthenticationFailed(\u0026#39;签名过期\u0026#39;) except jwt.InvalidTokenError: raise AuthenticationFailed(\u0026#39;用户非法\u0026#39;) except Exception as exc: raise AuthenticationFailed(str(exc)) # 因为payload就是用户信息字典 # print(payload) # return payload, jwt_value # 需要得到user对象 # 1. 去数据库查 # user = models.User.objects.get(pk=payload.get(\u0026#39;user_id\u0026#39;)) # 2. 不查库自己转 速度块一些 user = models.User(id=payload[\u0026#39;user_id\u0026#39;], username=payload[\u0026#39;username\u0026#39;]) return user, jwt_value # 没有带认证信息 直接抛异常 raise AuthenticationFailed(\u0026#39;你没有携带认证信息\u0026#39;) 基于BaseJSONWebTokenAuthentication 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import jwt from rest_framework.exceptions import AuthenticationFailed from rest_framework_jwt.authentication import BaseJSONWebTokenAuthentication from rest_framework_jwt.utils import jwt_decode_handler class MyJwtAuthentication(BaseJSONWebTokenAuthentication): def authenticate(self, request): jwt_value = request.META.get(\u0026#39;HTTP_AUTHORIZATION\u0026#39;) if jwt_value: try: # jwt提供了三段token 取出用payload的方法 并且有校验功能 payload = jwt_decode_handler(jwt_value) except jwt.ExpiredSignature: raise AuthenticationFailed(\u0026#39;签名过期\u0026#39;) except jwt.InvalidTokenError: raise AuthenticationFailed(\u0026#39;用户非法\u0026#39;) except Exception as exc: raise AuthenticationFailed(str(exc)) # 继承BasejsonWeb 直接调用下面方法获取user对象 user = self.authenticate_credentials(payload) return user, jwt_value # 没有带认证信息 直接抛异常 raise AuthenticationFailed(\u0026#39;你没有携带认证信息\u0026#39;) 多方式登录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # 使用用户名 手机号 邮箱 都可以登录 # 前端需要传的数据格式 { \u0026#34;username\u0026#34;: \u0026#34;lqz/13334449988/123@qq.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34; } # serializers.py import re from rest_framework import serializers from rest_framework.exceptions import ValidationError from rest_framework_jwt.settings import api_settings from api import models jwt_payload_handler = api_settings.JWT_PAYLOAD_HANDLER jwt_encode_handler = api_settings.JWT_ENCODE_HANDLER class LoginModelSerialzier(serializers.ModelSerializer): username = serializers.CharField() class Meta: model = models.User fields = [\u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;] def validate(self, attrs): # 在这写逻辑 username = attrs.get(\u0026#39;username\u0026#39;) # 用户名有三种方式 password = attrs.get(\u0026#39;password\u0026#39;) # 通过判断username数据不同 查询字段不一样 # 正则匹配 如果是手机号 if re.match(\u0026#39;^1[3-9][0-9]{9}$\u0026#39;, username): user = models.User.objects.filter(phone=username).first() elif re.match(\u0026#39;^.+@.+$\u0026#39;, username): # 邮箱 user = models.User.objects.filter(email=username).first() else: user = models.User.objects.filter(username=username).first() if user: # 存在用户 # 校验密码 因为是密文 要用check_password if user.check_password(password): # 签发token payload = jwt_payload_handler(user) # user传入 得到payload token = jwt_encode_handler(payload) # payload传入 得到token # self.token = token 推荐使用context self.context[\u0026#39;token\u0026#39;] = token self.context[\u0026#39;username\u0026#39;] = user.username return attrs else: raise ValidationError(\u0026#39;密码错误\u0026#39;) raise ValidationError(\u0026#39;用户不存在\u0026#39;) # views.py from rest_framework.viewsets import ViewSet from api import serializers # class Login2View(ViewSetMixin, APIView): class Login2View(ViewSet): \u0026#34;\u0026#34;\u0026#34;这是登录接口\u0026#34;\u0026#34;\u0026#34; # def post(self, request): # 不写post 直接写login? # pass def login(self, request, *args, **kwargs): # 1. 需要有个序列化的类 # 2. 生成序列化类对象 serializer = serializers.LoginModelSerialzier(data=request.data) # 3. 调用序列化对象的is_valid serializer.is_valid(raise_exception=True) token = serializer.context.get(\u0026#39;token\u0026#39;) # 4. return return Response({\u0026#39;status\u0026#39;:100, \u0026#39;msg\u0026#39;:\u0026#39;success\u0026#39;, \u0026#39;token\u0026#39;: token, \u0026#39;username\u0026#39;: serializer.context.get(\u0026#39;username\u0026#39;)}) # urls.py path(\u0026#39;login2/\u0026#39;, views.Login2View.as_view({\u0026#39;post\u0026#39;:\u0026#39;login\u0026#39;})) 配置过期时间 1 2 3 4 5 6 7 8 9 10 # 过期时间 \u0026#39;JWT_EXPIRATION_DELTA\u0026#39;: datetime.timedelta(seconds=300) # 配置 settings.py import datetime JWT_AUTH = { # 过期时间手动配置 \u0026#39;JWT_EXPIRATION_DELTA\u0026#39;: datetime.timedelta(days=7), } RBAC 1 2 3 4 5 6 7 8 9 10 11 # RBAC： 基于角色的访问控制 用在公司内部系统居多 # Django的Auth体系 就是内置了一套RBAC的权限系统 # 权限三表 User Group Permisson 多对多 多对多 # 权限六表 User Group Permisson UG关系表 GP关系表 正常5个就够：Django多一个 UP关系表 单独直接给每一个人加权限 DjangoAuth 权限6表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026#34;\u0026#34;\u0026#34; # 后台的权限控制(公司内部系统 crm/erp/协同平台) auth_user # 用户表 auth_group # 用户组 auth_permission # 权限表 auth_user_groups # 用户 组 关系表 多对多 auth_group_permissions # 组 权限 关系表 多对多 auth_user_user_permissions # 用户 权限 关系表 多对多 # 前台(主站) 需要用三大认证 - 认证 - 权限 - 频率 后台管理用户 和前台注册用户 可以是两个user表 也可以共用一个 \u0026#34;\u0026#34;\u0026#34; ","date":"2020-02-22T21:10:17+08:00","permalink":"https://ilolicon.github.io/p/djangorestframework/","title":"DjangoRESTframework"},{"content":"Django英文官方文档\nDjango中文官方文档\nDjango请求生命周期 流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026#34;\u0026#34;\u0026#34; 浏览器发送请求 =\u0026gt; WEB网关服务接口 =\u0026gt; Django框架 -\u0026gt; 中间件 middleware (-\u0026gt; 缓存数据库 拿到则返回) -\u0026gt; 路由层 urls.py -\u0026gt; 视图层 views.py -\u0026gt; 模板层 templates -\u0026gt; 模型层 modes.py -\u0026gt; 拿到数据/模板 渲染后按路径返回 请求经过WEB网关服务接口： - django自带的是wsgiref 1. 请求来的时候 解析请求 并封装为request对象 2. 响应走的时候 打包处理 - django自带的wsgiref模块本身能够支持的并发量很小 最多1000左右 - 上线会换成 nginx(反向代理) + uwsgi WSGI/wsgiref/uwsgi是什么关系? - WSGI 是协议 - wsgiref/uwsgi是实现该协议的功能模块 请求经过Django框架： -\u0026gt; 先经过Django中间件(类似与django的保安 门户) -\u0026gt; 路由层 urls.py 路由匹配与分发 识别路由匹配对应的视图函数 -\u0026gt; 视图层 views.py 网站整体的业务逻辑 - 视图层可能需要模板 -\u0026gt; 模板层(templates文件夹) 网站所有的html页面 - 视图层可能需要数据 -\u0026gt; 模型层 models.py **重要** ORM - 视图层拿到数据之后 渲染并按路径返回 \u0026#34;\u0026#34;\u0026#34; 扩展 缓存数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026#34;\u0026#34;\u0026#34; 提前已经将你想要的数据准备好 你来直接拿即可 - 减轻后端压力 - 提高效率和响应时间 缓存数据库在请求流程中的位置 - 经过中间件之后 直接请求缓存数据库 - 拿到 直接返回 - 没拿到 走正常流程 然后存一份到缓存数据库并返回 当你在修改数据的时候 你会发现数据并不是立即修改完的 而是需要经过一段时间才会修改(还在访问缓存的内容) \u0026#34;\u0026#34;\u0026#34; 注意事项 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 如何让你的计算机能够正常的启动Django项目 \u0026#34;\u0026#34;\u0026#34; 1. 计算机的名称不能有中文 2. 一个Pycharm窗口只开一个项目 3. 项目里面所有的文件也尽量不要出现中文 4. Python解释器结论使用 3.4-3.6之间的版本 4.1. 如果你的项目报错 点击最后一个报错信息 去源码中把逗号删掉 \u0026#34;\u0026#34;\u0026#34; # Django版本问题 推荐使用：LTS 官方长期支持维护的版本 \u0026#34;\u0026#34;\u0026#34; 1.x 2.x 3.x(成熟版本出来后考虑) 1.x 和 2.x 本身差距并不大 \u0026#34;\u0026#34;\u0026#34; 安装 1 2 3 4 5 6 7 8 # 安装django == 指定安装版本 pip install django==x.x.x # e.g. 直接安装 会自动卸载旧的安装新的 pip install django==1.11.11 # 验证是否安装成功 django-admin # 看是否输出帮助文档 Django基本操作 命令行操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 1. 创建django项目 # 如果已经实现创建项目目录 [目录] 直接换为 .(当前目录) django-admin startproject [项目名] [目录] django-admin startproject [name] . # e.g. cd MinhoDjango # 进入已存在的目录 作为项目根目录 django-admin startprojcet mysite . # 2. 启动django目录 python manage.py runserver # 默认: 127.0.0.1:8080 # 3. 创建应用 \u0026#34;\u0026#34;\u0026#34; Next, start your first app by running python manage.py startapp [app_label]. 应用名应该做到见名知意： - user - order - web - ... \u0026#34;\u0026#34;\u0026#34; python manage.py startapp app01 Pycharm创建 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; 1. File --\u0026gt; New Project --\u0026gt; Django项目 2. 启动 2.1 还是用命令行启动 2.2 点击绿色小箭头即可 3. 创建应用app 3.1 还是用命令行创建 3.2 Tools --\u0026gt; Run manage.py Task... # 进入shell startapp app01 # 创建app01 应用 4. 修改端口号以及创建server 右上角 --\u0026gt; Edit Configure \u0026#34;\u0026#34;\u0026#34; 区别 命令行与pycharm创建的区别\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026#34;\u0026#34;\u0026#34; 1. 命令行创建不会自动有 root_projects/templates 文件夹 需要你自己手动创建 而pycharm创建会自动帮你创建并且还会自动在配置文件中配置对应的路径 意味着 你在用命令创建django项目的时候 不单单需要创建templates文件夹 还需要去配置文件中配置路径 \u0026#34;\u0026#34;\u0026#34; # 命令行创建 TEMPLATES = [ { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.template.backends.django.DjangoTemplates\u0026#39;, \u0026#39;DIRS\u0026#39;: [], }, ] # Pycharm创建 TEMPLATES = [ { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.template.backends.django.DjangoTemplates\u0026#39;, \u0026#39;DIRS\u0026#39;: [BASE_DIR / \u0026#39;templates\u0026#39;] }, ] 应用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026#34;\u0026#34;\u0026#34; django 是一款专门用来开发app的web框架 django框架就类似一所大学(空壳子 需要自己创建具有不同功能的app) app就类似大虚额里面的各个学院(学院--具体功能的app) 比如开发淘宝： - 订单相关 - 用户相关 - 投诉相关 - 创建不同的app对应不同的功能 学课系统： - 学生功能 - 老师功能 一个app就是一个独立的功能模块 \u0026#34;\u0026#34;\u0026#34; 创建的应用 一定要去配置文件中注册\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Application definition \u0026#34;\u0026#34;\u0026#34; 一定要注册 否则应用不生效 创建出来的应用 第一步先去配置文件中注册 备注: 在使用Pycharm创建项目的时候 Pycharm可以帮你创建一个app并自动注册(仅一个) \u0026#34;\u0026#34;\u0026#34; INSTALLED_APPS = [ \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;app01.apps.App01Config\u0026#39;, # 全写 \u0026#39;app02\u0026#39;, # 简写 ] # 全写 or 简写 选择其中一种即可 主要文件介绍 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;\u0026#34;\u0026#34; MinhoDjango/ - manage.py django的入口文件 - db.sqlite3 django自带的sqlite3数据库(小型数据库 功能不全还有BUG) - mysite/ - __init__.py - settings.py 配置文件 - urls.py 路由与视图对应关系(路由层) - wsgi.py wsgiref模块(忽略) - app01 - migrations/ 所有的数据库迁移记录(类日志记录) - __init__.py - __init__.py - admin.py django后台管理 - apps.py 注册使用 - models.py 数据库相关的 模型类(模型层 ORM) - tests.py 测试文件(忽略) - views.py 视图函数(视图层) \u0026#34;\u0026#34;\u0026#34; 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 # SECURITY WARNING: don\u0026#39;t run with debug turned on in production! DEBUG = True # 上线之后改为Flase ALLOWED_HOSTS = [] # 上线之后可以写 \u0026#39;*\u0026#39; 允许所有 # 注册的app(app就是自带的功能模块) django一创建出来 自带6个功能模块 # Application definition INSTALLED_APPS = [ \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;app01.apps.App01Config\u0026#39;, \u0026#39;app02\u0026#39;, ] # Django中间件 MIDDLEWARE = [ \u0026#39;django.middleware.security.SecurityMiddleware\u0026#39;, \u0026#39;django.contrib.sessions.middleware.SessionMiddleware\u0026#39;, \u0026#39;django.middleware.common.CommonMiddleware\u0026#39;, \u0026#39;django.middleware.csrf.CsrfViewMiddleware\u0026#39;, \u0026#39;django.contrib.auth.middleware.AuthenticationMiddleware\u0026#39;, \u0026#39;django.contrib.messages.middleware.MessageMiddleware\u0026#39;, \u0026#39;django.middleware.clickjacking.XFrameOptionsMiddleware\u0026#39;, ] # HTML存放路径配置 TEMPLATES = [] # 项目指定数据库配置 默认sqlite3 # Database # https://docs.djangoproject.com/en/3.1/ref/settings/#databases DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.sqlite3\u0026#39;, \u0026#39;NAME\u0026#39;: BASE_DIR / \u0026#39;db.sqlite3\u0026#39;, } } # Password validation # https://docs.djangoproject.com/en/3.1/ref/settings/#auth-password-validators AUTH_PASSWORD_VALIDATORS = [] # 日志记录实践 LOGGING = { \u0026#39;version\u0026#39;: 1, \u0026#39;disable_existing_loggers\u0026#39;: False, \u0026#39;formatters\u0026#39;: { \u0026#39;verbose\u0026#39;: { \u0026#39;format\u0026#39;: \u0026#39;{levelname} {asctime} {module} {process:d} {thread:d} {message}\u0026#39;, \u0026#39;style\u0026#39;: \u0026#39;{\u0026#39;, }, \u0026#39;simple\u0026#39;: { \u0026#39;format\u0026#39;: \u0026#39;{levelname} {message}\u0026#39;, \u0026#39;style\u0026#39;: \u0026#39;{\u0026#39;, }, }, \u0026#39;filters\u0026#39;: { \u0026#39;require_debug_true\u0026#39;: { \u0026#39;()\u0026#39;: \u0026#39;django.utils.log.RequireDebugTrue\u0026#39;, }, }, \u0026#39;handlers\u0026#39;: { \u0026#39;console\u0026#39;: { \u0026#39;level\u0026#39;: \u0026#39;INFO\u0026#39;, \u0026#39;filters\u0026#39;: [\u0026#39;require_debug_true\u0026#39;], \u0026#39;class\u0026#39;: \u0026#39;logging.StreamHandler\u0026#39;, \u0026#39;formatter\u0026#39;: \u0026#39;simple\u0026#39; }, \u0026#39;file\u0026#39;: { \u0026#39;level\u0026#39;: \u0026#39;INFO\u0026#39;, # 实际开发建议使用ERROR \u0026#39;class\u0026#39;: \u0026#39;logging.handlers.RotatingFileHandler\u0026#39;, \u0026#39;filename\u0026#39;: os.path.join(os.path.dirname(BASE_DIR), \u0026#39;logs\u0026#39;, \u0026#39;chaos.log\u0026#39;), \u0026#39;maxBytes\u0026#39;: 200 * 1024 * 1024, # 100M \u0026#39;backupCount\u0026#39;: 10, # 日志文件备份数量 \u0026#39;formatter\u0026#39;: \u0026#39;verbose\u0026#39;, # 日志格式：详细 \u0026#39;encoding\u0026#39;: \u0026#39;utf-8\u0026#39; # 文件编码格式 } }, \u0026#39;loggers\u0026#39;: { \u0026#39;django\u0026#39;: { \u0026#39;handlers\u0026#39;: [\u0026#39;console\u0026#39;, \u0026#39;file\u0026#39;], \u0026#39;propagate\u0026#39;: True, } } } Django小白必会三板斧 HttpResponse HttpResponse 直接返回字符串\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.shortcuts import HttpResponse # Create your views here. # 视图函数必须要接收一个形参：request def index(request): \u0026#34;\u0026#34;\u0026#34; :param request: 请求相关的所有数据对象 比之前的environ更好用 是对象 直接. 取属性 比字典好用 :return: \u0026#34;\u0026#34;\u0026#34; data = HttpResponse(\u0026#39;Hello, Django\u0026#39;) print(\u0026#39;1\u0026#39;, data) print(\u0026#39;2\u0026#39;, type(data)) return HttpResponse(\u0026#34;Hello, Django\u0026#34;) \u0026gt;\u0026gt;\u0026gt; 1 \u0026lt;HttpResponse status_code=200, \u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; \u0026gt;\u0026gt;\u0026gt; 2 \u0026lt;class \u0026#39;django.http.response.HttpResponse\u0026#39;\u0026gt; render render 返回html文件 使用渲染之后的模板\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 from django.shortcuts import render # Create your views here. def index(request): return render(request, \u0026#39;myfirst.html\u0026#39;) # 命令行创建 需要配置模板目录 $ mkdir ${root_projects}/templates TEMPLATES = [ { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.template.backends.django.DjangoTemplates\u0026#39;, \u0026#39;DIRS\u0026#39;: [os.path.join(BASE_DIR, \u0026#39;templates\u0026#39;)] }, ] render两种传值方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 def index(request): \u0026#34;\u0026#34;\u0026#34; 1. 直接传一个字典 模板使用key进行使用 精确传值 使用哪个传哪个 2. local() locals() 会将所在的名称空间中所有的名字全部传递给HTML页面 当需要传的变量特别多的时候 使用 locals() 传值 \u0026#34;\u0026#34;\u0026#34; user_dict = {\u0026#39;username\u0026#39;: \u0026#39;Minho\u0026#39;, \u0026#39;age\u0026#39;: 25} # render 传值 1. # return render(request, \u0026#39;myfirst.html\u0026#39;, {\u0026#39;data\u0026#39;: user_dict, \u0026#39;date\u0026#39;: \u0026#39;2021-02-09\u0026#39;}) # render 传值 2. return render(request, \u0026#39;myfirst.html\u0026#39;, locals()) redirect 重定向\n1 2 3 4 5 6 7 8 9 from django.shortcuts import redirect # Create your views here. def index(request): # return redirect(\u0026#39;https://www.baidu.com/\u0026#39;) # 重定向到外部网址 return redirect(\u0026#39;/home/\u0026#39;) # 302重定向到 自己的网站 /home/ def home(request): return HttpResponse(\u0026#39;home\u0026#39;) 登录功能实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 登录功能 \u0026#34;\u0026#34;\u0026#34; html文件：默认都放在templates文件夹下 静态文件：将网站使用的静态文件默认都放在static文件夹下 静态文件：前端已经写好 能够直接调用使用的文件 - 网站写好的js文件 - 网站写好的css文件 - 网站用到的图片文件 - 第三方前端框架 ... 总结：拿来就可以直接使用的 \u0026#34;\u0026#34;\u0026#34; # django默认不会自动创建static文件夹 需要你手动创建 一般情况下 我们会在static文件夹内 还会做进一步的划分处理 =\u0026gt; 解耦合 方便管理 - static - js - css - img - 其他第三方文件 \u0026#34;\u0026#34;\u0026#34; 在浏览器中 输入url能够看到对应的资源 是因为后端提前开设了该资源的接口 -- 路由分发 如果访问不到资源 说明后端没有开设该资源的接口 \u0026#34;\u0026#34;\u0026#34; # 访问 login页面 没有加载bootstrap样式的问题 访问 http://127.0.0.1:8000/static/bootstrap-3.3.7-dist/css/bootstrap.min.css 报错 说明后端没有开设该资源的请求路由出来 # 静态文件配置 -- 重点 按照下面方法在settings.py配置文件配置static相关静态文件配置之后 即可访问引用的本地static文件夹下面的静态资源 -- 类似于django自己帮我们开设了对应的路由接口 login.html示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Login In\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;/static/bootstrap-3.3.7-dist/css/bootstrap.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;/static/bootstrap-3.3.7-dist/js/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;/static/js/jquery-3.5.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 class=\u0026#34;text-center\u0026#34;\u0026gt;登录\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 静态文件配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 类似于访问静态文件的令牌 # 如果你想要访问静态文件 你就必须以static开头 # 切记：该配置 是配置访问url的开头的值 令牌 并不是静态文件存放的目录 STATIC_URL = \u0026#39;/static/\u0026#39; \u0026#34;\u0026#34;\u0026#34; /static/ - 令牌 去下面STATICFILES_DIRS列表里面的目录里面 按顺序查找引用的文件 eg. bootstrap-3.3.7-dist/css/bootstrap.min.css 都没有找到 则报错 \u0026#34;\u0026#34;\u0026#34; # 静态文件配置 列表 可以有多个(令牌持有者可以访问的文件路径) # 静态文件真正存放的目录 可以有多个目录 按顺序解析 # 前面的找到请求的文件之后 不再向后查找 STATICFILES_DIRS = [ os.path.join(BASE_DIR, \u0026#39;static\u0026#39;), os.path.join(BASE_DIR, \u0026#39;static1\u0026#39;), ] # 浏览器 设置页面不缓存的方法 \u0026#34;\u0026#34;\u0026#34; 当你在写django项目的时候 可能会出现后端代码修改了但是前端页面没有变化的情况 1. 在同一个端口开了好几个django项目 一直在跑的是第一个django项目 2. 浏览器缓存的问题 按照下面方法解决 右键 --\u0026gt; 检查 --\u0026gt; 设置图标(settings) --\u0026gt; Preferences --\u0026gt; Network --\u0026gt; 勾选上 Disable cache(while Devtools is open) \u0026#34;\u0026#34;\u0026#34; 静态文件动态解析\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!-- 静态文件动态解析 使用模板语法 会自动解析setting.py里面配置的 STATIC_URL 然后自动拼接url e.g: STATIC_URL = \u0026#39;/static/\u0026#39; url -\u0026gt; /static/bootstrap-3.3.7-dist/js/bootstrap.min.js or STATIC_URL= \u0026#39;/xxx/\u0026#39; url -\u0026gt; /xxx/bootstrap-3.3.7-dist/js/bootstrap.min.js --\u0026gt; {% load static %} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{% static \u0026#39;bootstrap-3.3.7-dist/css/bootstrap.min.css\u0026#39; %}\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;{% static \u0026#39;bootstrap-3.3.7-dist/js/bootstrap.min.js\u0026#39; %}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; form表单\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # form表单 默认是GET方法请求数据 # ?后面的内容为参数 不参与(不影响)路径匹配 http://127.0.0.1:8000/login/?username=minho\u0026amp;password=123131313 \u0026#34;\u0026#34;\u0026#34; form表单action参数 1. 不写 默认向当前所在的url提交数据 2. 全写 指名道姓 3. 只写后缀 /login/ \u0026#34;\u0026#34;\u0026#34; \u0026#34;\u0026#34;\u0026#34; form表单提交方法 改为post提交数据 提交会报错 Forbidden (403) CSRF verification failed. Request aborted. 解决： 在前期 我们使用django提交post请求的时候 需要去配置文件中注释掉一行代码 注释掉 中间件配置中的 CsrfViewMiddleware \u0026#34;\u0026#34;\u0026#34; # settings.py MIDDLEWARE = [ \u0026#39;django.middleware.security.SecurityMiddleware\u0026#39;, \u0026#39;django.contrib.sessions.middleware.SessionMiddleware\u0026#39;, \u0026#39;django.middleware.common.CommonMiddleware\u0026#39;, # \u0026#39;django.middleware.csrf.CsrfViewMiddleware\u0026#39;, \u0026#39;django.contrib.auth.middleware.AuthenticationMiddleware\u0026#39;, \u0026#39;django.contrib.messages.middleware.MessageMiddleware\u0026#39;, \u0026#39;django.middleware.clickjacking.XFrameOptionsMiddleware\u0026#39;, ] # views.login处理函数 def login(request): # 返回一个登录界面 \u0026#34;\u0026#34;\u0026#34; GET请求和POST请求 应该有不同的处理机制 -\u0026gt; 如何处理? 引入下面 request对象方法初始 探索django封装的request对象 :param request: :return: \u0026#34;\u0026#34;\u0026#34; print(\u0026#39;enter login...\u0026#39;) return render(request, \u0026#39;login.html\u0026#39;) request对象方法初识 request.method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def login(request): # 返回一个登录界面 \u0026#34;\u0026#34;\u0026#34; GET请求和POST请求 应该有不同的处理机制 -\u0026gt; 如何处理? :param request: 请求相关的数据对象 里面有很多简易的方法 :return: \u0026#34;\u0026#34;\u0026#34; # 返回请求方式 并且是全大写的字符串 \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; # print(request.method) \u0026#34;\u0026#34;\u0026#34; 这种方式 2层逻辑 推荐下一种 if request.method == \u0026#39;GET\u0026#39;: print(\u0026#39;Method GET\u0026#39;) return render(request, \u0026#39;login.html\u0026#39;) elif request.method == \u0026#39;POST\u0026#39;: return HttpResponse(\u0026#34;收到了 POST请求\u0026#34;) \u0026#34;\u0026#34;\u0026#34; if request.method == \u0026#39;POST\u0026#39;: return HttpResponse(\u0026#39;收到POST\u0026#39;) return render(request, \u0026#39;login.html\u0026#39;) request.POST 1 2 3 4 # 获取用户post请求提交的普通数据(Form) 不包含文件 request.POST - request.PSOT.get() # 只获取列表最后一个元素 - request.POST.getlist() # 直接将整个列表取出 request.GET 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 获取用户get请求提交的数据 # get请求携带的数据是有大小限制的 大概只有4KB左右 # 而post请求则没有限制 request.GET # 获取到的数据类型 方法的使用 和 request.POST 一模一样 - request.GET.get() # 只获取列表最后一个元素 - request.GET.getlist() # 直接将整个列表取出 def login(request): # 返回一个登录界面 if request.method == \u0026#39;POST\u0026#39;: username = request.POST.get(\u0026#39;username\u0026#39;) return HttpResponse(\u0026#39;收到POST\u0026#39;) # 注意get 和 getlist方法区别 hobby = request.GET.getlist(\u0026#39;hobby\u0026#39;) return render(request, \u0026#39;login.html\u0026#39;) ORM Django本质 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Django本质 Django本身不是Server(不是 nginx or httpd) 只是个WSGI App 就是一个大函数 # 请求过程 浏览器发起一个HTTP Request报文 到TCPServer(HTTPServer) Server默认监听80 只不过这个Server正好它能提供http请求报文的解析和Http响应报文的封装 就是说Server是HTTP_Server 得有一个调用者 调用Django得这个函数 调用者就是WSGI_Server # Nginx 把http请求报文 ==\u0026gt; uwsgi软件/gunicorn软件(软件是WSGI Server) ==\u0026gt; 解析报文并调用Django App大函数 ==\u0026gt; 函数返回值 # request --\u0026gt; uwsgi --\u0026gt; wsgi.py --\u0026gt; application 注入两个参数调用 --\u0026gt; application(environ, start_response) --\u0026gt; 返回正文给wsgi封装为response报文 --\u0026gt; 前端显示 # 参考 Django中的实现 uwsgi等软件 调用的就是django/flask的wsgi.py 得到 application 入口 1 2 3 4 5 6 # 入口 根据wsgi的原理 我们知道Django就是APP 入口是项目的wsgi.py文件 1. 请求request来了后 2. 交给application(WSGIHandler实例) 3. application(environ, start_response)调用 4. 调用start_response后返回get_response返回的响应的结果 Django中的实现 1 2 3 4 5 6 7 8 # wsgi.py import os from django.core.wsgi import get_wsgi_application os.environ.setdefault(\u0026#39;DJANGO_SETTINGS_MODULE\u0026#39;, \u0026#39;cmdb.settings\u0026#39;) # application 就是那个app大函数 application = get_wsgi_application() ORM快速测试 测试脚本 根据上面原理得出下面这个脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 # django 项目统计目录创建 xx.py import os import django os.environ.setdefault(\u0026#39;DJANGO_SETTINGS_MODULE\u0026#39;, \u0026#39;cmdb.settings\u0026#39;) # 加载django配置 # 在settings.py 配置好数据库连接即可 django.setup(set_prefix=False) # 我就是那个app大函数 # 返回一个handler类的实例处理每一个请求 # application = get_wsgi_application() 配置settings.py 详细配置参考官网\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # MySQL数据库配置 DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.mysql\u0026#39;, \u0026#39;NAME\u0026#39;: \u0026#39;name\u0026#39;, # 连接的数据库名称 \u0026#39;USER\u0026#39;: \u0026#39;user\u0026#39;, # 连接用户 \u0026#39;PASSWORD\u0026#39;: \u0026#39;password\u0026#39;, # 连接密码 \u0026#39;HOST\u0026#39;: \u0026#39;host\u0026#39;, # 主机IP \u0026#39;PORT\u0026#39;: \u0026#39;3306\u0026#39;, # 端口 \u0026#39;CHARSET\u0026#39;: \u0026#39;utf8\u0026#39; } } # Django ORM难学 通过日志看对应SQL # res.query 或者直接调用返回对象的 query方法 可以直接打印SQL语句 # 具体logging模块详细信息 参考Python标准库文档 LOGGING = { \u0026#39;version\u0026#39;: 1, \u0026#39;disable_existing_loggers\u0026#39;: False, \u0026#39;handlers\u0026#39;: { \u0026#39;console\u0026#39;: { \u0026#39;class\u0026#39;: \u0026#39;logging.StreamHandler\u0026#39;, }, }, \u0026#39;loggers\u0026#39;: { # 本地 django 2.1.4及之前的版本 该配置无效 无法看到对象的SQL语句 显示为None \u0026#39;django.db.backends\u0026#39;: { \u0026#39;handlers\u0026#39;: [\u0026#39;console\u0026#39;], \u0026#39;level\u0026#39;: \u0026#39;DEBUG\u0026#39;, \u0026#39;propagate\u0026#39;: False, }, }, } mysqlclient or pymysql\n1 2 3 4 5 6 7 8 9 10 # 如果要使用pymysql 在项目包文件__init__.py中加入下面代码 import pymysql pymysql.install_as_MySQLdb() mysqlcilent # c语言编写 速度快 推荐 pymsyql # python原生 兼容度高 # 备注：使用pymysql 去项目配置文件所在目录的__init__.py文件加入以下内容 import pymysql pymysql.install_as_MySQLdb() 设置sql_mode\n1 2 3 4 5 6 # 设置sql_mode # https://docs.djangoproject.com/zh-hans/3.1/ref/databases/ \u0026#39;OPTIONS\u0026#39;: { \u0026#34;init_command\u0026#34;: \u0026#34;SET sql_mode=\u0026#39;STRICT_TRANS_TABLES\u0026#39;\u0026#34;, } 依赖 1 pip install mysqlclient ORM初识 简介 ORM 对象关系映射 对象和关系之间的映射 使用面向对象的方式来操作数据库\n1 2 3 4 5 6 7 # 关系模型和Python对象之间的映射 table =\u0026gt; class # 表 映射为 类 row =\u0026gt; object # 行 映射为 实例 column =\u0026gt; property # 字段 映射为 属性(类属性) # 不足 封装程度太高 有时候sql语句的效率偏低 需要你自己写SQL语句 实例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 描述 表名：student 字段-类型： - id-int - name-varchar - age-int # 到Python映射 class Student: id = ?某字段类型 name = ?某字段类型 age = ?某字段类型 # 最终得到的实例 class Student: def __init__(self): self.id = ? self.name = ? self.age = ? 创建model类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 去应用下面的 models.py 文件 from django.db import models # Create your models here. # model类 编写 class User(models.Model): id = models.AutoField(primary_key=True) # id int primary_key auto_increment username = models.CharField(max_length=32) # username varchar(32) password = models.IntegerField() # password int class Author(models.Model): \u0026#34;\u0026#34;\u0026#34; django orm当你不定义主键字段的时候 orm会自动帮你创建一个名为id的主键字段 后续我们在创建模型表的时候 如果主键字段名没有额外的叫法 那么主键字段可以省略不写 orm帮我们补 \u0026#34;\u0026#34;\u0026#34; username = models.CharField(max_length=32) password = models.IntegerField() 数据库迁移 1 2 3 4 # 数据库迁移命令 # 只要你修改了models.py中跟 **数据库** 相关的代码 就必须重新执行下面两条命令 $ python manage.py makemigrations # 将操作记录基础出来(migrations文件夹) $ python manage.py migrate # 将操作真正的同步到数据库中 字段类型 DjangoORM字段类型参考\n1 2 3 CharField # 必须要指定 max_length参数 不指定会直接报错 verbose_name # 该参数是所有字段都有的 用来对字段的解释 ... 字段的增删改查 字段的增加 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 给表增加字段的时候 表里面已经有数据的情况 # **增加外键字段的时候 给的默认值 需要先在对应表中存在 否则迁移报错** 1. 可以在终端内直接给出默认值 django命令行会在终端给出选择 $ You are trying to add a non-nullable field \u0026#39;age\u0026#39; to user without a default; we can\u0026#39;t do that (the database needs something to populate exi sting rows). $ Please select a fix: 1) Provide a one-off default now (will be set on all existing rows with a null value for this column) 2) Quit, and let me add a default in models.py 2. 设置该字段可以为空(根据实际情况考虑) info = models.CharField(max_length=32, verbose_name=\u0026#39;个人简介\u0026#39;, null=True) 3. 直接给字段设置默认值 hobby = models.CharField(max_length=32, verbose_name=\u0026#39;爱好\u0026#39;, null=False, default=\u0026#39;study\u0026#39;) 字段的修改 1 2 3 # models.py 修改后 直接执行迁移命令即可： $ python manage.py makemigrations $ python manage.py migrate 字段的删除 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 直接注释对应的字段 然后直接执行迁移命令即可 $ python manage.py makemigrations $ python manage.py migrate # 比较严重的问题 迁移命令执行完毕之后 数据库对应的数据也会被删除 # **注意** \u0026#34;\u0026#34;\u0026#34; 在操作models.py的时候 一定要细心 - 千万不要随意注释一些字段 - 执行迁移命令之前 最好先检查下自己写的代码 \u0026#34;\u0026#34;\u0026#34; # 个人建议： 当你离开你的计算机之后 一定要锁屏 数据的增删改查 QuerySet API 参考\n查 QuerySet.filter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 查 models.User.objects.filter(username=username) \u0026#34;\u0026#34;\u0026#34; 返回值可以先看成是列表套数据对象的格式 它也支持索引取值 切片操作 但是不支持负索引 它也不推荐你使用索引的方式取值 models.User.objects.filter(username=username)[0] models.User.objects.filter(username=username).first() \u0026#34;\u0026#34;\u0026#34; # 简单登录功能实现 使用 ORM 查询 def login(request): if request.method == \u0026#39;POST\u0026#39;: # 获取用户提交的用户名和密码 利用orm 校验数据 username = request.POST.get(\u0026#39;username\u0026#39;) password = request.POST.get(\u0026#39;password\u0026#39;) # 去数据库查询数据 from app01 import models user_obj = models.User.objects.filter(username=username).first() if user_obj: # 比对密码是否一致 if password == user_obj.password: return HttpResponse(\u0026#39;Login Success\u0026#39;) return HttpResponse(\u0026#39;Login Failed, Password Error\u0026#39;) return HttpResponse(\u0026#39;用户不存在\u0026#39;) return render(request, \u0026#39;login.html\u0026#39;) 增 QuerySet.create\n1 2 3 4 5 6 # create 返回当前被创建的对象本身 res = models.User.objects.create(username=username, password=password) # 实例化对象 调用save方法 user_obj = models.User(username=username, password=password) user_obj.save() # 保存数据 改 QuerySet.update\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # 先将数据库中的数据全部展示到前端 然后给每一个数据2个按钮 一个编辑一个删除 ef userlist(request): # 查询用户表里面 所有的数据 # 方式1 不推荐 # data = models.User.objects.filter() # 方式2 user_queryset = models.User.objects.all() return render(request, \u0026#39;userlist.html\u0026#39;, {\u0026#39;user_info\u0026#39;: user_queryset}) # 编辑功能 1. 点击编辑按钮朝后端发送编辑数据的请求 \u0026#34;\u0026#34;\u0026#34; Q: 如何告诉后端 用户想要编辑哪条数据? A: 将编辑按钮所在的哪一行数据的 主键值 发送给后端 -- 唯一确定值 Q: 如何发送主键值? A: \u0026lt;a\u0026gt; href=\u0026#34;/edit_user/?user_id={{ user.id }}\u0026#34; \u0026lt;/a\u0026gt; 利用url问号后面携带参数的方式 传主键值给后端获取 \u0026#34;\u0026#34;\u0026#34; 2. 后端查询出用户想要编辑的数据对象 展示到前端页面供用户查看和编辑 # view 代码实现 def userlist(request): # 查询用户表里面 所有的数据 # 方式1 不推荐 # data = models.User.objects.filter() # 方式2 user_queryset = models.User.objects.all() return render(request, \u0026#39;userlist.html\u0026#39;, {\u0026#39;user_info\u0026#39;: user_queryset}) def edit_user(request): # 获取url问号后面携带的参数 href=\u0026#34;/edit_user/?user_id={{ user.id }}\u0026#34; user_id = request.GET.get(\u0026#39;user_id\u0026#39;) # 查询当前用户想要编辑的数据对象 user_obj = models.User.objects.filter(id=user_id).first() if request.method == \u0026#39;POST\u0026#39;: username = request.POST.get(\u0026#39;username\u0026#39;) password = request.POST.get(\u0026#39;password\u0026#39;) # 如果是post提交 去数据库修改对象的数据内容 # 修改方式1 \u0026#34;\u0026#34;\u0026#34; 将filter查询出来的列表中所有的对象全部更新 批量更新操作 只会修改被修改的字段 \u0026#34;\u0026#34;\u0026#34; # models.User.objects.filter(id=user_id).update(username=username, password=password) # 修改方式2 \u0026#34;\u0026#34;\u0026#34; 该方式 当字段非常多的时候 效率会特别的低 从头到尾将数据的所有字段全部更新一遍 无论该字段是否被修改 \u0026#34;\u0026#34;\u0026#34; user_obj.username = username user_obj.password = password user_obj.save() # 内部自动识别 不是保存 而且更新 # 跳转到数据的展示页面 return redirect(\u0026#39;/userlist/\u0026#39;) # 将数据对象展示到页面上 return render(request, \u0026#39;edit_user.html\u0026#39;, {\u0026#39;user_info\u0026#39;: user_obj}) 删 QeurySet.delete\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 删除功能 \u0026#34;\u0026#34;\u0026#34; 跟编辑功能逻辑类似 \u0026#34;\u0026#34;\u0026#34; def del_user(request): # 获取用户想要删除的数据id值 user_id = request.GET.get(\u0026#39;user_id\u0026#39;) # 直接去数据库中找到对应的数据 删除即可 \u0026#34;\u0026#34;\u0026#34;delete 批量删除\u0026#34;\u0026#34;\u0026#34; models.User.objects.filter(id=user_id).delete() # 跳转到展示页面 return redirect(\u0026#39;/userlist/\u0026#39;) # 数据删除 最好不要真正的删除 添加 is_delete字段 \u0026#34;\u0026#34;\u0026#34; 真正的删除功能 需要二次确认 删除数据内部其实并不是真正的删除 我们会被数据添加一个标识字段 用来表示当前数据是否被删除 如果数据被删除 仅仅是将字段修改一下状态 展示的时候 筛选一下该字段即可 username password is_delete minho 123 0 karubin 123 1 数据值钱 删除危险且浪费 一般情况下 切记不要真正的去删除数据 \u0026#34;\u0026#34;\u0026#34; orm创建表关系 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026#34;\u0026#34;\u0026#34; 表与表之间的关系 - 一对多 - 多对多 - 一对一 判断表关系的方法：换位思考 \u0026#34;\u0026#34;\u0026#34; e.g. 图书表 book id title price 1 django 213.12 2 flask 123.33 3 c++ 89.08 出版社表 publish id name address 1 上海出版社 上海 2 北京出版社 北京 作者表 author id name age 1 minho 25 2 kimi 37 book2author id book_id author_id 1 1 1 2 1 2 3 2 2 4 3 1 \u0026#34;\u0026#34;\u0026#34; 图书和出版社 一对多的关系 外键字段建在多的那一方-book 图书和作者 多对多关系 创建第三张表来专门存储-book2author 一对一 应用场景： - 拆表 (作者表 与 作者详情表是一对一) - 作者表 - 作者详情表 \u0026#34;\u0026#34;\u0026#34; 一对多ForeignKey\n多对多ManyToManyField\n一对一OneToOneField\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 from django.db import models # Create your models here. # 创建表关系 先将基表创建出来 然后再添加外键字段 class Book(models.Model): title = models.CharField(max_length=32) price = models.DecimalField(max_digits=8, decimal_places=2) # 小数总共8位 小数点后面占2位 \u0026#34;\u0026#34;\u0026#34; 图书和出版社是一对多 并且书是多的一方 所以外键字段放在book表里面 如果字段对应的是ForeignKey 那么ORM会自动在字段后面加_id -\u0026gt; publish_id 后面定义ForeignKey的时候 不要自己加_id \u0026#34;\u0026#34;\u0026#34; publish = models.ForeignKey(to=\u0026#39;Publish\u0026#39;) # 默认就是与出版社表的主键字段做外键关联 可以通过to_field设置 \u0026#34;\u0026#34;\u0026#34; 图书和作者是多对多关系 外键字段建在任意一方均可 但是推荐创建再查询频率较高的一方 (查询方便) authors是一个虚拟字段 主要是用来高速ORM 书籍表 和 作者表 是多对多关系 让ORM自动帮你创建第三张表关系 django 1.x 自动级联更新删除 2.x 3.x需要加参数 \u0026#34;\u0026#34;\u0026#34; authors = models.ManyToManyField(to=\u0026#39;Author\u0026#39;) class Publish(models.Model): name = models.CharField(max_length=32) address = models.CharField(max_length=64) class Author(models.Model): name = models.CharField(max_length=32) age = models.IntegerField() \u0026#34;\u0026#34;\u0026#34; 作者与作者详情是一对一关系 外键字段建在任意一方都可以 但是推荐创建在查询频率较高的表中 OneToOneField 也会自动给字段加_id后缀 \u0026#34;\u0026#34;\u0026#34; author_detail = models.OneToOneField(to=\u0026#39;AuthorDetail\u0026#39;) class AuthorDetail(models.Model): phone = models.BigIntegerField() # 手机号 或者直接用字符类型 address = models.CharField(max_length=32) \u0026#34;\u0026#34;\u0026#34; ORM中如何定义三种关系 一对多：publish = models.ForeignKey(to=\u0026#39;Publish\u0026#39;) 多对多：authors = models.ManyToManyField(to=\u0026#39;Author\u0026#39;) 一对一：author_detail = models.OneToOneField(to=\u0026#39;AuthorDetail\u0026#39;) ForeignKey 和 OneToOneField关系字段 会自动在字段后面加_id后缀 ManyToManyField关系字段 会自动创建第三张关系对应表 无需我们手动创建 \u0026#34;\u0026#34;\u0026#34; # 注意 \u0026#34;\u0026#34;\u0026#34; 1. 在django1.x版本中 外键默认都是级联更新删除的 2. 多对多的表关系可以有好几种(三种)创建方式 这里只是其中一种 3. 针对外键字段里面的其他参数 暂时不做考虑 详情可以参考上面官网链接 \u0026#34;\u0026#34;\u0026#34; 多对多的三种创建关系 需要掌握 全自动 和 半自动(扩展性很高 一般情况下都采用半自动)\n全自动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 利用ORM 自动帮我们创建第三张关系表 class Book(models.Model): name = models.CharField(max_length=32) authors = models.ManyToManyField(to=\u0026#39;Author\u0026#39;) class Author(models.Model): name = models.CharField(max_length=32) \u0026#34;\u0026#34;\u0026#34; 优点： - 第三张关系表的model代码 不需要自己写 - 支持ORM提供操作第三张关系表的方法(add clear remove 正反向查询...) 缺点： - 第三张关系表的拓展性极差 没有办法额外添加字段 \u0026#34;\u0026#34;\u0026#34; 纯手动 不建议使用该方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 自己书写 第三张关系表 class Book(models.Model): name = models.CharField(max_length=32) class Author(models.Model): name = models.CharField(max_length=32) class Book2Author(models.Model): book = models.ForeignKey(to=\u0026#39;Book\u0026#39;) author = models.ForeignKey(to=\u0026#39;Author\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 优点： - 第三张表完全取决于你自己 进行额外扩展 缺点： - 需要自己写第三张关系表的model代码 - 不能够再使用ORM提供的简单方法 \u0026#34;\u0026#34;\u0026#34; 半自动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 还是手动创建第三张关系表 # 然后通过字段参数 解决全手动创建带来的缺点 无法使用ORM提供的方法 class Book(models.Model): name = models.CharField(max_length=32) # 利用额外参数 告诉ORM 第三张关系表我已经手动创建 你参考就行 不必再自动创建 # 多对多外键字段 可以写在任意一方 这里写在哪一边 会影响到through_fields参数的字段顺序 # 写在book表 through_fields=(\u0026#39;book\u0026#39;, \u0026#39;author\u0026#39;) author = models.ManyToManyField(to=\u0026#39;Author\u0026#39;, through=\u0026#39;Book2Author\u0026#39;, through_fields=(\u0026#39;book\u0026#39;, \u0026#39;author\u0026#39;) ) class Author(models.Model): name = models.CharField(max_length=32) # OR 写在author表 through_fields=(\u0026#39;author\u0026#39;, \u0026#39;book\u0026#39;) # author = models.ManyToManyField(to=\u0026#39;Author\u0026#39;, # through=\u0026#39;Book2Author\u0026#39;, # through_fields=(\u0026#39;author\u0026#39;, \u0026#39;book\u0026#39;) # ) class Book2Author(models.Model): book = models.ForeignKey(to=\u0026#39;Book\u0026#39;) author = models.ForeignKey(to=\u0026#39;Author\u0026#39;) \u0026#34;\u0026#34;\u0026#34; through_fields=(\u0026#39;xx\u0026#39;, \u0026#39;oo\u0026#39;) through_fields字段先后顺序： 本质：由第三张关系表 查询外键所在表 通过(第三张表)哪个字段 就把该字段放在前面一个参数 总结：简化判断 -\u0026gt; 当前表(外键字段所在的表)是谁 就把对应的关联字段放前面 \u0026#34;\u0026#34;\u0026#34; \u0026#34;\u0026#34;\u0026#34; 半自动不足： 可以使用orm的正反向查询 但是没法使用 add set remove clear这4个方法 \u0026#34;\u0026#34;\u0026#34; Model元编程 Django Model 背后的故事 \u0026ndash; 元编程\n测试环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cd ../project_dir # 安装django pip install django # 创建项目 django-admin startproject cmdb # 配置修改参考上文 # 创建user包 python manage.py startapp user # 注册 一定要在settings.py INSTALLED_APPS 注册user 否则不能迁移 Model数据库模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # user/models.py from django.db import models # Create your models here. class User(models.Model): # 继承的目录 代码复用 class Meta: # 元数据 db_table = \u0026#39;user\u0026#39; # 指定mysql中的表名 否则默认为module_class.__name__ # 字段定义 id = models.AutoField(primary_key=True) # 自增 同时是主键 Django只支持单一主键 # 元编程会在没有主键的请况下 建立一个字段名为:id 的自增主键 username = models.CharField(max_length=20, null=False) password = models.CharField(max_length=128, null=False) # passwd 密文 hash def __repr__(self): return \u0026#34;\u0026lt;User {}， {}\u0026gt;\u0026#34;.format(self.id, self.username) # self.id == self.pk 主键 __str__ = __repr__ # 迁移：Model类生成数据库中的表和字段 元类 类定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class A: # 语法定义 pass # type函数问什么 问你是谁的实例 # type说明什么？ A是type的实例 A称为类对象 由type构造出来的实例 print(1, type(A)) # class构造出来的是类 type是构造类的类 # 元类： 用来构造类的类型 # 元编程: 用编程的方法来编程 # 元数据: 用来描述数据的数据 print(type(type)) # type # 元类 用来构造类对象 不是用来继承的 # class Model(metaclass=ModelBase) 使用metaclass参数改变元类 # __new__ 两个作用 # 1. 用来实例化 # 2. 用在元编程中 print(\u0026#39;=\u0026#39; * 30) a = A() # a是A类的实例 print(2, type(a)) # A, a是由A构造出来的实例 django model 仿写 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class Field: def __init__(self, primary_key=False, name=None, null=False): self.pk = primary_key self.name = name # ？ self.null = null def __str__(self): return \u0026#34;\u0026lt;Field {}\u0026gt;\u0026#34;.format(self.name) __repr__ = __str__ class Manager: pass # type是Python提供的原始元类 # 不知道怎么构建元类 继承自type解决(因为type是元类) # 对比：普通类最终继承自object class ModelBase(type): # 元类编程中：构建类对象的 def __new__(cls, name, bases, attrs): print(\u0026#39;=\u0026#39; * 30) print(cls) # name, bases, attrs = args # 三元组 (name: 构造类的name, bases:构造出来类的 继承类, attrs:构造出来类的类属性) print(name, bases, attrs) # attrs[\u0026#39;id\u0026#39;] = \u0026#39;abc\u0026#39; print(attrs) pks = [] # 主键们 for k, v in attrs.items(): # k, v =\u0026gt; \u0026#39;username\u0026#39;, Field对象 if isinstance(v, Field): if v.pk: pks.append(v) if not v.name: v.name = k attrs[\u0026#39;pks\u0026#39;] = pks # 判断主键不存在 贼默认创建id主键 if not pks: id = Field(primary_key=True, name=\u0026#39;id\u0026#39;, null=False) pks.append(id) attrs[\u0026#39;pks\u0026#39;] = pks print(\u0026#39;=\u0026#39; * 30) # return None # 应该返回类对象 而不是None or 其他 # return super().__new__(cls, name, bases, attrs) new_class = super().__new__(cls, name, bases, attrs) # 省略1000行 # 判断objects 挂objects对象 setattr(new_class, \u0026#39;objects\u0026#39;, Manager()) return new_class # 改模子 由type改为使用ModelBase为元类 # 用ModelBase的__new__方法构造Model类 # 本来找type的 指定metaclass改变 # class Model(list, metaclass=ModelBase): class Model(metaclass=ModelBase): pass # m = Model() # None() =\u0026gt; TypeError # print(*Model.__dict__.items(), sep=\u0026#39;\\n\u0026#39;) # User继承自Model Model类由ModelBase构造 那么User也是由ModelBase构造 # 不用显示写：metaclass=ModelBase class User(Model): # 由元类构造 username = Field(null=False) password = Field(null=False) print(User.pks) # python manage.py runserver # 测试用的wsgi server 路由层 路由匹配 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 路由匹配 url(r\u0026#39;test\u0026#39;, views.test), url(r\u0026#39;testadd\u0026#39;, views.testadd), \u0026#34;\u0026#34;\u0026#34; http://127.0.0.1:8000/testadd 永远访问不到 永远访问的是views.test视图函数 url方法的第一个参数是正则表达式 只要第一个参数正则表达式能够匹配到内容 就会立刻停止往下匹配 直接执行对应的视图函数 \u0026#34;\u0026#34;\u0026#34; # 加斜杠/ django匹配的时候会自动加斜杠去匹配 \u0026#34;\u0026#34;\u0026#34; http://127.0.0.1:8000/testadd 第一次匹配 匹配不到 - 301 django会自动在末尾加一个斜杠 进行第二次匹配 - 200 OK django内部帮你做的重定向 - 一次匹配不行 - url末尾加斜杠 再来一次 \u0026#34;\u0026#34;\u0026#34; url(r\u0026#39;test/\u0026#39;, views.test), url(r\u0026#39;testadd/\u0026#39;, views.testadd), # 自动加斜杠功能可以取消 配置settings.py APPEND_SLASH = False # 取消自动加斜杠 默认为True 不建议修改 # QA Q: GET /msafbsvfbtest/ 可以匹配到 test/ A: url(r\u0026#39;^test/\u0026#39;, v2.test) # ^ 解决 Q: GET /test/sdanakvdbkaadad/daskndakjd 可以匹配到 test/ A: url(r\u0026#39;^test/$\u0026#39;, v2.test) # ^test$ 正则精确 test Q：如何写首页URL A: url(r\u0026#39;^$\u0026#39;, v2.home) # 首页匹配 不能写成url(r\u0026#39;\u0026#39;, v2.home) Q: 尾页(404页面 所有页面都没找到) 需要放在最后 A: url(r\u0026#39;\u0026#39;, v2.error) # 了解即可 不这样写 URL分组 1 2 3 4 5 \u0026#34;\u0026#34;\u0026#34; 分组：就是给某一段正则表达式用小括号括起来 \u0026#34;\u0026#34;\u0026#34; url(r\u0026#39;^test/\\d+$\u0026#39;, v2.test) # 正常访问 url(r\u0026#39;^test/(\\d+$)\u0026#39;, v2.test) # 分组后 报错TypeError test() takes 1 positional argument but 2 were given 无名分组 1 2 3 4 5 6 7 8 9 10 11 12 url(r\u0026#39;^test/(\\d+$)\u0026#39;, v2.test) # 分组后 报错TypeError 缺少位置参数 # test() takes 1 positional argument but 2 were given # 修改视图函数接收分组传递的参数 def test(request, args): print(args) return HttpResponse(\u0026#39;test\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 无名分组 就是将括号内正则表达式匹配到的内容当作 位置参数 传递给后面的视图函数 \u0026#34;\u0026#34;\u0026#34; 有名分组 1 2 3 4 5 6 7 8 9 10 11 12 \u0026#34;\u0026#34;\u0026#34; (?P\u0026lt;name\u0026gt;) 可以给正则表达式 分组并起一个别名 有名分组 就是将括号内正则表达式匹配到的内容当作 关键字参数 传递给后面的视图函数 \u0026#34;\u0026#34;\u0026#34; url(r\u0026#39;^testadd/(?P\u0026lt;year\u0026gt;\\d+)\u0026#39;, v2.testadd) # 起别名后 报错 TypeError 缺少关键字参数 # testadd() got an unexpected keyword argument \u0026#39;year\u0026#39; # 增加关键字对应的形参 def testadd(request, years): print(years) return HttpResponse(\u0026#39;testadd\u0026#39;) 不能混用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 url(r\u0026#39;^index/(\\d+)/(?P\u0026lt;year\u0026gt;\\d+)/\u0026#39;, v2.index) def index(request, args, year): print(args, year) return HttpResponse(\u0026#34;index\u0026#34;) \u0026gt;\u0026gt;\u0026gt; TypeError at /index/12313/32131313/ \u0026gt;\u0026gt;\u0026gt; index() missing 1 required positional argument: \u0026#39;args\u0026#39; # 总结： 不能混用 但是 同一个分组可以使用N多次 url(r\u0026#39;^index/(\\d+)/(\\d+)/(\\d+)/\u0026#39;, views.index), url(r\u0026#39;^index/(?P\u0026lt;year\u0026gt;\\d+)/(?P\u0026lt;month\u0026gt;\\d+)/(?P\u0026lt;day\u0026gt;\\d+)/\u0026#39;, views.index), def index(request, *args, **kwargs): print(args) # (\u0026#39;12\u0026#39;, \u0026#39;3123\u0026#39;, \u0026#39;42341\u0026#39;) print(kwargs) # {\u0026#39;year\u0026#39;: \u0026#39;12\u0026#39;, \u0026#39;month\u0026#39;: \u0026#39;3123\u0026#39;, \u0026#39;day\u0026#39;: \u0026#39;42341\u0026#39;} return HttpResponse(\u0026#34;\u0026lt;h1\u0026gt;index\u0026lt;/h1\u0026gt;\u0026#34;) 反向解析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; 本质：通过一些方法得到一个结果 该结果可以访问到对应的url 从而触发对应视图函数的运行 步骤： 1. 先给路由与视图函数起一个别名 url(r\u0026#39;^func_minho/\u0026#39;, views.func, name=\u0026#39;alias_func\u0026#39;), 2. 反向解析 2.1 后端反向解析 from django.shortcuts import reverse, HttpResponseRedirect url = reverse(\u0026#39;alias_func\u0026#39;) return HttpResponseRedirect(url) 2.2 前端反向解析 (模板语法) \u0026lt;a href=\u0026#34;{% url \u0026#39;alias_func\u0026#39; %}\u0026#34;\u0026gt;111\u0026lt;/a\u0026gt; \u0026#34;\u0026#34;\u0026#34; 最简单的请况 url第一个参数里面没用正则符号 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # url url(r\u0026#39;^home/\u0026#39;, views.home, name=\u0026#39;home_page\u0026#39;), \u0026#34;\u0026#34;\u0026#34; 给url函数添加一个 name参数(**唯一**) 起一个名字 类似于别名 注意: **别名唯一 别名不能冲突** 我可以访问到这个名字(url正则可以随意修改) 然后获取到对应的url 从而触发视图函数的运行 1. 前端 {% url \u0026#39;alias_name\u0026#39; %} alias_name对应url函数里面的 name参数对应的字符串 2. 后端 reverse() \u0026#34;\u0026#34;\u0026#34; 无名分组反向解析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # url url(r\u0026#39;^index/(\\d+)/\u0026#39;, views.index, name=\u0026#39;alias_index\u0026#39;), # 前端 \u0026lt;a href=\u0026#34;{% url \u0026#39;alias_index\u0026#39; 123 %}\u0026#34;\u0026gt;111\u0026lt;/a # 后端 reverse(\u0026#39;alias_index\u0026#39;, args=(1,)) # /index/1/ \u0026#34;\u0026#34;\u0026#34; 这个数字写代码的时候应该放什么? - 数字 一般情况下放的是数据的主键值 来做数据的编辑和删除 # urls.py url(r\u0026#39;^edit/(\\d+)/\u0026#39;, views.edit, name=\u0026#39;xxx\u0026#39;) # views.py def edit(request, edit_id): reverse(\u0026#39;xxx\u0026#39;, args=(edit_id,)) # html {% for user in user_queryset %} \u0026lt;a href=\u0026#39;{% url \u0026#39;xxx\u0026#39; user.id %}\u0026#39;\u0026gt;编辑\u0026lt;/a\u0026gt; {% endfor %} \u0026#34;\u0026#34;\u0026#34; 有名分组反向解析 1 2 3 4 5 6 7 8 9 10 11 12 13 # url url(r\u0026#39;^func/(?P\u0026lt;year\u0026gt;\\d+)\u0026#39;, views.func, name=\u0026#39;alias_func\u0026#39;) # 前端 \u0026lt;a href=\u0026#34;{% url \u0026#39;alias_func\u0026#39; year=2009 %}\u0026#34;\u0026gt;111\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;{% url \u0026#39;alias_func\u0026#39; 2021 %}\u0026#34;\u0026gt;222\u0026lt;/a\u0026gt; # 后端 1. 有名分组写法一 reverse(\u0026#39;alias_func\u0026#39;, kwargs={\u0026#39;year\u0026#39;: 2010}) 2. 有名分组 简便写法 reverse(\u0026#39;alias_func\u0026#39;, args=(2021,)) 路由分发 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026#34;\u0026#34;\u0026#34; 特点：django 每一个应用 都可以有自己的templates文件夹 urls.py static文件夹 正是基于上述特点 django能够非常好的做到分组开发(每个人只写自己的app) 多人开发完之后 只需要将每个人书写的app全部拷贝到一个新的django项目中 然后在配置文件里面注册所有的app 再利用路由分发的特点将所有的app整合起来 当一个django项目中的url特别多的时候 总路由urls.py代码非常冗余 不好维护 解决: 利用路由分发来减轻总路由的压力 \u0026#34;\u0026#34;\u0026#34; # 路由分发 \u0026#34;\u0026#34;\u0026#34; 利用路由分发之后 总路由不在处理 路由与视图函数的直接对应关系 而是做一个分发处理 处理：识别当前url是属于哪个应用下的 然后直接分发给对应的应用处理 \u0026#34;\u0026#34;\u0026#34; 路由分发实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 from django.conf.urls import url, include from app01 import urls as app01_urls from app02 import urls as app02_urls # 总路由 \u0026#34;\u0026#34;\u0026#34; 只要url是app01开头就会自动将url中app01后面的路径交给 app01下的urls.py去做匹配 \u0026#34;\u0026#34;\u0026#34; urlpatterns = [ # 路由分发 # 只要url前缀是app01开头的 全部交给app01处理 url(r\u0026#39;^app01/\u0026#39;, include(app01_urls)), # 只要url前缀是app02开头的 全部交给app02处理 url(r\u0026#39;^app02/\u0026#39;, include(app02_urls)), ] # 子路由 app01.urls from django.conf.urls import url from app01 import views urlpatterns = [ url(r\u0026#39;^reg/\u0026#39;, views.reg) ] # 子路由 app02.urls from django.conf.urls import url from app02 import views urlpatterns = [ url(r\u0026#39;^reg/\u0026#39;, views.reg) ] # 总路由 推荐写法 简便 url(r\u0026#39;^app01/\u0026#39;, include(\u0026#39;app01.urls\u0026#39;)), url(r\u0026#39;^app02/\u0026#39;, include(\u0026#39;app02.urls\u0026#39;)), # 注意事项：总路由的url 千万不能加$结尾 加了之后 无法继续向下匹配 名称空间 解决url别名 命名冲突的问题 了解即可 可以不用 保证别名不同即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 当多个应用出现了相同的别名 反向解析是否会自动识别对应的前缀 \u0026#34;\u0026#34;\u0026#34; 正常请况下的反向解析 是没有办法自动识别前缀的 \u0026#34;\u0026#34;\u0026#34; # 解决：利用名称空间 # 总路由加名称空间：namespace urlpatterns = [ url(r\u0026#39;^app01/\u0026#39;, include(\u0026#39;app01.urls\u0026#39;, namespace=\u0026#39;app01\u0026#39;)), url(r\u0026#39;^app02/\u0026#39;, include(\u0026#39;app02.urls\u0026#39;, namespace=\u0026#39;app02\u0026#39;)), ] # 子路由 别名一致 \u0026#34;\u0026#34;\u0026#34; # app01.urls urlpatterns = [url(r\u0026#39;^reg/\u0026#39;, views.reg, name=\u0026#39;reg\u0026#39;)] # app02.urls urlpatterns = [url(r\u0026#39;^reg/\u0026#39;, views.reg, name=\u0026#39;reg\u0026#39;)] \u0026#34;\u0026#34;\u0026#34; # 解析的时候 - 前端 \u0026lt;a href=\u0026#34;{% url \u0026#39;app01:reg\u0026#39; %}\u0026#34;\u0026gt;111\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;{% url \u0026#39;app02:reg\u0026#39; %}\u0026#34;\u0026gt;222\u0026lt;/a\u0026gt; - 后端 reverse(\u0026#39;app01:reg\u0026#39;) reverse(\u0026#39;app02:reg\u0026#39;) 总结：其实只要保证别名不冲突 就没有必要使用名称空间\n1 2 3 4 \u0026#34;\u0026#34;\u0026#34; 一般情况下 有多个app的时候 我们在起别名的时候 会加上对应app的前缀 这样的话 就能够确保多个app之前名字不冲突的问题 \u0026#34;\u0026#34;\u0026#34; 伪静态 了解即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026#34;\u0026#34;\u0026#34; 静态网页 数据是写死的 万年不变 伪静态 将一个动态网页 伪装为静态网页 为什么要伪装呢? e.g.: 博客园 伪装的目的 - 在于增大本网站的seo查询力度 - 并且增加搜索引擎收藏本网站的概率 搜索引擎：本质就是一个巨大的爬虫程序 总结：无论怎么优化 还是搞不过搜索竞价 \u0026#34;\u0026#34;\u0026#34; # 实现 把url设置为.html结尾 乍一看 以为是静态(伪静态) urlpatterns = [ url(r\u0026#39;^reg.html/\u0026#39;, views.reg, name=\u0026#39;app01_reg\u0026#39;), ] 视图层 视图函数必须返回HttpResponse对象\n1 2 # 否则报错 The view app01.views.index didn\u0026#39;t return an HttpResponse object. It returned None instead. 三板斧 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # HttpResponse 返回字符串类型 class HttpResponse(HttpResponseBase): pass # render 返回html页面 并且返回之前还可以给html文件传值 def render(request, template_name, context=None, content_type=None, status=None, using=None): \u0026#34;\u0026#34;\u0026#34; Returns a HttpResponse whose content is filled with the result of calling django.template.loader.render_to_string() with the passed arguments. \u0026#34;\u0026#34;\u0026#34; content = loader.render_to_string(template_name, context, request, using=using) return HttpResponse(content, content_type, status) # redirect 重定向 也是继承的HttpResponse render简单的内部原理 1 2 3 4 5 6 7 8 9 def index(request): from django.template import Template, Context res = Template(\u0026#39;\u0026lt;h1\u0026gt;{{ user }}\u0026lt;/h1\u0026gt;\u0026#39;) con = Context({\u0026#39;user\u0026#39;: {\u0026#39;username\u0026#39;: \u0026#39;minho\u0026#39;, \u0026#39;password\u0026#39;: 123}}) ret = res.render(con) print(ret) return HttpResponse(ret) \u0026gt;\u0026gt;\u0026gt; \u0026lt;h1\u0026gt;{\u0026amp;#39;username\u0026amp;#39;: \u0026amp;#39;minho\u0026amp;#39;, \u0026amp;#39;password\u0026amp;#39;: 123}\u0026lt;/h1\u0026gt; JsonResponse 1 2 3 4 5 6 7 8 9 10 \u0026#34;\u0026#34;\u0026#34; Q: json格式的数据有什么用? A: 前后端数据交互需要使用到json作为过渡 实现跨语言传输数据 前端序列化： - JSON.stringify() json.dumps() - JSON.parse() json.loads() \u0026#34;\u0026#34;\u0026#34; # 任务：给前端浏览器返回一个json格式的字符串 原生json模块实现 1 2 3 4 5 6 7 # 原生json模块实现 import json def ab_json(request): user_dict = {\u0026#39;username\u0026#39;: \u0026#39;Minho这是中文\u0026#39;, \u0026#39;password\u0026#39;: \u0026#39;123123\u0026#39;, \u0026#39;hobby\u0026#39;: \u0026#39;study\u0026#39;} # 先转成json格式字符串 json_str = json.dumps(user_dict, ensure_ascii=False) return HttpResponse(json_str) JsonResponse实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from django.http import JsonResponse def ab_json(request): user_dict = {\u0026#39;username\u0026#39;: \u0026#39;Minho这是中文\u0026#39;, \u0026#39;password\u0026#39;: \u0026#39;123123\u0026#39;, \u0026#39;hobby\u0026#39;: \u0026#39;study\u0026#39;} lst = [111, 222, 333, 444] # 读源码 掌握用法 如何传参 # 序列化 字典 return JsonResponse(user_dict, json_dumps_params={\u0026#39;ensure_ascii\u0026#39;: False}) # 序列化非字典对象 需要加safe参数 通过报错信息得知 # In order to allow non-dict objects to be serialized set the safe parameter to False return JsonResponse(lst, safe=False) # JsonResponse 默认只能序列化字典 序列化其他数据(其他可以被序列化的数据 不是所有的数据都能被序列化) 需要加safe参数 Django自带的序列化组件 DRF铺垫\n1 2 3 4 # 需求：在前端给我获取到后端用户表里面的所有数据 需要是列表套字典 # json格式化校验 https://www.bejson.com/ JsonResponse json.dumps 不再演示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from app02 import models def user_ser(request): # 返回 [{}, {}, {}, {}] user_queryset = models.User.objects.values() # data = [user for user in user_queryset] data = list(user_queryset) return HttpResponse(JsonResponse(data, safe=False)) # OR 自定构造字典结构 from app02 import models def user_ser(request): # 返回 [{}, {}, {}, {}] user_queryset = models.User.objects.all() data = [] for user_obj in user_queryset: tmp = { \u0026#39;pk\u0026#39;: user_obj.pk, \u0026#39;name\u0026#39;: user_obj.name, \u0026#39;age\u0026#39;: user_obj.age, \u0026#39;gender\u0026#39;: user_obj.get_gender_display(), } data.append(tmp) return HttpResponse(JsonResponse(data, safe=False)) \u0026#34;\u0026#34;\u0026#34; 前后端分离的项目： - 作为后端 只需要写代码将数据处理好 - 序列化返回给前端即可 - 再写一个接口文档 告诉前端每个字段代表的意思 \u0026#34;\u0026#34;\u0026#34; serializers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from app02 import models from django.core import serializers def user_ser(request): user_queryset = models.User.objects.all() \u0026#34;\u0026#34;\u0026#34; 会自动帮你将数据变成json格式的字符串 并且内部非常的全面 写接口 就是利用序列化组件渲染数据 然后写一个接口文档 \u0026#34;\u0026#34;\u0026#34; res = serializers.serialize(\u0026#39;json\u0026#39;, user_queryset) return HttpResponse(res) \u0026#34;\u0026#34;\u0026#34; 使用序列化组件 封装程度更高 需要你写的代码更少 \u0026#34;\u0026#34;\u0026#34; Form表单上传文件及后端如何操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; form表单上传文件类型的数据 1. method必须指定成post 2. enctype必须换成formdata \u0026#34;\u0026#34;\u0026#34; def ab_file(request): if request.method == \u0026#39;POST\u0026#39;: # print(request.POST) # 只能获取普通键值对数据 文件不行 # print(request.FILES) # \u0026lt;MultiValueDict: {\u0026#39;file\u0026#39;: [\u0026lt;TemporaryUploadedFile: python-3.8.7-amd64.exe (application/x-msdownload)\u0026gt;]}\u0026gt; file_obj = request.FILES.get(\u0026#39;file\u0026#39;) # 文件对象 print(file_obj.name) with open(file_obj.name, \u0026#39;wb\u0026#39;) as f: for line in file_obj.chunks(): # 推荐加上chunks f.write(line) return render(request, \u0026#39;form.html\u0026#39;) request对象方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026#34;\u0026#34;\u0026#34; request.method request.POST request.GET request.FILES \u0026#34;\u0026#34;\u0026#34; \u0026#34;\u0026#34;\u0026#34; request.path request.path_info request.get_full_path() # 能获取完整的rul及问号后面的参数 \u0026#34;\u0026#34;\u0026#34; URL: http://127.0.0.1:8000/app01/ab_file/?username=minho requesst.path -\u0026gt; /app01/ab_file/ request.path_info -\u0026gt; /app01/ab_file/ # 既能拿路由 也能拿参数 上面两个方法不能拿参数 request.get_full_path() -\u0026gt; /app01/ab_file/?username=minho \u0026#34;\u0026#34;\u0026#34; request.body # 原生的 浏览器发过来的二进制数据 - GET b\u0026#39;\u0026#39; - POST \u0026#34;\u0026#34;\u0026#34; FBV与CBV 视图函数既可以是函数也可以是类\nFBV 基于函数的视图\n1 2 3 # FBV def index(request): return HttpResponse(\u0026#39;index\u0026#39;) CBV 基于类的视图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # CBV路由 urls.py写法 # as_view() CBV路由写法和FBV有点不一样(其实本质相同) url(r\u0026#39;^login/\u0026#39;, views.MyLogin.as_view()), # 类视图 from django.views import View class MyLogin(View): \u0026#34;\u0026#34;\u0026#34;只要是处理业务逻辑的视图函数 形参里面肯定要有request\u0026#34;\u0026#34;\u0026#34; def get(self, request): return render(request, \u0026#39;form.html\u0026#39;) def post(self, request): return HttpResponse(\u0026#39;post方法\u0026#39;) \u0026#34;\u0026#34;\u0026#34; FBV和CBV各有千秋 CBV特点： 能够直接根据请求方式的不同 直接匹配到对应的方法执行 思考：内部如何实现的? -- **非常重要** 学习DRF必备的知识点 \u0026#34;\u0026#34;\u0026#34; CBV源码剖析 1 # 千万不要随意修改源码 出BUG很难找 突破口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # CBV源码剖析 突破口在urls.py from django.conf.urls import url from app02 import views urlpatterns = [ url(r\u0026#39;^index/\u0026#39;, views.index), url(r\u0026#39;^login/\u0026#39;, views.LoginView.as_view()), ] \u0026#34;\u0026#34;\u0026#34; 函数/方法 加括号执行优先级最高 as_view() 立即执行 猜测 as_view()可以通过我们自定义的类LoginView类直接调用 可能是下面2种情况 - 1. @staticmethod 修饰的静态方法 - 2. @classmethod 修饰的类方法 1. as_view()本质 url(r\u0026#39;^login/\u0026#39;, views.LoginView.as_view()) 上述代码在启动django的时候就会立刻执行as_view()方法 as_view()方法会返回一个函数 view =\u0026gt; url(^\u0026#39;^login/\u0026#39;, views.view) =\u0026gt; 变形后 和FBV一样 CBV与FBV在路由匹配上 本质是一样的 都是路由 对应 函数(函数内存地址) 2. 浏览器访问/login/ 触发views.view view具体做了什么? \u0026#34;\u0026#34;\u0026#34; as_view()本质\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @classonlymethod def as_view(cls, **initkwargs): def view(request, *args, **kwargs): self = cls(**initkwargs) # cls是我们自己写的类 调用的时候自动注入 # self = LoginView(**initkwargs) 产生一个我们自己写的类的实例 if hasattr(self, \u0026#39;get\u0026#39;) and not hasattr(self, \u0026#39;head\u0026#39;): self.head = self.get self.request = request self.args = args self.kwargs = kwargs return self.dispatch(request, *args, **kwargs) \u0026#34;\u0026#34;\u0026#34; 以后 经常会需要看源码 但是在看Python源码的时候 一定要时刻提醒自己 面向对象属性方法查找顺序 mro 总结：看源码 只要看到了self.xxx 一定要问自己 当前这个self到底是谁 \u0026#34;\u0026#34;\u0026#34; return view dispatch CBV精髓\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # CBV的精髓 def dispatch(self, request, *args, **kwargs): # Try to dispatch to the right method; if a method doesn\u0026#39;t exist, # defer to the error handler. Also defer to the error handler if the # request method isn\u0026#39;t on the approved list. # 获取当前请求的小写格式 然后比对当前请求方式是否合法 # get请求为例 if request.method.lower() in self.http_method_names: \u0026#34;\u0026#34;\u0026#34; 反射：通过字符串来操作对象的属性或方法 运行时获取类型定义信息 handler = getattr(自己写的类产生的对象, \u0026#39;get\u0026#39;, 当找不到get属性或者方法的时候就会用第三个参数) handler = 我们自己写的类里面的get方法 \u0026#34;\u0026#34;\u0026#34; handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed # 自动调用get方法 return handler(request, *args, **kwargs) 反射补充\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 运行时：runtime 区别于编译时 指的是程序被加载到内存中执行的时候 反射：reflection 执行是运行是获取类型定义信息 \u0026#34;\u0026#34;\u0026#34; 一个对象能够在运行时 像照镜子一样 反射出其类型信息 简单说 在Python中 能够通过一个对象 找出其type class attribute或method的能力 成为反射或者自省 Python源码里 使用最频繁的其实就是反射 \u0026#34;\u0026#34;\u0026#34; 具有反射能力的函数有: - type() - isinstance() - callable() - dir() - getattr() 等等... 反射相关的魔术方法： __getattr__ __setattr__ __delattr__ __getattribute__ # 特殊 尽量不用 内建函数 意义 getattr(object, name[, default]) 通过name返回object的属性值 当属性不存在 将使用default返回 如果没有default 则抛出AttributeError name必须为字符串 setattr(object, name, value) object的属性存在则覆盖 不存在则新增 hasattr(object, name) 判断对象是否具有这个名字的属性 name必须为字符串 CBV如何添加装饰器 1 2 CBV中 django不建议你直接给类的方法加装饰器 无论该装饰器能否正常工作 都不建议增加 加在CBV视图的具体方法上 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.views import View from django.utils.decorators import method_decorator class MyLogin(View): \u0026#34;\u0026#34;\u0026#34; CBV中 django不建议你直接给类的方法加装饰器 无论该装饰器能否正常工作 都不建议增加 \u0026#34;\u0026#34;\u0026#34; # @login_auth # 不能直接使用装饰器 @method_decorator(login_auth) # 方式1: 指名道姓 def get(self, request): return HttpResponse(\u0026#39;GET请求\u0026#39;) @method_decorator(login_auth) def post(self, request): return HttpResponse(\u0026#39;POST请求\u0026#39;) 加在类视图上 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.views import View from django.utils.decorators import method_decorator # 方式2 可以添加多个 针对不同的方法加不同的装饰器 @method_decorator(login_auth, name=\u0026#39;get\u0026#39;) @method_decorator(login_auth, name=\u0026#39;post\u0026#39;) class MyLogin(View): \u0026#34;\u0026#34;\u0026#34; CBV中 django不建议你直接给类的方法加装饰器 无论该装饰器能否正常工作 都不建议增加 \u0026#34;\u0026#34;\u0026#34; def get(self, request): return HttpResponse(\u0026#39;GET请求\u0026#39;) def post(self, request): return HttpResponse(\u0026#39;POST请求\u0026#39;) 加在dispath方法上 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from django.views import View from django.utils.decorators import method_decorator class MyLogin(View): \u0026#34;\u0026#34;\u0026#34; CBV中 django不建议你直接给类的方法加装饰器 无论该装饰器能否正常工作 都不建议增加 \u0026#34;\u0026#34;\u0026#34; # 看CBV源码可以得出 CBV里面的所有方法在执行之前都需要先经过dispath方法(该方法你可以看成是一个分发方法) # 方式3: 重写dispath方法 给dispath方法装 会直接作用于当前类里面所有的方法 @method_decorator(login_auth) def dispatch(self, request, *args, **kwargs): return super().dispatch(request, *args, **kwargs) def get(self, request): return HttpResponse(\u0026#39;GET请求\u0026#39;) def post(self, request): return HttpResponse(\u0026#39;POST请求\u0026#39;) 模板层 模板语法 传值 模板语法传值\n1 2 3 {# #} # 注释 {{ }} # 变量相关 {% %} # 逻辑相关 后端传值示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def index(request): # 模板语法可以传递的后端Python数据类型 n = 123 f = 11.11 b = True s = \u0026#39;name is minho\u0026#39; lst = [\u0026#39;kimi\u0026#39;, \u0026#39;huahua\u0026#39;, \u0026#39;minho\u0026#39;] tup = (\u0026#39;11\u0026#39;, \u0026#39;22\u0026#39;, 33) dic = {\u0026#39;username\u0026#39;: \u0026#39;minho\u0026#39;, \u0026#39;age\u0026#39;:20} se = {\u0026#39;按级别的\u0026#39;, \u0026#39;密码\u0026#39;} def func(): print(\u0026#39;我被执行了\u0026#39;) return \u0026#39;func return res\u0026#39; class MyClass: def get_self(self): return \u0026#39;self\u0026#39; @staticmethod def get_static(): return \u0026#39;static method\u0026#39; @classmethod def get_cls(cls): return \u0026#39;cls\u0026#39; # 对象被展示到html页面上 就类似于执行了打印操作也会触发__str__方法 def __str__(self): return \u0026#39;MyClass obj\u0026#39; obj = MyClass() return render(request, \u0026#39;index.html\u0026#39;, locals()) 前端展示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;p\u0026gt;整型：{{ n }} \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;浮点型：{{ f }} \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;字符串：{{ s }} \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;布尔值：{{ b }} \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;列表：{{ lst }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;元组：{{ tup }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;字典：{{ dic }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;集合：{{ se }}\u0026lt;/p\u0026gt; {# 传递函数名会自动加括号调用 但是模板语法不支持给函数传额外的参数 如果有参数 不执行也不报错 #} \u0026lt;p\u0026gt;函数：{{ func }}\u0026lt;/p\u0026gt; {# 传类名的时候也会自动加括号调用(实例化) #} \u0026lt;p\u0026gt;类：{{ MyClass }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;类对象(ins)：{{ obj }}\u0026lt;/p\u0026gt; {# Django模板语法 能够自动判断出当前的变量名是否可以加括号调用 如果可以就会自动执行 针对的是函数名和类名 #} \u0026lt;p\u0026gt;普通方法：{{ obj.get_self }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;静态方法：{{ obj.get_static }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;类方法：{{ obj.get_cls }}\u0026lt;/p\u0026gt; 取值 1 2 3 4 5 6 django模板语法的取值 是固定的格式 只能用\u0026#34;句点符\u0026#34; . 即可点键 也可以点索引 也可以两者混用 \u0026lt;p\u0026gt;username: {{ dic.username }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;list取值: {{ lst.0 }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;info: {{ dic.hobby.3.info}}\u0026lt;/p\u0026gt; 过滤器 1 2 # 过滤器 就类似于是模板语法内置的 内置方法 # django内置有60多个过滤器 了解10个左右就差不多 后面遇到再去了解 基本语法 1 {{ 数据|过滤器:参数 }} 常用过滤器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;h1\u0026gt;过滤器\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;统计长度：{{ s|length }}\u0026lt;/p\u0026gt; {# 第一个参数布尔值为True 就展示第一个参数的值 否则使用default的值 类似 dict.get(d, default) #} \u0026lt;p\u0026gt;默认值：{{ b|default:\u0026#39;啥也不是\u0026#39; }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;文件大小：{{ file_size|filesizeformat }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;日期格式化：{{ current_time|date:\u0026#39;Y-m-d H:i:s\u0026#39; }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;切片操作(支持步长)：{{ lst|slice:\u0026#39;0:4:3\u0026#39; }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;切取字符(包含3个.)：{{ info|truncatechars:9 }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;切取单词(不包含3个. 只按照空格切)：{{ eng|truncatewords:5 }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;移除特定的字符：{{ eng|cut:\u0026#39;model\u0026#39; }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;拼接操作：{{ lst|join:\u0026#39;$\u0026#39; }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;拼接操作(加法): {{ n|add:\u0026#39;10\u0026#39; }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;拼接操作(加法): {{ s|add:eng }}\u0026lt;/p\u0026gt; {# hhh默认不转义标签 为了安全 不执行恶意scripts代码#} \u0026lt;p\u0026gt;转义：{{ hhh|safe }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;转义：{{ sss|safe }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;转义：{{ res }}\u0026lt;/p\u0026gt; 转义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 模板语法 默认不转义标签 为了安全 不执行恶意scripts代码 # 转义标签用法 safe参数 # 前端 {{ var|safe }} # 后端 from django.utils.safestring import mark_safe res = mark_safe(\u0026#39;\u0026lt;h1\u0026gt;新新\u0026lt;/h1\u0026gt;\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 以后你在写全栈项目的时候 前端代码不一定非要在前端页面书写 也可以先在后端写好 然后再传递给前端页面 \u0026#34;\u0026#34;\u0026#34; 标签 不要被名字干扰 标签就是一堆逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 {# for循环 #} {% for l in lst %} \u0026lt;p\u0026gt;{{ forloop }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;{{ item }}\u0026lt;/p\u0026gt; # 一个个元素 {% endfor %} {# forloop需要掌握它的参数 #} { \u0026#39;parentloop\u0026#39;: {}, \u0026#39;counter0\u0026#39;: 0, \u0026#39;counter\u0026#39;: 1, \u0026#39;revcounter\u0026#39;: 6, \u0026#39;revcounter0\u0026#39;: 5, \u0026#39;first\u0026#39;: True, \u0026#39;last\u0026#39;: False } {# if判断 #} {% if b %} \u0026lt;p\u0026gt;True res\u0026lt;/p\u0026gt; {% elif s %} \u0026lt;p\u0026gt;elif res\u0026lt;/p\u0026gt; {% else %} \u0026lt;p\u0026gt;False res\u0026lt;/p\u0026gt; {% endif %} {# for if混合使用 #} {% for item in lst_empty %} {% if forloop.first %} \u0026lt;p\u0026gt;第一次循环\u0026lt;/p\u0026gt; {% elif forloop.last %} \u0026lt;p\u0026gt;最后一次循环\u0026lt;/p\u0026gt; {% else %} \u0026lt;p\u0026gt;{{ item }}\u0026lt;/p\u0026gt; {% endif %} {% empty %} \u0026lt;p\u0026gt;for循环的可迭代对象 内部没有元素 根本没法循环\u0026lt;/p\u0026gt; {% endfor %} {# 可以使用字典的方法 #} {% for item in dic.keys %} \u0026lt;p\u0026gt;{{ item }}\u0026lt;/p\u0026gt; {% endfor %} {% for item in dic.items %} \u0026lt;p\u0026gt;{{ item }}\u0026lt;/p\u0026gt; {% endfor %} {% for value in dic.values %} \u0026lt;p\u0026gt;{{ value }}\u0026lt;/p\u0026gt; {% endfor %} {% for item in lst %} \u0026lt;p\u0026gt;{{ item }}\u0026lt;/p\u0026gt; {% endfor %} {# with起别名 #} {% with dic.hobby.3.info as nb %} {# 在with语法内 就可以通过as后面的别名快速的使用到前面非常复杂获取数据的方式 #} \u0026lt;p\u0026gt;{{ nb }}\u0026lt;/p\u0026gt; {% endwith %} 自定义 过滤器/标签及inclusion_tag\n自定义过滤器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026#34;\u0026#34;\u0026#34; 先三步走： 1. 在应用下创建一个名字**必须**叫 templatetags文件夹 2. 在该文件夹内 创建任意名称的py文件 e.g: mytag.py 3. 在该py文件内 **必须**先书写下面两句固定的代码 (单词一个都不能错) form django import template register = template.Library() \u0026#34;\u0026#34;\u0026#34; from django import template register = template.Library() # 自定义过滤器(参数最多只有2个) # 主要使用 name=\u0026#34;\u0026#34; 后面的名字 也就是过滤器名字 函数的名字无所谓 随便取 @register.filter(name=\u0026#39;myfilter\u0026#39;) def my_sum(x, y): return x + y # html使用 \u0026lt;h1\u0026gt;自定义的使用(过滤器 最多只能有2个参数)\u0026lt;/h1\u0026gt; {% load mytags %} \u0026lt;p\u0026gt;{{ n|myfilter:666 }}\u0026lt;/p\u0026gt; 自定义标签 类似自定义函数\n1 2 3 4 5 6 7 8 9 # 自定义标签(参数可以有多个) @register.simple_tag(name=\u0026#39;plus\u0026#39;) def index(a, b, c, d): return \u0026#34;{}-{}-{}-{}\u0026#34;.format(a, b, c, d) # 使用 {% load mytags %} {# 标签多个参数之间 空格隔开 #} \u0026lt;p\u0026gt;{% plus \u0026#39;minho\u0026#39; 123 123 9988 %}\u0026lt;/p\u0026gt; 自定义inclusion_tag 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026#34;\u0026#34;\u0026#34; 内部原理： - 先定义一个方法 - 在页面上调用该方法 并且可以传值 - 该方法会生成一些数据 然后传递给一个html页面 - 之后 将渲染好的结果放到调用的位置 \u0026#34;自动生成某一个页面的局部部分\u0026#34; \u0026#34;\u0026#34;\u0026#34; # 自定义inclusion_tag @register.inclusion_tag(\u0026#39;left_menu.html\u0026#39;) def left(n): data = [\u0026#39;第{}项\u0026#39;.format(i) for i in range(n)] # inclusion_tag 两种给作用页面传值的方式 # 第一种 # return {\u0026#39;data\u0026#39;: data} # 第二种 return locals() # 将data传递给left_menu.html # 局部页面内容 \u0026lt;ul\u0026gt; {% for item in data %} \u0026lt;li\u0026gt;{{ item }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; # 使用 \u0026#34;\u0026#34;\u0026#34; 总结：当html页面某一个地方的页面需要传参数才能够动态的渲染出来 并且在多个页面上都需要使用到该局部 那么就考虑将该局部页面做成inclusion_tag形式 \u0026#34;\u0026#34;\u0026#34; {% load mytags %} {% left 5 %} 模板继承 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 \u0026#34;\u0026#34;\u0026#34; 有一些网站 这些网站页面整体都大差不差 只是某一些局部在做变化 同一个html页面 想重复使用大部分样式 只是局部的修改 \u0026#34;\u0026#34;\u0026#34; # 模板的继承 你自己先选好一个你想要继承的模板页面 {% extends \u0026#39;home.html\u0026#39; %} # 继承了之后 子页面跟模板页面长的一摸一样的 你需要在模板页面上提前划定可以被修改的区域 {% block content %} 模板内容 {% endblock %} # 子页面 就可以声明想要修改哪块划定的区域 {% block content %} 子页面内容 子页面除了可以自己写自己的之外 还可以继续使用模板的内容 {{ block.super }} {% endblock %} # 一般情况下 模板页面上应该至少有三块可以被修改的区域 # 这样划分之后 每一个子页面 就都可以有自己独有的css代码 html代码 js代码 1. html区域 {% block content %} 子页面自己的html内容 {% endblock %} 2. css区域 {% block css %} 子页面自己的css {% endblock %} 3. js区域 {% block js %} 子页面自己的js {% endblock %} \u0026#34;\u0026#34;\u0026#34; 一般情况下 模板的页面上 划定的区域越多 那么该模板的扩展性就越高 但是如果太多 那还不如自己写(没必要划分太多) 利用模板的继承 能够让自己的页面更加的好维护 \u0026#34;\u0026#34;\u0026#34; 模板导入 1 2 3 4 5 6 \u0026#34;\u0026#34;\u0026#34; 将页面的某一个局部(e.g：一个好看的表单/导航栏等等) 当成模块的形式 哪个地方需要就可以直接导入使用即可 \u0026#34;\u0026#34;\u0026#34; {% include \u0026#39;ok.html\u0026#39; %} 模型层 重要：跟数据打交道\n测试脚本 参考ORM部分得出的测试脚本\n1 2 3 4 5 6 7 8 9 10 import os import django os.environ.setdefault(\u0026#39;DJANGO_SETTINGS_MODULE\u0026#39;, \u0026#39;cmdb.settings\u0026#39;) # 加载django配置 django.setup(set_prefix=False) # 在下面继续写代码 就可以测试django里面的单个py文件 from app.model import User # 不能拿到最上面 所有的代码都必须等待环境准备完毕之后才能书写 ... 单表查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # django自带的sqlite3数据库对日期格式不是很敏感 处理的时候 容易出错 # 单表环境准备 modes.py class User(models.Model): name = models.CharField(max_length=32) age = models.IntegerField() reg_time = models.DateField() \u0026#34;\u0026#34;\u0026#34; DateField DateTimeField 这2个字段有2个重要参数： auto_now: 每次操作数据的时候 该字段会自动将当前时间更新 auto_now_add: 在每次创建数据的时候 会自动将当前创建时间记录下来 之后只要不人为的修改 那么就一直不变 \u0026#34;\u0026#34;\u0026#34; 增 1 2 3 4 5 6 7 8 9 10 11 # 1. create() 推荐 # create方法 返回当前增加对象本身 res = User.objects.create(name=\u0026#39;minhooo\u0026#39;, age=\u0026#39;18\u0026#39;, register_time=\u0026#39;2002-10-20\u0026#39;) print(res) # 2. save() import datetime ctime = datetime.datetime.now() # 日期字段可以接受字符串 也可以接受datatime对象 user_obj = User(name=\u0026#39;kimi\u0026#39;, age=25, register_time=ctime) user_obj.save() 删 1 2 3 4 5 6 7 8 9 10 11 12 13 # 删 \u0026#34;\u0026#34;\u0026#34; pk会自动查找到当前表的主键字段 指代的就是当前表的主键字段 用了pk之后 你就不需要指定当前表的主键字段到底叫什么 e.g: uid pid sid ... \u0026#34;\u0026#34;\u0026#34; # 1. delete() 推荐 res = User.objects.filter(pk=3).delete() print(res) # 2. user_obj的delete() 先查再删 两条sql语句 user_obj = User.objects.filter(pk=6).first() user_obj.delete() 改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 改 # 1. update() User.objects.filter(pk=4).update(name=\u0026#39;lomen\u0026#39;) # 获取user_obj 然后修改属性 调用save()更新 user_obj = User.objects.get(pk=4) # 不推荐使用get user_obj = User.objects.filter(pk=6) print(user_obj) user_obj.name = \u0026#39;pomno\u0026#39; user_obj.save() \u0026#34;\u0026#34;\u0026#34; get方法返回的直接就是当前数据对象 但是不推荐使用该方法: - get() 一旦数据不存在 该方法会直接报错 - filter() 不会报错 返回空QuerySet 还是使用filter \u0026#34;\u0026#34;\u0026#34; 必知必会13条 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 1. all() # 查询所有数据 2. filter() # 带有过滤条件的查询 WHERE 3. get() # 直接拿数据对象 但是条件不存在直接报错 4. first() # 拿QuerySet对象的第一个元素 5. last() # 拿QuerySet对象的最后一个元素 # 6 7 重要 经常使用 6. values() # 指定获取数据字段 select name, age from ... res = User.objects.values(\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;) print(res) # 返回值类似 列表套字典 \u0026gt;\u0026gt;\u0026gt; \u0026lt;QuerySet [{\u0026#39;name\u0026#39;: \u0026#39;Minho\u0026#39;, \u0026#39;age\u0026#39;: 18}, {\u0026#39;name\u0026#39;: \u0026#39;pomno\u0026#39;, \u0026#39;age\u0026#39;: 29}]\u0026gt; 7. values_list() # 用法同values 返回值类似 列表套元组 8. distinct() # 去重 res = User.objects.values(\u0026#39;name\u0026#39;).distinct( \u0026#34;\u0026#34;\u0026#34; 去重一定要是一模一样的数据 如果带有主键 那么肯定不一样 你在往后的查询中 一定不要忽略主键 \u0026#34;\u0026#34;\u0026#34; 9. order_by() # 排序 res = User.objects.order_by(\u0026#39;age\u0026#39;) # 默认升序 res = User.objects.order_by(\u0026#39;-age\u0026#39;) # 前面加- 降序 10. reverse() # 反转 反转的前提是 数据已经排过序 # 需要用在order_by之后 所以用的不多 res1 = User.objects.order_by(\u0026#39;age\u0026#39;).reverse() 11. count() # 统计 res = User.objects.count() 12. exclude() # 排除在外 WHERE NOT res = User.objects.exclude(name=\u0026#39;Minho\u0026#39;) 13. exists() # 基本用不到 返回布尔值 # 直接拿前面的数据就可以进行布尔判断 随意基本用不到 res = User.objects.filter(pk=10).exists() \u0026#34;\u0026#34;\u0026#34; 查看内部封装的SQL语句的方式 - 方式1：QuerySet_obj.query 只能用于queryset对象 - 方式2：所有的sql语句都能查看 配置文件配置 详见参考上面ORM详解 \u0026#34;\u0026#34;\u0026#34; 双下划线查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # age 大于35 __gt res = User.objects.filter(age__gt=35) # age 小于35 __lt res = User.objects.filter(age__lt=35) # 小于等于__lte 大于等于__gte res = User.objects.filter(age__lte=29) res = User.objects.filter(age__gte=29) # 成员查询 age是 18 or 29 or 55 res = User.objects.filter(age__in=[18, 29, 55]) # 范围查询 age是18到40之间 首尾都要 res = User.objects.filter(age__range=[18, 55]) # 查询名字里面含有n的数据 模糊查询 # __contains LIKE BINARY res = User.objects.filter(name__contains=\u0026#39;n\u0026#39;) # 忽略大小写 __contains LIKE res = User.objects.filter(name__icontains=\u0026#39;N\u0026#39;) # __startswith __endswith res = User.objects.filter(name__startswith=\u0026#39;M\u0026#39;) res = User.objects.filter(name__endswith=\u0026#39;o\u0026#39;) # 查询出注册时间是 2020.1月份的数据 # 按照月份 或者年份 等 查找数据 res = User.objects.filter(reg_time__month=\u0026#39;1\u0026#39;) res = User.objects.filter(reg_time__year=\u0026#39;2020\u0026#39;) 多表操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # models.py 模型准备 # 创建表关系 先将基表创建出来 然后再添加外键字段 class Book(models.Model): title = models.CharField(max_length=32) price = models.DecimalField(max_digits=8, decimal_places=2) # 小数总共8位 小数点后面占2位 publish_date = models.DateTimeField(auto_now_add=True) \u0026#34;\u0026#34;\u0026#34; 图书和出版社是一对多 并且书是多的一方 所以外键字段放在book表里面 如果字段对应的是ForeignKey 那么ORM会自动在字段后面加_id -\u0026gt; publish_id 后面定义ForeignKey的时候 不要自己加_id \u0026#34;\u0026#34;\u0026#34; publish = models.ForeignKey(to=\u0026#39;Publish\u0026#39;, on_delete=models.CASCADE) # 默认就是与出版社表的主键字段做外键关联 可以通过to_field设置 \u0026#34;\u0026#34;\u0026#34; 图书和作者是多对多关系 外键字段建在任意一方均可 但是推荐创建再查询频率较高的一方 authors是一个虚拟字段 主要是用来高速ORM 书籍表 和 作者表 是多对多关系 让ORM自动帮你创建第三张表关系 django 1.x 自动级联更新删除 2.x 3.x需要加参数 \u0026#34;\u0026#34;\u0026#34; authors = models.ManyToManyField(to=\u0026#39;Author\u0026#39;) class Publish(models.Model): name = models.CharField(max_length=32) address = models.CharField(max_length=64) email = models.EmailField() # 本质还是varchar(254) 该字段类型不是给models看的 而是给我们后面会学到的校验型组件看的 def __str__(self): return \u0026#34;\u0026lt;Publish {}\u0026gt;\u0026#34;.format(self.name) class Author(models.Model): name = models.CharField(max_length=32) age = models.IntegerField() \u0026#34;\u0026#34;\u0026#34; 作者与作者详情是一对一关系 外键字段建在任意一方都可以 但是推荐创建在查询频率较高的表中 OneToOneField 也会自动给字段加_id后缀 \u0026#34;\u0026#34;\u0026#34; author_detail = models.OneToOneField(to=\u0026#39;AuthorDetail\u0026#39;, on_delete=models.CASCADE) class AuthorDetail(models.Model): phone = models.BigIntegerField() # 电话号码用BigIntergerField或者直接用CharField address = models.CharField(max_length=32) 一对多 一对一 一对多外键的增删改查\n增 1 2 3 4 5 6 # 1. 直接写外键实际字段 放fk_id models.Book.objects.create(title=\u0026#39;三国演义\u0026#39;, price=123.23, publish_id=1) # 2. 虚拟字段 放对象 publish_obj = models.Publish.objects.filter(pk=2).first() models.Book.objects.create(title=\u0026#39;红楼梦\u0026#39;, price=666.32, publish=publish_obj) 删 1 2 # 删 models.Publish.objects.filter(pk=1).delete() # django 1.x 默认级联删除 改 1 2 3 4 5 6 7 # 修改 # 1. 同增加 models.Book.objects.filter(pk=2).update(publish_id=4) # 2. 同增加 publish_obj = models.Publish.objects.filter(pk=2).first() models.Book.objects.filter(pk=2).update(publish=publish_obj) 多对多 多对多的 增删改查 就是在操作第三张表\n增 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 如何给书籍添加作者 book_obj = models.Book.objects.filter(pk=4).first() print(book_obj.authors) # 第三张表不是我们创建 无法获取model # book_obj.authors 就类似于你已经取到了第三张表 # add() 传主键id book_obj.authors.add(1) # 书籍ID为2的书籍 绑定一个主键为1的作者 book_obj.authors.add(2, 3) # 添加多个作者 # add() 传对象 author_obj = models.Author.objects.filter(pk=1).first() author_obj2 = models.Author.objects.filter(pk=2).first() author_obj3 = models.Author.objects.filter(pk=3).first() book_obj.authors.add(author_obj2, author_obj3) \u0026#34;\u0026#34;\u0026#34; add给第三张关系表添加数据 括号内 既可以传对象 也可以传数字(id) 并且都支持传多个值 \u0026#34;\u0026#34;\u0026#34; 删 1 2 3 4 5 6 7 8 9 10 11 # 删 book_obj = models.Book.objects.filter(pk=4).first() # 传id book_obj.authors.remove(2) book_obj.authors.remove(1, 3) # 传对象 author_obj = models.Author.objects.filter(pk=3).first() author_obj2 = models.Author.objects.filter(pk=2).first() book_obj.authors.remove(author_obj, author_obj2) 改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 改 book_obj = models.Book.objects.filter(pk=2).first() # 传id book_obj.authors.set((1, 2)) # 括号内必须给一个可迭代对象 book_obj.authors.set((3,)) # 先删除数据 再增加 # 传对象 author_obj = models.Author.objects.filter(pk=3).first() author_obj2 = models.Author.objects.filter(pk=2).first() book_obj.authors.set([author_obj, author_obj2]) \u0026#34;\u0026#34;\u0026#34; set() 括号内必须传一个可迭代对象 该可迭代对象内 既可以传对象 也可以传数字(id) 都支持多个 \u0026#34;\u0026#34;\u0026#34; 清空 1 2 3 4 5 6 7 8 9 # 清空 # 在第三张关系表中 清空某个书籍与作者的绑定关系 # DELETE FROM `app02_book_authors` WHERE `app02_book_authors`.`book_id` = 2 book_obj = models.Book.objects.filter(pk=2).first() book_obj.authors.clear() \u0026#34;\u0026#34;\u0026#34; clear() 括号内不要加任何参数 \u0026#34;\u0026#34;\u0026#34; 跨表查询(重点) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # 正反向的概念 看外键字段在哪儿 外键字段在我手上 我查你就是正向 否则 外键字段不在我手上 我查你就是反向 # 正向 反向 假设： 一本书对应一个出版社 一个出版社可以出版多本书 那么 外键字段在 书 这边 正向：由 书 查询 出版社 反向：由 出版社 查询 书 book \u0026gt;\u0026gt;\u0026gt; 外键字段在书哪儿(正向) \u0026gt;\u0026gt;\u0026gt; publish publish \u0026gt;\u0026gt;\u0026gt; 外键字段在书哪儿(反向) \u0026gt;\u0026gt;\u0026gt; book 一对一和多对多的正反向判断也是如此 \u0026#34;\u0026#34;\u0026#34; 正向查询按外键字段 反向查询按表名小写 _set.all() \u0026#34;\u0026#34;\u0026#34; \u0026#34;\u0026#34;\u0026#34; 多表操作 1. 子查询 ORM --\u0026gt; 基于对象的跨表查询 - 先拿到一个数据对象 - 对象点点点 就能拿到对应的字段 2. 联表查询 ORM --\u0026gt; 基于双下划线的跨表查询 inner join left join right join union \u0026#34;\u0026#34;\u0026#34; 1. 基于对象的跨表查询 # 正向 book_obj.publish book_obj.authors.all() author_obj.author_detail # 反向 publish_obj.book_set # App01.Book.None publish_obj.book_set.all() author_obj.book_set.all() author_detail_obj.author 2. 基于双下划线的跨表查询 # 等价的一对正向和反向查询 models.Book.objects.filter(pk=1).values(\u0026#39;title\u0026#39;, \u0026#39;publish__name\u0026#39;) models.Publish.objects.filter(book__id=1).values(\u0026#39;book__title\u0026#39;, \u0026#39;name\u0026#39;) # 其他字段同理 # 利用双下划线的跨表查询 可以帮助你跨N多张表 只要有外键字段 models.Book.objects.filter(pk=1).values(\u0026#39;authors__author_detail__phone\u0026#39;) 子查询 基于对象的跨表查询\n正向 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 基于对象的跨表查询 先拿到关系字段在的对象 # 1. 查询书籍主键为2的出版社名称 book_obj = models.Book.objects.filter(pk=2).first() # 书查出版社 正向 按字段 res = book_obj.publish print(res, res.name, res.address) # 2. 查询书籍主键为2的作者 book_obj = models.Book.objects.filter(pk=4).first() # 书查作者 正向 # res = book_obj.authors # app02.Author.None 发现结果类似这样 ORM可能没错 少了 .all() res = book_obj.authors.all() # \u0026lt;QuerySet [\u0026lt;Author: Author object (2)\u0026gt;, \u0026lt;Author: Author object (3)\u0026gt;]\u0026gt; print(res) # 3. 查询作者minho的电话号码 author_obj = models.Author.objects.filter(name=\u0026#39;minho\u0026#39;).first() res = author_obj.author_detail print(res, res.phone, res.address) \u0026#34;\u0026#34;\u0026#34; 在书写ORM语句的时候 跟写sql语句一样的 不要试图一次将orm语句写完 如果比较复杂 就写一点看一点 正向什么时候需要加 .all() 当你的结果可能有多个的时候 就需要加 .all() 如果是一个结果 则直接能拿到数据对象 book_obj.publish book_obj.authors.all() author_obj.author_detail \u0026#34;\u0026#34;\u0026#34; 反向 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 4. 查询出版社是东方出版社出版的书 publish_obj = models.Publish.objects.filter(name=\u0026#39;东方出版社\u0026#39;).first() # 出版社查书 反向 res = publish_obj.book_set # app02.Book.None res = publish_obj.book_set.all() print(res) # 5. 查询作者是minho写过的书 author_obj = models.Author.objects.filter(name=\u0026#39;minho\u0026#39;).first() # 作者查书 反向 res = author_obj.book_set # app02.Book.None res = author_obj.book_set.all() print(res) # 5. 查询手机号是110的作者姓名 author_detail_obj = models.AuthorDetail.objects.filter(phone=\u0026#39;110\u0026#39;).first() res = author_detail_obj.author print(res, res.name) \u0026#34;\u0026#34;\u0026#34; 基于对象 反向查询的时候 当你的查询结果可以有多个的时候 就必须加 _set.all() 一对多 多对多 反向查询 当你的结果只有一个的时候 不需要加 _set.all() 一对一反向查询 \u0026#34;\u0026#34;\u0026#34; 联表查询 基于双下划线的跨表查询\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 1. 查询minho的手机号 res = models.Author.objects.filter(name=\u0026#39;minho\u0026#39;).values(\u0026#39;author_detail__phone\u0026#39;, \u0026#39;name\u0026#39;) print(res) # 反向 res = models.AuthorDetail.objects.filter(author__name=\u0026#39;minho\u0026#39;).values(\u0026#39;phone\u0026#39;, \u0026#39;author__name\u0026#39;) # 拿作者姓名是minho的作者详情 print(res) # 2. 查询书籍为2的出版社名称 和 书的名称 res = models.Book.objects.filter(pk=2).values(\u0026#39;publish__name\u0026#39;, \u0026#39;title\u0026#39;) print(res) # 反向 res = models.Publish.objects.filter(book__id=2).values(\u0026#39;name\u0026#39;, \u0026#39;book__title\u0026#39;) print(res) # 3. 查询书籍主键为3的作者姓名 res = models.Book.objects.filter(pk=3).values(\u0026#39;authors__name\u0026#39;) print(res) # 反向 res = models.Author.objects.filter(book__id=3).values(\u0026#39;name\u0026#39;) print(res) # 查询书籍主键是2的作者的手机号 # 涉及：book author authordetail res = models.Book.objects.filter(pk=3).values(\u0026#39;authors__author_detail__phone\u0026#39;) print(res) \u0026#34;\u0026#34;\u0026#34; 只要掌握了正反向的概念 以及双下划线查询 那么你就可以无限制的跨表 \u0026#34;\u0026#34;\u0026#34; 聚合查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 原生：max min sum count avg # orm: aggregate # 聚合查询 aggregate \u0026#34;\u0026#34;\u0026#34; 聚合查询通常情况下 都是配合分组一起使用的 只要是跟数据库相关的模块 基本上都在 django.db.models里面 如果上述没有那么应该在 django.db里面 \u0026#34;\u0026#34;\u0026#34; from django.db.models import Max, Min, Avg, Count, Sum # 1. 书的平均价格 res = models.Book.objects.aggregate(Avg(\u0026#39;price\u0026#39;)) print(res) # 2. 上述方法一次性使用 res = models.Book.objects.aggregate(Max(\u0026#39;price\u0026#39;), Min(\u0026#39;price\u0026#39;), Sum(\u0026#39;price\u0026#39;), Count(\u0026#39;pk\u0026#39;), Avg(\u0026#39;price\u0026#39;)) print(res) 分组查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # 原生：group by # orm: annotate # 分组查询 annotate \u0026#34;\u0026#34;\u0026#34; MySQL分组查询都有哪些特点 分组之后 默认只能获取到分组的依据 组内其他字段 都无法直接获取 严格模式：ONLY_FULL_GROUP_BY \u0026#34;\u0026#34;\u0026#34; # 1. 统计每一本书的作者个数 from django.db.models import Max, Min, Avg, Count, Sum res = models.Book.objects.annotate() # models后面点什么 就是按什么分组 # res = models.Book.objects.annotate(author_num=Count(\u0026#39;authors\u0026#39;)).values(\u0026#39;title\u0026#39;, \u0026#39;author_num\u0026#39;) # 与下面等价 不用加__id res = models.Book.objects.annotate(author_num=Count(\u0026#39;authors__id\u0026#39;)).values(\u0026#39;title\u0026#39;, \u0026#39;author_num\u0026#39;) \u0026#34;\u0026#34;\u0026#34; author_num 是我们自己定义的字段(别名) 用来存储统计出来的每本书对应的作者个数 \u0026#34;\u0026#34;\u0026#34; print(res) # 2. 统计每个出版社卖得最便宜的书的价格 res = models.Publish.objects.annotate(min_price=Min(\u0026#39;book__price\u0026#39;)).values(\u0026#39;name\u0026#39;, \u0026#39;min_price\u0026#39;) print(res) # 3. 统计不止一个作者的图书 # 先按着图书分组 然后过滤出不止一个作者的图书 res = models.Book.objects.annotate(author_num=Count(\u0026#39;authors\u0026#39;)).filter(author_num__gt=1).values(\u0026#39;title\u0026#39;, \u0026#39;author_num\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 只要你的orm语句得出的结果 还是一个queryset对象 那么它就可以继续无限制的使用点queryset对象封装的方法 \u0026#34;\u0026#34;\u0026#34; print(res) # 4. 查询每个作者出的书的总价格 res = models.Author.objects.annotate(sum_price=Sum(\u0026#39;book__price\u0026#39;)).values(\u0026#39;name\u0026#39;, \u0026#39;sum_price\u0026#39;) print(res) \u0026#34;\u0026#34;\u0026#34; 如果我想按照指定的字段分组 该如何处理? models.Book.objects.values(\u0026#39;price\u0026#39;).annotate() 如果 annotate()方法前面 有values指定字段 那么就按照指定字段分组 否则 按照models后面指定的表分组 如果出现分组查询报错的情况 你需要修改数据库严格模式 \u0026#34;\u0026#34;\u0026#34; F与Q查询 F查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 1. 查询卖出数大于库存数的书籍 # F查询 \u0026#34;\u0026#34;\u0026#34; 能够帮助你直接获取到表中某个字段对应的数据 当作查询条件 \u0026#34;\u0026#34;\u0026#34; from django.db.models import F res = models.Book.objects.filter(maichu__gt=F(\u0026#39;kucun\u0026#39;)) print(res) # 2. 将所有书籍的价格提升50块 models.Book.objects.update(price=F(\u0026#39;price\u0026#39;) + 500) # 3. 将所有书的名称后面加上爆款两个字 \u0026#34;\u0026#34;\u0026#34; 在操作字符类型的数据的时候 F不能够直接做到字符串的拼接 \u0026#34;\u0026#34;\u0026#34; from django.db.models.functions import Concat from django.db.models import Value models.Book.objects.update(title=Concat(F(\u0026#39;title\u0026#39;), Value(\u0026#39;爆款\u0026#39;))) # models.Book.objects.update(title=F(\u0026#39;title\u0026#39;) + \u0026#39;爆款\u0026#39;) # 所有的名称会全部变为空白 Q查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Q 实现查询的与 或 非 # Q查询 # 1. 查询卖出数大于100或者价格小于400的书籍 \u0026#34;\u0026#34;\u0026#34; filter括号内 多个参数是and关系 \u0026#34;\u0026#34;\u0026#34; res = models.Book.objects.filter(maichu__gt=100, price__lt=400) # filter 多个参数默认是AND关系 from django.db.models import Q res = models.Book.objects.filter(Q(maichu__gt=100), Q(price__lt=400)) # Q包裹 逗号分割 还是AND关系 res = models.Book.objects.filter(Q(maichu__gt=100) | Q(price__lt=400)) # | OR关系 res = models.Book.objects.filter(~Q(maichu__gt=100) | Q(price__lt=400)) # ~ NOT关系 print(res) # Q的高阶用法 能够将查询条件的左边也变成字符串的形式 而不是变量 q = Q() q.connector = \u0026#39;or\u0026#39; # Q对象链接 children 默认是AND关系 .connector修改 q.children.append((\u0026#39;maichu__gt\u0026#39;, 100)) q.children.append((\u0026#39;maichu__lt\u0026#39;, 600)) res = models.Book.objects.filter(q) # filter括号内支持直接放Q对象 默认还是AND关系 可以修改 print(res) django中如何开启事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 \u0026#34;\u0026#34;\u0026#34; 事务 ACID A 原子性 不可分割的最小单位 C 一致性 跟原子性是相辅相成的 I 隔离性 事务之间户型不干扰 D 持久性 事务一旦确认永久生效 事务的回滚 rollback 事务的确认 commit \u0026#34;\u0026#34;\u0026#34; # Django中如何简单的开启事务 from django.db import transaction try: with transaction.atomic(): # sql1 # sql2 ... # 在with代码块内书写的所有orm操作 都是同一个事务 orm... except Exception as err: print(err) print(\u0026#39;执行其他操作\u0026#39;) orm中常用字段及参数 DjangoORM字段类型参考\n博客参考\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 AutoField 主键字段 primary_key=True CharField -\u0026gt; varchar verbose_name # 字段的注释 max_length # 长度 必须提供 InterField -\u0026gt; int BigInterField -\u0026gt; bigint DecimalField max_digits=8 # 8位数字 decimal_places=2 # 2位小数 EmailField -\u0026gt; varchar(254) DateField -\u0026gt; date DateTimeField -\u0026gt; datetime auto_now # 每次修改数据的时候 都会自动更新当前时间 auto_now_add # 只在创建数据的时候记录创建时间 后续不会自动修改 BooleanField(Field) - 布尔值类型 该字段传布尔值(False/True) 数据库里面存0/1 TextField(Field) - 文本类型 该字段可以用来存大段内容(文章 博客) 没有字数限制 FileField(Field) - 字符类型 upload_to = \u0026#34;/data\u0026#34; # 给该字段传一个文件对象 会自动将文件保存到/data目录下 然后将文件路径保存到数据库中 /data/a.txt ... # 外键字段及参数 # 你在用ForeingKey(unique=True)字段创建一对一关系 orm会有一个提示 orm推荐你使用OneToOneField() unique=True ForeignKey(unique=True) == OneToOneField() db_index 如果db_index=True 则代表为此字段设置**索引** to_field 要关联的表的字段 默认不写关联的就是另外一张表的主键字段 on_delete 当删除关联表中的数据时 当前表与其关联的行的行为 \u0026#34;\u0026#34;\u0026#34; django2.x及以上版本时 需要你自己指定外键字段的级联更新 级联删除 \u0026#34;\u0026#34;\u0026#34; db_constraint 是否在数据库中创建外键约束 默认为True ... # django除了给你提供了很多字段类型之外 还支持你自定义字段 自定义字段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 自定义 class MyCharField(models.Field): def __init__(self, max_length, *args, **kwargs): self.max_length = max_length # 一定要是关键字传参 按位置传参会出错(看源码) super().__init__(max_length=max_length, *args, **kwargs) def db_type(self, connection): \u0026#34;\u0026#34;\u0026#34; 返回真正的数据类型及各种约束条件 \u0026#34;\u0026#34;\u0026#34; return \u0026#39;char({})\u0026#39;.format(self.max_length # 使用 myfield = MyCharField(max_length=16, null=True) choices参数 数据库字段设计常见\nchoicesc参数 在实际项目中 使用场景是非常广泛的\nField.choices\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026#34;\u0026#34;\u0026#34; 用户表 - 性别 - 学历 - 工作经验 - 是否结婚 - 客户来源 ... 针对某个可以列举完全的可能性字段 我们应该如何存储? 总结：只要某个字段的可能性是可以列举完全的 那么一般情况下 都会采用choices参数 \u0026#34;\u0026#34;\u0026#34; score_choices = [ (\u0026#39;A\u0026#39;, \u0026#39;优秀\u0026#39;), (\u0026#39;B\u0026#39;, \u0026#39;良好\u0026#39;), (\u0026#39;C\u0026#39;, \u0026#39;及格\u0026#39;), (\u0026#39;D\u0026#39;, \u0026#39;不及格\u0026#39;) ] # 保证字段类型 跟列举出来的元组的第一个数据类型一致即可 score = models.CharField(choices=score_choices) model准备 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # model准备 class User(models.Model): name = models.CharField(max_length=32) age = models.IntegerField() # 性别字段 # 存布尔值 不是特别合理 没有对应关系 True/Flase分别对应什么性别? # gender = models.BooleanField() gender_choices = [ (1, \u0026#39;男\u0026#39;), (2, \u0026#39;女\u0026#39;), (3, \u0026#39;其他\u0026#39;), ] gender = models.IntegerField(choices=gender_choices) # 看choices里面元组的第一个元素是什么类型 就是什么字段 \u0026#34;\u0026#34;\u0026#34; 该gender字段存的还是数字 但是如果存的数字在上面元组列举的范围之内 那么就可以非常轻松的获取到数字对应的真正的内容 1. gender字段存的数字 不在上述元组列举的范围内容? 2. 如果在 如何获取对应的中文信息? \u0026#34;\u0026#34;\u0026#34; def __str__(self): return \u0026#34;\u0026lt;User {}\u0026gt;\u0026#34;.format(self.name) 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 增 # 存的时候 没在choices列举的范围之内的数字 也能存进去 # 存的数据范围 还是按照字段类型决定 IntegerField models.User.objects.create(name=\u0026#39;mm\u0026#39;, age=18, gender=1, register_time=\u0026#39;2020-10-1\u0026#39;) models.User.objects.create(name=\u0026#39;nn\u0026#39;, age=67, gender=2, register_time=\u0026#39;2020-10-1\u0026#39;) models.User.objects.create(name=\u0026#39;bb\u0026#39;, age=22, gender=3, register_time=\u0026#39;2020-10-1\u0026#39;) models.User.objects.create(name=\u0026#39;vv\u0026#39;, age=9, gender=4, register_time=\u0026#39;2020-10-1\u0026#39;) # 取 user_obj = models.User.objects.filter(pk=10).first() # print(user_obj.gender) # 只要是choices参数的字段 如果你想要获取对应信息 固定写法: get_字段名_display() print(user_obj.get_gender_display()) # 如果没有对应关系 字段是什么还是展示什么 user_obj = models.User.objects.filter(pk=12).first() print(user_obj.get_gender_display()) 数据库查询优化 1 2 3 4 5 6 7 8 9 \u0026#34;\u0026#34;\u0026#34; ORM语句的特点：惰性查询 如果你仅仅只是书写了ORM语句 在后面根本没有用到该语句查询出来的参数 那么ORM会自动识别 直接不执行 要用到数据的时候 才会走数据库 \u0026#34;\u0026#34;\u0026#34; # only 与 defer # select_related 与 prefetch_related only与defer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # only # 获取user表中 所有用户的名字 res = User.objects.values(\u0026#39;name\u0026#39;) for d in res: print(d.get(\u0026#39;name\u0026#39;)) # 实现 获取到的是一个数据对象 然后 点name就能拿到名字 并且没有其他字段 # only使用 res = User.objects.only(\u0026#39;name\u0026#39;) for d in res: print(d.name) # 点only括号内的字段 不会走数据库 print(d.age) # 点only括号内没有的字段 会重新走数据库字段 而all()不需要 # defer使用 res = User.objects.defer(\u0026#39;name\u0026#39;) # 还是返回数据对象 除了没有name属性之外 其他的都有 for i in res: print(i.name) # 5条SQL print(i.age) # 1条SQL \u0026#34;\u0026#34;\u0026#34; defer与only刚好相反 defer括号内放的字段不在查询出来的对象里面 查询该字段需要重新走数据库 而如果查询的是非括号内的字段 则不需要走数据库 总结： - only 只会缓存指定字段的结果 后面循环去取指定字段 只会有1条SQL 取其他字段 N条SQL - defer 会缓存除指定字段以外的全部字段结果 后面循环取指定字段 N条SQL 取其他字段 1条SQL \u0026#34;\u0026#34;\u0026#34; select_related与prefetch_related 跟跨表操作有关\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 res = models.Book.objects.all() for i in res: print(i.publish.name) # 每循环一次 就走一次数据库查询 # select_related \u0026#34;\u0026#34;\u0026#34; select_related 内部直接先将book与publish连起来 然后一次性将大表里面的所有数据 全部封装给查询出来的对象 这个时候对象无论是点击book表的数据 还是publish的数据 都无需再走数据库查询了 注意事项： select_related括号内 只能放外键字段： - 一对一 一对多 可以 - 多对多 不行 抛出异常 \u0026#34;\u0026#34;\u0026#34; res = models.Book.objects.select_related(\u0026#39;publish\u0026#39;) # INNER JOIN 联表 for i in res: print(i.publish.name) # prefetch_related res = models.Book.objects.prefetch_related(\u0026#39;publish\u0026#39;) # 子查询 \u0026#34;\u0026#34;\u0026#34; prefetch_related 该方法内部其实就是子查询 将子查询查询出来的所有结果也给你封装到对象中 给你的感觉好像也是一次性搞定的 \u0026#34;\u0026#34;\u0026#34; for i in res: print(i.publish.name) # select_related与prefetch_related各有优缺点 不一定谁一定好 根据实际请况来看 批量插入数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 循环一次次插入数据 from . import models def ab_pl(request): # 先给book插入10000条数据 for i in range(10000): models.Book.objects.create(title=\u0026#39;第{}本书\u0026#39;.format(i)) # 再将所有的数据查询并展示到前端页面 book_queryset = models.Book.objects.all() return render(request, \u0026#39;ab_pl.html\u0026#39;, locals()) # 这个时候访问指向该视图函数的url的时候 页面会一致转圈 卡顿很久(根据数据量决定) - 慢 甚至超时 def ab_pl(request): \u0026#34;\u0026#34;\u0026#34; 当你想要批量插入数据的时候 使用orm给你提供的bulk_create能够大大的减少操作时间 INSERT INTO `app01_book` (`title`) VALUES (\u0026#39;第0本书\u0026#39;), (\u0026#39;第1本书\u0026#39;), ... \u0026#34;\u0026#34;\u0026#34; # 批量插入 极快 book_list = [models.Book(title=\u0026#34;第{}本书\u0026#34;.format(i)) for i in range(10000)] models.Book.objects.bulk_create(book_list) book_queryset = models.Book.objects.all() return render(request, \u0026#39;ab_pl.html\u0026#39;, locals()) Forms组件 使用表单\n前戏 1 2 3 4 5 6 7 8 \u0026#34;\u0026#34;\u0026#34; 写一个注册功能 获取用户名和密码 利用form表单提交数据 在后端判断用户名和密码 是否符合一定的条件 - 名字中不能含有 金瓶梅 - 密码不能少于三位 如果符合条件 需要你将提示信息展示到前s端页面 \u0026#34;\u0026#34;\u0026#34; V1版本 自己实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # VIEW def ab_form(request): back_dic = {\u0026#39;username\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;password\u0026#39;: \u0026#39;\u0026#39;} \u0026#34;\u0026#34;\u0026#34; 无论是post请求还是get请求 页面都能够获取到字典 只不过get请求来的时候 字典值都是空的 而post请求来之后 字典可能有值 \u0026#34;\u0026#34;\u0026#34; if request.method == \u0026#39;POST\u0026#39;: username = request.POST.get(\u0026#39;username\u0026#39;) password = request.POST.get(\u0026#39;password\u0026#39;) if \u0026#39;金瓶梅\u0026#39; in username: back_dic[\u0026#39;username\u0026#39;] = \u0026#39;不符合社会主义核心价值观\u0026#39; if len(password) \u0026lt; 3: back_dic[\u0026#39;password\u0026#39;] = \u0026#39;密码不能太短\u0026#39; return render(request, \u0026#39;ab_form.html\u0026#39;, locals()) # HTML \u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;p\u0026gt;username: \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;\u0026gt; \u0026lt;span style=\u0026#34;color: red\u0026#34;\u0026gt;{{ back_dic.username }}\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;password: \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;\u0026gt; \u0026lt;span style=\u0026#34;color: red\u0026#34;\u0026gt;{{ back_dic.password }}\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; V2版本 使用form组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;\u0026#34;\u0026#34; V1版本中 需要自己做下面三件事情 1. 手动书写前端获取用户数据的html代码 -\u0026gt; 渲染html代码 2. 后端对用户数据进行校验 -\u0026gt; 校验数据 3. 对不符合要求的数据进行前端提示 -\u0026gt; 展示提示信息 而form组件 可以把这三件事情 全部搞定 - 校验规则 可以直接由form组件完成 不需要频繁请求后端 - 把校验规则 提前告诉form组件 为什么数据校验非要去后端 不能在前端利用js直接完成呢? - 数据校验 前端可有可无 但是后端必须要有 - 前端的校验是弱不禁风的 你可以直接修改 或者利用爬虫程序绕过前端页面直接朝后端提交数据 e.g: 购物网站 - 选取货物之后 计算一个价格发送给后端 如果后端不做价格校验 实际是获取用户选择的所有商品的主键值 然后在后端查询出所有商品的价格 再次计算一遍 如果跟前端一致 完成支付 如果不一致直接拒绝 \u0026#34;\u0026#34;\u0026#34; 基本使用 1 2 3 4 5 6 7 8 from django import forms class MyForm(forms.Form): # username字符串最小3位 最大8位 username = forms.CharField(min_length=3, max_length=8) # password字符串最小3位 最大8位 password = forms.CharField(min_length=3, max_length=8) # email字段必须符合邮箱格式 email = forms.EmailField() 校验数据 环境准备及基本使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \u0026#34;\u0026#34;\u0026#34; 1. 测试环境的准备 可以自己拷贝代码准备 2. 其实在pycharm里面已经帮你准备了一个测试环境 - 直接点击pycharm底部的 PythonConsole 它会帮你准备测试环境 导入相关模块 \u0026#34;\u0026#34;\u0026#34; \u0026gt;\u0026gt;\u0026gt; from app02 import views # 1. 将待校验的数据组织成字典的形式传入(传递给需要验证的Form) \u0026gt;\u0026gt;\u0026gt; form_obj = views.MyForm({\u0026#39;username\u0026#39;:\u0026#39;minho\u0026#39;, \u0026#39;password\u0026#39;:\u0026#39;123\u0026#39;, \u0026#39;email\u0026#39;:\u0026#39;123\u0026#39;}) # 2. 验证数据是否合法 该方法只有在所有数据全部合法的请况下才会返回True \u0026gt;\u0026gt;\u0026gt; form_obj.is_valid() False # 3. 查看所有校验通过的数据 \u0026gt;\u0026gt;\u0026gt; form_obj.cleaned_data {\u0026#39;username\u0026#39;: \u0026#39;minho\u0026#39;, \u0026#39;password\u0026#39;: \u0026#39;123\u0026#39;} # 4. 查看所有不符合校验规则以及不符合的原因 # 返回字典 key:验证字段 value:列表(报错信息不唯一 可能有多个) \u0026gt;\u0026gt;\u0026gt; form_obj.errors { \u0026#39;email\u0026#39;: [\u0026#39;Enter a valid email address.\u0026#39;] } # 5. 校验数据只校验类中出现的字段 多传不影响 多传字段直接忽略 \u0026gt;\u0026gt;\u0026gt; form_obj = views.MyForm({\u0026#39;username\u0026#39;:\u0026#39;minho\u0026#39;, \u0026#39;password\u0026#39;:\u0026#39;123\u0026#39;, \u0026#39;email\u0026#39;:\u0026#39;123@qq.com\u0026#39;, \u0026#39;hobby\u0026#39;:\u0026#39;study\u0026#39;}) \u0026gt;\u0026gt;\u0026gt; form_obj.is_valid() True \u0026gt;\u0026gt;\u0026gt; form_obj.errors {} # 6. 校验数据 默认请况下 类里面所有的字段都必须传值 \u0026gt;\u0026gt;\u0026gt; form_obj = views.MyForm({\u0026#39;username\u0026#39;:\u0026#39;minho\u0026#39;, \u0026#39;password\u0026#39;:\u0026#39;123\u0026#39;}) \u0026gt;\u0026gt;\u0026gt; form_obj.is_valid() False \u0026gt;\u0026gt;\u0026gt; form_obj.errors {\u0026#39;email\u0026#39;: [\u0026#39;This field is required.\u0026#39;]} \u0026#34;\u0026#34;\u0026#34; 校验数据的时候 默认情况下：数据可以多传但是绝不能少传 \u0026#34;\u0026#34;\u0026#34; 渲染标签 forms组件只会自动帮你渲染用户输入的标签(input select radio checkbox) 不会帮你渲染提交按钮\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # view def index(request): # 1. 先产生一个空对象 form_obj = MyForm() # 2. 直接将该空对象传递给html页面 return render(request, \u0026#39;index.html\u0026#39;, locals()) # 前端利用空对象做操作 \u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;p\u0026gt;第1种渲染方式: 代码书写极少 封装程度太高 不便于后续扩展 一般情况下只在本地测试使用\u0026lt;/p\u0026gt; {{ form_obj.as_p }} {{ form_obj.as_ul }} {{ form_obj.as_table }} \u0026lt;p\u0026gt;第2种渲染方式：可扩展性很强 但是书写代码太多 一般情况下不用\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;{{ form_obj.username.label }}: {{ form_obj.username }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;{{ form_obj.password.label }}: {{ form_obj.password }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;{{ form_obj.email.label }}: {{ form_obj.email }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;第3种渲染方式：推荐使用 代码书写简单 并且扩展性也高\u0026lt;/p\u0026gt; {% for form in form_obj %} \u0026lt;p\u0026gt;{{ form.label }}:{{ form }}\u0026lt;/p\u0026gt; {% endfor %} \u0026lt;/form\u0026gt; \u0026#34;\u0026#34;\u0026#34; label属性默认展示的是Form类中字段首字母大写的形式 也可以自己修改 直接给字段对象加label属性即可 username = forms.CharField(min_length=3, max_length=8, label=\u0026#39;用户名\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 展示提示信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 \u0026#34;\u0026#34;\u0026#34; 浏览器会自动帮你校验数据 但是前端的校验弱不禁风 如何让浏览器不做校验? - form标签加一个 novalidate属性 \u0026#34;\u0026#34;\u0026#34; # view def index(request): # 1. 先产生一个空对象 form_obj = MyForm() if request.method == \u0026#39;POST\u0026#39;: # 2. 获取用户数据并检验 \u0026#34;\u0026#34;\u0026#34; 1. 数据获取繁琐 2. 校验数据需要构造成字典的格式传入才行 注意：request.POST可以看成就是一个字典 \u0026#34;\u0026#34;\u0026#34; # 3. 校验数据 form_obj = MyForm(request.POST) # 4. 判断数据是否合法 if form_obj.is_valid(): # 5. 如果合法 操作数据库存储数据库 return HttpResponse(\u0026#39;ok\u0026#39;) # 5. 不合法 有错误 # 2. 直接将该空对象传递给html页面 return render(request, \u0026#39;index.html\u0026#39;, locals()) # html \u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34; novalidate\u0026gt; {% for form in form_obj %} \u0026lt;p\u0026gt; {{ form.label }}:{{ form }} \u0026lt;span style=\u0026#34;color: red\u0026#34;\u0026gt;{{ form.errors.0 }}\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; {% endfor %} \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026#34;\u0026#34;\u0026#34; 1. 必备的条件 get请求和post请求 传给html页面的对象变量名必须一样 2. form组件当你的数据不合法的情况下 会保留你上次的数据 让你基于之前的结果进行修改 更加的人性化 \u0026#34;\u0026#34;\u0026#34; # 自定义错误提示信息 error_messages参数 class MyForm(forms.Form): username = forms.CharField(min_length=3, max_length=8, label=\u0026#39;用户名\u0026#39;, error_messages={ \u0026#39;min_length\u0026#39;: \u0026#39;用户名最少3位\u0026#39;, \u0026#39;max_length\u0026#39;: \u0026#39;用户名最大8位\u0026#39;, \u0026#39;required\u0026#39;: \u0026#39;用户名不能为空\u0026#39; }) password = forms.CharField(min_length=3, max_length=8, label=\u0026#39;密码\u0026#39;, error_messages={ \u0026#39;min_length\u0026#39;: \u0026#39;密码最少3位\u0026#39;, \u0026#39;max_length\u0026#39;: \u0026#39;密码最大8位\u0026#39;, \u0026#39;required\u0026#39;: \u0026#39;密码不能为空\u0026#39; }) email = forms.EmailField(label=\u0026#39;邮箱\u0026#39;, error_messages={ \u0026#39;invalid\u0026#39;: \u0026#39;邮箱格式不正确\u0026#39;, \u0026#39;required\u0026#39;: \u0026#39;邮箱不能为空\u0026#39; }) 钩子函数(hook) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \u0026#34;\u0026#34;\u0026#34; 在特定的节点自动触发完成响应操作 钩子函数在form组件中 就类似于第二道关卡 能够让我们自定义校验规则 在forms组件中有2类钩子 1. 局部钩子 当你需要给单个字段增加校验规则的时候可以使用 2. 全局钩子 当你需要给多个字段增加校验规则的时候可以使用 \u0026#34;\u0026#34;\u0026#34; # 实际案例 1. 校验用户名中不能含有666 # 只是校验username字段 局部钩子 2. 检验密码和确认密码是否一致 # password confirm两个字段 全局钩子 # 钩子函数 在类里面书写方法即可 class MyForm(forms.Form): username = forms.CharField(...) password = forms.CharField(...) confirm_password = forms.CharField(...) email = forms.EmailField(...) # 钩子函数 # 局部钩子 def clean_username(self): # 获取到用户名 username = self.cleaned_data.get(\u0026#39;username\u0026#39;) if \u0026#39;666\u0026#39; in username: # 展示错误信息 self.add_error(\u0026#39;username\u0026#39;, \u0026#39;不能包含666\u0026#39;) # 将钩子函数钩出去的数据(单个数据)再放回去 return username # 全局钩子 def clean(self): password = self.cleaned_data.get(\u0026#39;password\u0026#39;) confirm_password = self.cleaned_data.get(\u0026#39;confirm_password\u0026#39;) if not password == confirm_password: self.add_error(\u0026#39;confirm_password\u0026#39;, \u0026#39;两次密码不一致\u0026#39;) # 将钩子函数钩出去的数据(全部数据)再放回去 return self.cleaned_data 重要参数 Django官网表单字段详解\nforms组件 其他参数及补充知识点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 label 自定义字段名 error_messages 自定义报错信息 initial 默认值 required 是否必填 默认是True \u0026#34;\u0026#34;\u0026#34; 问题： 1. 字段没有样式 2. 针对不同类型的input如何修改 - text - password - date - radio - checkbox ... # 处理文本输入的部件 widget参数解决 https://docs.djangoproject.com/zh-hans/3.1/ref/forms/widgets/ widget=forms.PasswordInput # 调整样式 attrs参数解决 # 多个属性值 直接空格隔开即可 https://docs.djangoproject.com/zh-hans/3.1/ref/forms/widgets/#django.forms.Widget.attrs widget=forms.TextInput(attrs={\u0026#39;class\u0026#39;:\u0026#39;form-contral c1 c2\u0026#39;}) \u0026#34;\u0026#34;\u0026#34; validators 第一道关卡还支持正则校验 参考：https://docs.djangoproject.com/zh-hans/3.1/ref/validators/ validators=[RegexValidator(r\u0026#39;^[0-9]+$\u0026#39;, \u0026#39;请输入数字\u0026#39;), RegexValidator(r\u0026#39;^159[0-9]+$\u0026#39;, \u0026#39;数字必须以159开头\u0026#39;)] 其他字段类型 选择器和复选框部件\nForms组件源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \u0026#34;\u0026#34;\u0026#34; 切入点： form_obj.is_valid() \u0026#34;\u0026#34;\u0026#34; def is_valid(self): \u0026#34;\u0026#34;\u0026#34;Return True if the form has no errors, or False otherwise.\u0026#34;\u0026#34;\u0026#34; return self.is_bound and not self.errors \u0026#34;\u0026#34;\u0026#34; 如果is_vaild要返回True的话 那么： - self.is_bound()要为True - self.errors()要为False \u0026#34;\u0026#34;\u0026#34; # 只要传值 那么self.is_bound就为True self.is_bound = data is not None or files is not None @property def errors(self): \u0026#34;\u0026#34;\u0026#34;Return an ErrorDict for the data provided for the form.\u0026#34;\u0026#34;\u0026#34; if self._errors is None: self.full_clean() return self._errors # forms组件所有的功能基本都出自于该方法 def full_clean(self): \u0026#34;\u0026#34;\u0026#34; Clean all of self.data and populate self._errors and self.cleaned_data. \u0026#34;\u0026#34;\u0026#34; self._errors = ErrorDict() # 创建类空字典 if not self.is_bound: # Stop further processing. return self.cleaned_data = {} # If the form is permitted to be empty, and none of the form data has # changed from the initial data, short circuit any validation. if self.empty_permitted and not self.has_changed(): return # 这三行 整个forms组件精髓所在 self._clean_fields() # 检验字段源码 + 局部钩子 self._clean_form() # 全局钩子 self._post_clean() # An internal hook 校验字段/局部钩子源码解读 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def _clean_fields(self): for name, field in self.fields.items(): # value_from_datadict() gets the data from the data dictionaries. # Each widget type knows how to retrieve its own data, because some # widgets split data over several HTML fields. # 获取字段对应的用户数据 if field.disabled: value = self.get_initial_for_field(field, name) else: value = field.widget.value_from_datadict(self.data, self.files, self.add_prefix(name)) try: if isinstance(field, FileField): initial = self.get_initial_for_field(field, name) value = field.clean(value, initial) else: value = field.clean(value) self.cleaned_data[name] = value # 将合法的字段添加到cleaned_data if hasattr(self, \u0026#39;clean_%s\u0026#39; % name): # 利用反射获取局部钩子函数 value = getattr(self, \u0026#39;clean_%s\u0026#39; % name)() # ()调用 局部钩子函数需要有返回值 self.cleaned_data[name] = value except ValidationError as e: self.add_error(name, e) # 添加提示报错信息 # 得出钩子函数第二种验证字段不通过的报错方式 # 局部钩子 def clean_username(self): # 获取到用户名 username = self.cleaned_data.get(\u0026#39;username\u0026#39;) if \u0026#39;666\u0026#39; in username: # 展示错误信息 # 报错方式1 # self.add_error(\u0026#39;username\u0026#39;, \u0026#39;不能包含666\u0026#39;) # 报错方式2 看源码得出 较为繁琐一般不用 raise ValidationError(\u0026#39;不能包含未允许的数字\u0026#39;) # 将钩子函数钩出去的数据(单个数据)再放回去 return username 全局钩子源码解读 1 2 3 4 5 6 7 8 def _clean_form(self): try: cleaned_data = self.clean() # 全局钩子需要一个返回值 self.cleaned_data except ValidationError as e: self.add_error(None, e) else: if cleaned_data is not None: self.cleaned_data = cleaned_data _post_clean 1 2 3 4 5 6 7 \u0026#34;\u0026#34;\u0026#34;内部预留钩子 An internal hook\u0026#34;\u0026#34;\u0026#34; def _post_clean(self): \u0026#34;\u0026#34;\u0026#34; An internal hook for performing additional cleaning after form cleaning is complete. Used for model validation in model forms. \u0026#34;\u0026#34;\u0026#34; pass Cookie和Session 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 \u0026#34;\u0026#34;\u0026#34; 发展史： 1. 网站都没有保存用户功能的需求 所有用户访问返回的结果都是一样的 e.g: 新闻 博客 文章 ... 2. 出现了一些需要保存用户信息的网站 e.g: 淘宝 支付宝 京东 ... (需要知道你是谁) 以登陆功能为例：如果不保存用户登陆状态 也就意味着用户每次访问网站都需要重复的输入用户名和密码(你觉得这样的网站 你还想用吗?) 当用户第一次登陆成功之后 将用户的 用户名密码 返回给用户浏览器 让用户浏览器保存在本地 之后访问网站的时候浏览器自动将保存在浏览器上的用户名和密码发送给服务端 服务端获取之后自动校验 早期这种方式具有非常大的安全隐患(能够直接看到) 优化： 当用户登陆成功之后 服务端产生一个随机字符串(在服务端保存数据 用K:V键值对的形式) 交由客户端浏览器保存 随机字符串1：用户1相关信息 随机字符串2：用户2相关信息 随机字符串3：用户3相关信息 ... 之后访问服务端的时候 都带着该随机字符串 服务端去数据库中比对是否有对应的随机字符串从而获取到对应的用户信息 但是如果你拿到了(截获)该随机字符串 那么你就可以冒充当前用户 真实还是有安全隐患的 **在WEB领域 没有绝对的安全 也没有绝对的不安全** 基本上防御措施都需要程序员自己写代码完善 并且只能完善 没法杜绝 \u0026#34;\u0026#34;\u0026#34; # cookie 概念：服务端设置保存在客户端浏览器上的键值对(只要符合前面定义的都可以叫cookie) - 服务端保存在客户端浏览器上的信息都可以称之为cookie - 它的表现形式一般都是K:V键值对(可以有多个) - 浏览器可以选择不保存(但是会导致网页无法工作 比如无法登录) # session 概念：存储在服务端上的键值对(一般情况都跟用户信息有关 用来标识当前用户) - 数据是保存在服务端的 - 并且它的表现形式一般也是K:V键值对(可以有多个) - 需要基于cookie才能工作(其实大部分的保存状态的实现都需要基于cookie来做) # token - session虽然是保存在服务端的 但是经不住数据量大 - 服务端不再保存数据 - 登陆成功之后 将一段信息用自己定制的加密方式(加密算法别人不知道)对内容进行加密处理 - 然后将加密结果拼接在这段信息后面 整体返回给用户浏览器保存 [[信息内容][加密内容]] - 浏览器下次访问的时候带着该信息 服务端自动切去前面一段信息再次使用自己的加密算法 跟浏览器尾部的密文进行比对 # jwt认证 三段信息 总结： 1. cookie就是保存在客户端浏览器上的信息 2. session就是保存在服务端上的信息 3. session是基于cookie工作的(其实大部分的保存用户状态的操作 都需要使用到cookie) Cookie操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026#34;\u0026#34;\u0026#34; 虽然cookie是服务端告诉客户端浏览器需要保存的内容 但是客户端浏览器可以选择拒绝保存 如果禁止掉 那么只要是需要记录用户状态的网站 登陆功能都无法使用 \u0026#34;\u0026#34;\u0026#34; # 视图函数的返回值 return HttpResponse() return render() return redirect() # 如果你想要操作cookie 你就不得不利用HttpResponse对象 obj1 = HttpResponse() 操作cookie return obj1 obj2 = render() 操作cookie return obj2 obj3 = redirect() 操作cookie return obj3 设置cookie 1 2 3 4 5 6 7 8 9 10 11 12 # obj in [obj1, obj2, obj3] obj.set_cookie(key, value) # 在设置cookie的时候 可以添加一个超时时间 obj.set_cookie(\u0026#39;username\u0026#39;, \u0026#39;minho123123\u0026#39;, max_age=5/expires=5) - max_age - expires 这两个参数都是设置超时时间的 并且都是以秒为单位 需要注意的是 针对IE浏览器 需要使用expires # 设置键值对的时候 可以加盐处理 obj.set_signed_cokkie(key, value, salt=\u0026#39;盐\u0026#39;) 获取cookie 1 2 3 4 5 6 # obj in [obj1, obj2, obj3] request.COOKIES request.COOKIES.get(key) # 获取加盐cookie request.get_signed_cookie(key, salt=\u0026#39;盐\u0026#39;) 删除cookie 1 2 3 4 5 6 # 如何主动删除cookie - 退出登录|注销 @login_auth def logout(request): obj = redirect(\u0026#39;/app03/login/\u0026#39;) obj.delete_cookie(\u0026#39;username\u0026#39;) # 删除cookie 实现退出登录注销功能 return obj cookie版登录验证 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from django.shortcuts import render, HttpResponse, redirect, reverse def login(request): if request.method == \u0026#39;POST\u0026#39;: username = request.POST.get(\u0026#39;username\u0026#39;) password = request.POST.get(\u0026#39;password\u0026#39;) if username == \u0026#39;minho\u0026#39; and password == \u0026#39;123\u0026#39;: # 保存用户登陆状态 obj = redirect(reverse(\u0026#39;app03_home\u0026#39;)) # 让浏览器记录cookie obj.set_cookie(\u0026#39;username\u0026#39;, \u0026#39;minho123123\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 浏览器不单单会帮你存 而且后面每次访问你的时候 还会带着它过来 \u0026#34;\u0026#34;\u0026#34; # 跳转到一个需要用户登陆之后再能看的界面 return obj return render(request, \u0026#39;login.html\u0026#39;) def home(request): # 获取cookie信息 判断你有没有 if request.COOKIES.get(\u0026#39;username\u0026#39;) == \u0026#39;minho123123\u0026#39;: return HttpResponse(\u0026#39;我是home页面 只有登陆的用户才能进来\u0026#39;) # 没有登陆应该跳转到登陆页面 return redirect(reverse(\u0026#39;app03_login\u0026#39;)) 登陆检验简单装饰器 1 2 3 4 5 6 7 8 9 10 \u0026#34;\u0026#34;\u0026#34; 问题1：如果需要验证登陆的视图有非常多 这样写很冗余 -\u0026gt; 装饰器 解决：校验用户是否登陆的简单装饰器 \u0026#34;\u0026#34;\u0026#34; def login_auth(wrapped): def wrapper(request, *args, **kwargs): if request.COOKIES.get(\u0026#39;username\u0026#39;): return wrapped(request, *args, **kwargs) return redirect(reverse(\u0026#39;app03_login\u0026#39;)) return wrapper 完整登陆代码示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 \u0026#34;\u0026#34;\u0026#34; 问题2： 有下面多个视图的情况下 我访问/index 会被重定向到/login 但是 我输入用户名密码登陆之后 自动跳转到/home 而不是我想访问的/index/ 用户如果在没有登陆的情况下 想访问一个需要登陆的页面 那么先跳转到登陆页面 当用户输入正确的用户名和密码之后 应该跳转到用户之前想要访问的页面去 而不是直接写死 解决：见下面稍微完整的登陆示例代码 \u0026#34;\u0026#34;\u0026#34; from functools import wraps from django.shortcuts import render, HttpResponse, redirect, reverse def login_auth(wrapped): @wraps(wrapped) def wrapper(request, *args, **kwargs): # print(request.path) # print(request.get_full_path()) # 能够获取到用户上一次想要访问的url target_url = request.get_full_path() if request.COOKIES.get(\u0026#39;username\u0026#39;): return wrapped(request, *args, **kwargs) # return redirect(\u0026#39;/login/?next={}\u0026#39;.format(target_url)) return redirect(reverse(\u0026#39;app03_login\u0026#39;) + \u0026#39;?next={}\u0026#39;.format(target_url)) return wrapper def login(request): if request.method == \u0026#39;POST\u0026#39;: username = request.POST.get(\u0026#39;username\u0026#39;) password = request.POST.get(\u0026#39;password\u0026#39;) if username == \u0026#39;minho\u0026#39; and password == \u0026#39;123\u0026#39;: # 获取用户上一次想要访问的url target_url = request.GET.get(\u0026#39;next\u0026#39;) # 可能为None - 用户直接访问/login的情况 if target_url: obj = redirect(target_url) else: # 保存用户登陆状态 obj = redirect(reverse(\u0026#39;app03_home\u0026#39;)) # 让浏览器记录cookie obj.set_cookie(\u0026#39;username\u0026#39;, \u0026#39;minho123123\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 浏览器不单单会帮你存 而且后面每次访问你的时候 还会带着它过来 \u0026#34;\u0026#34;\u0026#34; # 跳转到一个需要用户登陆之后再能看的界面 return obj return render(request, \u0026#39;login.html\u0026#39;) @login_auth def home(request): return HttpResponse(\u0026#39;我是home页面 只有登陆的用户才能进来\u0026#39;) @login_auth def index(request): return HttpResponse(\u0026#39;Index Page, Need Login\u0026#39;) @login_auth def users(request): return HttpResponse(\u0026#39;Users Page, Need Login\u0026#39;) Session操作 如何使用会话\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 \u0026#34;\u0026#34;\u0026#34; session数据是保存在服务端的(存到哪儿? 数据库 -\u0026gt; session表) 给客户端返回的是一个随机字符串 客户端cookie -\u0026gt; sessionid:随机字符串 1. 在默认情况下操作session的时候 需要一张表来存 django默认提供一张django_session表 django会默认创建很多张表 django_session就是其中一张(No such table:django_session) 2. django默认session的过期时间是14天 但是你也可以人为的修改它 3. django_session表中的数据是取决于浏览器的 同一个计算机上(IP地址) 同一个浏览器 只会有一条数据生效(当session过期的时候 可能会出现多条数据对应一个浏览器 但是这个数据没意义- 无效数据;但是该现象不会持续很久 内部会自动识别过期的数据清除 你也可以通过代码请除) 目的 -\u0026gt; 主要为了节省服务端资源 通过一个唯一的cookieID 服务端就知道来的用户是谁 然后服务端根据不同的cookieID 在服务端上保存一段时间的私密资料(如账号密码等) 这就是服务端session保存 4. session是保存在服务端的 但是session的保存位置可以有多种选择 4.1 MySQL 4.2 文件 4.3 redis/memcache...缓存 4.4 其他 ... 5. session还可以对保存的随机字符串做加盐处理 设置session - session可以设置多个 但是参考上面第3点 - session也可以设置过期时间 request.session[\u0026#39;key\u0026#39;] = value # 把request.session当作一个字典 获取session request.session.get(\u0026#39;key\u0026#39;) 清除session request.session.delete() # 只删服务端当前session request.session.flush() # 浏览器和服务端都清空(推荐使用) \u0026#34;\u0026#34;\u0026#34; 设置session 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # views.py def set_session(request): \u0026#34;\u0026#34;\u0026#34; 设置session内部发生了哪些事： 1. django内部会自动帮你生成一个随机字符串 2. django内部自动将随机字符串和对应的数据存储到django_session表中 这一步不是直接生效的 分为下面两步 2.1 先在内存中产生操作数据的缓存 2.2 在响应结果经过django中间件的时候 才真正操作数据库 3. 将产生的随机字符串返回给客户端浏览器保存(设置cookie) \u0026#34;\u0026#34;\u0026#34; request.session[\u0026#39;hobby\u0026#39;] = \u0026#39;girl\u0026#39; return HttpResponse(\u0026#39;Session Set\u0026#39;) # session设置过期时间 request.session.set_expire() 括号内可以放4种类型的参数 1. 整数 多少秒只会失效 2. 日期对象(datetime/timedelta) 到指定日期之后失效 3. 0 一旦当前浏览器关闭立刻失效 4. None 失效时间取决于django内部全局session默认的失效时间(14天) # 测试过期是否是生效 def set_session(request): request.session[\u0026#39;hobby\u0026#39;] = \u0026#39;girl\u0026#39; request.session[\u0026#39;hobby1\u0026#39;] = \u0026#39;girl1\u0026#39; request.session[\u0026#39;hobby2\u0026#39;] = \u0026#39;girl2\u0026#39; request.session.set_expiry(0) return HttpResponse(\u0026#39;Session Set\u0026#39;) def get_session(r): # print(request.session.get(\u0026#39;hobby\u0026#39;)) if r.session.get(\u0026#39;hobby\u0026#39;): print(r.session) # 封装为一个对象 \u0026lt;django.contrib.sessions.backends.db.SessionStore object at 0x...\u0026gt; print(r.session.get(\u0026#39;hobby1\u0026#39;)) print(r.session.get(\u0026#39;hobby2\u0026#39;)) return HttpResponse(\u0026#39;Session Get\u0026#39;) return HttpResponse(\u0026#39;No Session\u0026#39;) # 浏览器关闭后 重新打开则失效 django_session Table数据 session_key session_data expire_date 0mzz5pprookey7rjd4m3pl6onoa5jdtm NjRhZjljYzM1NDNkNzhkNmVkOWVkM2QzZGY2MGE1OWNhYzQwODBmNTp7ImhvYmJ5IjoiZ2lybCJ9 2021-03-10 01:59:31 客户端cookie Name Value sessionid 0mzz5pprookey7rjd4m3pl6onoa5jdtm 获取session 1 2 3 4 5 6 7 8 9 10 11 def get_session(request): \u0026#34;\u0026#34;\u0026#34; 获取session内部发生了那些事： 1. 自动从浏览器请求中获取sessionid对应的随机字符串 2. 拿着该随机字符串去django_session中查找对应的数据 3. 比对数据 3.1 如果比对上 则将对应得数据取出并以字典得形式封装到request.session中 3.2 如果比对不上 则request.session.get()返回的是None - dict.get()方法获取不到key 默认返回None \u0026#34;\u0026#34;\u0026#34; print(request.session.get(\u0026#39;hobby\u0026#39;)) return HttpResponse(\u0026#39;Session Get\u0026#39;) 清除session 1 2 3 4 def del_session(request): request.session.delete() # 只删除服务端的有效session request.session.flush() # 服务端和浏览器都删(推荐使用) return HttpResponse(\u0026#39;Session Delete\u0026#39;) django中session配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1. 数据库Session SESSION_ENGINE = \u0026#39;django.contrib.sessions.backends.db\u0026#39; # 引擎（默认） 2. 缓存Session SESSION_ENGINE = \u0026#39;django.contrib.sessions.backends.cache\u0026#39; # 引擎 SESSION_CACHE_ALIAS = \u0026#39;default\u0026#39; # 使用的缓存别名（默认内存缓存，也可以是memcache），此处别名依赖缓存的设置 3. 文件Session SESSION_ENGINE = \u0026#39;django.contrib.sessions.backends.file\u0026#39; # 引擎 SESSION_FILE_PATH = None # 缓存文件路径，如果为None，则使用tempfile模块获取一个临时地址tempfile.gettempdir() 4. 缓存+数据库 SESSION_ENGINE = \u0026#39;django.contrib.sessions.backends.cached_db\u0026#39; # 引擎 5. 加密Cookie Session SESSION_ENGINE = \u0026#39;django.contrib.sessions.backends.signed_cookies\u0026#39; # 引擎 其他公用设置项： SESSION_COOKIE_NAME ＝ \u0026#34;sessionid\u0026#34; # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串（默认） SESSION_COOKIE_PATH ＝ \u0026#34;/\u0026#34; # Session的cookie保存的路径（默认） SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名（默认） SESSION_COOKIE_SECURE = False # 是否Https传输cookie（默认） SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输（默认） SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周）（默认） SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期（默认） SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存（默认） session版登录验证 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 from functools import wraps def check_login(func): @wraps(func) def inner(request, *args, **kwargs): next_url = request.get_full_path() if request.session.get(\u0026#34;user\u0026#34;): return func(request, *args, **kwargs) else: return redirect(\u0026#34;/login/?next={}\u0026#34;.format(next_url)) return inner def login(request): if request.method == \u0026#34;POST\u0026#34;: user = request.POST.get(\u0026#34;user\u0026#34;) pwd = request.POST.get(\u0026#34;pwd\u0026#34;) if user == \u0026#34;alex\u0026#34; and pwd == \u0026#34;alex1234\u0026#34;: # 设置session request.session[\u0026#34;user\u0026#34;] = user # 获取跳到登陆页面之前的URL next_url = request.GET.get(\u0026#34;next\u0026#34;) # 如果有，就跳转回登陆之前的URL if next_url: return redirect(next_url) # 否则默认跳转到index页面 else: return redirect(\u0026#34;/index/\u0026#34;) return render(request, \u0026#34;login.html\u0026#34;) @check_login def logout(request): # 删除所有当前请求相关的session request.session.delete() return redirect(\u0026#34;/login/\u0026#34;) @check_login def index(request): current_user = request.session.get(\u0026#34;user\u0026#34;, None) return render(request, \u0026#34;index.html\u0026#34;, {\u0026#34;user\u0026#34;: current_user}) \u0026#34;\u0026#34;\u0026#34; 总结： django默认给我们提供了一张 django_session表 学了session之后 我们发现 我们通过 request.session.get(key) 可以拿到我们存储的数据 而且可以在任意视图直接使用 高阶用法： 有时候 如果多个视图函数都需要使用到一些数据的话 你也可以考虑将该数据存储到django_session表中 方便后续的使用 e.g: 登录验证码校验 \u0026#34;\u0026#34;\u0026#34; Django中间件 中间件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 django自带七个中间件 每个中间件都有各自对应的功能 并且django还支持程序员自定义中间件 你在用django开发项目的时候 只要是涉及到 全局 相关的功能 都可以使用中间件方便的完成 e.g: - 全局用户身份校验 - 全局用户权限校验 - 全局访问频率校验(反爬虫措施之一 -- 破解：IP代理池) - ...(其他涉及全局的功能) \u0026#34;\u0026#34;\u0026#34; django中间件是django的门户(请求来和走 两个方向都要经过) 1. 请求来的时候 需要先经过中间件才能到达真正的django后端 2. 响应走的时候 也需要经过中间件才能发送出去 \u0026#34;\u0026#34;\u0026#34; - 仔细理解django请求生命周期流程图 - 研究django中间件代码规律 自带七个中间件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # 列表里面其实不是字符串 是在导入模块(字符串方式导入模块) 模块路径的字符串形式 MIDDLEWARE = [ \u0026#39;django.middleware.security.SecurityMiddleware\u0026#39;, \u0026#39;django.contrib.sessions.middleware.SessionMiddleware\u0026#39;, \u0026#39;django.middleware.common.CommonMiddleware\u0026#39;, \u0026#39;django.middleware.csrf.CsrfViewMiddleware\u0026#39;, \u0026#39;django.contrib.auth.middleware.AuthenticationMiddleware\u0026#39;, \u0026#39;django.contrib.messages.middleware.MessageMiddleware\u0026#39;, \u0026#39;django.middleware.clickjacking.XFrameOptionsMiddleware\u0026#39;, ] # 看源码几个中间件的代码组织结构 \u0026#34;\u0026#34;\u0026#34; django支持程序员自定义中间件 并且暴露给程序员五个可以自定义的方法 1. 第一类 必须掌握 - process_request - process_response 2. 了解即可 - process_view - process_template_response - process_exception \u0026#34;\u0026#34;\u0026#34; class SessionMiddleware(MiddlewareMixin): def process_request(self, request): csrf_token = self._get_token(request) if csrf_token is not None: # Use same token next time. request.META[\u0026#39;CSRF_COOKIE\u0026#39;] = csrf_token def process_response(self, request, response): return response class CsrfViewMiddleware(MiddlewareMixin): def process_request(self, request): csrf_token = self._get_token(request) if csrf_token is not None: # Use same token next time. request.META[\u0026#39;CSRF_COOKIE\u0026#39;] = csrf_token def process_view(self, request, callback, callback_args, callback_kwargs): return self._accept(request) def process_response(self, request, response): return response class AuthenticationMiddleware(MiddlewareMixin): def process_request(self, request): request.user = SimpleLazyObject(lambda: get_user(request)) 自定义中间件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026#34;\u0026#34;\u0026#34; 固定步骤： 1. 在项目名或者应用名下创建以一个任意名称的文件夹 2. 在该文件夹内创建一个任意名称的py文件 3. 在该py文件内需要书写类(这个类必须继承MiddlewareMixin) 3.1 在这个类里面 就可以自定义这5个方法 3.2 这5个方法并不是全部都需要书写 用到几个写几个 4. 需要将类的路径以字符串的形式注册到配置文件才能生效 # 注册中间件 MIDDLEWARE = [ \u0026#39;django.middleware.security.SecurityMiddleware\u0026#39;, \u0026#39;django.contrib.sessions.middleware.SessionMiddleware\u0026#39;, \u0026#39;django.middleware.common.CommonMiddleware\u0026#39;, \u0026#39;django.middleware.csrf.CsrfViewMiddleware\u0026#39;, \u0026#39;django.contrib.auth.middleware.AuthenticationMiddleware\u0026#39;, \u0026#39;django.contrib.messages.middleware.MessageMiddleware\u0026#39;, \u0026#39;django.middleware.clickjacking.XFrameOptionsMiddleware\u0026#39;, \u0026#39;你自己写的中间件路径1\u0026#39;, \u0026#39;你自己写的中间件路径2\u0026#39;, \u0026#39;你自己写的中间件路径3\u0026#39;, ] \u0026#34;\u0026#34;\u0026#34; 中间件方法详解 1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; django支持程序员自定义中间件 并且暴露给程序员五个可以自定义的方法 1. 第一类 必须掌握 process_request(self, request) process_response(self, request, response) 2. 了解即可 process_view(self, view_name, *args, **kwargs) process_template_response(self, request, response) process_exception(self, request, exception) \u0026#34;\u0026#34;\u0026#34; process_request 使用频率最高 最好用的 重点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1. 请求来的时候 需要经过每一个中间件里面的process_request方法 结果的顺序是按照配置文件中注册的中间件顺序 从上往下 依次执行 2. 如果中间件里面没有定义该方法 那么直接跳过执行下一个中间件 3. 如果该方法返回了HttpResponse对象 那么请求将不再继续往后执行 而是直接原路返回(e.g:校验失败不允许访问 反爬...) 总结：process_request方法 就是用来做全局相关的所有限制功能 \u0026#34;\u0026#34;\u0026#34; 研究： 如果在第一个process_request方法 就已经返回了HttpResponse对象 那么响应走的时候 是经过所有的中间件里面的process_response还是有其他情况? 结果：其他情况 会直接走同级别(同一个中间件)的process_response 然后依次返回 Flask框架也有类似的中间件 但是它的规律与django不一样：Flask中间件只要返回数据了就必须经过所有中间件里面的类似于process_response方法 \u0026#34;\u0026#34;\u0026#34; process_response 重点\n1 2 3 4 5 6 7 8 9 10 1. 响应走的时候 需要经过每一个中间件的process_response方法 该方法有两个额外的参数 process_response(request, response) response: 默认就是后端视图函数返回给浏览器的内容 2. 该方法必须返回一个HttpResponse对象 2.1 默认返回的就是形参response 2.2 你也可以返回自己的内容 3. 顺序是按照配置文件中注册了的中间件 从下往上 依次经过 如果你没有定义的话 直接跳过执行下一个 process_view 1 2 3 4 5 6 def process_view(self, request, view_name, *args, **kwargs): print(view_name, args, kwargs) print(\u0026#39;自定义中间件里面的process_view\u0026#39;) 路由匹配成功之后 执行视图函数之前 会自动执行中间件里面的process_view方法 顺序是按照配置文件中注册的中间件顺序 从上往下 依次执行 process_template_response 1 2 3 4 5 6 7 8 9 10 11 def index(request): print(\u0026#39;我是视图函数index\u0026#39;) obj = HttpResponse(\u0026#39;index\u0026#39;) def render(): print(\u0026#39;内部的render\u0026#39;) return HttpResponse(\u0026#39;ojbk\u0026#39;) obj.render = render return obj 返回的HttpResponse对象有render属性的时候才会触发 顺序是按照配置文件中注册了的中间件 从下往上 依次经过 process_exception 1 2 当视图函数中出现异常的情况下触发 顺序是按照配置文件中注册了的中间件 从下往上 依次经过 编程思想 1 # 基于django中间件的一个重要的编程思想 importlib简单介绍 1 2 3 4 5 6 7 8 9 10 11 12 # 有以下目录结构 Projects/ - myfile/ - b.py - a.py # b.py name = \u0026#39;bbbbbb\u0026#39; \u0026#34;\u0026#34;\u0026#34; 问题：如何在a.py中使用b.py里面的变量? \u0026#34;\u0026#34;\u0026#34; 模块导入 1 2 3 4 # 方法1 from myfile import b print(b.name) importlib使用 1 2 3 4 5 6 7 8 # 方法2 import importlib res = \u0026#39;myfile.b\u0026#39; ret = importlib.import_module(res) # 内部处理：from myfile import b print(ret) # 该方法最小只能到模块(py文件名) 不能到py文件下面的变量(类 函数 变量...) importlib进阶使用 配置文件注册功能 importlib模块 字符串切割rsplit maxsplit参数 反射 getattr()\u0026hellip; 面向对象鸭子类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 # notify.py 里面封装的三个通知函数 def wechat(content): print(\u0026#39;微信通知：%s\u0026#39; % content) def qq(content): print(\u0026#39;qq通知：%s\u0026#39; % content) def email(content): print(\u0026#39;邮箱通知：%s\u0026#39; % content) \u0026#34;\u0026#34;\u0026#34; 我在其他地方要使用这三个通知函数 可以全部导入 然后进行使用 问题：如果我很多地方都使用了这三个通知函数 现在我需要把其中一种方式取消掉 怎么办? 1. 找到所有使用的地方 注释掉对应通知函数 - 可以解决 使用地方多的话 比较麻烦 2. importlib高阶使用 \u0026#34;\u0026#34;\u0026#34; from notify import * def send_all(content): wechat(content) # qq(content) email(content) if __name__ == \u0026#39;__main__\u0026#39;: send_all(\u0026#39;啥时候放长假\u0026#39;) =============================== # 解决上述问题 把notify通知的方法封装为类到一个包里面的三个模块 notify/ - __init__.py # 包文件 - email.py - qq.py - wechat.py # email.py class Email: def __init__(self): pass # 发送邮件前需要做的前期准备工作 def send(self, content): # 其他通知封装类似 都提供一个send方法 print(\u0026#39;邮箱通知：%s\u0026#39; % content) # 然后提供一个配置文件settings.py - django启发 NOTIFY_LIST = [ \u0026#39;notify.email.Email\u0026#39;, # \u0026#39;notify.qq.QQ\u0026#39;, \u0026#39;notify.wechat.Wechat\u0026#39;, ] # 重点：在notify包的__init__.py文件中做一下操作 import settings # 导入配置文件 import importlib # 导入importlib def send_all(content): for path_str in settings.NOTIFY_LIST: module_path, class_name = path_str.rsplit(\u0026#39;.\u0026#39;, maxsplit=1) # 从右往左切 只切一次 # 拿到模块名和类名 # module_path = \u0026#39;notify.email\u0026#39; class_name = \u0026#39;Email\u0026#39; # 1. 利用字符串导入模块 module = importlib.import_module(module_path) # from notify import email # 2. 利用反射获取类名 cls = getattr(module, class_name) # 拿到类名 Email QQ Wechat # 3. 生成类的对象(实例化) obj = cls() # 4. 利用鸭子类型直接拿调用send方法 obj.send(content) # 最后使用 start.py \u0026#34;\u0026#34;\u0026#34; 这个时候 可扩展性非常高 如果我们不想用哪个方法 直接去配置文件注释掉对应的配置即可 需要加通知方法 也很方便 \u0026#34;\u0026#34;\u0026#34; import notify notify.send_all(\u0026#39;通知\u0026#39;) csrf跨站请求伪造 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026#34;\u0026#34;\u0026#34; 钓鱼网站(e.g: 大学英语4 6级 登录缴费钓鱼网站) 我搭建一个跟正规网站一摸一样的界面(中国银行) 用户不小心进入到了我们的网站 用户给某个人转钱 打钱的操作确确实实提交给了中国银行的系统 用户的钱也确实减少了 唯一的不同就是目标账户不是用户想要转钱的账户 变成了一个莫名其妙的账户 内部本质： 我们在钓鱼网站的页面 针对目标账号 只给用户提供一个没有name属性的普通input框 然后我们在内部隐藏一个已经写好name和value的input框 提交的时候 action url写正常网站的url ========= 如何规避上述问题 -- csrf跨站请求伪造 网站在给用户返回一个具有提交数据功能页面的时候 会给这个页面加一个唯一标识(不同的页面不一样 永远不重复) 当这个页面朝后端发送post请求的时候 我的后端会先校验这个唯一标识 如果这个唯一标识不对 直接拒绝(403 forbidden) 如果成功则正常执行(csrf中间件帮我们搞定) \u0026#34;\u0026#34;\u0026#34; Form表单如何校验 1 2 3 4 5 6 7 8 \u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; {% csrf_token %} \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;csrfmiddlewaretoken\u0026#34; value=\u0026#34;唯一的随机字符串\u0026#34;\u0026gt; ... \u0026lt;/form\u0026gt; \u0026lt;!-- hidden属性 隐藏 --\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;csrfmiddlewaretoken\u0026#34; value=\u0026#34;JCVNo1kxO4Z1WSUSmFkLBTFsO6XIYAl3Gr9VUfSQoWo6gBJn4jJxhn8V6YCWJxdQ\u0026#34;\u0026gt; Ajax如何校验 方式一 1 2 3 4 5 6 7 8 9 10 11 12 13 $.ajax({ url: \u0026#34;/cookie_ajax/\u0026#34;, type: \u0026#34;POST\u0026#34;, data: { \u0026#34;username\u0026#34;: \u0026#34;Tonny\u0026#34;, \u0026#34;password\u0026#34;: 123456, \u0026#34;csrfmiddlewaretoken\u0026#34;: $(\u0026#34;[name = \u0026#39;csrfmiddlewaretoken\u0026#39;]\u0026#34;).val() // 使用JQuery取出csrfmiddlewaretoken的值 拼接到data中 // \u0026#34;csrfmiddlewaretoken\u0026#34;: \u0026#39;{{ csrf_token }}\u0026#39; // 或者利用模板语法提供的快捷书写 }, success: function (data) { console.log(data); } }) 方式二 1 2 3 4 5 6 7 8 9 $.ajax({ url: \u0026#34;/cookie_ajax/\u0026#34;, type: \u0026#34;POST\u0026#34;, headers: {\u0026#34;X-CSRFToken\u0026#34;: $.cookie(\u0026#39;csrftoken\u0026#39;)}, // 从Cookie取csrf_token 并设置ajax请求头 data: {\u0026#34;username\u0026#34;: \u0026#34;Q1mi\u0026#34;, \u0026#34;password\u0026#34;: 123456}, success: function (data) { console.log(data); } }) 方式三(通用) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 将这段代码配置到你的Django项目的静态文件中 直接导入该文件即可自动帮我们解决ajax提交post数据时校验csrf_token的问题(依赖jQuery) function getCookie(name) { var cookieValue = null; if (document.cookie \u0026amp;\u0026amp; document.cookie !== \u0026#39;\u0026#39;) { var cookies = document.cookie.split(\u0026#39;;\u0026#39;); for (var i = 0; i \u0026lt; cookies.length; i++) { var cookie = jQuery.trim(cookies[i]); // Does this cookie string begin with the name we want? if (cookie.substring(0, name.length + 1) === (name + \u0026#39;=\u0026#39;)) { cookieValue = decodeURIComponent(cookie.substring(name.length + 1)); break; } } } return cookieValue; } var csrftoken = getCookie(\u0026#39;csrftoken\u0026#39;); function csrfSafeMethod(method) { // these HTTP methods do not require CSRF protection return (/^(GET|HEAD|OPTIONS|TRACE)$/.test(method)); } $.ajaxSetup({ beforeSend: function (xhr, settings) { if (!csrfSafeMethod(settings.type) \u0026amp;\u0026amp; !this.crossDomain) { xhr.setRequestHeader(\u0026#34;X-CSRFToken\u0026#34;, csrftoken); } } }); django跨站请求伪造保护官方文档\ncsrf相关装饰器 装饰器方法\n装饰类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u0026#34;\u0026#34;\u0026#34; 1. 网站整体都不校验csrf 就单单几个视图函数需要校验 2. 网站整体都校验csrf 就单单几个视图函数不需要校验 csrf_exempt - 忽视校验 csrf_protect - 需要校验 \u0026#34;\u0026#34;\u0026#34; # 解决:Django提供的装饰器 from django.views.decorators.csrf import csrf_exempt, csrf_protect # FBV直接加对应装饰器即可 # @csrf_exempt @csrf_protect def index(request): pass # CBV csrf_protect - 全局忽视 局部需要校验 -\u0026gt; 使用CBV装饰器的三种方法都可以 csrf_exempt - 全局校验 局部忽视校验 -\u0026gt; 只可以加给dispath方法 才有效 @method_decorator(csrf_exempt, name=\u0026#39;dispath\u0026#39;) class MyIndex(View): # @method_decorator(csrf_exempt) def dispath(self, request, *args, **kwargs): return super().dispath(request, *args, **kwargs) def post(self, request): return HttpResponse(\u0026#39;POST\u0026#39;) Auth模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 只要是跟用户相关的登录、注册、检验、修改密码、注销、验证用户是否登录 都能用该模块实现 \u0026#34;\u0026#34;\u0026#34; 其实我们在创建好一个django项目之后 直接执行数据库迁移命令 会自动生成很多表 django_session auth_user # 用户表 django在启动之后 就可以直接访问admin路由 需要输入用户名和密码 数据参考的就是auh_user表 并且还必须是管理员才能进入 创建超级用户(管理员) eatesuperuser 依赖于auth_user表完成用户相关的所有功能 使用auth模块 要用就用全套 封装的很好 \u0026#34;\u0026#34;\u0026#34; 常用方法总结 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 1. 比对用户名和密码是否正确 # 括号内必须同时传入用户名和密码 user_obj = auth.authenticate(request, username=username, password=password) print(user_obj) # 用户对象 数据不符合返回None print(user_obj.username) # minho print(user_obj.password) # 密文 2. 保存用户状态 auth.login(request,user_obj) # 类似于reqeust.session[key] = user_obj # 只要执行了该方法 你就可以在任何地方通过request.user就能获取到当前登录的用户对象 # 它自动去django_session里面查找对应的用户对象 给你封装到request.user中 3. 判断当前用户是否登录 request.user.is_authenticated() 4. 获取当前登录用户 # 获取用户对象 未登录：AnonymousUser request.user 5. 校验用户是否登录 - 装饰器 from django.contrib.auth.decorators import login_required # 两种使用方式 # 局部配置 @login_required(login_url=\u0026#39;/login/\u0026#39;) # 全局配置 LOGIN_URL = \u0026#39;/login/\u0026#39; # settings.py 6. 比对原密码 request.user.check_password(old_password) # 自动加密对比密码 7. 修改密码 request.user.set_password(new_password) # 这步不会影响数据库 仅仅是在修改对象的属性 request.user.save() # 真正的操作数据库 8. 注销 auth.logout(request) # request.session表找到登录的对象 类似：request.session.flush 9. 注册 User.objects.create(username=username, password=password) # 写入数据 不能使用create 密码没有加密处理 后面使用密码比对 request.user.check_password 会出错 # 创建普通用户 User.objects.create_user(username=username, password=password) # 创建超级用户(了解): 使用代码创建查超级用户 邮箱必填 命令行创建可以不填 User.objects.create_superuser(username=username, password=password, email=\u0026#39;1234567@qq.com\u0026#39;) 完整代码示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 from django.shortcuts import render, HttpResponse, redirect from django.contrib import auth from django.contrib.auth.decorators import login_required from django.contrib.auth.models import User from hmac import compare_digest \u0026#34;\u0026#34;\u0026#34; 使用auth模块 要用就用全套 否则会出一些奇怪的错误 \u0026#34;\u0026#34;\u0026#34; def login(request): if request.method == \u0026#39;POST\u0026#39;: username = request.POST.get(\u0026#39;username\u0026#39;) password = request.POST.get(\u0026#39;password\u0026#39;) # 去用户表中校验数据 # 1. 表如何获取 # 2. 密码如何比对 user_obj = auth.authenticate(request, username=username, password=password) print(user_obj) # 用户对象 数据不符合返回None # print(user_obj.username) # print(user_obj.password) if user_obj: # 保存用户状态 auth.login(request,user_obj) # 类似于reqeust.session[key] = user_obj # 只要执行了该方法 你就可以在任何地方通过request.user就能获取到当前登录的用户对象 # 它自动去django_session里面查找对应的用户对象 给你封装到request.user中 \u0026#34;\u0026#34;\u0026#34; authenticate 1. 自动查找auth_user标签 2. 自动给密码加密再比对 该方法注意事项：括号内必须同时传入用户名和密码 不能只传用户名(一步直接筛出用户对象 否则还需要通过用户名再去查找密码 再比对) \u0026#34;\u0026#34;\u0026#34; return render(request, \u0026#39;login.html\u0026#39;) # @login_required(login_url=\u0026#39;/app03/login/\u0026#39;) # 局部配置: 用户没有登录跳转到login_user后面指定的网址 @login_required def home(request): \u0026#34;\u0026#34;\u0026#34;用户登录之后才能看home\u0026#34;\u0026#34;\u0026#34; # 获取用户对象 未登录：AnonymousUser print(request.user) # 判断用户是否登录 print(request.user.is_authenticated()) return HttpResponse(\u0026#39;OK\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 如果局部和全局都有 局部优先 局部和全局哪个好? 全局的好处在于 无需重复写代码 但是跳转的页面却很单一 局部的好处在于 不同的视图函数在用户没有登录的情况下可以跳转到不同的页面 \u0026#34;\u0026#34;\u0026#34; # @login_required(login_url=\u0026#39;/app03/login/\u0026#39;) @login_required def index(request): return HttpResponse(\u0026#39;index\u0026#39;) @login_required def set_password(request): if request.method == \u0026#39;POST\u0026#39;: old_password = request.POST.get(\u0026#39;old_password\u0026#39;) new_password = request.POST.get(\u0026#39;new_password\u0026#39;) confirm_password = request.POST.get(\u0026#39;confirm_password\u0026#39;) # 先检验2次密码是否一致 if new_password == confirm_password: # 校验老密码是否对不对 is_right = request.user.check_password(old_password) # 自动加密对比密码 if is_right: # 修改密码 request.user.set_password(new_password) # 直到这步不会影响数据库 仅仅是在修改对象的属性 request.user.save() # 真正的操作数据库 return redirect(\u0026#39;/app03/login/\u0026#39;) return render(request, \u0026#39;set_password.html\u0026#39;, locals()) @login_required def logout(request): auth.logout(request) # request.session表找到登录的对象 类似：request.session.flush return redirect(\u0026#39;/app03/login/\u0026#39;) def register(request): if request.method == \u0026#39;POST\u0026#39;: username = request.POST.get(\u0026#39;username\u0026#39;) password = request.POST.get(\u0026#39;password\u0026#39;) confirm_password = request.POST.get(\u0026#39;confirm_password\u0026#39;) # 操作auth_user表 写入数据 if compare_digest(password, confirm_password): # User.objects.create(username=username, password=password) # 写入数据 不能使用create 密码没有加密处理 # 创建普通用户 User.objects.create_user(username=username, password=password) # 创建超级用户(了解): 使用代码创建查超级用户 邮箱必填 命令行创建可以不填 # User.objects.create_superuser(username=username, password=password, email=\u0026#39;1234567@qq.com\u0026#39;) return render(request, \u0026#39;register.html\u0026#39;) 如何扩展auth_user表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 from django.db import models from django.contrib.auth.models import User, AbstractUser # 扩展auth_user表的两种方式 # 第一种：一对一关系 不推荐 class UserDetail(models.Model): phone = models.BigIntegerField() user = models.OneToOneField(to=\u0026#39;User\u0026#39;) # 第二种：利用面向对象的继承 class UserInfo(AbstractUser): \u0026#34;\u0026#34;\u0026#34; 如果继承了AbstractUser 那么在执行数据库迁移命令的时候 auth_user表就不会再创建出来了 而UserInfo表中会出现 auth_user所有的字段外加自己扩展的字段 这么做的好处：在于你能够直接点击你自己的表更加快速的完成操作及扩展 前提： 1.在继承之前没有执行过数据库迁移命令 auth_user没有被创建出来 - 在数据库设计阶段就要明确需不需要扩展该字段 如果当前库已经创建了 那么你就重新换一个库 2.继承的类里面 不要覆盖AbstractUser里面的字段名 表里面有的字段不能动 只能额外扩展字段 3.需要在配置文件中告诉django 你要用UserInfo替换auth_user *** AUTH_USER_MODEL = \u0026#39;app03.UserInfo\u0026#39; # 应用名.表名 不要加models \u0026#34;\u0026#34;\u0026#34; phone = models.BigIntegerField() \u0026#34;\u0026#34;\u0026#34; 你如果自己写表替代了auth_user 那么 auth模块的功能还是照常使用 参考 的表也由原来的auth_user变成了UserInfo \u0026#34;\u0026#34;\u0026#34; Django版本区别 1 2 1.x 2.x 3.x区别 2.x 3.x 差不多 路由层 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026#34;\u0026#34;\u0026#34; 1. django 1.x 路由层使用的是url方法 django 2.x 3.x 路由层使用的是path方法 - url() 第一个参数支持正则 - path() 第一个参数是不支持正则的 写什么就匹配什么 如果你不习惯使用path 也提供了另一个方法 re_path from django.urls import re_path from django.conf.urls import url # 可以继续使用url 不推荐 2.x 3.x 里面的re_path() 等价于1.x里面的url 2. 虽然path不支持正则 但是它的内部支持5种转换器 \u0026#34;\u0026#34;\u0026#34; path转换器 博客参考\n示例 1 2 # 将第二个路由里面的内容先转成整型 然后以关键字的形式传递给后面的视图函数 path(\u0026#39;index/\u0026lt;int:id\u0026gt;/\u0026#39;, views.index) 5种转换器 1 2 3 4 5 6 # 5种转换器 str 匹配除了路径分隔符（/）之外的非空字符串，这是默认的形式 int 匹配正整数，包含0 slug 匹配字母、数字以及横杠、下划线组成的字符串 uuid 匹配格式化的uuid，如 075194d3-6885-417e-a8a8-6c931e272f00 path 匹配任何非空字符串 包含了路径分隔符（/）（不能用？） 自定义转换器 1 2 3 4 5 6 7 8 9 10 # 除了有默认的5个转换器之外 还支持自定义转换器 class MonthConverter: regex=\u0026#39;\\d{2}\u0026#39; # 属性名必须为regex def to_python(self, value): return int(value) def to_url(self, value): # 匹配的regex是两个数字，返回的结果也必须是两个数字 return value 自动转换器使用 1 2 3 4 5 6 7 8 9 10 11 from django.urls import path,register_converter from app01.path_converts import MonthConverter # 注册 register_converter(MonthConverter,\u0026#39;mon\u0026#39;) # 使用 from app01 import views urlpatterns = [ path(\u0026#39;articles/\u0026lt;int:year\u0026gt;/\u0026lt;mon:month\u0026gt;/\u0026lt;slug:other\u0026gt;/\u0026#39;, views.article_detail, name=\u0026#39;aaa\u0026#39;), ] 模型层 1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; 模型层里面1.x外键默认都是级联更新删除的 但是到了2.x和3.x中 需要你自己手动配置on_delete参数 \u0026#34;\u0026#34;\u0026#34; # 1.x publish = models.ForeignKey(to=\u0026#39;Publish\u0026#39;) # 2.x 3.x # 具体参数参考官网文档 publish = models.ForeignKey(to=\u0026#39;Publish\u0026#39;, on_delete=\u0026#39;xxx\u0026#39;) on_delete参数补充\nForeignKey.on_delete\n1 2 3 4 5 6 7 on_delete=models.CASCADE, # 删除关联数据,与之关联也删除 on_delete=models.DO_NOTHING, # 删除关联数据,什么也不做 on_delete=models.PROTECT, # 删除关联数据,引发错误ProtectedError on_delete=models.SET_NULL, # 删除关联数据,与之关联的值设置为null（前提该字段需要设置为可空,一对一同理） on_delete=models.SET_DEFAULT, # 删除关联数据,与之关联的值设置为默认值（前提FK字段需要设置默认值,一对一同理） on_delete=models.SET(), # 删除之后执行一个函数 on_delete=RESTRICT, # New in Django 3.1. ","date":"2020-02-10T22:13:06+08:00","permalink":"https://ilolicon.github.io/p/django/","title":"Django"}]